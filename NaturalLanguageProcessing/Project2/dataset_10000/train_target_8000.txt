1929 or 1989?
PARIS – As the economic crisis deepens and widens, the world has been searching for historical analogies to help us understand what has been happening.
At the start of the crisis, many people likened it to 1982 or 1973, which was reassuring, because both dates refer to classical cyclical downturns.
Today, the mood is much grimmer, with references to 1929 and 1931 beginning to abound, even if some governments continue to behave as if the crisis was more classical than exceptional.
The tendency is either excessive restraint (Europe) or a diffusion of the effort (the United States).
Europe is being cautious in the name of avoiding debt and defending the euro, whereas the US has moved on many fronts in order not to waste an ideal opportunity to implement badly needed structural reforms.
For geo-strategists, however, the year that naturally comes to mind, in both politics and economics, is 1989.
Of course, the fall of the house of Lehman Brothers has nothing to do with the fall of the Berlin Wall.
Indeed, on the surface it seems to be its perfect antithesis: the collapse of a wall symbolizing oppression and artificial divisions versus the collapse of a seemingly indestructible and reassuring institution of financial capitalism.
Yet 2008-2009, like 1989, may very well correspond to an epochal change, whose unfolding consequences will be felt for decades.
The end of the East-West ideological divide and the end of absolute faith in markets are historical turning points.
And what happens in 2009 may jeopardize some of the positive results of 1989, including the peaceful reunification of Europe and the triumph of democratic principles over nationalist, if not xenophobic, tendencies.
In 1989, liberal democracy triumphed over the socialist ideology incarnated and promoted by the Soviet Bloc.
For many of his supporters, it was President Ronald Reagan who, with his deliberate escalation of the arms race, pushed the Soviet economy to the brink, thereby fully demonstrating the superiority of liberal societies and free markets.
Of course, there are obvious differences between 1989 and now.
First, and perhaps above all, the revolutions of 1989 and the subsequent collapse of the Soviet Union put an end to global bipolarity.
By contrast, 2009 is likely to pave the way to a new form of bipolarity, but with China substituting for the Soviet Union.
Second, whereas democracy and market capitalism appeared as clear – if more fragile than expected – winners in 1989, it is difficult in 2009, with the spread of the global crisis, to distinguish winners from losers.
Everyone seems to be a loser, even if some are more affected than others.
Yet, history is unfair, and the US, despite its greater responsibility for today’s global crisis, may emerge in better shape than most countries from the morass.
In better shape, but not alone.
As a visiting professor at Harvard and MIT, I am getting a good preview of what the world could look like when the crisis finally passes.
One senses something like the making of an American-Asian dominated universe.
From the incredible media lab at MIT to the mathematics and economics departments at Harvard, Asians – Chinese and Indians, in particular – are everywhere, like the Romans in Athens in the first century BC: full of admiration for those from whom they were learning so much, and whom they would overcome in the coming decades.
But before this new order appears, the world may be faced with spreading disorder, if not outright chaos.
What, for example, will happen to a country as central and vulnerable as Egypt when hundred of thousands of Egyptians working in the Gulf are forced to return to their homeland as a result of the crisis in the oil-producing countries?
When the rich get less rich, the poor get poorer.
And what about the foreign workers who have reached for the “European dream” and are now faced with potential explosions of xenophobia in Europe’s supposedly open countries?
The consequences of 1989 ended up being less enduring than many observers, including me, would have assumed.
We can only hope that, in the end, the consequences of 2009 similarly prove to be far less dramatic than we now – intuitively and in our historical reflexes – feel them to be.
What Failed in 2008?
BERKELEY – To solve a problem, it is not enough to know what to do.
You actually have to implement the solution – and be willing to change course if it turns out that you did not know quite as much as you thought.
That is the message of two recent books that, together, tell you everything you need to know about the 2008 financial crisis: what caused it, what can be done to prevent it from recurring, and why those things have yet to be done.
The first book is The Shifts and the Shocks, by the conservative British journalist Martin Wolf, who begins by cataloguing the major shifts that set the stage for the economic disaster that continues to shape the world today.
His starting point is the huge rise in wealth among the world’s richest 0.1% and 0.01% and the consequent pressure for people, governments, and companies to take on increasingly unsustainable levels of debt.
Meanwhile, policymakers were lulled into complacency by the widespread acceptance of economic theories such as the “efficient-market hypothesis,” which assumes that investors act rationally and use all available information when making their decisions.
As a result, markets were deregulated, making it easier to trade assets that were perceived to be safe, but were in fact not.
As a result, systemic risk proliferated beyond central bankers’ wildest imagination.
Untested – and ultimately incorrect – assumptions created a policymaking environment defined by what can only be called hubris.
Officials underestimated tail risks.
They set inflation targets at around 2% – leaving little room for maneuver when the water got choppy.
And, most audaciously of all, the European Union introduced the euro as a common currency.
Indeed, wrongheaded policymaking continued long after the crisis began.
Politicians responded to worsening economic conditions by hewing as closely as possible to failed prescriptions, making sure to do no more than absolutely necessary to address the biggest economic disaster since the Great Depression.
Wolf’s prescription for countering the crisis is simple, smart, and unassailable.
In the short term, he suggests that countries with reserve currencies spend more (especially to finance public-sector investments) and issue more debt.
Their central banks, he argues, should raise inflation targets to 3% or even 4% per year.
Over the medium term, according to Wolf, countries need to put in place regulatory measures that lower debt levels and discourage overleveraging.
The eurozone, too, must resolve its internal contradictions, either by disbanding or by introducing “a minimum set of institutions and policies” that allow the monetary union to function properly.
Wolf’s long-term solutions include tackling inequality, “more global regulation,” a greater degree of “freedom for individual countries to craft their own responses,” and economic analysis that is less in thrall to the free-market ideologues that led us into the crisis in the first place.
And yet, as recommendable as Wolf’s proposals may be, little has been done to implement them.
The reasons why are found in the second book: Hall of Mirrors, by&nbsp;my friend, teacher, and patron, Barry Eichengreen.
Eichengreen traces our tepid response to the crisis to the triumph of monetarist economists, the disciples of Milton Friedman, over their Keynesian and Minskyite peers – at least when it comes to interpretations of the causes and consequences of the Great Depression.
When the 2008 financial crisis erupted, policymakers tried to apply Friedman’s proposed solutions to the Great Depression.
Unfortunately, this turned out to be the wrong thing to do, as the monetarist interpretation of the Great Depression was, to put it bluntly, wrong in significant respects and radically incomplete.
The resulting policies were enough to prevent the post-2008 recession from developing into a full-blown depression; but that partial success turned out to be a Pyrrhic victory, for it allowed politicians to declare that the crisis had been overcome, and that it was time to embrace austerity and focus on structural reform.
The result is today’s stagnant economy, marked by anemic growth that threatens to become the new normal.
The United States and Europe are on track to have thrown away 10% of their potential wealth, while the failure to strengthen financial-sector regulation has left the world economy exposed to the risk of another major crisis.
Wolf and Eichengreen would agree that the main shortcomings that led to the 2008 financial crisis – and that continue to underpin our inadequate response to it – are intellectual.
Indeed, the only true lesson of the crisis so far seems to be that its lessons will never truly be learned.
A Comeback Strategy for Europe
STOCKHOLM/MADRID – When Pope Francis addressed the European Parliament last November, he compared the European Union to a grandmother – pleasant and rich with experience, but lacking the vitality and energy of the past.
It is high time, Francis argued, that EU leaders shed their dozy image, recognize the strategic challenges that Europe faces, and forge a clear policy for tackling them.
Admittedly, the pope’s characterization was alarmingly accurate in some respects.
But, despite its seeming lassitude, Europe retains significant strengths.
It is a hub of high-level thought and innovation; it is home to some of the world’s most competitive regions and industries; and, perhaps most impressive, it has built a community and market encompassing a half-billion people.
But the world is changing: the Asia-Pacific region is increasingly influencing global developments, economic and otherwise.
The Trans-Pacific Partnership – by which the United States and 11 other countries would create a mega-regional free-trade zone – would most likely accelerate this shift (all the more so if China eventually joins).
Though the TPP faces no shortage of hurdles to clear before an agreement is finalized, its potential to augment Asia’s economic power cannot be underestimated.
Europe must work to secure its position in the new world order – beginning by enhancing its own trade and investment ties with the US.
The problem is that, as the TPP negotiations progress, talks on the EU-US Transatlantic Trade and Investment Partnership (TTIP) have become so deeply mired in domestic controversies that the entire project may well be scuttled.
Business leaders on both sides of the Atlantic are convinced that a successful TTIP agreement would bring substantial economic benefits – a perception that many studies reinforce.
Yet trivial issues – for example, the use of chlorinated chicken and settlements of investor disputes – continue to dominate the debate.
The TTIP’s goal is to unleash the power of the transatlantic economy, which remains by far the world’s largest and wealthiest market, accounting for three-quarters of global financial activity and more than half of world trade.
(If the TTIP was opened to other economies – such as Turkey, Mexico, and Canada – the benefits would be even greater.)
Even more compelling than the benefits of achieving an agreement, though, are the potentially catastrophic consequences of failure.
For starters, a breakdown of TTIP talks would give considerable ammunition to those in the United Kingdom who advocate withdrawal from the EU; conversely, if the TTIP were implemented, the UK would be unwise – and thus unlikely – to leave.
Moreover, the perception that the EU’s internal squabbles had led it to squander a strategic opportunity would probably drive the US to accelerate its disengagement from the continent.
And Russian President Vladimir Putin would invariably regard the EU’s failure as a major opportunity to exert more influence over parts of Europe.
All of this contributes to a starkly fundamental strategic risk: If the TTIP stalls or collapses, while the TPP moves forward and succeeds, the global balance will tip strongly in Asia’s favor – and Europe will have few options, if any, for regaining its economic and geopolitical influence.
When the TTIP was first proposed, Europe seemed to recognize its value.
Indeed, it was the EU that pushed the US, which initially doubted Europe’s commitment, to launch the negotiation process in June 2013.
The ambition was to complete the negotiations on “one tank of gas.”
No one wanted to endure protracted talks – or the associated political pain.
But EU leaders essentially abandoned the project, seemingly confirming American fears.
Trade negotiators struggled to make headway, while anti-globalization groups seized control of the public discourse, presenting the TTIP as a threat to everything from Europe’s democracy to its health.
This is dangerously inaccurate talk, and EU leaders must prevent it from gaining any more traction by making the strategic case for the agreement.
And they must revive their commitment to conclude the talks successfully in 2015.
This is not to say that resolving the remaining issues in the TTIP negotiations will be simple.
But establishing a trade agreement, especially one that entails so many regulatory issues, is always difficult, as it must account for the complexity and changeability of modern economies.
The fact is that the challenges inherent in completing the TTIP are no more intractable than those that EU leaders have faced in the last few years of crisis.
When the TTIP negotiations resume next month, EU leaders must push for genuine progress, with the goal of completing a deal by the end of the year.
The good news is that the recent midterm elections in the US might have improved their chances.
President Barack Obama now might get so-called fast-track negotiating authority from Congress.
If he does, Congress would simply approve or reject any negotiated agreement, rather than picking it apart.
The US presidential election season is starting, and other issues in the new year could easily take over the EU agenda.
That is why Europe’s leaders have no time to waste.
They must seize economic opportunity – and avert strategic disaster.
The Year That Ended an Epoch?
MADRID – As 2016 comes to an end, the outlook for 2017 is shrouded in uncertainty.
Tensions in the Middle East are rising, and populist movements have appeared in Europe and the United States.
In the Middle East, the tragic conflict in Syria continues, despite several fruitless attempts at rapprochement, which were marred by the fundamental disagreement about Syrian President Bashar al-Assad’s future role in any peace process or political transition.
Meanwhile, over the past week, Syrian government troops, backed by Russia and Iran, have retaken almost all of Aleppo – once Syria’s largest city, now utterly devastated by the war.
The world’s priority for the coming year must be to achieve peace in Syria, which will require close regional and international cooperation.
On December 27, Iran, Russia, and Turkey will hold a tripartite meeting in Moscow to discuss a political solution for the Syria conflict.
That meeting, if it takes place, is likely to be overshadowed by the fallout from the assassination of Russia’s ambassador to Turkey.
But it is nothing if not surprising that these parties, and not the US and the European Union, would be negotiating such an agreement.
One positive development this year came in March, when the EU and Turkey signed an agreement to address the refugee crisis.
Turkey has now taken in some three million Syrian refugees since the beginning of the conflict.
Although EU-Turkey relations are currently not at their best, the dialogue between the two sides must continue in 2017, not least because of their common interests, which are based not only on economic interdependence, but also on the refugee crisis and the collective fight against terrorism.
European politics next year, meanwhile, will be consumed by the Brexit negotiations.
In March, the United Kingdom will likely invoke Article 50 of the Treaty of Lisbon, triggering the formal procedure for withdrawal from the EU.
The challenge will be to reach an agreement that guarantees the wellbeing of future EU-UK relations.
This will not be easy, and EU negotiators have already set a timeline of only 18 months.
While much remains uncertain, what is clear is that if the UK wants to retain access to the European single market, it will have to accept the EU’s four freedoms, including the free movement of workers.
In 2017, several European countries will hold general elections, and there is a risk that isolationist, anti-European populist movements will make a strong showing.
For the EU to lose a country as militarily and economically important as the UK is bad enough; but to lose a founding EU member state, such as France, would be tragic.
Fortunately, many Europeans’ views toward the EU actually improved in the aftermath of the Brexit referendum.
But this will not lessen the challenge for EU governments in the year ahead.
They must unite societies divided by powerful global forces, such as globalization and rapid technological innovation.
The Brexit referendum, followed by Donald Trump’s victory in the US presidential election, signaled the rise of populism in the West.
But now that Trump is filling his cabinet with oligarchs and former military men, we have reason to doubt that he will keep his promise to govern without the Washington “establishment.”
Trump’s incoming administration is full of unknowns, but there can be no doubt that his rejection of multilateral institutions will endanger international efforts to cooperate on solutions to the world’s biggest problems.
This holds peril for US-EU relations.
In previous years, the Paris climate agreement and the nuclear agreement with Iran were rays of light in a world closing itself off to multilateralism.
In the coming years, such rays may become scarcer still.
Now more than ever, we need the kind of dialogue that builds strategic trust between great powers.
And yet, Trump’s statements casting doubt on continued US adherence to a “One China” policy vis-à-vis Taiwan could severely damage relations between the world’s two largest economies.
Similarly, notwithstanding the pro-Russian leanings of some among Trump’s team, the US-Russian relationship also lacks strategic trust, owing to Russia’s military intervention in Syria, its invasion of eastern Ukraine, and its alleged interference in the US election.
The coming year will be particularly important for Europe.
Relations between the EU and the US must remain strong, rooted in mutual respect for democracy, freedom, and human rights.
After a turbulent 2016, and with little positive news in international politics, 2017 is shaping up to be a year of challenges and uncertainty.
But the biggest uncertainty of all is whether this is simply the end of another year, or the end of a geopolitical epoch.
Another Slow Year for the Global Economy
WASHINGTON, DC – Last April, the International Monetary Fund projected that the world economy would grow by 3.5% in 2015.
In the ensuing months, that forecast was steadily whittled down, reaching 3.1% in October.
But the IMF continues to insist – as it has, with almost banal predictability, for the last seven years – that next year will be better.
But it is almost certainly wrong yet again.
For starters, world trade is growing at an anemic annual rate of 2%, compared to 8% from 2003 to 2007.
Whereas trade growth during those heady years far exceeded that of world GDP, which averaged 4.5%, lately, trade and GDP growth rates have been about the same.
Even if GDP growth outstrips growth in trade this year, it will likely amount to no more than 2.7%.
The question is why.
According to Christina and David Romer of the University of California, Berkeley, the aftershocks of modern financial crises – that is, since World War II – fade after 2-3 years.
The Harvard economists Carmen Reinhart and Kenneth Rogoff say that it takes five years for a country to dig itself out of a financial crisis.
And, indeed, the financial dislocations of 2007-2008 have largely receded.
So what accounts for the sluggish economic recovery?
One popular explanation lies in the fuzzy notion of “secular stagnation”: long-term depressed demand for goods and services is undermining incentives to invest and hire.
But demand would remain weak only if people lacked confidence in the future.
The only logical explanation for this enduring lack of confidence, as Northwestern University’s Robert Gordon has painstakingly documented and argued, is slow productivity growth.
Before the crisis – and especially from 2003 to 2007 – slow productivity growth was being obscured by an illusory sense of prosperity in much of the world.
In some countries – notably, the United States, Spain, and Ireland – rising real-estate prices, speculative construction, and financial risk-taking were mutually reinforcing.
At the same time, countries were amplifying one another’s growth through trade.
Central to the global boom was China, the rising giant that flooded the world with cheap exports, putting a lid on global inflation.
Equally important, China imported a huge volume of commodities, thereby bolstering many African and Latin American economies, and purchased German cars and machines, enabling Europe’s largest economy to keep its regional supply chains humming.
This dynamic reversed around March 2008, when the US rescued its fifth-largest investment bank, Bear Sterns, from collapse.
With the eurozone banks also deeply implicated in the subprime mortgage mess and desperately short of US dollars, America and much of Europe began a remorseless slide into recession.
Whereas in the boom years, world trade had spread the bounty, it was now spreading the malaise.
As each country’s GDP growth slowed, so did its imports, causing its trading partners’ growth to slow as well.
The US economy began to emerge from its recession in the second half of 2009, thanks largely to aggressive monetary policy and steps to stabilize the financial system.
Eurozone policymakers, by contrast, rejected monetary stimulus and implemented fiscal austerity measures, while ignoring the deepening distress of their banks.
The eurozone thus pushed the world into a second global recession.
Just when that recession seemed to have run its course, emerging economies began to unravel.
For years, observers had been touting the governance and growth-enhancing reforms that these countries’ leaders had supposedly introduced.
In October 2012, the IMF celebrated emerging economies’ “resilience.”
As if on cue, that facade began to crumble, revealing an inconvenient truth: factors like high commodity prices and massive capital inflows had been concealing serious economic weaknesses, while legitimizing a culture of garish inequality and rampant corruption.
These problems are now being compounded by the growth slowdown in China, the fulcrum of global trade.
And the worst is yet to come.
China’s huge industrial overcapacity and property glut needs to be wound down; the hubris driving its global acquisitions must be reined in; and its corruption networks have to be dismantled.
In short, the factors that dragged down the global economy in 2015 will persist – and in some cases even intensify – in the new year.
Emerging economies will remain weak.
The eurozone, having enjoyed a temporary reprieve from austerity, will be constrained by listless global trade.
Rising interest rates on corporate bonds portend slower growth in the US.
China’s collapsing asset values could trigger financial turbulence.
And policymakers are adrift, with little political leverage to stem these trends.
The IMF should stop forecasting renewed growth and issue a warning that the global economy will remain weak and vulnerable unless world leaders act energetically to spur innovation and growth.
Such an effort is long overdue.
Trumpian Uncertainty
NEW YORK – Every January, I try to craft a forecast for the coming year.
Economic forecasting is notoriously difficult; but, notwithstanding the truth expressed in Harry Truman’s request for a one-armed economist (who wouldn’t be able to say “on the other hand”), my record has been credible.
In recent years, I correctly foresaw that, in the absence of stronger fiscal stimulus (which was not forthcoming in either Europe or the United States), recovery from the Great Recession of 2008 would be slow.
In making these forecasts, I have relied more on analysis of underlying economic forces than on complex econometric models.
For example, at the beginning of 2016, it seemed clear that the deficiencies of global aggregate demand that have been manifest for the last several years were unlikely to change dramatically.
Thus, I thought that forecasters of a stronger recovery were looking at the world through rose-tinted glasses. Economic developments unfolded much as I anticipated.
Not so the political events of 2016.
I had been writing for years that unless growing inequality – especially in the US, but also in many countries throughout the world – was addressed, there would be political consequences.
But inequality continued to worsen – with striking data showing that average life expectancy in the US was on the decline.
These results were foreshadowed by a study last year, by Anne Case and Angus Deaton, which showed that life expectancy was on the decline for large segments of the population – including America’s so-called angry men of the Rust Belt.
But, with the incomes of the bottom 90% having stagnated for close to a third of a century (and declining for a significant proportion), the health data simply confirmed that things were not going well for very large swaths of the country.
And while America might be at the extreme of this trend, things were little better elsewhere.
But, if it seemed clear that there would be political consequences, their form and timing were far less obvious.
Why did the backlash in the US come just when the economy seemed to be on the mend, rather than earlier?
And why did it manifest itself in a lurch to the right?
After all, it was the Republicans who had blocked assistance to those losing their jobs as a result of the globalization they pushed assiduously. It was the Republicans who, in 26 states, refused to allow the expansion of Medicaid, thereby denying health insurance to those at the bottom.
And why was the victor somebody who made his living from taking advantage of others, openly admitted not paying his fair share of taxes, and made tax avoidance a point of pride?
Donald Trump grasped the spirit of the time: things weren’t going well, and many voters wanted change.
Now they will get it: there will be no business as usual. But seldom has there been more uncertainty.
Which policies Trump will pursue remains unknown, to say nothing of which will succeed or what the consequences will be.
Trump seems hell-bent on having a trade war.
But how will China and Mexico respond?
Trump may well understand that what he proposes will violate World Trade Organization rules, but he may also know that it will take a long time for the WTO to rule against him.
And by then, America’s trade account may have been rebalanced.
But two can play that game: China can take similar actions, though its response is likely to be more subtle.
If a trade war were to break out, what would happen?
Trump may have reason to think he could win; after all, China is more dependent on exports to the US than the US is on exports to China, which gives the US an advantage.
But a trade war is not a zero-sum game. The US stands to lose as well.
China may be more effective in targeting its retaliation to cause acute political pain.
And the Chinese may be in a better position to respond to US attempts to inflict pain on them than the US is to respond to the pain that China might inflict on Americans.
It’s anybody’s guess who can stand the pain better.
Will it be the US, where ordinary citizens have already suffered for so long, or China, which, despite troubled times, has managed to generate growth in excess of 6%?
More broadly, the Republican/Trump agenda, with its tax cuts even more weighted toward the rich than the standard GOP recipe would imply, is based on the idea of trickle-down prosperity – a continuation of the Reagan era’s supply-side economics, which never actually worked.
Fire-breathing rhetoric, or raving three a.m. tweets, may assuage the anger of those left behind by the Reagan revolution, at least for a while.
But for how long?
And what happens then?
Trump might like to repeal the ordinary laws of economics, as he goes about his version of voodoo economics. But he can’t.
Still, as the world’s largest economy leads the way into uncharted political waters in 2017 and beyond, it would be foolhardy for a mere mortal to attempt a forecast, other than to state the obvious: the waters will almost certainly be choppy, and many – if not most – pundit ships will sink along the way.
9/11 and the New Authoritarianism
Five years after the attacks on the Twin Towers in New York and the Pentagon in Washington, “9/11” is no longer a mere date.
It has entered the history books as the beginning of something new, a new era perhaps, but in any case a time of change.
The terrorist bombings in Madrid and London and elsewhere will also be remembered; but it is “9/11” that has become the catchphrase, almost like “August 1914.”
But was it really a war that started on September 11, 2001?
Not all are happy about this American notion.
During the heyday of Irish terrorism in the UK, successive British governments went out of their way not to concede to the IRA the notion that a war was being waged.
“War” would have meant acceptance of the terrorists as legitimate enemies, in a sense as equals in a bloody contest for which there are accepted rules of engagement.
This is neither a correct description nor a useful terminology for terrorist acts, which are more correctly described as criminal.
By calling them war – and naming an opponent, usually al-Qaeda and its leader, Osama bin Laden – the United States government has justified domestic changes that, before the 9/11 attacks, would have been unacceptable in any free country.
Most of these changes were embodied in the so-called “USA Patriot Act.”
Though some of the changes simply involved administrative regulations, the Patriot Act’s overall effect was to erode the great pillars of liberty, such as habeas corpus , the right to recourse to an independent court whenever the state deprives an individual of his freedom.
From an early date, the prison camp at Guantánamo Bay in Cuba became the symbol of something unheard of: the arrest without trial of “illegal combatants” who are deprived of all human rights.
The world now wonders how many more of these non-human humans are there in how many places.
For everyone else, a kind of state of emergency was proclaimed that has allowed state interference in essential civil rights.
Controls at borders have become an ordeal for many, and police persecution now burdens quite a few.
A climate of fear has made life hard for anyone who looks suspicious or acts suspiciously, notably for Muslims.
Such restrictions on freedom did not meet with much public opposition when they were adopted.
On the contrary, by and large it was the critics, not the supporters, of these measures who found themselves in trouble.
In Britain, where Prime Minister Tony Blair supported the US attitude entirely, the government introduced similar measures and even offered a new theory.
Blair was the first to argue that security is the first freedom.
In other words, liberty is not the right of individuals to define their own lives, but the right of the state to restrict individual freedom in the name of a security that only the state can define.
This is the beginning of a new authoritarianism.
The problem exists in all countries affected by the threat of terrorism, though in many it has not become quite as specific.
In most countries of continental Europe, “9/11” has remained an American date.
There is even a debate – and indeed some evidence – concerning the question of whether involvement in the “war against terrorism” has actually increased the threat of terrorist acts.
Germans certainly use this argument to stay out of the action wherever possible.
This stance, however, has not prevented the spread of something for which a German word is used in other languages, too: Angst .
A diffuse anxiety is gaining ground.
People feel uneasy and worried, especially when traveling.
Any train accident or airplane crash is now at first suspected of being an act of terrorism.
Thus, 9/11 has meant, directly or indirectly, a great shock, both psychologically and to our political systems.
While terrorism is fought in the name of democracy, the fight has in fact led to a distinct weakening of democracy, owing to official legislation and popular angst.
One of the worrying features of the 9/11 attacks is that it is hard to see their purpose beyond the perpetrators’ resentment of the West and its ways.
But the West’s key features, democracy and the rule of law, have taken a far more severe battering at the hands of their defenders than by their attackers.
Two steps, above all, are needed to restore confidence in liberty within the democracies affected by the legacy of 9/11.
First, we must make certain that the relevant legislation to meet the challenge of terrorism is strictly temporary.
Some of today’s restrictions on habeas corpus and civil liberties have sunset clauses restricting their validity; all such rules should be re-examined by parliaments regularly.
Second, and more importantly, our leaders must seek to calm, rather than exploit, public anxiety.
The terrorists with whom we are currently at “war” cannot win, because their dark vision will never gain broad popular legitimacy.
That is all the more reason for democrats to stand tall in defending our values – first and foremost by acting in accordance with them.
9/11 in Perspective
NEW YORK – It was a decade ago that 19 terrorists took control of four planes, flew two into the twin towers of the World Trade Center, hit the Pentagon with a third, and crashed the fourth in a field in Pennsylvania after passengers resisted and made it impossible for the terrorists to complete their malevolent mission.
In a matter of hours, more than 3,000 innocent people, mostly Americans, but also people from 115 other countries, had their lives suddenly and violently taken from them.
September 11, 2001, was a terrible tragedy by any measure, but it was not a historical turning point.
It did not herald a new era of international relations in which terrorists with a global agenda prevailed, or in which such spectacular terrorist attacks became commonplace. On the contrary, 9/11 has not been replicated.
Despite the attention devoted to the “Global War on Terrorism,” the most important developments of the last ten years have been the introduction and spread of innovative information technologies, globalization, the wars in Iraq and Afghanistan, and the political upheavals in the Middle East. 
As for the future, it is much more likely to be defined by the United States’ need to put its economic house in order; China’s trajectory within and beyond its borders; and the ability of the world’s governments to cooperate on restoring economic growth, stemming the spread of nuclear weapons, and meeting energy and environmental challenges.
It is and would be wrong to make opposition to terrorism the centerpiece of what responsible governments do in the world.
Terrorists continue to be outliers with limited appeal at best.
They can destroy but not create.
It is worth noting that the people who went into the streets of Cairo and Damascus calling for change were not shouting the slogans of Al Qaeda or supporting its agenda.
Moreover, measures have been implemented to push back, successfully, against terrorists.
Intelligence assets have been redirected. Borders have been made more secure and societies more resilient.
International cooperation has increased markedly, in part because governments that cannot agree on many things can agree on the need to cooperate in this area.
Military force has played a role as well.
Al Qaeda lost its base in Afghanistan when the Taliban government that had provided it sanctuary was ousted from power.
Osama bin-Laden was finally found and killed by US Special Forces in the suburbs of Islamabad.
Drones – unmanned aircraft that are remotely steered – have proven to be effective in killing a significant number of terrorists, including many of the most important leaders.
Weak governments can be made stronger; governments that tolerate or support terrorism must be held accountable.
But progress is not to be confused with victory.
Terrorists and terrorism cannot be eliminated any more than we can rid the world of disease.
There will always be those who will resort to force against innocent men, women, and children in pursuit of political goals.
Indeed, terrorists are advancing in some areas.
Pakistan remains a sanctuary for Al Qaeda and some of the world’s other most dangerous terrorists.
A mixture of instability, government weakness, and ideology in countries such as Yemen, Libya, Somalia, and Nigeria are providing fertile territory for terrorists to organize, train, and mount operations – much as they did in Afghanistan did a decade ago.
New groups constantly emerge from the ruins of old ones.
There is also a growing danger of homegrown terrorism.
We have seen it in Great Britain and the US.
The Internet, one of the great inventions of the modern Western world, has shown itself to be a weapon that can be used to incite and train those who wish to cause harm to that world.
The question raised in October 2003 by then US Secretary of Defense Donald Rumsfeld is no less relevant today: “Are we capturing, killing, or deterring and dissuading more terrorists every day than the madrassas and the radical clerics are recruiting, training, and deploying against us?”
All things being equal, we probably are.
But even small terrorist successes are costly in terms of lives, money, and making open societies less so.
What is to be done?
Alas, there is no single or silver bullet.
The establishment of a Palestinian state will not be enough for those terrorists who want to see the elimination of the Jewish state, any more than reaching a compromise over Kashmir will satisfy those Pakistan-based terrorists with bigger agendas vis-à-vis India.
Reducing unemployment is desirable, of course, but many terrorists do not come from poverty.
Helping to make societies in the Middle East and elsewhere more democratic might reduce the alienation that can lead to radicalism and worse, but this is easier said than done.
Of course, we want to continue to find ways to make ourselves less vulnerable and terrorists more so.
But what may be most important, particularly in the Arab and Islamic communities, is to end any acceptance of terrorism.
The Nigerian father who warned the US embassy in Lagos that he feared what his own son might do – before that same young man attempted to detonate a bomb aboard a flight to Detroit on Christmas Day 2009 – is an example of just this.
Only when more parents, teachers, and community leaders behave likewise will recruitment of terrorists dry up and law-enforcement authorities receive full cooperation from the populations they police.
Terrorism must lose its legitimacy among those who have historically supported or tolerated it before it will lose its potency.
Transatlantic Trade for All
WASHINGTON, DC – The negotiations to create a Transatlantic Trade and Investment Partnership between the European Union and the United States are being widely welcomed.
British Prime Minister David Cameron has called the TTIP a “once-in-a-generation prize,” citing potential gains of £80 billion ($125.5 billion) each for the EU and the US and £85 billion for the rest of the world.
For a world weary of waiting for the World Trade Organization’s interminable Doha trade round to conclude, even a bilateral trade initiative may seem like a boon, especially when, as a recent Financial Times editorial pointed out, “bilateral” covers half of the world’s economy.
But there is a serious downside: The deal could hurt developing-country exporters, unless the EU and the US make a concerted effort to protect these actors’ interests.
The feature of the proposed pact that elicits the most excitement – its focus on regulatory barriers like mandatory product standards – should actually incite the greatest concern.
Given low tariffs in the EU and the US – less than 5%, on average – further preferential reductions will not seriously handicap outsiders.
But, when it comes to standards – such as those governing safety, health, and the environment – the market-access requirements are brutal and binary: either you meet the established standard or you do not sell.
As a result, third-country firms’ options will depend on how TTIP standards are established: through harmonization (adoption of a common standard) or mutual recognition (acceptance of goods that meet one another’s established standards).
The first option would enable producers everywhere to take advantage of economies of scale.
But, in some cases, the harmonized standard could be more stringent than some countries’ original standards.
Even though new standards would apply to suppliers from all exporting countries, compliance costs usually vary, meaning that those less equipped to meet higher standards could suffer.
In the late 1990’s, when the EU decided to harmonize standards for aflatoxins (a group of toxic compounds produced by certain molds), eight member states – including Italy, the Netherlands, and Spain – raised their national standards substantially, which is likely to have caused African exports of cereals, dried fruits, and nuts to Europe to decline by as much as $670 million.
With mutual recognition, the EU and the US would accept each other’s standards or conformity-assessment procedures, allowing firms to adhere to the less stringent requirements in each area.
If the policy were extended to third-country firms, it would have a powerful liberalizing impact.
For example, Malaysian television producers could choose to comply with, say, America’s easier-to-meet safety standards, then sell the same product in both markets, reaping the benefits of economies of scale while lowering compliance costs.
If, however, the TTIP excluded third-country firms from the mutual recognition policy, their competitiveness vis-à-vis European and American companies would diminish substantially.
Indeed, our research shows that when mutual-recognition agreements include restrictive rules of origin, intra-regional trade increases – at the expense of trade with other countries – and that developing countries tend to suffer most.
In fact, excessively constraining rules of origin have proved problematic for some of the EU’s previous recognition agreements, such as those governing professional-services standards.
While a Brazilian orange admitted for sale in Portugal can be sold throughout the EU, a Brazilian engineer or accountant licensed in Portugal must fulfill separate licensing requirements to work elsewhere in the EU, hampering much-needed labor mobility by forcing non-European workers to endure costly and inefficient bureaucratic procedures.
Furthermore, when it comes to tariffs and standards, WTO rules are not created equal.
While they protect countries excluded from bilateral or regional tariff agreements, thereby ensuring that integrated markets do not receive additional advantages, few safeguards exist to shield third countries from the fallout of agreements on mandatory standards.
Even in the absence of international rules, the EU and the US could take two actions to ensure that the TTIP does not have adverse consequences for developing economies.
First, they could allow all countries to reap the benefits of a bilateral mutual-recognition deal by agreeing not to impose restrictive rules of origin.
Second, where they do consider harmonization, they could favor the less stringent of the original standards, unless there is credible evidence that it would not support the relevant regulatory objective.
This is akin to a WTO test for departures from established international standards.
If the EU and the US made these two commitments, the rest of the world could follow the TTIP negotiations with hope, rather than trepidation.
A Balanced Look at Sino-American Imbalances
BEIJING – Before July 2007, most economists agreed that global imbalances were the most important threat to global growth.
It was argued that the United States’ rising net foreign debt-to-GDP ratio – the result of chronic current-account deficits – would put a sharp brake on capital inflows, in turn weakening the dollar, driving up interest rates, and plunging the US economy into crisis.
But this scenario failed to materialize. Instead, the crisis stemmed from the US sub-prime debacle, which quickly dragged the global economy into its deepest recession since the 1930’s.
Most economists failed to foresee the economic dynamics that actually led to the crisis, because they failed to pay enough attention to the rapid increase in US total debt.
Instead, they focused exclusively on US foreign debt, ignoring household debt (mortgage and consumer debt), public debt, business debt, and financial debt.
In particular, they should have paid greater attention to the sustainability of US mortgage and consumer debt.
In 2007, the mortgage and consumer debt-to-GDP ratio was more than 90%, compared to 24% for net foreign debt.
Of course, the various components of debt differ considerably in their character and sources of financing – and thus in their sustainability.
But all parts of a country’s total debt and how it is financed are interconnected.
This means two things. First, funds from different sources of finance are interchangeable to a certain degree: deficiency of funds for one component of total debt can be supplemented by surplus funds originally aimed at financing other components.
Second, troubles in any single component of total debt will have an impact on all the other components.
After the subprime crisis erupted, mortgage and consumer debt was paid down by households either with their savings or by default.
The fall in US total debt, and the narrowing of the financing gap between total debt and domestic funds, led to a significant improvement in the US current-account deficit in 2008-2009, disproving US Federal Reserve Board Chairman Ben Bernanke’s claim that the deficit was caused by a global “saving glut.”
Indeed, America’s current-account position strengthened despite the dollar’s appreciation in the face of safe-haven demand.
Unfortunately, as a result of the private-sector deleveraging and an increase in household savings, the US economy, driven by debt and consumption, slid into recession.
To offset the negative impact of private-sector deleveraging on growth, the US government has maintained expansionary fiscal and monetary policies.
Now, with household debt sustained on a knife-edge after feverish government intervention, the fiscal position has deteriorated dramatically and the current-account balance has worsened again.
Sustainability of public debt has replaced sustainability of private debt as the biggest threat to financial stability, and the focus of debate about the US current account has shifted from the sustainability of foreign debt to the impact of reducing the external deficit on growth and employment.
The dilemma facing US policymakers is how to stimulate growth while lowering the level of total debt.
The most important way to achieve both objectives is to increase exports by strengthening US competitiveness.
But where will increased competitiveness come from?
Devaluation of the dollar could improve US competitiveness in the short run, but it is not a solution.
Because rapid fiscal deterioration now has investors worrying about capital losses on US government securities, devaluation would make foreigners more hesitant to finance America’s budget deficit.
If foreign financing is not forthcoming, yields on US government debt will rise and the US economy will fall back into recession.
In the long run, America’s growth pattern must undergo a structural shift from reliance on debt and consumption one based on Americans vaunted capacity for creativity and innovation.
Only then will America improve its competitiveness enough to allow the government to reduce both private and public debt to sustainable levels while maintaining a respectable growth rate.
But neither improved competitiveness, nor reduction of total debt, can be achieved overnight.
In the short run, the US current-account deficit will remain, regardless of which country runs bilateral surpluses.
Thus, China’s continued reinvestment of its current-account surplus in US government securities is of utmost important for US growth and financial stability.
Given that America benefits mightily from China’s purchases of US government securities, it is difficult to understand why the US government and Congress have been complaining so much about the bilateral current-account deficit.
It is also difficult to grasp why China is so reluctant to reduce its bilateral surplus, given meager returns on its massive holdings of US government securities and a sustained risk of large capital losses in the future.
The good news is that, following President Hu Jintao’s recent visit to Washington, both America and China have been taking positive steps to resolve their differences over the bilateral current-account balance.
That augurs well for a more rational and constructive Sino-American dialogue on global imbalances, which would certainly benefit the global economy.
A Banking Union Baby Step
BRUSSELS – At the beginning of the financial crisis, it was said that banks were, in Charles Goodhart’s crisp phrase, “international in life, but national in death.”
At the time (2008-2009), large international banks had to be rescued by their home countries’ governments when they ran into trouble.
But the problem now in Europe is the opposite: banks are “national in life, but European in death.”
In Spain, for example, local savings banks (cajas) financed an outsize real-estate boom.
As the boom turned to bust, the losses threatened to overwhelm the capacity of the Spanish state, and the problem became European, because it threatened the very survival of the euro.
The Spanish case is symptomatic of a larger problem.
National supervisors always tend to minimize problems at home.
Their instinct (and their bureaucratic interest) is to defend their countries’ “national champion” bank(s) abroad.
But their resistance to recognizing problems at home runs even deeper.
Until recently, the Spanish authorities maintained that the problems in their country’s real-estate sector were temporary.
To acknowledge the truth would have meant admitting that for years they had overlooked the build-up of an unsustainable construction boom that now threatens to bankrupt the entire country.
In the case of Ireland, the situation was initially not much different.
When problems started to surface, the finance minister at the time initially claimed that the country would carry out “the cheapest bank rescue ever.”
Given national supervisors’ predictable tendency not to recognize problems at home, it seemed natural that the cost of cleaning up insolvent banks should also be borne at the national level.
It thus seemed to make sense that even in the eurozone, banking supervision remained largely national.
The recently created European Banking Authority has only limited powers over national supervisors, whose daily work is guided mainly by national considerations.
But reality has shown that this approach is not tenable.
Problems might originate at the national level, but, owing to monetary union, they quickly threaten the stability of the entire eurozone banking system.
At their June summit, Europe’s leaders finally recognized the need to rectify this situation, transferring responsibility for banking supervision in the eurozone to the European Central Bank.
Given that financial integration is particularly strong within the monetary union, putting the ECB in charge was an obvious choice.
Moreover, the ECB already bears de facto responsibility for the stability of the eurozone’s banking system.
But, until now, it had to lend massive amounts to banks without being able to judge their soundness, because all of that information was in the hands of national authorities who guarded it jealously and typically denied problems until it was too late.
Putting the ECB in charge should also help to stop the creeping disintegration process, which is not publicly visible, but is very real nonetheless.
Just ask any of the large international banking groups headquartered in financially stressed eurozone countries.
Consider the case of a bank headquartered in Italy, but with an important subsidiary in Germany.
The German operations naturally generate a surplus of funds (given that savings in Germany far exceed investment on average).
The parent bank would like to use these funds to reinforce the group’s liquidity.
But the German supervisory authorities consider Italy at risk and thus oppose any transfer of funds there.
The supervisor of the home country (Italy) has the opposite interest.
It would like to see the “internal capital market” operate as much as possible.
Here, too, it makes sense to have the ECB in charge as a neutral arbiter with respect to these opposing interests.
But, while putting the ECB in charge of banking supervision solves one problem, it creates another: can national authorities still be held responsible for saving banks that they no longer supervise?
Economic (and political) logic requires that the eurozone will soon also need a common bank rescue fund.
Officially, this has not yet been acknowledged.
But that is often the way that European integration proceeds: an incomplete step in one area later requires further steps in related areas.
This incremental approach has worked well in the past; indeed, today’s European Union resulted from it.
But a financial crisis does not give policymakers the time that they once had to explain to voters why one step required another.
They will have to walk much more quickly to save the euro.
The Renewed Promise of Abenomics
TOKYO – Japan’s Liberal Democratic Party scored a decisive victory in the December 14 parliamentary election, with Japanese voters demonstrating their overwhelming approval of Prime Minister Shinzo Abe’s macroeconomic policy agenda.
Though voter turnout was relatively low, owing largely to the somewhat technical nature of the issues, the election’s message was clear: most Japanese abhor the prospect of a return to the grim economic trajectory that prevailed in Japan before “Abenomics.”
When the first “arrow” of Abenomics – a fiscal stimulus program – was launched nearly two years ago, asset markets' immediate response was positive.
The second arrow of Abenomics – monetary easing – intensified these effects.
In the last two years, Japan’s stock market has almost doubled in value, increasing the wealth of Japanese consumers.
Moreover, the yen has fallen by nearly one-third against the US dollar, from around ¥80 to nearly ¥120 per dollar, invigorating Japan’s export industries.
Even more encouraging are developments in the labor market, which, unlike those in asset markets, reflect outcomes, not expectations.
Here, too, the news is good.
The labor market has tightened, with unemployment standing at 3.5% and the job-to-applicant ratio above parity.
To be sure, there have been some setbacks: Japan’s GDP shrank in the second and third quarters of 2014.
But the downturn, which resulted from April’s consumption-tax hike – from 5% to 8% – cannot be blamed on Abenomics.
Indeed, Abe was honoring a law enacted by the previous government, led by the Democratic Party of Japan.
The first two arrows of Abenomics were aimed at stimulating demand – and they were extremely effective.
The consumption-tax hike was needed to sustain them in flight. Unfortunately, the hike was too large to keep them aloft.
The good news is that the tax hike’s impact is temporary. Soon, it will begin to taper off, and industrial output will approach full capacity.
When demand begins to exceed supply, demand-side stimulus policies will become increasingly ineffective, and it will be time to launch the third arrow of Abenomics: growth-enhancing structural reforms.
Such reforms are essential to raise productivity growth and improve the Japanese economy’s competitiveness.
Four imperatives stand out.
The first task should be to eliminate – or, at least, reduce – the thicket of government regulations that is stifling economic dynamism.
The current system is so convoluted and complex that it took more than three decades to open a new medical school in Tokyo.
Likewise, flights to Haneda airport, a convenient connection to the Tokyo city area, have been rationed.
This is no formula for long-term economic success.
Furthermore, Japan’s government should push to complete negotiations for the Trans-Pacific Partnership, which is currently being negotiated among 12 countries, from Mexico to the United States to Vietnam.
The TPP would improve Japan’s trade prospects considerably, including in sensitive sectors like agriculture, where exports of fast-moving consumer goods like flowers and vegetables would benefit.
Japan’s leaders must also work to expand the workforce, which faces severe constraints, owing largely to the country’s rapidly aging population.
In the absence of large-scale immigration, to which Japanese remain unamenable, one relatively simple solution would be to integrate more women into the labor force.
A 10% increase in Japan’s female labor-force participation rate – an entirely attainable goal – would translate into an almost 5% gain in total labor-force participation.
Finally, Abe’s government must reduce the corporate-tax rate to align it more closely with international standards.
Amid increasingly intense international competition to attract foreign investment, reducing the corporate tax would actually increase Japan’s tax revenues, by spurring companies to invest their vast cash stockpiles in more productive activities.
Now that Abe’s government has a renewed mandate from Japanese voters, it must deliver on its promises – and that means decisive and comprehensive implementation of structural reforms.
Of course, this will require some sacrifices.
Indeed, households have already endured some hardship, brought about by the consumption-tax hike.
The next step is for Abe’s government to use its political capital to overcome vested interests, both in the bureaucracy and the business community.
This means compelling businesses to give up some of the special tax benefits they now enjoy.
For their part, politicians must participate in the taxpayer identification system.
And bureaucrats must forego some of the power that excessive regulation affords them.
If all of these groups join the Japanese public in accepting reasonable sacrifices, Abe’s government can fulfill its promise and build a thriving economy.
For the sake of all Japanese – not to mention a world economy in need of a new source of dynamism – that promise deserves to be met.
The Missing Arrow of Abenomics
TOKYO – In his drive to kick-start the Japanese economy, Prime Minister Shinzo Abe, shortly after taking office in 2012, introduced a large fiscal stimulus and put in place a bold program of monetary easing.
Since then, Japanese policymakers have been working to launch what Abe calls the third “arrow” of his agenda: arduous reforms of key industries and the demolition of structural barriers to growth.
But the focus on public policy has left a “fourth arrow” – the private sector – untouched and seemingly ignored.
This is unfortunate, because the government cannot fix Japan’s ills on its own.
Annual productivity growth has been stubbornly sluggish, rarely rising above 2% for much of the past two decades, reflecting both missed opportunities and declining cost competitiveness.
Japan’s productivity slump permeates the entire economy; labor and capital productivity gains have nearly stalled in almost every sector – even in Japan’s signature advanced manufacturing industries.
Labor productivity in the transport-equipment sector, for example, is barely half that of Germany.
This trend puts annual GDP growth on course to average only 1.3% through 2025, implying a third consecutive decade of stagnation.
Such an outcome would coincide with – and exacerbate the effects of – an adverse demographic shift that will constrain fiscal revenues and drive up costs for universal health care and pension benefits.
Japan’s ability to alter its trajectory depends on individual companies making decisions to invest, change workplace policies, deploy new technologies, and test untried business models.
Abe’s structural reforms will take time and political will to enact, but Japanese companies cannot afford to sit still.
They can and must act, without waiting for the government to change its policies.
In many cases, the economy’s bottlenecks are not regulatory in nature, but stem from entrenched ways of doing business.
New research by the McKinsey Global Institute examines Japan’s advanced manufacturing, retail, financial services, and health-care industries in detail – and finds substantial untapped productivity potential in every area.
For starters, Japanese firms must become more globally integrated.
Exporting to the fastest-growing overseas markets is one obvious route to overcoming sluggish demand growth at home.
But, rather than just selling products abroad, Japanese enterprises need to expand operations beyond their borders and cast a wider net for international talent.
Japanese companies have formidable R&amp;D operations, but most will need to reconfigure them to obtain better returns and impact.
The process must start with an understanding of what the customer wants and a determination to deliver solutions accordingly.
Closed and tightly managed R&amp;D operations must be transformed into more fluid, open processes involving collaboration with customers and suppliers.
Japanese companies will also need to improve their capabilities in areas such as marketing, pricing, and talent development.
While there are some pockets of excellence, most Japanese firms are severely lacking in these areas.
To compete in global markets, they will need to achieve the same consistency in these areas that they have in their traditional areas of strength.
Many Japanese companies have yet to digitize paper-based processes and replace outdated information-technology systems.
Others would benefit from moving beyond basic digitization to next-generation technologies, such as big-data analytics.
Companies can also head off looming labor shortages with intelligent software systems and robotics.
Manufacturers can augment or replace their assembly lines with technologies such as the Internet of Things and 3D printing.
More broadly, Japanese companies have to organize for performance and discipline.
As policy changes unleash market forces, businesses will face greater competition.
Some may need to reorganize or exit unprofitable markets; others may have to undertake mergers and acquisitions to achieve economies of scale.
Finally, shareholders and senior executives should tie performance goals to incentives.
Some of Japan’s corporate giants have already begun shifting from traditional seniority-based advancement toward merit-based pay structures.
Others should follow their lead.
Promoting younger and more diverse talent can create agile organizations with fresh ideas.
If Japan’s private sector rises to the challenge, it can move the economy onto a path of faster growth.
Innovations in one company would cascade across its entire industry by forcing competitors to raise their game.
In the 1950s and 1960s, for example, Toyota introduced more efficient production processes that were eventually adopted by the entire automobile industry.
Instead of settling for a future of 1.3% annual GDP growth, Japan could attain roughly 3% annual growth through 2025.
Doing so would require the growth rate of labor productivity to more than double, but this is an attainable goal.
More than half of this growth increment can be met by adopting best practices that companies around the world already use, while technology can close much of the remaining gap.
Japanese business leaders need to combine big thinking with a focused attention to detail.
They will need to create innovative products, penetrate new markets, and make bold investments in equipment, technology, and talent, while simultaneously scrutinizing every aspect of their operations for inefficiency and waste.
Traditional ways of doing business may have to be abandoned.
But there is ample scope to make progress and spur faster economic growth.
Immense trade flows, the rise of billions of new consumers in the emerging world, and technology breakthroughs are rapidly transforming the global economy.
Japan can shift its current trajectory by turning this wave of disruption into opportunity.
From Russia With Unrequited Love
NEW DELHI – Japanese Prime Minister Shinzo Abe has assiduously courted Russian President Vladimir Putin, meeting with him more than a dozen times in four years.
This month he hosted Putin in Tokyo and in his hometown of Nagato (famed for its onsen, or natural hot springs).
But Abe’s courtship has so far yielded little for Japan, and much for Russia.
Abe’s diplomatic overtures to Putin are integral to his broader strategy to position Japan as a counterweight to China, and to rebalance power in Asia, where Japan, Russia, China, and India form a strategic quadrangle.
Abe has already built a close relationship with India, and he sees improved relations with Russia – with which Japan never formally made peace after World War II – as the missing ingredient for a regional power equilibrium.
But Abe’s trust-building efforts with Russia are not aimed only at checking Chinese aggression.
He also wants Russia to return its southernmost Kuril Islands – a resource-rich area known as the Northern Territories in Japan – which the Soviet Union seized just after the United States dropped nuclear bombs on Hiroshima and Nagasaki in August 1945.
In exchange, Abe has offered economic aid, investments in Russia’s neglected Far East, and major energy deals.
Abe has, however, encountered several obstacles.
For starters, Japan is a participant in the US-led sanctions that were imposed on Russia after it annexed Crimea in March 2014.
These sanctions have pushed Russia closer to its traditional rival, China; and Putin has publicly identified the sanctions as a hindrance to concluding a peace treaty with Japan.
In response to Abe’s overtures, Putin has doggedly tried to drive a hard bargain.
Russia has bolstered its defenses on the four disputed islands, and, just prior to this month’s summit, he told the Japanese media that the current territorial arrangement suits Russian interests.
“We think that we have no territorial problems,” he said. “It’s Japan that thinks that it has a territorial problem with Russia.”
The US-led sanctions regime and low oil prices have battered the Russian economy, which is expected to contract by 0.8% in 2016.
Thus, Putin is more reluctant than ever to offer territorial concessions, lest it tarnish his domestic image as a staunch defender of Russian national interests.
Against this backdrop, it is not surprising that Abe left the recent “onsen summit” with dashed hopes of resolving the territorial dispute, while Putin returned home with 68 new commercial accords.
Many of the new agreements are symbolic, but some are substantive, including deals worth $2.5 billion and an agreement to set up a $1 billion bilateral-investment fund.
Under the latter agreement, Japan and Russia are supposed create a “special framework” for joint economic activities on the disputed islands.
But the plan has already run into trouble.
Peter Shelakhaev, a senior Russian official who leads the government’s Far East Investment and Export Agency, has indicated that there are legal hurdles to establishing such a framework, and that Japanese firms doing business on the Kurils would have to pay taxes to Russia.
If Japan did that, however, it would effectively be recognizing Russia’s jurisdiction over the islands.
Abe has thus been denied the legacy that he sought, while Putin has succeeded in easing Russia’s international isolation.
Abe was the first G7 leader to hold a summit with Putin after Russia annexed Crimea, and now Russia has won Japan’s economic cooperation, too.
Japan is the only G7 country that has a territorial dispute with Russia, and it is clearly more eager to reach a deal than the Kremlin is.
But this has only strengthened Russia’s hand.
While Japan has softened its position, and signaled that it may accept only a partial return of the islands, Russia has grown only more intransigent.
After the recent summit, Abe revealed that Putin now seems to be reneging on a 1956 agreement between Japan and the Soviet Union, which stipulates that the smaller two of the four islands will be returned to Japan after a peace treaty is signed.
As it happens, this year marks the 60th anniversary of that joint declaration, which was widely viewed as a breakthrough at the time.
The Kremlin is now suggesting that its commitment to fulfilling the declaration was conditional on Japan not joining any security alliance against Russia.
And Putin has expressed concerns that the 1960 Japan-US Security Treaty would extend to the disputed islands if they were returned, thus allowing the US to establish a military presence there.
Japan is in no position to address Russia’s concerns.
It cannot opt out of the US-led sanctions regime; and it cannot exempt the disputed Kurils from its security treaty with the US, especially now that it has been urging the US to provide an explicit commitment to defend the Japanese-controlled Senkaku Islands, over which China claims sovereignty.
Putin, for his part, appears smugly content with his negotiating position.
Not only did he arrive almost three hours late to the onsen summit, in keeping with his habit of leaving foreign leaders waiting; he also declined a Japanese government gift – a male companion for his native Japanese Akita dog, which Japan gave him in 2012.
There is little hope now that Abe will see tangible returns on the political capital he has invested in cultivating Putin.
And Japan’s dilemma will only deepen.
US President-elect Donald Trump’s desire to improve relations with Russia may give Abe leeway to continue wooing Putin; but if Russia gets the US in its corner, it won’t need Japan anymore.
A Berlin Consensus?
HONG KONG – A recent trip to Berlin brought back memories of an earlier visit in the summer of 1967, when I was a poor student who marveled at the Wall that would divide and devastate an entire society for another two decades.
Berlin today is vibrant and rejuvenated, rebuilt by the German peoples' hard work and sacrifice to unify the country, and an apt setting for the conference of the Institute for New Economic Thinking (INET), which I was there to attend.
The conference’s theme was “Paradigm Lost,” with more than 300 economists, political scientists, systems analysts, and ecologists gathering to rethink economic and political theory for the challenges and uncertainty posed by growing inequality, rising unemployment, global financial disarray, and climate change.
Almost everyone agreed that the old paradigm of neoclassical economics was broken, but there was no agreement on what can replace it.
Nobel laureate Amartya Sen attributed the European crisis to four failures – political, economic, social, and intellectual.
The global financial crisis, which began in 2007 as a crisis of US subprime lending and has broadened into a European sovereign-debt (and banking) crisis, has raised questions that we cannot answer, owing to over-specialization and fragmentation of knowledge.
And yet there is no denying that the world has become too intricate for any simple, overarching theory to explain complex economic, technological, demographic, and environmental shifts.
In particular, the rise of emerging markets has challenged traditional Western deductive and inductive logic.
Deductive inference enables us to predict effects if we know the principles (the rule) and the cause.
By inductive reasoning, if we know the cause and effects, we can infer the principles.
Eastern thinking, by contrast, has been abductive, moving from pragmatism to guessing the next steps.
Abductive inference is pragmatic, looking only at outcomes, guessing at the rule, and identifying the cause.
Like history, social-scientific theory is written by the victors and shaped by the context and challenges of its time.
Free-market thinking evolved from Anglo-Saxon theorists (many from Scotland), who migrated and colonized territories, allowing fortunate individuals to assume that there were no limits to consumption.
European continental thinking, responding to urbanization and the need for social order, emphasized institutional analysis of political economy.
Thus, the emergence of neoclassical economics in the nineteenth century was very much influenced by Newtonian and Cartesian physics, moving from qualitative analysis to quantifying human behavior by assuming rational behavior and excluding uncertainty.
This “predetermined equilibrium” thinking – reflected in the view that markets always self-correct – led to policy paralysis until the Great Depression, when John Maynard Keynes’s argument for government intervention to address unemployment and output gaps gained traction.
By the 1970’s, the neoclassical general-equilibrium school captured Keynesian economics through real-sector models that assumed that “finance is a veil,” thereby becoming blind to financial markets’ destabilizing effects.
Economists like Hyman Minsky, who tried to correct this, were largely ignored as Milton Friedman and others led the profession’s push for free markets and minimal government intervention.
But then technology, demographics, and globalization brought dramatic new challenges that the neoclassical approach could not foresee.
Even as the world’s advanced countries over-consumed through leveraging from derivative finance, four billion of the world’s seven billion people began moving to middle-income status, making huge demands on global resources and raising the issue of ecological sustainability.
New thinking is required to manage these massive and systemic changes, as well as the integration of giants like China and India into the modern world.
A change of mindset is needed not just in the West, but also in the East.
In 1987, the historian Ray Huang explained it for China:
“As the world enters the modern era, most countries under internal and external pressure need to reconstruct themselves by substituting the mode of governance rooted in agrarian experience with a new set of rules based on commerce.…This is easier said than done.
The renewal process could affect the top and bottom layers, and inevitably it is necessary to recondition the institutional links between them.
Comprehensive destruction is often the order; and it may take decades to bring the work to completion.”
Using this macro-historical framework, we can see Japanese deflation, European debt, and even the Arab Spring as phases of systemic changes within complex structures that are interacting with one another in a new, multipolar global system.
We are witnessing simultaneous global convergence (the narrowing of income, wealth, and knowledge gaps between countries) and local divergence (widening income, wealth, and knowledge gaps within countries).
Adaptive systems struggle with order and creativity as they evolve.
As the philosopher Bertrand Russell presciently put it: “Security and justice require centralized governmental control, which must extend to the creation of a world government if it is to be effective.
Progress, on the contrary, requires the utmost scope for personal initiative that is compatible with social order.”
A new wave of what the economist Joseph Schumpeter famously called “creative destruction” is under way: even as central banks struggle to maintain stability by flooding markets with liquidity, credit to business and households is shrinking.
We live in an age of simultaneous fear of inflation and deflation; of unprecedented prosperity amid growing inequality; and of technological advancement and resource depletion.
Meanwhile, existing political systems promise good jobs, sound governance, a sustainable environment, and social harmony without sacrifice – a paradise of self-interested free riders that can be sustained only by sacrificing the natural environment and the welfare of future generations.
We cannot postpone the pain of adjustment forever by printing money.
Sustainability can be achieved only when the haves become willing to sacrifice for the have-nots.
The Washington Consensus of free-market reforms for developing countries ended more than two decades ago.
The INET conference in Berlin showed the need for a new one – a consensus that supports sacrifice in the interest of unity.
Europe could use it.
Accepting Japan at Its Word
TOKYO – In recent years, the number of tourists visiting Japan has been increasing rapidly, reaching a record 13.4 million last year, a 29% increase from 2013.
Japan seems to be making great strides toward its goal of recapturing the position as an Asian cultural center that it held a century ago, when the Indian Nobel laureate poet Rabindranath Tagore lived in Tokyo.
Chinese revolutionary leaders Sun Yat-sen and Chiang Kai-shek, along with many other prominent Asians, moved there as well.
Anyone visiting Japan today would do well to learn two key words: domo, meaning “hello,” “thanks,” or “well,” and sumimasen, which can carry any of the meanings of domo, as well as “sorry” or “excuse me.”
Ordinary Japanese say sumimasen countless times each day, to apologize to friends or strangers for even the most trivial accident or mistake.
But, as Japan’s leaders have experienced firsthand since World War II, expressing regret to other countries is not so simple.
Yet that is precisely what Prime Minister Shinzo Abe must do in his upcoming statement marking the 70th anniversary of the end of the war.
The statement will be based on consultations with many of Japan’s, and the world’s, leading WWII historians, as well as – and more important – with himself, his conscience, and his heart, because he understands the significance of his words on this highly fraught topic.
Of course, Abe is far from the first Japanese leader to confront this challenge.
His statement will follow a long line of declarations by prime ministers and chief cabinet secretaries expressing sincere remorse over the events of WWII.
Twenty years ago, Prime Minister Tomiichi Murayama, the head of the Socialist Party, acknowledged that “Japan, through its colonial rule and aggression, caused tremendous damage and suffering to the people of many countries,” particularly in Asia.
He went on to express “feelings of deep remorse” and offer a “heartfelt apology” to the victims.
Ten years later, Prime Minister Junichiro Koizumi reiterated Murayama’s words, adding that since the war, Japan had been “manifesting its remorse for the war through actions,” especially development assistance and humanitarian activities.
Koizumi also pledged that “Japan, as a peace-loving nation, will work to achieve peace and prosperity for all humankind with all its resources.”
Despite these straightforward declarations of regret, some governments and citizens continue to demand more, giving the impression that nothing a Japanese leader says or does will convince them of the country’s remorse.
This intractability is, in some cases, understandable; the pain of survivors and their descendants remains acute.
But in many other cases, the unwillingness to move beyond history is driven by political interests.
Indeed, political motivations are behind claims that Abe does not agree with past official apologies, despite his repeated assurances that he does, as well as suggestions that he is seeking to revise history, even though he has never denied Japan’s colonial aggression.
Moreover, some have produced portrayals of Japan, as a whole, as an unrepentant country – or, worse, as one that is hell-bent on remilitarization.
Such depictions are breathtaking in their audacity, given Japan’s seven-decade record as a peaceful and constructive member of the international community.
This is not lost on those in Japan who ask for how long their country will have to apologize, with some even suggesting that after 70 years, a “tweet” on the subject should amount to adequate acknowledgement by Abe.
The prime minister, however, remains committed to issuing a strong and sincere statement on the subject.
Early this year, Abe announced his intention to use the 70th anniversary statement to communicate Japan’s remorse for the war, describe the progress the country has made in upholding peace, and describe the contributions that Japan can make to Asia and the rest of the world in the coming decades.
In fact, it is the third component of the announcement that inspires fear in some observers: By helping to build a strong security architecture in the Asia-Pacific region, Japan could undermine the ability of some actors to advance their own interests.
That is why they launched a whisper campaign against Abe’s statement months before he even began to write it.
But, of course, Asian security and prosperity is in everyone’s interest.
Given this, not even the language of Abe’s statement is particularly important; what matters is the determination he expresses, and the actions he takes to follow through – with appropriate humility – on his pledges.
And it seems that Abe is, indeed, determined to make real contributions to peace, based on effective cooperation with Japan’s friends and allies.
But if Asia is to move beyond its past, the victims of Japan’s wartime aggression must recognize that the Japan of 2015 is not the Japan of 1931, 1941, or even 1945, and that, as many Asian leaders have realized over the years, forgiveness benefits everyone.
In 1998, South Korean President Kim Dae-jung responded positively to a statement by former Japanese Prime Minister Keizo Obuchi.
The governments of Indonesia, the Philippines, Vietnam, and other countries have done the same, and now welcome Japan’s commitment to act with its allies to protect regional security.
These countries’ openness to reconciliation have enabled Japan to recast itself as a key arbiter of regional peace and prosperity, not to mention an increasingly dynamic cultural hub.
It is time for the rest of the region to follow suit, accepting at face value Japan’s sincere apologies and working with the country to build a better future.
At a time when Asia is facing serious security challenges, this stance could not be more urgent.
A Big Chance for Small Farmers
NEW YORK – The G-8’s $20 billion initiative on smallholder agriculture, launched at the group’s recent summit in L’Aquila, Italy, is a potentially historic breakthrough in the fight against hunger and extreme poverty.
With serious management of the new funds, food production in Africa will soar.
Indeed, the new initiative, combined with others in health, education, and infrastructure, could be the greatest step so far toward achieving the Millennium Development Goals, the internationally agreed effort to reduce extreme poverty, disease, and hunger by half by 2015 .
During 2002-2006, I led the United Nations Millennium Project, which aimed to achieve the Millennium Development Goals, for then-UN Secretary General Kofi Annan.
One cornerstone of the project was “smallholder farmers,” meaning peasant farm families in Africa, Latin America, and Asia – working farms of around one hectare (2.5 acres) or less.
These are some of the poorest households in the world, and, ironically, some of the hungriest as well, despite being food producers.
They are hungry because they lack the ability to buy high-yield seeds, fertilizer, irrigation equipment, and other tools needed to increase productivity.
As a result, their output is meager and insufficient for their subsistence.
Their poverty causes low farm productivity, and low farm productivity reinforces their poverty.
It’s a vicious circle, technically known as a poverty trap.
The UN Millennium Project’s Hunger Task Force, led by two world-leading scientists, M. S. Swaminathan and Pedro Sanchez, examined how to break this vicious circle.
The Hunger Task Force determined that Africa could substantially increase its food production if help was given to smallholder farmers, in the form of agricultural inputs.  The Millennium Project recommended a big increase in global funding for this purpose.  Drawing on that work and related scientific findings, Annan launched a call in 2004 for an African Green Revolution, based on an expanded partnership between Africa and donor countries.
Many of us, notably current UN Secretary General Ban Ki-moon, have worked hard to make this possible, with Ban repeatedly emphasizing the special emergency arising from the global food, financial, and energy crises of the past two years.
The G-8 announcement reflects these years of effort, and of course the boost from the leadership of US President Barack Obama, Spanish Prime Minister Jose Luis Zapatero, Australian Prime Minister Kevin Rudd, World Bank President Robert Zoellick, European Commissioner Louis Michel, European Parliamentarian Thijs Berman, and others.
Now the key is to make this effort work.
The lessons of history are clear.
Getting seed and fertilizer to smallholder farmers at highly subsidized prices (or even free in some cases) will make a lasting difference.
Not only will food yields rise in the short term, but farm households will use their higher incomes and better health to accumulate all sorts of assets: cash balances, soil nutrients, farm animals, and their children’s health and education.
That boost in assets will, in turn, enable local credit markets, such as micro-finance, to begin operating.
Farmers will be able to buy inputs, either out of their own cash, or by borrowing against their improved creditworthiness.
A consensus has now been reached on the need to assist smallholders, but obstacles remain.
Perhaps the main risk is that the “aid bureaucracies” now trip over each other to try to get their hands on the $20 billion, so that much of it gets taken up by meetings, expert consultations, overhead, reports, and further meetings.
“Partnerships” of donors can become an expensive end in themselves, merely delaying real action.
If donor governments really want results, they should take the money out of the hands of thirty or more separate aid bureaucracies and pool it in one or two places, the most logical being the World Bank in Washington and the International Fund for Agricultural Development (IFAD) in Rome.
One or both of these agencies would then have an account with several billion dollars.
Governments in hunger-stricken regions, especially Africa, would then submit national action plans that would provide details on how they would use the donor funds to get high-yield seeds, fertilizer, irrigation, farm tools, storage silos, and local advice to impoverished farmers.
An independent expert panel would review the national plans to verify their scientific and managerial coherence.
Assuming that a plan passes muster, the money to support it would quickly be disbursed.
Afterward, each national program would be monitored, audited, and evaluated.
This approach is straightforward, efficient, accountable, and scientifically sound.
Two major recent success stories in aid have used this approach: the Global Alliance on Vaccines and Immunizations, which successfully gets immunizations to young children, and the Global Fund to Fight AIDS, TB, and Malaria, which supports national action plans to battle these killer diseases.
Both have saved millions of lives during the past decade, and have paved the way to a new more efficient and scientifically sound method of development assistance.
Not surprisingly, many UN agencies and aid agencies in rich countries fight this approach.
All too often, the fight is about turf, rather than about the most effective way to speed help to the poor.
Obama, Rudd, Zapatero, and other forward-thinking leaders can therefore make a huge difference by following up on their pledges at the G-8 and insisting that the aid really works.
The bureaucracies must be bypassed to get help to where it is needed: in the soil tilled by the world’s poorest farm families.
A Black and White Question
NEW YORK – In the afternoon of July 16 two men appeared to be breaking into a fine house in an expensive area of Cambridge, Massachusetts.
Alerted by a telephone call, a policeman arrived smartly on the scene.
He saw one black male standing inside the house and asked him to come out.
The man refused.
He was then told to identify himself.
The man, still refusing to step out, said he was a Harvard professor, showed his ID, and warned the cop not to mess with him.
He said something about black men in America being singled out, and asked the cop, who was white, for his name and identification.
The cop, joined by several colleagues, arrested the professor for disorderly conduct.
We now know that the professor had broken into his own home, with the help of his chauffeur, because the door was jammed. 
What was unusual here was not the cop’s heavy-handedness.
Most people in the US know that if you talk back to the police, they will get nasty very fast.
The fact that the man was black might or might not have made the cop go for his handcuffs even sooner than he might normally have done.
That, too, would not have been unusual.
What made this case special was that Henry Louis “Skip” Gates is one of the most celebrated professors in the country, famous for his books, his articles, and numerous television appearances.
He is a grandee, a mover and shaker in the academic and media world, a friend of President Barack Obama.
That is why he warned the cop, Sgt. James Crowley, a veteran of the Cambridge police force, not to mess with him.
Class and race overlap in the US.
In this instance, it is impossible to pry them apart.
Gates, deeply conscious, indeed a specialist of the terrible history of race relations in his country, instinctively assumed that he was a victim of prejudice.
From his words it appears that he was equally conscious of not getting the proper respect due to a distinguished Harvard professor and media celebrity.
As he put it to his daughter in an interview published online: “[Crowley] should have gotten out of there and said, ‘I’m sorry, sir, good luck.
Loved your [television] series—check with you later!’”
Alas, Sgt.Crowley had never heard of Professor Gates.
A local man whose brothers all serve in the police force, a sports fan, and an amateur basketball coach, Crowley does not move in the same social circles as Gates.
As it happens, the charges were duly dropped, and there the case might have rested if President Obama, tired and frustrated after weeks of fighting for his healthcare bill, had not weighed in on behalf of his “friend” Gates, and called the police “stupid.”
Both he and Gates then spoke of “learning” from the incident.
Gates might even be planning a television documentary on racial profiling.
One thing to be learned, if we didn’t know this already, is how close racial sensitivities are to the surface of US life, despite the election of a black president.
The complexities of black anger, white guilt, and of black, and white fear, are so vexed that most Americans prefer not to talk about race at all.
The field is too full of mines.
One of Obama’s great achievements is that he made it into a serious topic through the brilliance and subtlety of his rhetoric.
And there remains plenty to talk about: the grotesquely disproportionate number of black men in US prisons; the lack of educational opportunities in poor, mostly black areas; the appalling healthcare system; and the very real brutality used by police officers against blacks, who don’t have the privilege of a Harvard ID.
It is probably true that many white policemen, even if they are trained to avoid racial profiling, as Sgt. Crowley was, need to be convinced that a black man can be at home in one of the finer houses of Cambridge, or any other American city.
But is the Gates affair the right way to enter into this discussion?
One might argue that it
There is, however, a danger that it will have an adverse affect on the necessary national discussion about race.
By having made such a big issue out of what was in fact a relatively minor event Gates could be accused of trivializing much worse instances of abuse.
Indeed, we don’t even know for certain whether this was such an instance.
Crowley never mentioned the color of Gates’ skin. There was no question of violence.
There were just very raw nerves and hypersensitivity to hints of disrespect, on the part of the professor, and of the cop.
Outrage about a professor who is not to be messed with is not the best way to discuss the plight of countless, poor, anonymous people, whom most of us find it too easy to ignore.
A Bollywood Bride for Sarkozy?
PARIS &#45;&#45; Ever since French President Nicolas Sarkozy took himself off his country’s most-eligible-bachelor list by publicly acknowledging his affair with supermodel-turned-pop-musician Carla Bruni during a romantic trip to Euro Disney, he’s run into trouble. 
His ratings have dipped below 50% for the first time.
Older French citizens don’t find the public spectacle of their leader in love very amusing.
Abroad, Egyptian lawmakers were so exercised over the prospect of the French head of state sharing a bed with his girlfriend that several vented their disapproval on the floor of the parliament. 
Likewise, India is all in a quandary over how to handle protocol during Sarkozy’s impending visit to the subcontinent as the guest of honor at the country’s Republic Day celebrations on January 26.
Should the First Girlfriend have her own motorcade, as a first lady would?
Meanwhile, the same hard-right Hindu groups that protest Valentine’s Day as a decadent Western holiday have warned that if Sarkozy arrives with his girlfriend in tow, they’ll be out in the streets to welcome him.
This controversy has threatened to cast a pall over a much-heralded summit between two of the world’s great democracies.
With lucrative deals at stake for the big-ticket products that drive the French economy – military hardware, nuclear power plants, and Airbus planes – France has a strong interest in a successful summit in India.
So, as rumors fly of secret marriage ceremonies either already concluded or in the works, could the trouble brewing in India over the French president’s very public love life be behind the rush to have the couple legally wed?
The news in Sarkozy’s favored media outlet
It’s “serious,” the smitten president admitted.
But he refused, even under direct questioning by reporters, to reveal an exact date.
“You’ll probably find out after it’s happened,” he taunted.
Rumor has it the couple has set February 8 or 9 for the wedding.   Others say that Sarkozy has already outsmarted the media by secretly marrying in the Elysee Palace, even as he was dodging wedding questions.
If that is true, then Sarkozy missed the romantic opportunity of a lifetime.
If the couple sizzled for cameras with Luxor and Petra as the backdrop, just imagine how hot things could get at the most romantic spot on Earth, the Taj Mahal.
And, given the current rage for all things Bollywood in France, a lavish Indian wedding would be fitting.
Bruni’s own life path closely resembles any number of Bollywood stars who have made the transition from model to actress.
A comely brunette who sings is perfect for a Bollywood makeover.
The Indian government will be nothing if not relieved to see the first girlfriend made a wife.
As one of India’s leading daily newspapers, the
Despite the sometimes downright pornographic on-screen writhing of Bollywood starlets, India is still a deeply conservative society.
Divorce is anathema. (Sarkozy is now twice divorced.)
And, while mistresses abound among the privileged classes, they do not strut publicly by their power-mates’ sides.
Kissing and fondling in public, even by spouses, is taboo.
In this respect, India more resembles the France with which Sarkozy wants to make a clean break than the current one.
Most Indians, as it seems many French, would prefer not to shed the “hypocrisy” Sarkozy laments on the part of his predecessors (read: former French President François Mitterrand, who had a child with his mistress about whom the public knew nothing until the man’s funeral).
Sarkozy, of all people, should know that a large part of the gravitas of office derives from pomp and circumstance.
Statecraft is a realm where appearances are meant to be deceiving.
When Sarkozy, who otherwise has such finely tuned media instincts, protests that he’s no different from any other man, he comes dangerously close to confusing the office and the person of the president.
Most French people could only dream of an exotic wedding in India.
Sarkozy could make that dream come true.
If he really is as head-over-heels in love with Bruni as he claims, and plans to marry her imminently, why not take advantage of his upcoming trip to India and make this a wedding to remember?
He could meet his bride seated majestically on the caparison of an elaborately decorated elephant, and she would look ravishing swathed and bejeweled in Indian finery.
The “bling-bling” president, as Sarkozy has been dubbed, can wear all the gold he wants and heap yet more diamonds on his bride. 
The cameras would roll, Indians would smile, and France would be treated to a Bollywood spectacle beyond its wildest dreams.
And if it’s too late for the wedding, there’s always the reception.
A Born-Again CAP
WAGENINGEN, NETHERLANDS – Born in 1957, the Common Agricultural Policy (CAP) is now more than 50 years old, and the European Commission is proposing what it calls a health check for its middle-aged child.
But superficial repairs will not meet the European Union’s future needs. The CAP must be born again.
Work on its renewal is due to start now, with the completed project ready in 2013. But a much more profound re-think is needed.
The CAP’s original aim was to provide a secure source of food for the six original member states of the Union, which were importers of food and sought a degree of self-sufficiency.
Good, healthy, and cheap food had to be accessible for all citizens.
Improved agricultural productivity would benefit rural areas and give farmers a comparative share in the Union’s growing wealth.
Instruments to achieve those objectives were developed, and food security was achieved.
The CAP quickly came to be seen as the jewel in the crown of the European project.
As the EU has evolved and expanded, food systems have become more complex, involving production, processing, supply-chain organization, and wholesale and retail distribution, with all of these involving new issues like health and the environment.
The use of land is also receiving more serious scrutiny.
A 1991 study by the Netherlands Scientific Council for Governmental Policy, entitled
Those figures were for an EU of 15 countries, so with today’s 27 members the possibilities are even greater.
A Dutch analysis of land use has shown that by employing the best technical and ecological means on the best available land, substantial gains could be made in food production.
So it is not surprising that the number of farmers needed has fallen substantially.
Viewed from the standpoint of food security and the wealth of rural areas, there is now an urgent need to revisit the CAP’s main instruments so that a new policy formula can be introduced.
Perverse subsidies must be removed and recent new ones favoring products such as bio-fuels reconsidered.
The
A simplified CAP would encourage cleaner, more productive, and efficient agriculture.
A side benefit for the EU’s standing in the world could be that the World Trade Organization’s stalled Doha negotiations could be restarted once farmers in developing countries are assured of getting a fair deal from Europe.
Moreover, the CAP’s role as a motor of political and social integration in Europe could be restored once renewed policies are in place.
But renewal of this sort cannot be left to global market forces, as the results might not necessarily benefit European agriculture and society.
If the market “misbehaves,” farmers could be reduced to poverty, leading to the neglect of large areas of Europe.
That is a real enough danger to which policymakers must give serious thought as they reform the CAP on the basis of the following five pillars.
1.&#160;&#160;&#160;&#160;&#160; The EU needs a knowledge and innovation policy that strengthens European agriculture’s competitiveness.
Such a policy has been successful in the Netherlands, substantially contributing to the development and power of the country’s agribusiness.
Ten of 21 branches of Dutch agribusiness, including horticultural seeds, ornamentals, seed potatoes, and veal, are among the top contributors to the national economy and the country’s trade balance.
In the EU as a whole, a policy directed toward research programs stimulating scientific excellence and greater coherence in the European knowledge system would greatly strengthen agriculture’s competitiveness and contribute to food security and sustainable development.
2.&#160;&#160;&#160;&#160;&#160; Europe also needs a restructuring policy for land use.
Many structural improvement programs have been financed at the European level, but agricultural production and land use are not among them.
The development of an Agricultural Main Structure would compliment the European Ecological Main Structure.
Reforestation and the repair of natural ecosystems should also be part of a land use policy.
3.&#160;&#160;&#160;&#160;&#160; A policy for European food systems would treat production, processing, distribution, logistics, and retailing in combination.
Consumption patterns and preferences are an integral part of such systems.
Preliminary studies by the European Science Foundation’s “Forward Look on European Food Systems” could prove useful in devising an EU-wide policy.
4.&#160;&#160;&#160;&#160;&#160; Metropolitan agriculture in a rapidly urbanizing world can provide high-quality produce on small amounts of land.
It offers an answer to rising demand for healthy food with minimal environmental side effects.
5.&#160;&#160;&#160;&#160;&#160; A new CAP should include a policy to safeguard Europe’s landscapes.
But a cultural heritage should not be maintained everywhere, nor should it ignore cost.
And it should not be a defensive policy of the sort that tends to concentrate on poor-quality land.
These five pillars involve drastic choices, but they will probably require less money from Europe’s taxpayers, not more.
They could make a real contribution to cleaner, more productive, and efficient farming and land use, while addressing social needs.
A Breakthrough Against Hunger
NEW YORK – Today’s world hunger crisis is unprecedentedly severe and requires urgent measures.
Nearly one billion people are trapped in chronic hunger – perhaps 100 million more than two years ago.
Spain is taking global leadership in combating hunger by inviting world leaders to Madrid in late January to move beyond words to action.
With Spain’s leadership and United Nations Secretary General Ban Ki-moon’s partnership, several donor governments are proposing to pool their financial resources so that the world’s poorest farmers can grow more food and escape the poverty trap.
The benefits of some donor help can be remarkable.
Peasant farmers in Africa, Haiti, and other impoverished regions currently plant their crops without the benefit of high-yield seed varieties and fertilizers.
The result is a grain yield (for example, maize) that is roughly one-third less than what could be achieved with better farm inputs.
African farmers produce roughly one ton of grain per hectare, compared with more than four tons per hectare in China, where farmers use fertilizers heavily.
African farmers know that they need fertilizer; they just can’t afford it.
With donor help, they can.
Not only do these farmers then feed their families, but they also can begin to earn market income and to save for the future.
By building up savings over a few years, the farmers eventually become creditworthy, or have enough cash to purchase vitally necessary inputs on their own.
There is now widespread agreement on the need for increased donor financing for small farmers (those with two hectares or less of land, or impoverished pastoralists), which is especially urgent in Africa.
The UN Secretary General led a steering group last year that determined that African agriculture needs around $8 billion per year in donor financing – roughly four times the current total – with a heavy emphasis on improved seeds, fertilizer, irrigation systems, and extension training.
In addition to direct help for small farms, donors should provide more help for the research and development needed to identify new high-yielding seed varieties, especially to breed plants that can withstand temporary flooding, excess nitrogen, salty soils, crop pests, and other challenges to sustainable food production.
Helping the poor with today’s technologies, while investing in future improved technologies, is the optimum division of labor.
This investment pays off wonderfully, with research centers such as the International Rice Research Institute and the International Maize and Wheat Improvement Centre providing the high-yield seeds and innovative farming strategies that together triggered the Asian Green Revolution.
These centers are not household names, but they deserve to be.
Their scientific breakthroughs have helped to feed the world, and we’ll need more of them.
Dozens of low-income, food-deficit countries, perhaps as many as 40-50, have elaborated urgent programs for increased food production by small farms, but are currently held back by the lack of donor funding.
These countries have appealed to the World Bank for financing, and the Bank made a valiant effort in 2008 to help through its new Global Food Crisis Response Program (GFCRP).
But the Bank does not yet have sufficient funds to meet these countries’ urgent needs, and has had to ration assistance to a small fraction of the flows that could be effectively and reliably used.
Hundreds of millions of people, in the meantime, remain trapped in hunger.
Many individual donor countries have declared that they are now prepared to increase their financial support for smallholder agriculture, but are searching for the appropriate mechanisms to do so.
The current aid structures are inadequate.
The more than 20 bilateral and multilateral donor agencies for agriculture are highly fragmented and of insufficient scale individually and collectively.
Despite the dedicated efforts of many professionals, the response to the hunger crisis remains utterly inadequate.
The 2008 planting seasons came and went with much too little additional help for impoverished small farmers.
African countries search endlessly, and mostly fruitlessly, for the small amounts of funding needed for their purchases of fertilizer and improved seeds.
My colleagues and I, serving on an advisory committee for the Spanish initiative, have recommended that donors pool their funds into a single international account, which we call the Financial Coordination Mechanism (FCM).
These pooled funds would enable farmers in poor countries to obtain the fertilizer, improved seed varieties, and small-scale irrigation equipment that they urgently need.
Poor countries would receive prompt and predictable financing for agricultural inputs from a single account, rather than from dozens of distinct and fragmented donors.
By pooling financial resources into a single-donor FCM, aid programs’ administrative costs could be kept low, the availability of aid flows could be assured, and poor countries would not have to negotiate 25 times in order to receive help. 
The time for business as usual is over.
The donors promised to double aid to Africa by 2010, but are still far off track.
Indeed, during the past 20 years, they actually cut aid for agriculture programs, and only now are reversing course.
Meanwhile, a billion people go hungry each day.
We need a breakthrough that is demonstrable, public, clear, and convincing, that can mobilize the public’s hearts and minds, and that can demonstrate success.
History can be made in Madrid at the end of January, when the world’s richest and poorest countries converge to seek solutions to the global hunger crisis.
The lives of the billion poorest people depend on it.
A Breakthrough Opportunity for Global Health
NEW YORK – Every year, millions of people die from preventable and treatable diseases, especially in poor countries.
In many cases, lifesaving medicines can be cheaply mass-produced, but are sold at prices that block access to those who need them.
And many die simply because there are no cures or vaccines, because so little of the world’s valuable research talent and limited resources is devoted to addressing the diseases of the poor.
This state of affairs represents a failure of economics and law that urgently needs to be corrected.
The good news is that there are now opportunities for change, most promisingly through an international effort headed by the World Health Organization that would begin to fix the broken intellectual-property regime that is holding back the development and availability of cheap drugs.
Two main problems limit the availability of medicines today.
One is that they are very costly; or, more accurately, the price charged for them is very high, though the cost of producing them is but a fraction of that amount.
Second, drug development is geared toward maximizing profit, not social benefit, which skews efforts directed at the creation of medicines that are essential to human welfare.
Because the poor have so little money to spend, drug companies, under current arrangements, have little incentive to do research on the diseases that afflict them.
It doesn’t have to be this way.
Drug companies argue that high prices are necessary to fund research and development.
But, in the United States, it is actually the government that finances most health-related research and development – directly, through public support (National Institutes of Health, National Science Foundation), and indirectly, through public purchases of medicine, both in the Medicare and Medicaid programs.
Even the part that is not government-financed is not a conventional market; most individuals’ purchases of prescription medicines are covered by insurance.
Government finances health-care research because improved medicines are a public good.
The resulting knowledge benefits everyone by stopping epidemics and limiting the economic and human toll of widespread illness.
Efficiency requires sharing research as widely as possible as soon as it is available.
Thomas Jefferson compared knowledge to candles: when one is used to light another, it does not diminish the light of the first.
On the contrary, everything becomes brighter.
Yet, in America and most of the world, drug prices are still exorbitant and the spread of knowledge is tightly limited.
That is because we have created a patent system that gives innovators a temporary monopoly over what they create, which encourages them to hoard their knowledge, lest they help a competitor.
While this system does provide incentives for certain kinds of research by making innovation profitable, it allows drug companies to drive up prices, and the incentives do not necessarily correspond to social returns.
In the health-care sector, it may be more profitable to devote research to a “me-too” drug than to the development of a treatment that really makes a difference.
The patent system may even have adverse effects on innovation, because, while the most important input into any research is prior ideas, the patent system encourages secrecy.
A solution to both high prices and misdirected research is to replace the current model with a government-supported prize fund.
With a prize system, innovators are rewarded for new knowledge, but they do not retain a monopoly on its use.
That way, the power of competitive markets can ensure that, once a drug is developed, it is made available at the lowest possible price – not at an inflated monopoly price.
Fortunately, some US lawmakers are taking a strong interest in this approach.
The Prize Fund for HIV/AIDS Act, a congressional bill introduced by Senator Bernie Sanders, is just such an initiative.
His bill also contains an important provision aimed at encouraging open-source research, which would move the current research model away from secrecy toward sharing.
But, globally, our innovation system needs much bigger changes.
The WHO’s efforts to encourage broad reforms at the international level are crucial.
This spring, the WHO released a report that recommends solutions similar to those proposed in the US Senate bill, but on a global level.
Importantly, the report, “Research and Development to Meet Health Needs in Developing Countries,” recommends a comprehensive approach, including mandatory funding contributions from governments for research on developing countries’ health needs; international coordination of health-care priorities and implementation; and a global observatory that would monitor where needs are greatest.
In late May, the international community will have a chance to begin implementing these ideas at the WHO World Health Assembly – a moment of hope for public health around the world.
Reforming our innovation system is not just a matter of economics.
It is, in many cases, a matter of life and death.
It is therefore essential to de-link R&amp;D incentives from drug prices, and to promote greater sharing of scientific knowledge.
For America, the Sanders bill marks important progress.
For the world, the WHO’s recommendations represent a once-in-a-generation opportunity to remedy a long-standing and egregious inequity in health care, and, more broadly, to set a model for governance of global public goods befitting an era of globalization.
We cannot afford to let this opportunity pass us by.
Absent-Minded Killers
As a species, human beings have a major self-control problem.
We humans are now so aggressively fishing, hunting, logging, and growing crops in all parts of the world that we are literally chasing other species off the planet.
Our intense desire to take all that we can from nature leaves precious little for other forms of life.
In 1992, when the world’s governments first promised to address man-made global warming, they also vowed to head off the human-induced extinction of other species.
The Convention on Biological Diversity, agreed at the Rio Earth Summit, established that “biological diversity is a common concern of humanity.”
The signatories agreed to conserve biological diversity, by saving species and their habitats, and to use biological resources (e.g., forests) in a sustainable manner.
In 2002, the treaty’s signatories went further, committing to “a significant reduction in the current rate of biodiversity loss” by 2010.
Unfortunately, like so many other international agreements, the Convention on Biological Diversity remains essentially unknown, un-championed, and unfulfilled.
That neglect is a human tragedy.
For a very low cash outlay – and perhaps none at all on balance – we could conserve nature and thus protect the basis of our own lives and livelihoods.
We kill other species not because we must, but because we are too negligent to do otherwise.
Consider a couple of notorious examples.
Some rich countries, such as Spain, Portugal, Australia, and New Zealand, have fishing fleets that engage in so-called “bottom trawling.”
Bottom trawlers drag heavy nets over the ocean bottom, destroying magnificent, unexplored, and endangered marine species in the process.
Complex and unique ecologies, most notably underground volcanoes known as seamounts, are ripped to shreds, because bottom trawling is the “low cost” way to catch a few deep sea fish species.
One of these species, orange roughy, has been caught commercially for only around a quarter-century, but already is being fished to the point of collapse.
Likewise, in many parts of the world, tropical rainforest is being cleared for pasture land and food crops.
The result is massive loss of habitat and destruction of species, yielding a tiny economic benefit at a huge social cost.
After cutting down a swath of rainforest, soils are often quickly leached of their nutrients so that they cannot sustain crops or nutritious grasses for livestock.
As a result, the new pasture land or farmland is soon abandoned, with no prospect for regeneration of the original forest and its unique ecosystems.
Because these activities’ costs are so high and their benefits so low, stopping them would be easy.
Bottom trawling should simply be outlawed; it would be simple and inexpensive to compensate the fishing industry during a transition to other activities.
Forest clearing, on the other hand, is probably best stopped by economic incentives, perhaps combined with regulatory limits.
Simply restricting the practice of land clearing probably would not work, since farm families and communities would face a strong temptation to evade legal limits.
On the other hand, financial incentives would probably succeed, because cutting down forest to create pastureland is not profitable enough to induce farmers to forego payments for protecting the land.
Many rainforest countries have united in recent years to suggest the establishment of a rainforest conservation fund by the rich countries, to pay impoverished small farmers a small amount of money to preserve the forest.
A well-designed fund would slow or stop deforestation, preserve biodiversity, and reduce emissions of carbon dioxide the burning of cleared forests.
At the same time, small farmers would receive a steady flow of income, which they could use for micro-investments to improve their household’s wealth, education, and health.
Aside from banning bottom trawling and establishing a global fund for avoided deforestation, we should designate a global network of protected marine areas, in which fishing, boating, polluting, dredging, drilling, and other damaging activities would be prohibited.
Such areas not only permit the regeneration of species, but also provide ecological benefits that spill over to neighboring unprotected areas.
We also need a regular scientific process to present the world with the evidence on species abundance and extinction, just as we now have such a process for climate change.
Politicians don’t listen very well to individual scientists, but they are forced to listen when hundreds of scientists speak with a united voice.
Finally, the world should negotiate a new framework no later than 2010 to slow human-induced climate change.
There can be little doubt that climate change poses one of the greatest risks to species’ viability.
As the planet warms, and rain and storm patterns change dramatically, many species will find themselves in climate zones that no longer support their survival.
Some can migrate, but others (such as polar bears) are likely to be driven to extinction unless we take decisive action to head off climate change.
These measures are achievable by 2010.
They are affordable, and in each case would ultimately deliver large net benefits.
Most importantly, they would allow us to follow through on a global promise.
It is too painful to believe that humanity would destroy millions of other species – and jeopardize our own future – in a fit of absent-mindedness.
Making Do With More
BERKELEY – In the United States, just three out of ten workers are needed to produce and deliver the goods we consume.
Everything we extract, grow, design, build, make, engineer, and transport – down to brewing a cup of coffee in a restaurant kitchen and carrying it to a customer's table – is done by roughly 30% of the country's workforce.
The rest of us spend our time planning what to make, deciding where to install the things we have made, performing personal services, talking to each other, and keeping track of what is being done, so that we can figure out what needs to be done next.
And yet, despite our obvious ability to produce much more than we need, we do not seem to be blessed with an embarrassment of riches.
One of the great paradoxes of our time is that workers and middle-class households continue to struggle in a time of unparalleled plenty.
We in the developed countries have more than enough to cover our basic needs.
We have enough organic carbon-hydrogen bonds to break to provide us with calories; enough vitamins and other nutrients to keep us healthy; enough shelter to keep us dry; enough clothing to keep us warm; enough capital to keep us, at least potentially, productive; and enough entertainment to keep us from being bored.
And we produce all of it for an average of less than two hours a day of work outside the home.
John Maynard Keynes was not off by much when he famously predicted in 1930 that the human race's “economic problem, the struggle for subsistence," was likely to be “solved, or be at least within sight of solution, within a hundred years."
It will take another generation, perhaps, before robots have completely taken over manufacturing, kitchen work, and construction; and the developing world looks to be 50 years behind. But Keynes would have been spot on had he targeted his essay at his readers' great-great-great-great grandchildren.
And yet there are few signs that working- and middle-class Americans are living any better than they did 35 years ago.
Even stranger, productivity growth does not seem to be soaring, as one would expect; in fact, it seems to be decelerating, according to research by John Fernald and Bing Wang, economists in the Economic Research Department of the Federal Reserve Bank of San Francisco.
Growth prospects are even worse, as innovation hits gale-force headwinds.
One way to reconcile the changes in the job market with our lived experience and statistics like these is to note that much of what we are producing is very different from what we have made in the past.
For most of human experience, the bulk of what we produced could not be easily shared or used without permission.
The goods we made were what economists call “rival" and “excludible" commodities.
Being “rival" means that two people cannot use the same product at the same time.
Being “excludible" means that the owner of a product can easily prevent others from using it.
These two traits put a great deal of bargaining power in the hands of those who control production and distribution, making them ideal for a market economy based on private property.
Money naturally flows to where utility and value are being provided – and those flows are easy to track in national accounts.
But much of what we are producing in the information age is neither rival nor excludible – and this changes the entire picture.
The creation of information-age goods is difficult to incentivize; their distribution is hard to monetize; and we lack the tools to track them easily in national accounts.
The result is an ever-growing discrepancy between what people would be willing to pay for a given service and growth as measured in national statistics.
In other words, we are producing and consuming much more than our economic indicators suggest – and the creators of many of those products are not being adequately compensated.
This produces a set of unique problems.
To ensure that the workers of today and tomorrow are able to capture the benefits of the information age will require us to redesign our economic system to stimulate the creation of these new types of commodities.
In addition to developing ways to account for this new type of wealth, we will have to develop channels through which demand for a product contributes to the income of its creator.
Only by finding ways to put true value on the goods we produce will we be able to sustain a middle-class society, rather than one of techno-plutocrats and their service-sector serfs.
The New Brain Drain in Science
DUBAI – In December 2013, the Nobel laureate physicist Peter Higgs told The Guardian that if he were seeking a job in academia today, “I don’t think I would be regarded as productive enough.”
Having published fewer than ten papers since his groundbreaking work in 1964, Higgs believes that no university would employ him nowadays.
Academics are well acquainted with the notion of “publish or perish.”
They must publish their work in peer-reviewed journals increasingly often to climb the career ladder, protect their jobs, and secure funding for their institutions.
But what happens to scientists and other scholars, such as those in the Middle East, who have different research concerns from – and scant connections to – the professional journals that can make or break an academic/scientific career?
Scholars and institutions with high publishing rates in the established journals receive better productivity scores, which translate into bigger rewards, in terms of enhanced careers and greater research funding.
Whether the work they are publishing has a measurable impact on their field of study is, sadly, too often a secondary concern.
The incentives they face mean that quantity often comes before quality.
Academic journals determine the various disciplinary rankings that academic institutions are compelled to climb, which leads institutions to hire and retain only those scholars who can produce at high rates.
This has given rise to a deeper, twofold problem: academic journals have become disproportionately influential, and they have placed a premium on empirical research.
With respect to the first problem, journals are gradually replacing institutions as the arbiters of quality within academic communities.
Scholars in almost any discipline seeking jobs at “A-level” institutions must publish in a select few A-level journals that are seen as gateways.
These journals’ editorial boards increasingly privilege positivist theoretical work – meaning research that is based on empirical data analysis.
Qualitative research – such as ethnographies, participatory surveys, and case studies – is often designated as suitable only for B- and C-level journals.
Academics conducting empirical research have a big advantage over those carrying out qualitative work, because they can use efficient software and powerful computers to test their hypotheses quickly and account for different variables in data sets.
This kind of work can be cheaper, too, because a single data set can generate multiple journal articles.
To be sure, there is nothing wrong with scientific practices evolving along with technology, or with academics using richer data sets and better software.
But adoption of this quantitative approach should not be the single most important criterion for assessing scientific excellence and deciding career trajectories.
After all, knowledge is acquired in different ways, and empirical positivism is only one method in a larger epistemological inventory.
The positivist trend in science today is particularly problematic for developing countries, where data sets are scarce and often of poor quality.
Thus, scientists working in developing countries face a dilemma: either work on rich-world problems for which there is abundant data, or risk career advancement by conducting qualitative work that will not make it into A-level journals.
Academics who move from data-rich countries in Europe and North America to data-poor countries in the Middle East and elsewhere often face this problem.
As researchers at my institution in Abu Dhabi know, conducting surveys for qualitative research is feasible; but generating rich data from scratch for theory-building research is extremely difficult.
At the International Conference on Science and Technology Indicators this year, a French academic researching soil in Africa reported that only 5% of the published work in his field has originated from African researchers.
When he dug deeper into his own research, he found that 50% of what he had learned about African soil came from African researchers, who have not or could not publish their work in international academic journals.
Countries where English is not the lingua franca are particularly disadvantaged in science, not because they lack academic excellence, but because English-language journals call the shots.
Non-English academic journals simply do not command the same attention in the science community.
As a result, the scope of research topics that many countries can undertake is limited, and they must struggle to retain scientific talent.
This is particularly true in the Middle East, where governments are struggling to diversify their economies, in order to make them more resilient.
As English-language empirical-research journals consolidate their hold on the channels that determine whether or not a scientist will have a successful career, developing countries will have to invest heavily in their own data infrastructure to place domestic researchers on a more competitive footing.
But even – or especially – if developing countries do make such investments, much will be lost to science.
With (mostly) United States-based academic journals reigning over global science, no one has to move to become part of a new brain drain, whereby scientists’ research priorities, problems, and methods gravitate to the dominant positivist epistemology, at the expense of all alternatives.
Polluters Must Pay
NEW YORK – When BP and its drilling partners caused the Deepwater Horizon oil spill in the Gulf of Mexico in 2010, the United States government demanded that BP finance the cleanup, compensate those who suffered damages, and pay criminal penalties for the violations that led to the disaster.
BP has already committed more than $20 billion in remediation and penalties.
Based on a settlement last week, BP will now pay the largest criminal penalty in US history – $4.5 billion.
The same standards for environmental cleanup need to be applied to global companies operating in poorer countries, where their power has typically been so great relative to that of governments that many act with impunity, wreaking havoc on the environment with little or no accountability.
As we enter a new era of sustainable development, impunity must turn to responsibility.
Polluters must pay, whether in rich or poor countries.
Major companies need to accept responsibility for their actions.
Nigeria has been Exhibit A of corporate environmental impunity.
For decades, major oil companies, including Shell, ExxonMobil, and Chevron, have been producing oil in the Niger Delta, an ecologically fragile environment of freshwater swamp forests, mangroves, lowland rainforests, and coastal barrier islands.
This rich habitat supports remarkable biodiversity – or did before the oil companies got there –&#160;and more than 30 million local inhabitants, who depend on the local ecosystems for their health and livelihoods.
Twenty years ago, the International Union for Conservation of Nature and Natural Resources classified the Niger Delta as a region of high biodiversity of marine and coastal flora and fauna – tree species, fish, birds, and mammals, among other forms of life – and therefore rated it as a very high priority for conservation.
Yet it also noted that the region’s biodiversity was under massive threat, with little or no protection.
The global companies operating in the delta have spilled oil and flared natural gas for decades, without regard for the natural environment and the communities impoverished and poisoned by their actions.
One estimate puts the cumulative spills over the past 50 years at approximately 10 million barrels – twice the size of the BP spill.
The data are uncertain: there have been many thousands of spills during this period – often poorly documented and their magnitude hidden or simply unmeasured by either the companies or the government.
Indeed, just as BP was being hit with new criminal penalties, ExxonMobil announced yet another pipeline leak in the Niger Delta.
The environmental destruction of the delta is part of a larger saga: corrupt companies operating hand in hand with corrupt government officials.
The companies routinely bribe officials to gain oil leases, lie about output, evade taxes, and dodge responsibility for the environmental damage that they cause.
Nigerian officials have become fabulously wealthy, owing to decades of payoffs by international companies that have plundered the delta’s natural wealth.
Shell, the largest foreign operator in the Niger Delta, has been criticized repeatedly for its egregious practices and its unwillingness to be held to account.
Meanwhile, the local population has remained impoverished and beset by diseases caused by unsafe air, poisoned drinking water, and pollution in the food chain.
Local lawlessness has led to gang warfare and persistent illegal tapping into the pipelines to steal oil, leading to further massive oil spills and frequent explosions that kill dozens, including innocent bystanders.
In the colonial era, it was the official purpose of imperial power to extract wealth from the administered territories.
In the post-colonial period, the methods are better disguised.
When oil companies misbehave in Nigeria or elsewhere, they are protected by the power of their home countries.
Don’t mess with the companies, they are told by the United States and Europe.
Indeed, one of the largest bribes (a reputed $180 million) paid in recent times in Nigeria was by Halliburton, a company tightly intertwined with US political power.
(Dick Cheney went from being Halliburton’s CEO to the US vice presidency.)
Last year, the United Nations Environment Program (UNEP) issued a remarkable report on Ogoniland, a major ethnic homeland in the Niger Delta that has been at the epicenter of conflict between local communities and international oil.
The report was as scathing as it was scientifically clear.
Despite many past promises of a cleanup, Ogoniland remains in environmental agony, impoverished and sickened by the oil industry.
UNEP also offered clear and detailed recommendations, including emergency measures to ensure safe drinking water; cleanup activities targeting the mangroves and soils; public-health studies to identify and counteract the consequences of pollution; and a new regulatory framework.
The world’s governments have recently agreed to move to a new framework for sustainable development, declaring their intention to adopt Sustainable Development Goals at the Rio+20 Summit in June.
The SDGs offer a critical opportunity for the world to set clear, compelling standards for government and corporate behavior.
Many major companies, including in the oil industry, have expressed their readiness to support sustainable development goals.
Cleaning up the Niger Delta would provide the strongest possible example of a new age of accountability.
Shell, Chevron, ExxonMobil, and other major oil companies should step forward and help to fund the necessary cleanup, ushering in a new era of responsibility.
The Nigerian government’s own accountability is on the line as well.
It is heartening that several Nigerian senators have recently been in the forefront of efforts to strengthen the rule of law in the oil sector.
The cleanup of the Niger Delta provides an ideal opportunity for Nigeria, the oil industry, and the international community to show convincingly that a new age has dawned.
From now on, sustainable development must not be a mere slogan, but rather an operational approach to global governance and well-being on a strained and crowded planet.
A Centerless Euro Cannot Hold
CAMBRIDGE – With youth unemployment touching 50% in eurozone countries such as Spain and Greece, is a generation being sacrificed for the sake of a single currency that encompasses too diverse a group of countries to be sustainable?
If so, does enlarging the euro’s membership really serve Europe’s apparent goal of maximizing economic integration without necessarily achieving full political union?
The good news is that economic research does have a few things to say about whether Europe should have a single currency.
The bad news is that it has become increasingly clear that, at least for large countries, currency areas will be highly unstable unless they follow national borders.
At a minimum, currency unions require a confederation with far more centralized power over taxation and other policies than European leaders envision for the eurozone.
What of Nobel Prize winner Robert Mundell’s famous 1961 conjecture that national and currency borders need not significantly overlap?
In his provocative American Economic Review paper “A Theory of Optimum Currency Areas,” Mundell argued that as long as workers could move within a currency region to where the jobs were, the region could afford to forgo the equilibrating mechanism of exchange-rate adjustment.
He credited another (future) Nobel Prize winner, James Meade, for having recognized the importance of labor mobility in earlier work, but criticized Meade for interpreting the idea too stringently, especially in the context of Europe’s nascent integration.
Mundell did not emphasize financial crises, but presumably labor mobility is more important today than ever.
Not surprisingly, workers are leaving the eurozone’s crisis countries, but not necessarily for its stronger northern region.
Instead, Portuguese workers are fleeing to booming former colonies such as Brazil and Macau.
Irish workers are leaving in droves to Canada, Australia, and the United States.
Spanish workers are streaming into Romania, which until recently had been a major source of agricultural labor in Spain.
Still, if intra-eurozone mobility were anything like Mundell’s ideal, today we would not be seeing 25% unemployment in Spain while Germany’s unemployment rate is below 7%.
Later writers came to recognize that there are other essential criteria for a successful currency union, which are difficult to achieve without deep political integration.
Peter Kenen argued in the late 1960’s that without exchange-rate movements as a shock absorber, a currency union requires fiscal transfers as a way to share risk.
For a normal country, the national income-tax system constitutes a huge automatic stabilizer across regions.
In the US, when oil prices go up, incomes in Texas and Montana rise, which means that these states then contribute more tax revenue to the federal budget, thereby helping out the rest of the country.
Europe, of course, has no significant centralized tax authority, so this key automatic stabilizer is essentially absent.
Some European academics tried to argue that there was no need for US-like fiscal transfers, because any desired degree of risk sharing can, in theory, be achieved through financial markets.
This claim was hugely misguided.
Financial markets can be fragile, and they provide little capacity for sharing risk related to labor income, which constitutes the largest part of income in any advanced economy.
Kenen was mainly concerned with short-term transfers to smooth out cyclical bumpiness.
But, in a currency union with huge differences in income and development levels, the short term can stretch out for a very long time.
Many Germans today rightly feel that any system of fiscal transfers will morph into a permanent feeding tube, much the way that northern Italy has been propping up southern Italy for the last century.
Indeed, more than 20 years on, Western Germans still see no end in sight for the bills from German unification.
Later, Maurice Obstfeld pointed out that, in addition to fiscal transfers, a currency union needs clearly defined rules for the lender of last resort.
Otherwise, bank runs and debt panics will be rampant.
Obstfeld had in mind a bailout mechanism for banks, but it is now abundantly clear that one also needs a lender of last resort and a bankruptcy mechanism for states and municipalities.
A logical corollary of the criteria set forth by Kenen and Obstfeld, and even of Mundell’s labor-mobility criterion, is that currency unions cannot survive without political legitimacy, most likely involving region-wide popular elections.
Europe’s leaders cannot carry out large transfers across countries indefinitely without a coherent European political framework.
European policymakers today often complain that, were it not for the US financial crisis, the eurozone would be doing just fine.
Perhaps they are right.
But any financial system must be able to withstand shocks, including big ones.
Europe may never be an “optimum” currency area by any standard.
But, without further profound political and economic integration – which may not end up including all current eurozone members – the euro may not make it even to the end of this decade.
Achieving a “Europe of Results”
BRUSSELS – The tsunami that has swept across financial markets is a global catastrophe.
If handled correctly, however, the crisis may yet raise the esteem of the European Union and its institutions.
The EU’s legitimacy problem has two different aspects: apathy, leading to a low turnout in the European parliamentary elections, and outright euro-skepticism.
The voter-turnout problem partly reflects frustration about the present state of the EU, and also people’s impression that they can exert little influence by voting one way or the other.
Euro-skepticism, on the other hand, and the looming threat of anti-European populism, is directly linked to the idea that the EU is not merely incapable of offering a solution to the crisis, but in fact is part of the problem.
So, although the EU represents our best hope of ensuring that Europe is internationally competitive in today’s increasingly difficult environment, it is actually being blamed for globalization.
Many people confuse these two aspects of the EU’s legitimacy problem, and believe that somehow turnout in European elections can be increased by pointing out to people how good and important the EU is.
But in most cases, this is not possible.
At first sight, the easiest answer to the problem of low voter turnout is to give more power to the European Parliament.
But if this was the solution, then we would not have had steadily declining turnouts since the high point of 63%, at the first elections to the European Parliament in 1979. After all, since then the EP’s influence and powers of joint decision-making have grown constantly.
The trouble is that, EP elections must be “about” something if voters are to be interested, which means they must involve a real choice.
And a real choice requires Europe-wide election campaigns by all parties. This would also involve making the choice of the European Commission’s president dependent on the outcome of the EP elections.
But, in fact, both of these conditions have already been met; in 2004, Portuguese Prime Minister José Manuel Durão Barroso was appointed President of the Commission because he came from the political organization with the strongest election result, the European People’s Party.
And this year’s elections saw a more intensive presence of party organizations at European level than ever before.
Instead, I believe that the most important way to reawaken voters’ interest in European elections will be to open up the election of the Commission’s President to them, and create a genuinely Europe-wide political debate during the next election campaign.
The Euro-skepticism problem can be tackled only if the Union itself starts to perform better, and is seen to be doing so.
That is why in the aftermath of the failed referenda four years ago in France and the Netherlands on the Constitutional treaty, the Commission tried to emphasize the idea of a “Europe of Results” that would seek to convince citizens of its worth through concrete achievements.
Given the gravity of the economic crisis, the time has come for the EU to demonstrate its strengths whenever possible.
The aim must be not only to win back the hearts of Europeans who have become skeptical, but also to convince them that the Union is indispensable to meeting the challenges Europeans face.
Europe’s citizens understand that the relatively small nation-states that make up the EU are no longer able to face these enormous challenges on their own.
In Ireland, last autumn’s financial crisis provoked a turnaround in public opinion about the EU, and even in Iceland, although it lies on the periphery of our continent, membership of the EU and the euro have become a priority.
European countries have become so interconnected that isolated national measures on issues like financial-market regulation are hopeless.
A changing world in which new powers like China and India play an increasingly important role will not wait for Europe to make up its mind.
The EU must instead show leadership through its efforts to solve the world’s current problems.
As for the European People’s Party, for us the economy is not an end in itself but should serve the people.
The economic crisis was caused by shortsightedness and a lack of control in the global financial system. Now we must redefine the role of regulators in financial markets and in the wider economy, for we cannot let the financial sector walk off with the profits and leave taxpayers bearing the losses.
That doesn’t mean that we are advocating a move to socialism; we want better and smarter regulation, not regulation for its own sake.
We see five keys to recovery:
New job creation must be a core priority, with reform and investment in education and life-long learning necessary to create opportunity for all;
A “Europe of Results” is achievable.
It can strengthen the EU’s legitimacy, though, only if policy recommendations such as these, and the successes that result from implementing them, are communicated clearly and effectively to the general public.
A Clarion Call for Emerging Markets
ITHACA – With 2012 underway, it is worth reflecting on how a decade of strong economic growth in emerging markets led to last year’s resounding political transformations.
From the dramatic events in the Middle East, to the groundswell of support for the anti-corruption crusader Anna Hazare in India, leaders in emerging markets are getting a clear message from the streets that growth is not everything.
They ignore this message at their peril.
Emerging-market economies delivered solid growth during the 2000’s, and even survived the global financial crisis without a growth collapse.
But the specter of rising corruption is compromising the legitimacy of their economic gains and eroding support for further reforms needed to sustain their growth momentum.
Corruption takes many forms, but, in emerging markets, a combination of factors has turned it into a cancer that ultimately topples regimes.
Relentless low-level corruption is a major irritant for poor people in many of these countries; indeed, it limits their access to the social services and basic government functions that they often depend upon for their very survival.
Another type of corruption involves siphoning enormous sums of money from large-scale projects.
In India, for example, the government lost as much as $30-40 billion of much-needed revenue when coveted band spectrum was sold through a rigged auction.
For ordinary people, large-scale corruption is less visible, because, while the sums involved are mind-boggling, the costs are not as directly felt as they are in the case of lower-level graft.
But the perception of this type of mega-corruption has changed as rapid growth has increased inequality.
In countries like China and India, rapid economic growth has lifted a huge number of people out of poverty.
But the fruits of globalization and rapid growth have not been evenly shared – the rich become super-rich, even as a large fraction of the population remains destitute.
Rising income inequality is hardly limited to emerging markets, but their combination of open corruption and pervasive inequities creates a toxic brew that is undermining support for reforms that would strengthen and consolidate their economic gains.
In many emerging markets, a lack of political freedom adds to the combustible mix.
The combination of corruption, inequality, and political repression builds up enormous pressure, and there are no institutional channels through which to release it.
But freer political regimes are not a panacea.
In a democracy like India’s, the politically well-connected benefit from skewed growth, thus increasing the resentment of those left behind.
The opportunity to “throw the rascals out” in each election cycle helps to let off some steam, but it does not resolve the problems that are generating it.
It is difficult to predict what triggers popular protest, but economic factors are key.
For example, rising food prices tend to hurt the poor, especially the urban poor, who spend a large share of their income on food; unlike agricultural workers, they receive none of the benefits of higher food prices.
With swelling urban populations, it will become increasingly difficult to keep a lid on these pressures.
Some governments have reacted to recent events with political repression, information blackouts, or a combination of authoritarian measures.
China, for example, blocked media coverage of the Egyptian protests.
The Arab Spring, however, reveals the fragility of repressive political regimes that try to maintain their legitimacy by limiting information flows.
The main lesson for dynamic emerging-market countries is that an exclusive focus on GDP growth may ultimately not be good for economic and political stability.
Even with rapid increases in national income, if these countries’ leaders do not distribute the benefits fairly, they will become vulnerable to popular discontent.
Tackling corruption is critical to improving long-term growth and maintaining social stability.
These economies need measures that help to keep the poor out of poverty traps, and that give them realistic opportunities to improve their economic well-being.
Such steps include broadening financial markets to give more people access to credit and investment, strengthening social safety nets to protect the economically vulnerable, and improving educational access and quality.
These lessons apply equally to advanced economies, which also suffer from rising inequality and subtle forms of corruption.
But, for those wealthy economies, restoring decent growth is now the major priority.
Emerging markets have a golden opportunity to build on their economic gains and lock in growth and stability by tackling deep-seated problems like corruption.
As the past year’s events have shown, the costs of inaction could be calamitous.
A Climate Deal is Not Enough
AMSTERDAM – During the COP15 climate summit in Copenhagen, world leaders have been negotiating the future of our planet. All the signs suggest that they are unlikely to sign a global climate treaty.
The politicians, civil servants, and other participants at the Copenhagen summit have mainly been bombarding each other with numbers.
Figures on how much various countries should reduce CO2 emissions, the amount of money they should put up in coming years, the exact nature of their responsibilities, how much temperature increase Earth will be able to endure, and how long we can continue to wait.
These are all very important issues.
But the mere figures are simply not enough. A different approach to the problem of climate change is needed.
The climate issue can only be solved on the basis of shared, deeply felt ethical principles.
Humanity has reached a critical moment in Earth’s history, at which peoples and nations will have to recognize their solidarity – with each other and with the Earth – and start acting upon it.
Similar to the way world leaders adopted the United Nations Millennium Declaration in September 2000, and embraced the resulting Millennium Development Goals, today’s climate negotiators will have to commit themselves to creating a basis of shared fundamental ethical principles.
Such a basis is not hard to find.
Its inspiration can be the Earth Charter, which, launched in 2000, was initiated by, among others, former USSR President Mikhail Gorbachev and Wangari Mathaai, who received the 2004 Nobel Peace Prize for her efforts in the Green Belt Movement, a pan-African tree-planting initiative.
The climate problem does not stop at borders.
In the next few decades, a low-lying country like the Netherlands will need to invest billions of euros to intensify its age-old struggle against rising water.
But in many other countries, the water is already flooding over the dikes, both literally and figuratively.
Climate change affects particularly those countries that lack the money needed to take adequate measures against rising sea levels, persistent droughts, or devastating storms, even though they had nothing to do with the primary cause of these problems – industrialization in the developed countries.
Apart from the necessary, often infrastructural adaptations to survive the effects of climate change, enormous efforts to prevent even worse things from happening are required.
Large investments in forestation, agriculture, and energy supply are called for.
In devising solutions, the role of women should be the main focus.
Women are often the first people who have to address the problem of gaining access to natural resources, and they are capable of playing a major role as pioneers in finding solutions to climate change and the way humankind should adapt to it.
In the short term, the world should become a sustainable global society of low CO2 emitters.
This is a mission for all humankind, in which patriotic feelings and thinking in terms of power blocs have no place.
The pursuit of a sustainable global society of low CO2 emitters requires a tremendous effort.
Precisely for this reason, it also requires a broadly shared ethical basis.
This would guide the negotiating parties in such a way that they look not only for solutions to a part of the problem, but first and foremost at a comprehensive solution to the entire problem.
The climate change issue is too important to be left in the care of politicians.
In Copenhagen, it is therefore imperative that not only nation states, but the business community and citizens combine their efforts to save our planet’s climate. That is not only a scientific necessity; it is an ethical imperative.
A Communist Party without Communism
PRINCETON – Russian President Vladimir Putin’s anointment of Alexander Medvedev to succeed him in what is supposed to be a democratic presidential election next March shows that Russia’s leaders have not changed a whit.
It looks increasingly likely that, as under Leonid Brezhnev, we will see the same names in the news for decades to come.
According to Gleb Pavlovsky, the Putin regime’s leading ideologist, the current Russian system is perfect in all respects but one: it doesn’t know its enemies.
Indeed, it seems as if everyone in the Kremlin is reading Carl Schmitt, the Nazi legal theorist who taught that naming your enemy is the central mission of politics.
In the spirit of Schmitt, Putin’s men designated a liberal party, the Union of Right Forces, as their ur-enemy.
Its public meetings were broken up by armed police; its leaders arrested and beaten; Putin called its supporters “coyotes.”
What is surprising is that this aggressive behavior occurred in response to no visible danger.
Oil prices are soaring, as are Putin’s approval ratings.
His appointees control everything that matters, from Gazprom to the Central Electoral Committee.
Since the pacification of Chechnya with violence and subsidies, the incarceration or emigration of a few financially viable opponents, and the massive “social investments” of recent years, which, under Medvedev’s personal supervision, have bribed the population, no credible force can seriously challenge Putin’s men.
Yet their regime is in crisis, and they know it.
Russia’s economy is more dependent on gas and oil than ever before.
Military reform has been reversed.
Despite increasing incomes, Russians are less educated and less healthy than they were when Putin came to power; they still die at a shockingly young age.
Russian involvement in world affairs is tainted by poison and corruption.
State monopolies undo what private businesses created.
With more money, ill-educated bureaucrats hire more ill-educated bureaucrats; as a result, the regime fails to rule the country.
The country is unruly, and its rulers know it.
So they panic.
Putin’s aim was to subject all power to the control of Russia’s security forces.
His generation of KGB officers watched the collapse of the Communist Party and all the governmental bodies that it “directed and controlled,” including the KGB.
Under Putin, the security service has had its revenge.
Its people have become powerful, arrogant, and enormously rich.
They have also become disobedient.
In 2004, General Viktor Cherkesov, then Putin’s representative in northwest Russia, published an essay that glorified the KGB as the only unspoiled authority in a corrupted country.
This essay, more than anything else, defined Putin’s second term.
In October 2007, Cherkesov (now chief of one of the most obscure and powerful services, the Federal Anti-Drug Administration) published another essay in which he lamented his colleagues’ degradation: warriors had turned into traders, he complained.
Earlier, generals from a competing service, the FSB, had arrested Cherkesov’s deputy for “illegal bugging.”
In a public gesture of despair, Cherkesov admitted the failure of Putin’s project to reanimate Russian governance by subordinating it to the security services.
Cherkesov’s deputy remains in prison.
Most believe that Putin is unable to intervene in his defense.
In the absence of Communist Party control, these security officers betrayed their corporate ethic and engaged in horse-trading, applying force when a trade did not go well.
That this happens to ordinary Russians is clear; what Cherkesov revealed was that Putin’s circle also confronts this situation.
What is to be done when ex-KGB warriors turn their swords and bugs against one another?
Cherkesov’s case exemplifies Putin’s nightmare.
But if your instincts betray you, you go back to even deeper ones.
Now that Putin’s people have left their predecessors’ neo-liberal ideas behind and feel disenchanted with the ex-KGB clique, the task is to recreate an omnipresent political party that controls the security services, the administration, business, and much else.
This party will be centralized under personal leadership and will reduce the state to a legal fiction.
Preaching nationalism, its managers will believe in their universal competence, as opposed to KGB-style professionalism and corporatism.
Boris Yeltsin forbade party cells in state-controlled institutions by decree.
Putin’s lawyers will reverse that decision; the party will have cells or committees in every factory, corporation, military unit, university department, etc.
Integrated by the leader’s charisma and party discipline, party members will direct and unify the desolated country.
This is Putin’s plan.
Like former Soviet leader Yuri Andropov, the only other KGB man to rule Russia, Putin will become the party’s general secretary.
As in the Soviet era, state and governmental officials will be reduced to party ciphers – the role that President Medvedev will play under General Secretary Putin.
And, of course, being General Secretary carries no constitutional term limit.
In the end, Putin has what history left him: not ideas, just a faction yearning to consolidate its grip on power.
Lenin and Trotsky needed a party to make their ideology a reality; Putin and Medvedev are devising an ideology to solidify their party.
It is a bizarre ideology.
Accusing warriors of being traders and traders of being thieves, it shuns its Marxist origins.
It will subordinate all who really do work – traders, warriors, journalists, and others – to party ideologues whose sole job is to search for enemies.
A Confederal Solution for Palestine
LONDON – Last month, while in New York City, I happened to be staying in the same hotel as Israeli Prime Minister Binyamin Netanyahu.
To accommodate his security needs, the hotel had been converted into a fortress, much like Israel itself.
Netanyahu was in the United States for yet another round of Middle East peace talks.
The US offered various sweeteners to induce Israel to freeze its West Bank settlement construction for another 90 days.
The Israelis refused; another impasse was reached.
What, then, might be the prospects of a negotiated peace between two peoples with claims to the same land?
The answer is: very poor.
All peace efforts since the Oslo accords of 1993 have been based on the “two-state solution,” according to which Israel is supposed to turn over the occupied territories to a Palestinian state, the Palestinians are supposed to renounce any claims on the Jewish state, and everyone is supposed to live happily ever after.
A negotiated “land for peace” solution still remains official Western doctrine.
As US Secretary of State Hillary Clinton put it in a recent speech, “a just, lasting, and comprehensive peace” has to be based on “two states for two peoples.”
Meanwhile, the two main parties to the dispute, Palestine and Israel, are searching for unilateral alternatives to the stymied “peace process.”
The Palestinians are pushing for international recognition of their statehood, while the Israelis are using their settlement policy to preempt a Palestinian state.
Palestinian President Mahmoud Abbas has said that, if the latest peace talks collapse, he will press for UN recognition of a Palestinian state based on the 1967 borders.
This month, Brazil and Argentina recognized “Palestine,” and a cascade of Latin American countries is expected to follow.
Abbas is now setting his sights on Europe, and would ask Turkey to serve as a go-between.
The game is to use international recognition of an independent Palestinian state to pressure the US to retreat from its almost unconditional support for Israeli policy.
Israel’s main concern continues to be security.
The official Western doctrine is that Israel’s long-term security depends on the success of the “peace process.”
In practice, Israel has been taking other measures to secure its future.
Media attention has been focused on the “security wall,” which has certainly succeeded in reducing the level of violence.
But, to the hawks who now control Israeli politics, the key to Israel’s security depends on depth of defense, for which expansion of the settlements is indispensable.
The hawks’ recipe for survival is threefold: continued military and economic support from the US, defensible frontiers through a strategic settlement program, and the carve-up of the Palestinian West Bank into disconnected bantustans, or subordinate authorities, incapable of concerted opposition to Israeli policy.
Thus, while Abbas seeks to create a new “fact on the ground” by drumming up international support for a Palestinian state, Israel aims to trump him by making such a state unviable.
The ideal alternative to both strategies is a peace process that aims not to create two states, but rather to establish the political and economic basis for a single confederal state.
Indeed, the two-state solution was always an illusion.
There was never enough land to satisfy the passionate possessiveness of all those with claims to it.
And, over time, Israeli settler disengagement from the West Bank and East Jerusalem has become just as impossible as any attempt by Israel to expel its remaining Arabs.
Israeli Jews are bound to stay in the West Bank and East Jerusalem, and Israeli Arabs are bound to stay in Israel proper.
These are the “facts on the ground” that doom Palestinian hopes for a sovereign Palestinian state no less than Israeli hopes for a wholly Jewish state.
Moreover, land for peace never made sense from an economic point of view.
If compensation for wrongs to the Palestinians was to be the guiding principle, there were always better ways of going about it than to found a rickety, poverty-ridden new country dependent on foreign aid.
Most people have forgotten that the Paris Protocols of April 1994 established a customs union between Israel and the occupied territories, with a joint Economic Council to adjudicate trade disputes.
The free movement of goods, labor, and capital between the two parts could have given a tremendous economic boost to Palestinian GDP.
It could also have been the basis of a confederal state, whose Palestinian part would have benefited from the West Bank settlers’ productivity and taxes.
But this benign prospect was undermined by the violence needed to maintain the Jewish state and enable the emergence of a Palestinian one.
The official view remains that only an internationally guaranteed two-state settlement will bring about the security needed for the economic revival of the Palestinian territories.
But it is just possible that unilateral Israeli policy, implicitly backed by the US, will create interim conditions of peace that are sufficient for economic growth to cool Palestinian nationalism.
The Palestinian cause is not the overriding preoccupation of even the Arab states, so Netanyahu’s strategy of defense in depth stands a better chance of success than Abbas’s pursuit of statehood through international recognition.
Netanyahu’s project is not moral.
But that doesn’t mean that it won’t work, at least for a time.
A Confederation for Kosovo
Time is running out in Kosovo.
If a United Nations-backed settlement is not reached by early December, the province’s majority Albanian population is likely to declare independence unilaterally – a move that the United States has announced it may support.
That would be a disastrous step.
Russia would be furious, because it fears that Kosovo’s secession – whether or not it is internationally recognized – might fuel separatist movements in the former Soviet empire.
Serbia is even more strongly opposed.
Dusan Prorokovic, Serbia’s state secretary for Kosovo, has said that his country might use force to maintain its sovereignty.
Even if the government hesitates, ultranationalist groups might push Prime Minister Vojislav Kostunica to send in troops: the current UN presence in Kosovo is very thin (only 40 “military observers” and 2,116 policemen) but the stationing of 15,000 NATO troops could make any armed clash very dangerous.
After eight years of international administration, Kosovo’s Albanian majority has tasted freedom and is eager for full independence.
But Serbia claims that the province remains an essential part of its historical and cultural tradition.
Moreover, independence would not be accepted by the Serbian public, which has already watched in dismay as “Great Serbia” has been gradually whittled away, most recently with the secession of Montenegro.
Serbia is prepared to concede only “enhanced autonomy” to Kosovo, and some capacity to enter into international agreements.
Yet, while the two parties now seem irreconcilable, it is not too late for compromise.
But this is possible only by resuscitating – and updating – an old institution of the international community: a confederation of states.
By means of a binding UN Security Council resolution, Kosovo could be granted full and exclusive authority over its citizens and territory, as well as limited capacity for action on the international scene.
It could be authorized to enter into trade agreements as well as agreements concerning individuals (for example, admission and circulation of foreigners, or extradition), plus the right to seek admission to the UN (which does not require full sovereignty and independence).
Kosovo would thus gain some essential trappings of statehood.
However, a decision-making body consisting of delegates from Kosovo, Serbia, and the European Union would be given full authority over major foreign policy issues (for example, alliances and relations with international economic institutions), defence, borders (in case Kosovo wished to join with Albania), and the treatment of Kosovo’s Serbian minority.
As a result, Kosovo and Serbia would constitute two distinct international subjects, bound by a confederation hinging on a common decision-making body.
Of course, this confederation would be asymmetrical, because the Serbian government’s sovereignty over the rest of Serbia would remain intact and unlimited, whereas the Kosovar government’s “sovereignty” over Kosovo would be restrained.
To avoid one of the two parties getting the upper hand and imposing arbitrary decisions, the common decision-making body should consist of four Serbian delegates, two Kosovar delegates, and three representatives of the EU, thus requiring both sides to gain the support of the European delegates.
In addition, the EU should create a small but effective military force (say, 5,000 troops) to back up the common body’s decisions.
As with any compromise, the contending parties would both gain and lose from this arrangement.
Serbia would save face, and would continue to have a say on crucial matters concerning Kosovo, including the treatment of the Serbian minority.
Kosovo would acquire limited independence, with its status rising from a province of a sovereign state to an international subject capable of entering into certain agreements with other states and even joining the UN.
The EU would benefit as well, by contributing to the stabilization of a highly volatile area.
Subsequently, the EU would monitor Kosovo and prevent any dispute that might turn violent.
A final advantage of this solution is that it would be temporary.
Historically, confederations sooner or later either become federations (as occurred in the US, Germany, and Switzerland) or, pushed by centrifugal forces, split up (as with the United Arab Republic, established in 1958, which split three years later into Egypt and Syria).
The confederation I advocate would thus constitute an intermediate stage (lasting five or ten years), at the end of which Kosovo is likely to become fully independent.
Delaying a final solution in this way would provide time to verify Kosovo’s prospects of joining the EU and thus eventually sharing “sovereign authority” with other independent states, which could deflate Kosovars’ dangerously robust nationalistic demands.
A Cool Calculus of Global Warming
The British government recently issued the most comprehensive study to date of the economic costs and risks of global warming, and of measures that might reduce greenhouse gas emissions, in the hope of averting some of the direst consequences.
Written under the leadership of Sir Nicholas Stern of the London School of Economics, who succeeded me as Chief Economist of the World Bank, the report makes clear that the question is no longer whether we can afford to do anything about global warming, but whether we can afford not to.
The report proposes an agenda whose cost would be equivalent to just 1% of annual consumption, but would save the world risk equivalent costs that are five times greater.
The reported costs of global warming are higher than in earlier studies because it takes into account the mounting evidence that the process of global warming is highly complex and non-linear, with a non-negligible chance that it may proceed much faster than had previously been thought and that the extent of warming may be much greater than had previously been thought.
Indeed, the study may actually significantly underestimate the costs: for instance, climate change may lead to more weather variability, a possible disappearance or major shift of the Gulf Stream – of particular concern to Europe – and a flourishing of disease.
When I served in 1995 on the Intergovernmental Panel on Climate Change, the scientific group that periodically assesses the science of global warming, there was overwhelming evidence that the concentration of greenhouse gases in the atmosphere had increased markedly since the beginning of the industrial revolution, that human activity had contributed significantly to those increases, and that they would have profound effects on climate and sea levels.
But few saw, for instance, the Artic ice cap melting as rapidly as now seems to be the case.
Still, some suggest that because we are not certain about how bad global warming will be, we should do little or nothing.
To me, uncertainty should make us act more resolutely today, not less.
As one scientist friend puts it: if you are driving on a mountain road, approaching a cliff, in a car whose brakes may fail, and a fog bank rolls in, should you drive more or less cautiously?
Global warming is one of those rare instances where the scientific community is more fearful of what may be happening than the population at large.
Scientists have glimpsed what the future may portend.
As the Stern report points out, as usual, the poor are the most vulnerable.
A third of Bangladesh will be underwater by the end of this century.
The Maldives and a host of Pacific Island states will disappear: our twenty-first-century Atlantis.
To an economist, the problem is obvious: polluters are not paying the full costs of the damage they cause.
Pollution is a global externality of enormous proportions.
The advanced countries might mean Bangladesh and the disappearing island states no harm, but no war could be more devastating.
A global externality can best be dealt with by a globally agreed tax rate.
This does not mean an increase in overall taxation, but simply a substitution in each country of a pollution (carbon) tax for some current taxes.
It makes much more sense to tax things that are bad, like pollution, than things that are good, like savings and work.
Although President George W. Bush says he believes in markets, in this case he has called for voluntary action.
But it makes far more sense to use the force of markets – the power of incentives – than to rely on goodwill, especially when it comes to oil companies that regard their sole objective as maximizing profits, regardless of the cost to others.
Exxon has reportedly been funding so-called think tanks to undermine confidence in the science of global warming, just as the tobacco industry funded “research” to question the validity of statistical findings showing the link between smoking and cancer.
Some companies even seem to celebrate the melting of the polar ice cap, because it will reduce the cost of extracting the oil that lies beneath the Arctic Ocean.
The good news is that there are many ways by which improved incentives could reduce emissions – partly by eliminating the myriad of subsidies for inefficient usages.
The US subsidizes corn-based ethanol, and imposes tariffs on sugar-based ethanol; hidden in the tax code are billions of dollars of subsidies to the oil and gas industries.
Most importantly, price signals that show the true social costs of energy derived from fossil fuels will encourage innovation and conservation.
Small changes in practices, when replicated by hundreds of millions of people, can make an enormous difference.
For example, simply changing the color of roofs in warm climates to reflect sunlight or planting trees around houses can lead to great savings on energy used for air conditioning.
We have but one planet, and should treasure it.
Global warming is a risk that we simply cannot afford to ignore anymore.
A Cool Head for the Hottest Issues
LONDON – Reading Barack Obama’s Dreams from My Father , the US president’s beautifully written reflections on his early life and identity, most people are struck by his cool and intellectual approach.
This is not to say that he is unemotional.
Obama can rage and weep.
But he rarely seems to act on the basis of raw sentiment or instinctive prejudice.
Pragmatic and highly intelligent, sooner or later every issue receives the full attention of his forensic curiosity.
Recalling Hillary Clinton’s famous Democratic primary television advertisement, Obama, it turns out, is exactly the sort of president that most of us would want to have in the post for that 3 a.m. phone call about an international crisis.
He would not be afraid to act, but he would be prepared to think first.
I do not think, therefore, that Obama will be too vexed by some of the criticism he faces at the end of his first year in office, though he will undoubtedly grimace at the defeat of the Democratic candidate in the special election in Massachusetts to fill Ted Kennedy’s old seat.
Obama was praised extravagantly a year ago; 12 months on, the criticism is over the top, too.
Obama inherited a terrible legacy – recession, financial meltdown, Iraq, Afghanistan. He has not solved all of these problems.
But it is difficult to see any really bad mistakes, except perhaps allowing himself to be pushed around by Israeli Prime Minister Netanyahu and giving China the impression that he was prepared for a bilateral relationship entirely on China’s terms.
That seems to be changing now.
Obama may have come to understand that when you are the leader of the world’s only superpower, you need to be feared just a little if you are to be respected.
The left in America criticizes Obama for not turning the economy around already.
The right angrily denounces him as a crypto-communist because he wants every American to have health care.
With a dispassionate eye on the long game, what will the president himself be thinking?
One issue that Obama is certain to have in his sights is a problem that shadowed the world for years.
When I was growing up in the 1950’s and 1960’s, world peace was based on the nuclear standoff between the US and the Soviet Union. The main strategic assessment on both sides of the Berlin Wall was that if either side made a wrong move, all of us might end up consumed in the flames of a nuclear holocaust.
We have forgotten those days.
Yet there are still 23,000 nuclear warheads on our planet, with the explosive power of 150,000 Hiroshima bombs.
Terrorist groups would undoubtedly like to get their hands on one.
In all, there are eight nuclear-weapon states – the US, Russia, Britain, France, China, Israel, India, and Pakistan.
North Korea may also have a few bombs. Iran is believed by many to be trying to develop one.
Other states, which have their own civil nuclear capacity, have the potential to develop a weapon. The number of countries in this category is bound to increase as the number of nuclear power reactors doubles over the next 20 years.
The Nuclear Non-Proliferation Treaty (NPT) has contained the number of nuclear states.
A conference is to be held in May to renew and review it.
Obama clearly recognizes that the NPT needs to be strengthened in order to prevent countries from turning their civil nuclear-power capacity into weapons.
But Obama also knows that if the existing nuclear states want others to accept tougher restrictions, they will have to cut back their nuclear arsenals. This is principally an issue for the US and Russia, which possess 95% of the world’s nuclear weapons.
In addition, it would help if the US could take a strong lead by ratifying the Comprehensive Nuclear-Test-Ban Treaty.
The nuclear issue is one of the biggest items on the Obama agenda. How it is handled will help to define his presidency.
Even before the talking gets serious in May, there will be the question of Iran to sort out.
Iran says that it seeks no more than its own ability to produce nuclear power.
Disbelief grows with every revelation of secret Iranian facilities and plans, and with every refusal by Iran to negotiate safeguards that would allow for civil use while preventing weaponization.
The US, the European Union, and Russia have tried to engage Iran on this issue, so far without success.
China seems likely to block effective sanctions on Iran because of its close energy relationship with the country.
How China eventually handles this will profoundly affect its standing in the US and Europe.
These are going to be some of the major questions for Obama over the next year and more.
If he gets them right, he can forget about his short-term critics.
Fortunately, he is smart enough to know this.
A Crisis in Full Flight
MUNICH – For a while, it looked as if the European Central Bank’s €1 trillion credit program to pump liquidity into Europe’s banking system had calmed global financial markets.
But now interest rates for Italian and Spanish government bonds are on the rise again, closing in on about 6%.
Of course, this may not be the breaking point beyond which the debt burden becomes unsustainable.
After all, interest rates in Southern Europe were well above 10% in the decade before the euro was introduced.
Even Germany at that time had to pay bondholders more than 6%.
Nevertheless, the markets are clearly signaling growing doubt about whether Spain and Italy will be willing to bear their debt burden.
The main problem is Spain, where private and public-sector foreign debt is larger than that of Greece, Portugal, Ireland, and Italy combined, and, as in Greece, is in the neighborhood of 100% of GDP (93% to be precise).
A quarter of the labor force and half of Spain’s youth are unemployed, reflecting the country’s loss of competitiveness in the wake of the real-estate bubble inflated by cheap euro credit in the pre-crisis period.
The current-account deficit remains at 3.5% of GDP, despite the recession-induced decline in imports, while economic contraction will cause Spain to miss its budget-deficit target again.
Moreover, Spain’s debt with the ECB’s TARGET settlement system rose by €55 billion ($72 billion) between February and March, because capital outflows of that amount had to be compensated.
Since July 2011, Spain’s TARGET debt has grown by €199 billion.
Capital is in full flight, more than offsetting the inflows from 2008-2010.
The cumulative total since the beginning of the first crisis year (2008) means that Spain has financed its entire current-account deficit via the printing press.
The picture is little better in Italy, where the current-account balance has swung from a surplus of around 2% of GDP to a 3%-of-GDP deficit over the last ten years.
The country’s TARGET debt grew by €76 billion from February to March, with the total since July 2011 reaching €276 billion.
Italy, too, is being drained of capital; in fact, the flight of investors accelerated after the ECB’s liquidity injection.
It is now clear that the ECB itself has caused a large part of the capital flight from countries like Spain and Italy, because the cheap credit that it offered drove away private capital.
The purpose of the ECB’s measures was to re-establish confidence and bring about a recovery of the inter-bank market.
In this, too, it has not really been successful, despite the huge amount of money that it put on the table.
Indeed, now the French are looking wobbly.
As capital fled the country between July 2011 and January 2012, France’s TARGET debt increased by €95 billion.
France, too, has become uncompetitive, owing to the cheap credit brought by the euro in its initial years.
According to a recent study by Goldman Sachs, the country’s price level must drop by an estimated 20% vis-à-vis the euro average – that is, depreciate in real terms – if the economy is to regain competitiveness within the eurozone.
Italy will have to depreciate by 10-15%, and Spain by roughly 20%.
While Greece and Portugal face the need for deflation totaling 30% and 35%, respectively, the figures for Spain and Italy are high enough to justify fears about the future development of the eurozone.
These imbalances can be redressed only with great effort, if at all, and only if one accepts a decade of stagnation.
For Greece and Portugal, staying in the eurozone will be a tight squeeze.
There are many who would solve the problem by routing more and more cheap credit through public channels – bailout funds, eurobonds, or the ECB – from the eurozone’s healthy core to the troubled South.
But this would unfairly force savers and taxpayers in the core countries to provide capital to the South on terms to which they would never voluntarily agree.
Already German, Dutch, and Finish savings amounting to €15,000, €17,000, and €21,000, respectively, per working person have been converted from marketable investments into mere equalization claims against the ECB.
No one knows what these claims will be worth in the event of a eurozone breakup.
Above all, however, the permanent public provision of cheap credit would ultimately lead to a lingering infirmity, if not to Europe’s economic collapse, because the eurozone would become a central management system with state control over investment.
Such systems cannot work, because they eliminate the capital market as the economic system’s main steering mechanism.
One cannot help but wonder how thoughtlessly Europe’s politicians have started down this slippery slope.
A Crisis in Two Narratives
CHICAGO – With the world’s industrial democracies in crisis, two competing narratives of its sources – and appropriate remedies – are emerging.
The first, better-known diagnosis is that demand has collapsed because of high debt accumulated prior to the crisis.
Households (and countries) that were most prone to spend cannot borrow any more.
To revive growth, others must be encouraged to spend – governments that can still borrow should run larger deficits, and rock-bottom interest rates should discourage thrifty households from saving.
Under these circumstances, budgetary recklessness is a virtue, at least in the short term.
In the medium term, once growth revives, debt can be paid down and the financial sector curbed so that it does not inflict another crisis on the world.
This narrative – the standard Keynesian line, modified for a debt crisis – is the one to which most government officials, central bankers, and Wall Street economists have subscribed, and needs little elaboration.
Its virtue is that it gives policymakers something clear to do, with promised returns that match the political cycle.
Unfortunately, despite past stimulus, growth is still tepid, and it is increasingly difficult to find sensible new spending that can pay off in the short run.
Attention is therefore shifting to the second narrative, which suggests that the advanced economies’ fundamental capacity to grow by making useful things has been declining for decades, a trend that was masked by debt-fueled spending.
More such spending will not return these countries to a sustainable growth path.
Instead, they must improve the environment for growth.
The second narrative starts with the 1950’s and 1960’s, an era of rapid growth in the West and Japan.
Several factors, including post-war reconstruction, the resurgence of trade after the protectionist 1930’s, the introduction of new technologies in power, transport, and communications across countries, and expansion of educational attainment, underpinned the long boom.
But, as Tyler Cowen has argued in his book The Great Stagnation, once these “low-hanging fruit” were plucked, it became much harder to propel growth from the 1970’s onward.
Meanwhile, as Wolfgang Streeck writes persuasively in New Left Review, democratic governments, facing what seemed, in the 1960’s, like an endless vista of innovation and growth, were quick to expand the welfare state.
But, when growth faltered, this meant that government spending expanded, even as its resources shrank.
For a while, central banks accommodated that spending.
The resulting high inflation created widespread discontent, especially because little growth resulted.
Faith in Keynesian stimulus diminished, though high inflation did reduce public-debt levels.
Central banks then began to focus on low and stable inflation as their primary objective, and became more independent from their political masters.
But deficit spending by governments continued apace, and public debt as a share of GDP in industrial countries climbed steadily from the late 1970’s, this time without inflation to reduce its real value.
Recognizing the need to find new sources of growth, towards the end of Jimmy Carter’s presidency, and then under Ronald Reagan, the United States deregulated industry and the financial sector, as did Margaret Thatcher in the United Kingdom.
Productivity growth increased substantially in these countries over time, which persuaded Continental Europe to adopt reforms of its own, often pushed by the European Commission.
Yet even this growth was not enough, given previous governments’ generous promises of health care and pensions – promises made even less tenable by rising life expectancy and falling birth rates.
Public debt continued to grow.
And the incomes of the moderately educated middle class failed to benefit from deregulation-led growth (though it improved their lot as consumers).
The most recent phase of the advanced economies’ frenzied search for growth took different forms.
In some countries, most notably the US, a private-sector credit boom created jobs in low-skilled industries like construction, and precipitated a consumption boom as people borrowed against overvalued houses.
In other countries, like Greece, as well as under regional administrations in Italy and Spain, a government-led hiring spree created secure jobs for the moderately educated.
In this “fundamental” narrative, the advanced countries’ pre-crisis GDP was unsustainable, bolstered by borrowing and unproductive make-work jobs.
More borrowed growth – the Keynesian formula – may create the illusion of normalcy, and may be useful in the immediate aftermath of a deep crisis to calm a panic, but it is no solution to a fundamental growth problem.
If this diagnosis is correct, advanced countries need to focus on reviving innovation and productivity growth over the medium term, and on realigning welfare promises with revenue capacity, while alleviating the pain of the truly destitute in the short run.
For example, Southern Europe’s growth potential may consist in deregulating service sectors and reducing employment protection to spur creation of more private-sector jobs for retrenched government workers and unemployed youth.
In the US, the imperative is to improve the match between potential jobs and worker skills.
People understand better than the government what they need and are acting accordingly.
Many women, for example, are leaving low-paying jobs to acquire skills that will open doors to higher-paying positions.
Too little government attention has been focused on such issues, partly because payoffs occur beyond electoral horizons, and partly because the effectiveness of government programs has been mixed.
Tax reform, however, can provide spur retraining and maintain incentives to work, even while fixing gaping fiscal holes.
Three powerful forces, one hopes, will help to create more productive jobs in the future: better use of information and communications technology (and new ways to make it pay), lower-cost energy as alternative sources are harnessed, and sharply rising demand in emerging markets for higher-value-added goods.
The advanced countries have a choice.
They can act as if all is well, except that their consumers are in a funk, and that “animal spirits” must be revived through stimulus.
Or they can treat the crisis as a wake-up call to fix what debt has papered over in the last few decades.
For better or worse, the narrative that persuades these countries’ governments and publics will determine their future –&nbsp;and that of the global economy.
Financing the Next Development Agenda
WASHINGTON, DC – As the 2015 target date for the Millennium Development Goals approaches, the United Nations is intensifying its efforts to foster debate about what comes next for promotion of development worldwide.
The outcome of these discussions will shape policies and investment aimed at spurring GDP growth, strengthening human capital, and promoting more inclusive prosperity.
With the global population expected to reach nine billion people by 2050 – a significant proportion of whom will reside in developing or underdeveloped countries – the international community must improve access to education, health care, and employment opportunities worldwide.
Meanwhile, the prospect of a rise in global temperature of more than 2°C (3.6°F) over pre-industrial levels by the end of this century (which would trigger global warming’s most damaging effects) calls for higher investment in sustainable urbanization, climate-smart agriculture, and social safety nets.
Both factors challenge us to define, in the longer term, more sustainable patterns of production and consumption.
Governments, civil society, and the private sector must rise to the challenge, cooperating to find and implement creative solutions.
But, first, they must anticipate the associated financing requirements, which will soon surpass the current capacities of governments and international donors, and take action now to activate new, reliable sources of financing.
To start, governments should design targeted, evidence-based policies and support the development of sound institutions.
This would make government services more effective, while helping to catalyze additional development aid from traditional donors and mobilize private-sector resources.
In many countries, there is considerable scope for domestic resource mobilization.
Broadening the tax base, improving tax administration, and closing gaps in the value-added tax could make a significant difference in lower-income countries, where tax revenues account for only about 10-14% of GDP, compared to 20-30% of GDP in high-income countries.
More equitable taxation would have a positive impact on governance, another important tool for mobilizing domestic resources.
With improved corporate and public governance and clear transfer-pricing policies, resource-rich countries could shore up their capacity to negotiate fair contracts with extractive industries, balance revenues and expenditures over time, and manage their natural endowments more transparently.
Progress in these areas would help governments to channel their spending more effectively toward those who would benefit the most.
For example, only 8% of the $409 billion spent on fossil-fuel subsidies in 2010 reached the poorest 20% of the population.
A targeted support program could increase substantially the efficiency of spending, freeing up resources for education, health, and poverty eradication.
Furthermore, promoting financial deepening and inclusiveness could accelerate private-sector growth, creating more opportunities.
Indeed, broader access to financial services would help the estimated 400 million micro, small, and medium-size enterprises in developing countries to prosper, while enabling the 2.5 billion people worldwide who currently lack access to such services to build their assets.
A deeper and more efficient financial sector would also reduce transaction costs and facilitate risk management.
Local-currency bond markets could help to develop domestic investor bases and mobilize domestic savings to support long-term investments.
At the same time, the international community should work to improve the availability and effectiveness of official development assistance.
The ODA target of 0.7% of GDP – agreed in 2002 at the International Conference on Financing for Development in Monterrey, Mexico – should motivate countries to increase their contributions.
They can also take steps to make ODA more predictable from year to year.
Donors should structure aid to ensure that it supports sound national development policies and programs, rather than their own narrow interests.
This is particularly relevant as emerging development partners, especially the BRICS (Brazil, Russia, India, China, and South Africa), offer new kinds of aid packages that incorporate investment and non-financial assistance.
Private charities, which have been instrumental in promoting innovation in fields such as health care, the environment, and education, could provide valuable insight into channeling aid more effectively.
More generally, improving coordination among donors would help to maximize the impact of aid on the ground.
While ODA remains an important source of financing for fragile and very-low-income countries, it represents only 7% of net financial flows to developing countries, where foreign direct investment, remittances, long-term debt, and portfolio investment have a larger impact.
Donors should leverage aid to “grow the pie” and to diversify financing sources for the world’s poorest countries by providing risk guarantees, innovative investment vehicles, debt syndication, and co-financing arrangements.
Attracting even a fraction of the assets held by institutional investors, sovereign-wealth funds, and public pension funds could boost development finance substantially.
Diaspora populations are another major potential source of development financing.
Reducing transfer costs, which average an estimated 9% of the value of transactions, would put more money into the hands of those who need it most.
Tailoring financial products for diaspora communities could attract resources for investment, while reinforcing migrants’ ties – economic and otherwise – to their home countries.
Finally, the international community bears a special responsibility for delivering global public goods.
The responsibility to preserve the environment, stem the spread of communicable diseases, strengthen the international financial architecture, enhance developing-country participation in the global trading system, and facilitate the exchange of knowledge lies at the intersection of national development priorities and global interests.
Duty-free, quota-free access to OECD markets, complemented by simpler, more transparent rules of origin, would raise GDP by 1% in the least-developed countries, lifting millions out of poverty.
Investment in statistical capacity would help governments and businesses worldwide to make better policy decisions, based on a more accurate accounting of the associated costs and benefits.
The challenge of the post-2015 development agenda lies in finding creative solutions to support prosperity, equality, and sustainability.
Together, governments, civil society, international organizations, and the private sector can improve the availability and quality of finance for development, and shape a better future for all.
A Czech Moment
PRAGUE – As I listened to what some Europeans were saying as my country prepared to take over the presidency of the European Union, I heard dim echoes of Neville Chamberlain’s infamous description of Czechoslovakia as “a faraway country of which we know little.”
I suppose that Donald Rumsfeld’s misguided bid a few years ago to incite a divide between “new and old” Europe contributed to the re-emergence of that disdainful attitude. 
The reality is that there is no such thing as “old and new” Europe, and there never was.
The break with communism and reunification of Europe is now almost two decades old.
We Czechs are 100% European, and were even when the Iron Curtain cut us off from democratic Europe.
Indeed, our pro-EU sentiments may be all the stronger because our membership in the Union, like our freedom, is so comparatively new.
So no one in Europe needs to fear that the Czech Republic has some nostalgic or idiosyncratic agenda that it wants to impose on the Union.
On the contrary, events have imposed an agenda on Europe that we cannot escape and for which solidarity – true union – will be needed.
The primary, and most pressing, of the problems we face is the financial and economic crisis that is enveloping the EU.
Unfortunately, conditions across the Union will likely worsen before they begin to improve.
The type of social unrest recently witnessed in Greece may spread, because the downturn is likely to take a disproportionate toll on Europe’s young people, who are seeking jobs at a time when hard-pressed European businesses will be able to offer them very few.
It will fall to the Union, once again, to help transform despair into hope.
We Czechs know something about this, as the wrenching economic transition that we underwent in the 1990’s taught us much about how the right policies can break the grip of hopelessness.
To contain today’s financial and economic crisis, Europe will also need to continue the cooperation that it has shown up to this point.
The very existence of our Union, and particularly of the euro, has already helped to prevent the competitive devaluations and beggar-thy-neighbor policies that ravaged Europe during the 1930’s – the last time the continent faced so brutal an economic downturn. 
But we cannot be complacent that the forces of national egoism will remain in check.
For now, EU governments’ coordinated fiscal stimulus has deprived populists of their usual charge that the EU is indifferent to the fate of individuals.
Even more policy coordination will be needed both to confront the crisis and to re-establish EU norms once the storm clouds begin to dissipate.
Although it is right that the Stability and Growth Pact has become more flexible in these extraordinary times, its rules did secure a successful first decade for the euro.
These rules must eventually be restored intact if Europe is to return to the path of sustainable growth, and a consensus will need to be forged now to make that happen.
The second key challenge that we will face during our European presidency is that of Russia.
A new Partnership and Cooperation Agreement (PCA) between the EU and the Russian Federation must be negotiated.
Those negotiations should have begun seriously last year, but the war in Georgia intervened to put them on hold.
Now those talks have resumed, but the background to the negotiations has changed dramatically.
Russia’s economy is now in far worse shape than that of EU members.
The collapse of world oil and gas prices has wounded Russia’s budget, and lack of investment in the country’s energy sector over the years is now causing the declining production that economists have long predicted.
Until now, Russia has cared less about a new PCA than the EU, because two-thirds of Russia’s exports to the Union comprise natural resources, which bring in cash even without the strong rules that a PCA provides.
Given the stark changes in economic conditions, however, it is now in Russia’s national interest to reassure international markets that it is a reliable place to do business, for which a new PCA would serve as an ideal signal.
Moreover, without a new PCA, individual European countries may feel it necessary to seek even more bilateral agreements with Russia.
Indeed, many EU members have been in a race with each other to see who will be Russia’s closest friend in the Union.
But the bilateral deals that have emerged from this race sometimes come at the expense of other Union members, and may unbalance relations within the Union as a whole.  Only a rules-based EU framework can provide a firm foundation for both bilateral and Union-wide relations with Russia. 
Europe’s main strength in foreign policy is not its commitment to a rules-based multilateralism, important as that undoubtedly is, but its unity.
When the Georgia crisis erupted, Europe united around a single position on Russia’s withdrawal.
It is the Czech Republic’s task, and that of the Swedish EU presidency that will follow our own, to maintain this unity as the PCA negotiations move forward.
During the 1990’s, the US and Europe erred in treating Russia with benign neglect.  It would be a mistake for Russia to respond in kind today by seeking to prolong the PCA negotiations in the hope that a possibly more amenable EU president may one day offer softer terms.
We, like all EU presidencies, will be representing the wider Union interests when we negotiate.
The Trade Delusion
LONDON – Since 2008, global trade has grown slightly more slowly than global GDP.
The Doha Round of World Trade Organization negotiations ended in failure.
Transatlantic and transpacific trade negotiations are progressing slowly, held back by the resistance of special interests.
But, though many experts fear that protectionism is undermining globalization, threatening to impede global economic growth, slower growth in global trade may be inevitable, and trade liberalization is decreasingly important.
To be sure, for 65 years, rapid trade growth has played a vital role in economic development, with average advanced-economy industrial tariffs plummeting from more than 30% to below 5%.
The creation of Europe’s single market facilitated increased intra-European trade.
Japan, South Korea, and Taiwan achieved rapid economic catch-up on the basis of export-led growth.
China has followed the same path over the last 30 years.
Trade grew about twice as fast as global output from 1990 to 2008.
But there is no reason why trade should grow faster than GDP forever.
Indeed, even if there were no trade barriers at all, trade might grow significantly more slowly than GDP in some periods.
Several factors make it possible that we are entering such a period.
For starters, there is the changing pattern of consumption in the advanced economies.
Richer people spend an increasing share of their income on services that are either impossible to trade (for example, restaurant meals) or difficult to trade (such as health services).
Non-tradable sectors tend to account for a growing share of employment and economic activity.
For several decades, that tendency has been offset by ever more intensive trading of tradable goods, often passing through many countries in complex supply chains.
In the future, however, the shift to non-tradable consumption may dominate.
Indeed, trade intensity may decline even for manufactured goods.
Trade is partly driven by differences in labor costs.
China’s dramatic manufacturing growth reflected low wages up to now.
But as real wages in China and other emerging economies grow, incentives for trade will decline.
The more that global incomes converge, the less trade there may be.
In addition, as the economists Erik Brynjolfsson and Andrew McAfee of MIT have argued in their book The Second Machine Age, rapid advances in information technology may enable increasingly extensive automation.
Some manufacturing activities, though few jobs, may well return to developed countries, as the advantages of proximity to customers and lower transport costs outweigh decreasingly important differences in labor costs.
Global trade as a share of GDP may therefore decline, but without adverse consequences for global economic growth.
Rising productivity does not require relentlessly increasing trade intensity.
Earth, after all, does not trade with other planets, yet its economy still grows.
Optimal trade intensity depends on many factors – such as relative labor costs, transport costs, productivity levels, and economy-of-scale effects.
Trends in these factors might make reduced trade intensity not only inevitable but desirable.
Even if that is true, international trade will still play a vital role, and preventing any reversal of past trade liberalization is essential.
But further trade liberalization is bound to be of declining importance to economic growth.
With industrial tariffs already dramatically reduced most potential benefits of trade liberalization have already been grasped.
Estimates of the benefits of further trade liberalization are often surprisingly low – no more than a few percentage points of global GDP.
That is small compared to the cost of the 2008 financial crisis, which has left output in several advanced economies 10-15% below pre-crisis trend levels.
It is small, too, compared to the difference in economic performance between successful catch-up countries – such as China – and other countries that have enjoyed the same access to global markets but have performed less well for other reasons.
The main reason for slow progress in trade negotiations is not increasing protectionism; it is the fact that further liberalization entails complex trade-offs no longer offset by very large potential benefits.
The Doha Round’s failure has been decried as a setback for developing countries. And some liberalization – say, of advanced economies’ cotton imports – would undoubtedly benefit some low-income economies.
But full trade liberalization would have a complex impact on the least developed economies, some of which would benefit only if compensated for the loss of the preferential access to advanced-economy markets that they currently enjoy.
This implies that further progress in trade liberalization will be slow.
But slow progress is a far less important challenge to growth prospects than the debt overhang in developed economies, or infrastructure and educational deficiencies in many developing economies.
That reality often goes unacknowledged.
The importance of past trade liberalization has left the global policy establishment with a bias toward assuming that further liberalization would bring similar benefits.
But while the potential global benefits of trade liberalization have declined, reduced trade intensity might still impede economic development in some countries.
Only a handful of economies over the last 60 years have fully caught up to advanced-economy living standards, and all relied on export-led growth to drive productivity and job creation in manufacturing.
Relying solely on that model will be more difficult in the future.
China is so big that it must develop domestic drivers of growth at an earlier stage of development than did Japan, Taiwan, or South Korea; as a result, its exports will inevitably decline (relative to GDP).
Meanwhile, for some low-income countries, increased manufacturing and service-sector automation of the sort described by Brynjolfsson and McAfee, whether within advanced economies or within China’s established industrial clusters, will make the path to middle- and high-income status more difficult to achieve.
That poses important challenges for development policy, which further trade liberalization can alleviate only marginally.
Rethinking the Monetization Taboo
LONDON – Now that the pace of the US Federal Reserve’s “tapering” of its asset-purchase program has been debated to death, attention will increasingly turn to prospects for interest-rate increases.
But another question looms: How will central banks achieve a final “exit” from unconventional monetary policy and return balance sheets swollen by unconventional monetary policy to “normal” levels?
To many, a larger issue needs to be addressed.
The Fed’s tapering merely slows the growth of its balance sheet.
The authorities would still have to sell $3 trillion of bonds to return to the pre-crisis status quo.
The rarely admitted truth, however, is that there is no need for central banks’ balance sheets to shrink.
They could stay permanently larger; and, for some countries, permanently bigger central-bank balance sheets will help reduce public-debt burdens.
As a recent IMF paper by Carmen Reinhart and Kenneth Rogoff illustrates, advanced economies face debt burdens that cannot be reduced simply through a mix of austerity, forbearance, and growth.
But if a central bank owns the debt of its own government, no net public liability exists.
The government owns the central bank, so the debt is to itself, and the interest expense comes back to the government as the central bank’s profit.
If central bank holdings of government debt were converted into non-interest-bearing perpetual obligations, nothing substantive would change, but it would become obvious that some previously issued public debt did not need to be repaid.
This amounts to “helicopter money” after the fact.
In 2003, then-Fed Chairman Ben Bernanke argued that Japan, facing deflation, should increase public expenditure or cut taxes, funding the operation by printing money rather than issuing bonds.
This, he argued, was bound to increase national income, because the direct stimulative effect would not be offset by concern about future debt burdens.
His advice was not followed; large Japanese deficits were in fact bond-financed.
But the debts held by the Bank of Japan (BoJ) could still be written off.
In Japan’s case, this would reduce government debt by an amount equal to more than 40% of GDP today, and around 60% if implemented after the bond purchases planned for 2014.
Objections focus on two risks: central-bank losses and excessive inflation.
But both of these outcomes can be avoided.
Central banks have bought government bonds with money on which they currently pay zero or very low interest rates.
So, as interest rates rise, central banks might face costs exceeding their income.
But central banks can choose to pay zero interest on a portion of the reserves that commercial banks hold with them, even when they increase the policy interest rate.
And they can require commercial banks to hold zero-interest reserves at the central bank equal to a defined proportion of their loans, thus preventing inflationary growth of private credit and money.
Permanent monetization of government debts is undoubtedly technically possible.
Whether it is desirable depends on the outlook for inflation.
Where inflation is returning to target levels, debt monetization could be unnecessarily and dangerously stimulative.
Central-bank bond sales, while certainly not inevitable, may be appropriate.
But if deflation is the danger, permanent monetization may be the best policy.
I predict that Japan will, in effect, permanently monetize some government debt.
After two decades of low growth and deflation, Japanese gross public debt is now above 240% of GDP (and above 140% of GDP on a net basis); and, with the fiscal deficit at 9.5% of GDP, the debt burden continues to increase.
According to the IMF, to reduce its net public debt to 80% of GDP by 2030, Japan would have to turn today’s 8.6% primary budget deficit (the balance excluding interest payments) into a 6.7% primary surplus by 2020 and maintain such surpluses continuously until 2030.
That will not happen, and any attempt to reach that target would drive Japan into a severe depression.
But the government does not need to repay the ¥140 trillion ($1.4 trillion) of its debt that the BoJ already owns.
The BoJ will continue to increase its balance sheet until it achieves its 2% inflation target.
Thereafter, its balance sheet may stabilize in absolute yen terms and fall slowly as a percentage of GDP, but its absolute size will probably never decrease – a likelihood that should cause no concern.
It is precisely what happened to the Fed’s balance sheet after its wartime and postwar buying of US government bonds came to an end in 1951.
Even as permanent monetization occurs, however, the truth may be obfuscated.
If government bond repayments to the BoJ continued, but were always offset by new BoJ bond purchases, and if the BoJ kept the interest rate on reserves at zero, the net effect would be the same as a debt write-off, but the fiction of “normal” central-bank operations could be maintained.
Central banks can monetize debt while pretending not to.
That pretense may reflect a useful taboo: if we overtly recognize that debt write-off/monetization is possible, politicians might want to do it all the time and in excess, not just in circumstances that make it appropriate.
The historical experience of Weimar Germany, or that of Zimbabwe today, illustrates the danger.
As a result, even when permanent monetization occurs – as it almost certainly will in Japan and possibly elsewhere – it may remain forever the policy that dare not speak its name.
Such reticence may serve a useful purpose.
But it must not blind central banks and governments to the full range of policy tools available to address today’s severe debt overhangs.
The Great Credit Mistake
LONDON – Before the financial crisis erupted in 2008, private credit in most developed economies grew faster than GDP.
Then credit growth collapsed.
Whether that fall reflected low demand for credit or constrained supply may seem like a technical issue.
But the answer holds important implications for policymaking and prospects for economic growth.
And the official answer is probably wrong.
The prevailing view has usually stressed supply constraints and the policies needed to fix them.
An impaired banking system, it is argued, starves businesses, particularly small and medium-size enterprises (SMEs), of the funds they need to expand.
In September 2008, US President George W. Bush wanted to “free up banks to resume the flow of credit to American families and businesses.”
The stress tests and recapitalizations of US banks in 2009 were subsequently hailed as crucial to the recovery of both the banking system and the economy.
By contrast, the European Central Bank’s inadequately tough stress tests in 2010 were widely panned for leaving eurozone banks too weak to provide adequate credit.
In the United Kingdom, banks have been criticized for not lending the reserves created by quantitative easing to the real economy, leading the Bank of England to introduce its “funding for lending” scheme in 2012.
In the eurozone, it is hoped that this year’s asset quality review (AQR) and stress tests will finally dispel concerns about bank solvency and free up credit supply.
A “credit crunch” – particularly in trade finance – was certainly a key reason why the financial crisis generated a real economy recession.
Taxpayer-funded bank rescues, higher bank capital requirements, and ultra-easy monetary policy have all been vital to overcome credit supply constraints.
But there is strong evidence that once the immediate crisis was over, lack of demand for credit played a far larger role than restricted supply in impeding economic growth.
That argument is persuasively made by Atif Mian and Amir Sufi in House of Debt, an important new book that analyzes US data on a county-by-county basis.
Mian and Sufi show that the recession was caused by a collapse of household consumption, and that consumption fell most in those counties where pre-crisis borrowing and post-crisis real-estate prices left households facing the largest relative losses in net wealth.
It was in those US counties, too, that local businesses cut employment most aggressively.
For SMEs, a shortage of customers, not a shortage of credit, constrained borrowing, employment, and output.
And the customers were absent because the pre-crisis credit boom had left them over-leveraged.
In the UK, many business surveys from 2009-2012 told the same story.
Poor customer demand was ranked well ahead of credit availability as a constraint on growth.
Economic growth can indeed continue to be severely depressed by a debt overhang even when credit supply is unrestricted and cheap.
Many Japanese companies were left overleveraged by the boom and bust in credit and real estate in the 1980s and early 1990s.
By the late 1990s, the Japanese banking system was offering companies loans at near-zero interest rates.
But, rather than borrow to invest, firms cut investment to pay down debt, driving two decades of stagnation and deflation.
Since 2011, the ECB’s analysis of weak eurozone growth has stressed the negative impact of an impaired and fragmented financial system, with high sovereign-bond yields and funding costs for banks resulting in prohibitive lending terms in the peripheral countries.
Major progress in fixing these problems has already been achieved.
The ECB’s latest Monthly Bulletin documents this, citing multiple indicators of improved credit availability and pricing.
Nonetheless, the rate of decline in private-sector loans has accelerated over the last year – from -0.6% to -2% – and low demand is acknowledged to be the main driver of depressed credit growth.
Simultaneous private deleveraging and fiscal consolidation are restricting eurozone growth far more than remaining restrictions on credit supply.
Despite the ECB’s own evidence, however, the policy focus remains on fixing the credit-supply problem, through the AQR and stress tests, and through the ECB’s own version of a funding for lending scheme, announced on June 5.
That reflects a recurring tendency in official policy debates, particularly in the eurozone, to concentrate on fixable problems to the exclusion of more difficult issues.
Fixing impaired banking systems after a crisis is both essential and achievable.
Moreover, even when public rescue costs are inevitable, they are typically small change compared to the economic harm wrought by the financial crisis and post-crisis recession.
By contrast, a large debt overhang may be intractable unless policy orthodoxies are challenged.
Japan offset private deleveraging in the 1990s by running massive public deficits.
The US has pulled out of recession faster than the eurozone, not only – or even primarily – because it fixed its banking system faster, but because it pursued more stimulative fiscal policies.
But fiscal stimulus is constrained within the eurozone, where member countries no longer issue their own currency and “sovereign” debt therefore carries a default risk.
Aggressive monetary expansion through quantitative easing is also far more complicated and politically contentious in a currency area with no federal debt for the central bank to buy.
To survive and thrive, the eurozone will need to become more centralized, with some common fiscal revenues, expenditures, and debts.
Of course, this scenario implies immensely difficult political choices.
But the starting point for debate must be realism about the nature and severity of the problems facing the eurozone.
If eurozone policy assumes that fixing the banks will fix the economy, the next ten years in Europe could look like the 1990s in Japan.
A Daughter of Dictatorship and Democracy
SEOUL – It is something of a cliché question in South Korea nowadays: Who would be the country’s next president if the election were held tomorrow, rather than in December 2012?
Numerous opinion polls show Park Geun-hye of the ruling Grand National Party (GNP) to be the leading candidate.
If elected, she would be South Korea’s first woman president, and, for her rivals, her dominant position in the race is an uncomfortable but unassailable fact.
South Korean voters of all ages and regions have welcomed Park as a candidate for their country’s leadership.
Her political style is both refreshing and relevant, because she comes across as sincere and forthright at a time when the public is hungry for moral leadership.
And she has an astonishing talent for simplifying complicated issues accurately, which she likely learned – along with how to interpret and manipulate the political connotations of every issue – from her father, former President Park Chung-hee.
Acclaimed as a national hero among radical right-wingers, the iron-fisted Park Chung-hee ruled South Korea from 1963 to 1979, in the wake of the 1961 military coup, only to be assassinated by his intelligence chief.
His daughter is proud of his legacy, which marked the beginning of South Korea’s economic boom.
Indeed, as a pillar of export-oriented modernity, Park Chung-hee was once lionized as the archetype of a modernizing political leadership in military-authoritarian states.
At home, he still ranks first in popularity among the country’s heads of state, kindling nostalgia like a popular old record – a corollary to people’s frustration and anger at the current government of President Lee Myung-bak.
Park, who lost her first bid for the GNP’s nomination to Lee in 2007, needs to ensure that no rupture with her erstwhile rival knocks her off the path to victory in 2012.
An astute politician, Park did not hesitate to campaign wholeheartedly for Lee the last time around – a move that, as part of long-term political strategy, made perfect sense.
To many South Koreans, the election is now Park’s to lose.
No candidate on the horizon seems able to stop her.
If she wins, it will be the result of her seriousness and tenacity, not her political heritage.
No one in South Korea’s conservative movement doubts that Park is one of them.
And, as an icon of the right, she is well aware that she cannot afford to betray her status.
Despite her charisma, Park is neither a Sarah Palin nor an Eva Peron.
Indeed, she looks more like a Korean Margaret Thatcher – a lady not for turning, in Thatcher’s famous phrase, and with clearly thought-through political principles animating her actions.
In any case, she seems destined to establish a new South Korea focusing on her landmark pledge ‘jul pu se,’ literally meaning ‘reduce-loosen-strengthen tax-cuts,’ deregulation, and law and order, not just to add another chapter to her father’s old book.
Her administration would mark a fresh departure from the country’s troubled recent past.
Left-leaning pundits claim that the dictator’s daughter has the same autocratic vision as her father, though Park invariably prefers incremental change to radical measures, and cut her political teeth in the tough-minded politics of the GNP.
Others take a flagrantly sexist stance, arguing that a woman president would be a non-starter as long as the North Korean regime continues to threaten national security.
Although these criticisms don’t seem to bother the electorate very much, Park’s path to victory may yet prove narrower than her supporters expect.
She has been called the “Queen of Elections,” in particular since she won a campaign in 2006 after being slashed with a box cutter by a deranged man.
But she must convincingly outline practical strategies to resolve South Korea’s most serious problems, including high unemployment, worsening educational performance, and North Korea’s nuclear weapons program.
Ms. Park once pledged to provide loans for working-class families from elementary school to college years, while contending that local universities should be empowered to have more autonomy.
She favors engagement policy and the six-party talks so as to resolve the nuclear troubles.
Come presidential election-day in 2012, South Korean voters will pick the candidate who embodies pragmatism and centrism over a partisan or ideologue.
Park’s success will depend, in the end, on the effectiveness of her campaign in further defining her character along those lines.
Unlike former Peruvian dictator Alberto Fujimori’s daughter, who lost her presidential bid in Peru last month, Park is likely to defy her family’s tragic history.
If she does, she will be Asia’s most powerful woman, perhaps the most powerful in the world, at the end of next year.
A Day for Planetary Justice
PRINCETON – What we are doing to our planet, to our children and grandchildren, and to the poor, by our heedless production of greenhouse gases, is one of the great moral wrongs of our age.
On October 24, you can stand up against this injustice.
October 24 is 350 Day.
The name comes from the number of parts per million of carbon dioxide in the atmosphere that, according to Jim Hansen, perhaps the world’s leading climate scientist, we should not exceed if we are to avoid potentially catastrophic climate change.
It is a measure of the seriousness of our problem that CO2 is already at 386 ppm, and is rising by two ppm each year.
The need to cut greenhouse gases has become increasingly clear as predictions of global warming – denounced as “alarmist” when they were first made just a few years ago – have repeatedly turned out to have been too conservative.
We are approaching a point of no return, at which feedback loops will kick in and continue to warm the planet, no matter what we do.
The melting of arctic ice is one example.
Four hundred years ago, explorers sought the legendary “Northeast Passage” across the north of Europe and Russia to China.
They found the arctic ice impenetrable, and soon gave up their quest.
This year, commercial vessels successfully navigated the Northeast Passage.
That is one of many recent dramatic signs that our climate is changing and that our planet is warmer than it has been for a very long time.
But ice-free arctic waters are more than a symptom of global warming. They are themselves a cause of further warming: ice and snow reflect the sun’s rays.
An ice-free surface absorbs more warmth from the sun than one covered in snow or ice.  In other words, our greenhouse gas emissions have, by causing enough warming to melt the arctic ice, created a feedback loop that will generate more warming, and melt more ice, even if we were to stop emitting all greenhouse gases tomorrow.
Other feedback loops pose a similar danger.
In Siberia, vast quantities of methane, an extremely potent greenhouse gas, are locked up in what used to be called “permafrost” – regions in which it was assumed that the ground was permanently frozen.
But areas that used to be frozen are now thawing, releasing methane and thus contributing to further warming – and to further thawing, which releases more methane.
Developing nations are grasping just how outrageous the current distribution of greenhouse-gas emissions really is.
At the United Nations Summit on Climate Change in September, President Paul Kagame of Rwanda pointed out that, while developed nations outside Africa are almost entirely responsible for the problem, its greatest impact will probably be on Africa, which has few resources to cope with the challenge.
Kagame then suggested giving every country an annual per capita quota for CO2 emissions, and allowing developing countries that are below the quota to trade their excess quota with countries that are above theirs.
The money that developing countries would receive for this would not be aid, but rather a recognition that the rich nations must pay for something that in the past they simply appropriated: far more than their fair share of our atmosphere’s capacity to absorb our waste gases.
Sri Lanka took a similar stance, using studies from the UN Intergovernmental Panel on Climate Change to calculate that in 2008, environmentally permissible carbon emissions totaled no more than 2,172 kilograms per person.
In fact, the world’s per capita emissions were 4,700 kilograms, or more than double the permissible limit.
But, while emissions in the rich nations were far above the permissible limit, Sri Lankan emissions were, at 660 kilograms, well below it.
As Sri Lanka’s government pointed out, “That means low-emitting countries like us could not emit more because our space has already been exploited by developed or global heavy polluting countries without our consent.”
This situation is an injustice of vast proportions, reminiscent of – and arguably much worse than – the now-repudiated colonialism of the Western powers in the nineteenth century.
The task of remedying it must begin at the meeting on climate change that will be held in Copenhagen in December.
Many political leaders have expressed support for strong action on climate change, but what most of them regard as “strong action” will not be enough to get us back below 350 ppm.
In some countries, including the United States, there are major political obstacles to taking even modest steps.
On October 24, people in nearly every country will be taking action to raise awareness of the need for an international treaty to bring our atmosphere back to 350 ppm of CO2.
There will be climbers hanging banners high in the Himalayas, where the glaciers are melting, and scuba divers at Australia’s Great Barrier Reef, which is threatened by climate change.
Churches will ring bells 350 times, 350 cyclists will circle towns, and, in many places, 350 trees will be planted.
At www.350.org you can find out what is happening near you and join in, or put your own idea online.
But don’t just sit back and hope that others will do enough to make an impact.
One day your grandchildren will ask you: what did you do to meet the greatest moral challenge of your time?
A Day of Liberation
When I was seven years old, in 1960, my grandmother Angelica opened my eyes to the meaning of 8 May 1945, the day when Nazi Germany surrendered and World War II ended in Europe.
We were spending our summer holidays in Normandy where the liberation of Europe from Nazism had started on D-Day, 6 June 1944.
One evening, I listened to my parents and my grandmother talking about the past.
I have forgotten the details of their conversation, but I can still hear my grandmother’s sigh of relief when she said “Thank God we lost that war!”
From a child’s perspective, it wasn’t self-evident that losing was a good thing.
But of course, my grandmother was right to equate defeat with liberation.
The more I have thought about the lesson she taught me 45 years ago, the clearer I have seen another, less obvious dimension in what she said: It is “we” who lost the war.
Collectively, the Germans had not been the innocent victims of a small gang of criminal outsiders called “Nazis” – Nazism had been an inside ideology supported by millions of Germans, and every German was liable for its atrocities whether or not he or she had adhered to it individually.
In today’s Germany, an overwhelming majority subscribes to the proposition that 8 May 1945 was a day of liberation – not only for Europe, but also for Germany itself.
Compared to public opinion in 1960, that’s certainly an enormous progress.
But paradoxically, it may also contain an element of forgetfulness, because it tends to conceal the fact that liberation required a military defeat.
To use my grandmother’s parlance, it is not “us” who were the liberators, but “them”.
The way people see the past tells us more about their present attitudes than about the past itself.
This is what the term “politics of memory” is meant to indicate.
And this is why it doesn’t matter whether the relevant events happened 60 years ago (as World War II), 90 years (as in the case of the Armenian genocide) or even 600 years (such as the battle of Kosovo in 1389).
A violent conflict in the past may survive as a war of memories in the present, as can be observed in the current dispute between China and South Korea on one side, and Japan on the other.
A war of memories, in turn, may sometimes lead to a violent conflict in the future.
Former perpetrators often try to de-legitimize their former victims’ moral superiority by claiming they were victims themselves.
Therefore, the 60th anniversary of the firebombing of Dresden by Allied forces on 13 February 1945 has probably been a more crucial moment in terms of the German “politics of memory” than the 60th anniversary of 8 May 1945 is going to be.
Far-right groups infamously dubbed the attack by which at least 30,000 people were killed “Dresden’s Holocaust of bombs.”
Fortunately, their propaganda campaign has been a failure.
Although it is true that thousands of the civilians killed in Dresden and other German cities were innocent at an individual level, there can be no doubt it was morally imperative that Germany be defeated collectively.
On the left side of the German political spectrum, the proposition that 8 May 1945 was a day of liberation remains unchallenged.
However, it is sometimes repressed that the massive use of force had been necessary to achieve that result.
Left-wing pacifism tends to overlook this simple fact.
Its slogan “Never again war!” is only half the truth – the other half is “Never again appeasement!” 8 May 1945 was not “zero hour,” as a popular saying in Germany goes.
It had an antecedent, that is, a lack of pre-emptive resistance at home and abroad to the threat that built up in Nazi Germany during the 1930’s.
There is yet another lesson to be learned.
Yes, 8 May 1945 was a day of liberation to which the Soviet army contributed decisively.
But for millions of Central and East Europeans, liberation was followed by Stalin’s oppressive regime.
The current war of memories between the Baltic republics and Russia, with regard to the international celebration in Moscow on 9 May this year, reminds Germany of a special historic responsibility.
The German-Soviet non-aggression treaty, the so-called Hitler-Stalin pact, concluded in August 1939, had been supplemented by a secret appendix dividing the border states Finland, Estonia, Latvia, Lithuania, Poland and Romania into spheres of interest for the two parties.
But excusing Nazi atrocities by pointing to Stalinist crimes is an intellectually and morally unacceptable stratagem.
When Chancellor Schröder travels to Moscow for the Red Square celebrations, he should bear in mind Nazi Germany’s contribution to the Baltic tragedy.
On 8 May this year, public speakers will remind us how important it is not to forget.
They will stress that if the lessons of history are not learned, history is bound to repeat itself.
All this is perfectly true.
But personally, I will also remember my grandmother’s sentence “Thank God we lost that war!”
Thank God – and thanks to all those brave Allied soldiers who sacrificed their lives for the sake of Europe’s liberty.
But in terms of the all-important roles of a currency as an investment vehicle or reserve asset, the outlook for the renminbi is much less promising, owing to China’s still-tight capital controls and low level of financial development.
A Defeat for International Tax Cooperation
NEW YORK – Most of the world’s governments – eager to mobilize more tax revenues to finance development and curb pervasive tax-avoidance schemes, such as those revealed in the so-called Luxembourg Leaks scandal last year – have an interest in collaborating on taxation matters.
Yet at the Third International Conference on Financing for Development, held in Addis Ababa last month, the momentum toward strengthening international tax cooperation came to an abrupt halt.
Developed countries blocked a proposal at the conference to establish an intergovernmental tax body within the United Nations to replace the current UN Committee of Experts.
These countries insist that tax cooperation should take place exclusively under the leadership of the OECD, a body that they control.
The rest of the world should hope this will prove to be a pause rather than an end to progress on international tax cooperation, which began 13 years ago, at the first International Conference on Financing for Development in Monterrey, Mexico.
Two years later, in 2004, the United Nations Economic and Social Council (ECOSOC) upgraded its “ad hoc group” of tax experts to a regular committee.
This meant that the experts would meet regularly and have an expanded mandate that went beyond merely updating a model double-taxation treaty.
Four years later, at the Second Conference on Financing for Development, in Doha, Qatar, policymakers acknowledged that more needed to be done in tax matters, and asked ECOSOC to consider strengthening institutional arrangements.
And then, in the year leading up to the Addis Ababa conference, the UN Secretary-General endorsed the need for “an intergovernmental committee on tax cooperation, under the auspices of the United Nations.”
His endorsement, along with strong support from nongovernmental organizations and the Independent Commission for the Reform of International Corporate Taxation, gave greater force to the demand by developing countries, organized around the Group of 77 and China, for an equal voice in setting global tax norms.
Up until the 11th hour of negotiations in Addis Ababa, they stood firm in calling for an intergovernmental body with the mandate and resources to create a coherent global framework for international tax cooperation.
But to no avail: Developed countries, led by the United States and the United Kingdom –home to many of the multinational corporations implicated in the “Lux Leaks” – succeeded in blocking this much-needed advance in global governance.
In the end, the Addis Ababa Action Agenda provides that the current Committee of Experts will continue to function according to its 2004 mandate, with three additional meeting days per year, all funded through voluntary contributions.
That is a profoundly disappointing outcome.
The developed countries have an argument – but not a convincing one.
The OECD, whose members are essentially the world’s 34 richest countries, certainly has the capacity to set international standards on taxation.
Yet the domination of a select group of countries over tax norms has meant that, in reality, the global governance architecture for taxation has not kept pace with globalization.
The Monterrey Consensus reached in 2002 included a call to enhance “the voice and participation of developing countries in international economic decision-making and norms-setting.”
But although the OECD invites some developing countries to participate in its discussions to establish norms, it offers them no decision-making power.
The OECD is thus a weak surrogate for a globally representative intergovernmental forum.
Such a body must operate under the auspices of the United Nations, which bears the institutional legitimacy necessary to respond effectively to the challenges of globalization with coherent global standards to combat abusive tax practices and ensure fair taxation of corporate profits worldwide.
Despite the disappointment in Addis Ababa, the call for reform of the international tax system is not likely to be silenced.
Instead, it will grow louder on all sides, as the developed countries’ counter-productive resistance to any give and take on international cooperation results in a tsunami of unilateral tax measures beyond OECD control.
The Making of Euro-Jihadism
MADRID – The Belgian historian Henri Pirenne linked Europe’s birth as a Christian continent in the eighth century to its rupture with Islam.
Pirenne probably would never have expected a Muslim ghetto in Brussels to emerge, much less become a hub of jihadism, with marginalized and angry young Muslims revolting against Europe from within its own borders.
Divorce is not an option these days.
But nor is the kind of marriage that the Islam scholar Tariq Ramadan advocates.
Ramadan, a grandson of the founder of the Muslim Brotherhood in Egypt, is a Swiss citizen and a resident of the United Kingdom who argues that Islamic ethics and values should be injected into the European system.
Europe would then not just tolerate Islam, but actually embrace it as an integral part of itself.
The problem with Ramadan’s vision is that Europe is an overwhelmingly secular continent, with a profoundly forward-thinking approach to ethics.
Islamic societies, by contrast, are both deeply religious and deeply embedded in the past.
When Islamists speak of political or social reform, they are typically looking backward, hoping to resurrect a time when core European principles – from gender equality to gay marriage – were repudiated.
Even Muslims who support the modernization of Islam would typically stop well short of Europe’s ethical vision.
The flaws in Ramadan’s proposed solution to Euro-jihadism mirror the flaws in his explanation for the phenomenon, which he attributes largely to Europe’s involvement in the wars in the Middle East, its supposed collusion with Israel’s suppression of the Palestinians, and its support of Arab autocrats.
“We cannot,” he writes, “support dictatorships … be silent when civilians are massacred south of our borders, and hope that we will not receive a response to the injustice and humiliation we have provoked.”
But it is the United States that launched wars in Iraq and Afghanistan, offers unconditional support to Israel, and has repeatedly propped up Arab autocrats.
And it is Europe that has consistently criticized these policies – often harshly.
Yet America is not being subjected to a major surge of jihadist sentiment within its borders.
It might have helped that US President Barack Obama backed away from some of these policies.
When the Arab Spring uprisings began, for example, he was quick to cut support for Tunisian President Zine El Abidine Ben Ali and Egyptian President Hosni Mubarak, allowing protesters – inspired by the Western model of democracy – to secure regime change.
The return to autocracy in Egypt in 2013, via Abdel Fattah el-Sisi’s coup d’état, certainly was not aided by the US or Europe, both of which supported the democratically elected Muslim Brotherhood.
Europe has offered even more direct help to Arab countries in recent years.
If it were not for Europe’s military intervention, Libyans would still be living under the tyrannical Muammar el-Qaddafi.
True, Europe could have done more to prevent the ensuing chaos in Libya.
But the people of Libya surely must take responsibility for the proliferation of competing militias that refuse to unite to save their state from total collapse.
More broadly, though the West – especially the US – has made grave policy errors in the Arab world over the last 50 years, external powers cannot be blamed entirely for the region’s meltdown.
That is the result of a profound civilizational crisis – one that can be redressed only by the people of the Arab world.
If Europe’s foreign policy is not responsible for the Arab world’s current turmoil, it certainly cannot be the reason for the rise of jihadism within its own borders.
The real problem lies at home: a disastrous deficit of effective policies related to social justice, education, housing, and employment for young European Muslims.
Marginalization generates frustration, which is subsequently fed by growing Islamophobia and the rise of raucous right-wing movements throughout the continent.
This link is apparent in the fact that the majority of European jihadists come from underprivileged backgrounds.
Not particularly well versed in the true teachings of Islam, and lacking opportunities to improve their lives, they become easy prey for extremists.
Jihadism, with its absolute certainty and grand mission, offers a sense of purpose, pride, and identity – not to mention adventure – and an outlet for their anger against the “home” that has denied them those things.
The story of America’s Muslims is the measure of Europe’s failure.
Like most Americans, Muslims in the US maintain a certain amount of faith in the American dream.
They are mostly middle class, and, despite all the talk about rising economic inequality, they have not given up on the belief that, in the US, hard work and initiative are rewarded.
America is a country of immigrants, with a dynamic economy that has enabled newcomers, time and again, to achieve great success.
In Europe, by contrast, improving one’s social standing has always been very difficult; and, at a time of economic stagnation and staggeringly high unemployment, it is not getting any easier.
Socially, America also offers something to Muslims that Europe does not.
Its fundamentally religious culture enables Muslims to retain their identity to a far greater extent than in secular Europe.
Indeed, America’s core values – personal responsibility and constitutional patriotism – can be easier for Muslims to swallow than Europe’s more aggressively secular brand of liberalism.
As a result, integration and assimilation tend to be easier for Muslims in America.
All of this suggests that Europe must look inward to address homegrown jihadism effectively.
This does not mean that it should temper its secularism, much less its liberal values.
Rather, Europe must breathe life into its own “European dream,” ensuring that all people have access to real opportunities to improve their lives.
Otherwise, it will face a lost generation of millions of young Europeans – Muslim and otherwise.
The New Climate Economics
NEW YORK – This Friday, in its latest comprehensive assessment of the evidence on global warming, the United Nations Intergovernmental Panel on Climate Change will show that the world’s climate scientists are more certain than ever that human activity – largely combustion of fossil fuels – is causing temperatures and sea levels to rise.
In recent years, a series of extreme weather events – including Hurricane Sandy in New York and New Jersey, floods in China, and droughts in the American Midwest, Russia, and many developing countries – have caused immense damage.
Last week, Mexico experienced simultaneous hurricanes in the Pacific and in the Gulf of Mexico that devastated towns and cities in their path.
Climate change will be a major driver of such events, and we risk much worse.
This puts a new debate center stage: how to reconcile increased action to reduce greenhouse gas emissions with strong economic growth.
It is a debate that is already mired in controversy.
As most countries have started making serious investments in renewable energy, and many are implementing carbon prices and regulations, critics complain that such policies may undermine growth.
With the global economy still recovering from the 2008 financial crash, higher energy costs – not yet fully offset by greater energy efficiency – are worrying business and political leaders.
The advent of shale gas has confused the energy debate even more.
If gas is substituted for coal, it can be a useful bridge to a low-carbon future.
But astonishingly, it is coal, the dirtiest fuel, that is experiencing the sharpest increase in use.
Companies and investors are hedging their bets by taking a few resource-efficiency measures and investing in some low-carbon assets, but leaving their high-carbon portfolios and activities largely intact.
Policy vacillation in some countries has not helped.
Advocates of stronger action respond that low-carbon investments can generate much stronger, cleaner growth.
They point to the savings available from energy efficiency, and to the market opportunities generated by clean-energy technologies as the processes of learning and discovery take hold.
They seek to demonstrate the benefits that a more sustainable pattern of development can bring to the world’s cities, to people’s health (from the reduction in air pollution), to energy security, and to the ability of the world’s poor to access energy.
And they propose green bonds and public investment banks to finance new infrastructure and jobs at a time when world interest rates are low and demand is depressed in many countries.
These are serious economic debates, but too often they have become entangled in ideological disputes about the appropriate response to the economic crisis and the value of government intervention in markets.
That is regrettable.
Climate change is not a partisan issue, and climate policy is essentially market-based.
It is about correcting market failures so that markets and entrepreneurship can play their proper role of ensuring innovation and efficient resource allocation.
In order to escape this impasse, we have helped to launch the Global Commission on the Economy and Climate.
The Commission’s New Climate Economy project brings together seven leading policy research institutes from six continents, overseen by a panel of former heads of government and finance ministers and prominent business leaders, and advised by a panel of leading economists from across the world.
Its purpose is to provide authoritative new evidence concerning how governments and businesses can achieve stronger economic growth while simultaneously addressing climate risks.
Few governments or investors start from the standpoint of climate change.
They want to promote investment and economic growth, create jobs, stabilize public finances, expand markets, turn profits, ensure reliable energy and food supplies, produce goods and services, reduce poverty, and build cities.
So the primary question that we need to ask is not whether we can reduce emissions, but how public policy can help to achieve these core goals while reducing emissions and building a more climate-resilient economy.
There is now a lot of experience around the world in this area.
When the Stern Review on the economics of climate change was published seven years ago, the subject was largely theoretical.
Now countries at all stages of development are pursuing new patterns of economic growth that take climate into account.
Germany, for example, is planning the world’s most ambitious low-carbon energy transition, based on energy conservation and renewables.
South Korea has made “green growth” a central economic goal.
Mexico’s 2012 General Law on Climate Change has put it on course for a major increase in clean power.
China has placed the industrial development of green technologies at the top of its agenda.
Ethiopia is seeking to move to lower-carbon farming.
Brazil has significantly reduced the rate of deforestation in the Amazon.
Some major businesses are providing powerful examples of what is possible.
Unilever has committed to the sustainable sourcing of agricultural and forest products.
Coca-Cola is phasing out all use of climate-polluting hydrofluorocarbons.
The retail giant Wal-Mart is driving emissions reduction throughout its supply chain.
Meanwhile, the World Bank and the European Investment Bank have stopped lending to high-emission coal plants.
Yet genuine questions remain about how fast economies should move on to a low-carbon path, and the most effective way to do so.
Some low-carbon policies have clearly been expensive, while other, apparently cost-effective options, have not been pursued at all.
Any structural transformation involves costs, trade-offs, and uncertainties, and it is vital that we understand these properly.
Powerful interests will, of course, oppose any low-carbon transition, dismissing and often drowning out those who stand to benefit.
That makes it even more important to clarify the choices.
As science makes clear how imperative the climate question is, it is time for economists and policymakers to explain how it can be answered.
Only the Poor Die Young
ROTTERDAM – People who are lower on the socioeconomic ladder (indicated by their level of education, occupation, or income) have shorter and less healthy lives, on average, than those on higher rungs.
Indeed, life expectancy at birth often varies by 5-10 years, depending on social and economic well-being, with poorer people spending 10-20 more years of life suffering from illness or disability than their wealthier counterparts.
In the nineteenth century, this situation would not have been surprising, given low average income, widespread poverty, and lack of social security.
But such data are commonly reported for high-income countries today, including those ranking high on indices of economic prosperity and human development – even Western Europe’s highly developed welfare states.
Since the end of World War II, Western European countries have tried to reduce socioeconomic inequality, or offset its consequences, through progressive taxation, social security programs, and a wide range of collectively financed provisions, such as public housing, education, health care, and cultural and leisure facilities.
But, while these policies have reduced inequalities in some social and economic outcomes, including income, housing quality, and health-care access, they have been insufficient to eliminate health inequalities.
Long-term time-series data indicate that the socioeconomic mortality gap narrowed before the 1950’s, but has grown substantially since then.
More puzzling is the fact that more generous welfare policies do not translate into smaller health disparities.
Even the Nordic countries – world leaders when it comes to creating universal and well-designed welfare policies that cover citizens from cradle to grave – face significant health disparities, despite their relatively low income inequality.
To be sure, modern welfare states have far from abolished social inequality, with disparities in access to material and human resources continuing to generate highly unequal lives among their citizens. But the welfare state’s aim has never been radical redistribution of wealth.
Rather, welfare policies are intended to create a compromise between the interests of employees and employers, laborers and the middle classes. As a result, their redistributive effects are modest.
So, while a partial failure of the welfare state may help to explain the persistence of health inequalities, one must look elsewhere to understand – and reverse – their rise. Two possible explanations have emerged from the rapidly growing scientific literature on the subject: selective upward social mobility and delayed diffusion of behavioral change.
In reality, both factors are at work.
During the twentieth century, social mobility increased slowly but steadily in all high-income countries, with educational achievement and occupational status depending less on family background and more on cognitive ability and other personal characteristics.
As a result, the lower socioeconomic groups have not only shrunk in size, but have probably also become more homogeneous in terms of personal characteristics that increase the risk of health problems.
Moreover, people with a higher socioeconomic position tend to adopt new behaviors first, and to abandon more readily behaviors that are found to damage health, such as smoking and high-fat diets.
Given this, new behavioral recommendations by health authorities tend to exacerbate health inequalities, at least temporarily.
Significant disparities in smoking, physical exercise, diet, and alcohol consumption afflict many of Western Europe’s welfare states.
The welfare system, which was created to combat poverty, has been less effective against “diseases of affluence” like heart disease and lung cancer.
All of this highlights the need for creative solutions to disparities that unnecessarily and unfairly blight the lives of those who have the least, generate massive health-care costs, and pose a barrier to increased labor-force participation (impeding efforts in some countries to raise the retirement age).
In the last few decades, social policy in most Western European countries has moved away from redistribution. This is a mistake, given that the consequences of this shift – rising income inequality, weaker social safety nets, and reduced health-care access – will aggravate health inequalities in the long run.
In fact, more, better-targeted redistributive policies, which account for the effects of selective upward social mobility and different rates of diffusion of behavioral change, are crucial to improving health outcomes in lower socioeconomic groups.
Income support should be complemented by preventive health programs, while health literacy programs could help to diminish the link between low cognitive ability and bad health.
Equal access to health care is not enough. Reducing inequalities in health outcomes requires more intensive health care for patients in lower socioeconomic brackets, tailored to their specific needs and challenges.
For example, revenues from tobacco taxation, which disproportionately affects lower income groups, should be used to fund cessation-support programs that target disadvantaged smokers.
Significant and persistent health inequality indicates that, by raising the health levels of those with lower incomes or less education, massive strides could be made in improving populations’ overall health.
This may require reshaping the welfare system to some extent, but the payoff would be well worth the effort.
Read more from "Visionary Voices"
The Mouse Click that Roared
CAMBRIDGE – Until recently, cyber security has primarily interested computer geeks and cloak-and-dagger types.
The Internet’s creators, part of a small, enclosed community, were very comfortable with an open system in which security was not a primary concern.
But, with some three billion or so users on the Web nowadays, that very openness has become a serious vulnerability; indeed, it is endangering the vast economic opportunities that the Internet has opened for the world.
A “cyber attack” can take any number of forms, including simple probes, defacement of Web sites, denial-of-service attacks, espionage, and destruction of data.
And the term “cyber war,” though best defined as any hostile action in cyberspace that amplifies or is equivalent to major physical violence, remains equally protean, reflecting definitions of “war” that range from armed conflict to any concerted effort to solve a problem (for example, “war on poverty”).
Cyber war and cyber espionage are largely associated with states, while cyber crime and cyber terrorism are mostly associated with non-state actors.
The highest costs currently stem from espionage and crime; but, over the next decade or so, cyber war and cyber terrorism may become greater threats than they are today.
Moreover, as alliances and tactics evolve, the categories may increasingly overlap.
Terrorists might buy malware from criminals, and governments might find it useful to hide behind both.
Some people argue that deterrence does not work in cyberspace, owing to the difficulties of attribution.
But that is facile: inadequate attribution affects inter-state deterrence as well, yet it still operates.
Even when the source of an attack can be successfully disguised under a “false flag,” governments may find themselves sufficiently enmeshed in symmetrically interdependent relationships such that a major attack would be counterproductive.
China, for example, would lose from an attack that severely damaged the American economy, and vice versa.
An unknown attacker may also be deterred by cyber-security measures.
If firewalls are strong, or redundancy and resilience allow quick recovery, or the prospect of a self-enforcing response (“an electric fence”) seems possible, an attack becomes less attractive.
While accurate attribution of the ultimate source of a cyber attack is sometimes difficult, the determination does not have to be airtight.
To the extent that false flags are imperfect and rumors of the source of an attack are widely deemed credible (though not legally probative), reputational damage to an attacker’s soft power may contribute to deterrence.
Finally, a reputation for offensive capability and a declared policy that keeps open the means of retaliation can help to reinforce deterrence.
Of course, non-state actors are harder to deter, so improved defenses such as pre-emption and human intelligence become important in such cases.
But, among states, even nuclear deterrence was more complex than it first looked, and that is doubly true of deterrence in the cyber domain.
Given its global nature, the Internet requires a degree of international cooperation to be able to function.
Some people call for the cyber equivalent of formal arms-control treaties.
But differences in cultural norms and the difficulty of verification would make such treaties hard to negotiate or implement.
At the same time, it is important to pursue international efforts to develop rules of the road that can limit conflict.
The most promising areas for international cooperation today most likely concern problems posed for states by third parties such as criminals and terrorists.
Russia and China have sought to establish a treaty establishing broad international oversight of the Internet and “information security,” which would prohibit deception and embedding malicious code or circuitry that could be activated in the event of war.
But the US has argued that arms-control measures banning offensive capabilities could weaken defenses against attacks and would be impossible to verify or enforce.
Likewise, in terms of political values, the US has resisted agreements that could legitimize authoritarian governments’ censorship of the Internet – for example, by the “great firewall of China.”
Moreover, cultural differences impede any broad agreements on regulating online content.
Nonetheless, it may be possible to identify behaviors like cyber crime that are illegal in many domestic jurisdictions.
Trying to limit all intrusions would be impossible, but one could start with cyber crime and cyber terrorism involving non-state parties.
Here, major states would have an interest in limiting damage by agreeing to cooperate on forensics and controls.
The transnational cyber domain poses new questions about the meaning of national security.
Some of the most important responses must be national and unilateral, focused on hygiene, redundancy, and resilience.
It is likely, however, that major governments will soon discover that the insecurity created by non-state cyber actors will require closer cooperation among governments.
A Democratic Burma?
TOKYO – Historic transformations often happen when least expected.
Mikhail Gorbachev’s liberalizing policies of glasnost and perestroika in the Soviet Union emerged at one of the Cold War’s darkest hours, with US President Ronald Reagan pushing for strategic missile defense and the two sides fighting proxy wars in Afghanistan and elsewhere.
Deng Xiaoping’s economic opening followed China’s bloody – and failed – invasion of Vietnam in 1978.
And South Africa’s last apartheid leader, F. W. de Klerk, was initially perceived as just another apologist for the system – hardly the man to free Nelson Mandela and oversee the end of white minority rule.
Now the world is suddenly asking whether Burma (Myanmar), after six decades of military dictatorship, has embarked on a genuine political transition that could end the country’s pariah status.
Is Burma, like South Africa under de Klerk, truly poised to emerge from a half-century of self-imposed isolation?
And can Aung San Suu Kyi, the heroic opposition leader, and Thein Sein, Burma’s new president, engineer a political transition as skillfully and peacefully as Mandela and de Klerk did for South Africa in the early 1990’s?
Despite her two decades of house arrest and isolation, Suu Kyi possesses two of the gifts that enabled Mandela to carry out his great task: a reassuring serenity and an utter lack of vindictiveness.
As Burma’s authorities test reform, these gifts, together with her negotiating skills and, most of all, her vast moral authority, will be tested as never before.
Moreover, unlike Mandela during his 27-year imprisonment, Suu Kyi has had her hopes raised – and dashed – before.
In the mid-1990’s, and again in 2002-2003, reconciliation between Suu Kyi’s National League for Democracy (NLD) and the military junta seemed to be in the offing.
On both occasions, however, the regime’s hardliners gained the upper hand, crushing prospects for reform.
Yet Suu Kyi, and much of the Burmese opposition, is beginning to admit that today’s political liberalization might be the real thing.
Because Burma’s generals say almost nothing in public, it is difficult to fathom why they allowed elections that elevated Thein Sein to power, or to explain their willingness to embrace dialogue with the long-suppressed opposition.
Recent events suggest one possible explanation: Burma’s rulers have grown wary of China’s almost smothering embrace – a result of the country’s international isolation.
Indeed, public protests against China’s commercial exploitation of Burma’s natural resources became so widespread that the government called a halt to construction by Chinese investors on the huge and environmentally damaging Myitsone Dam on the Irrawaddy River.
Thein Sein’s decision to halt the project is clearly an important policy shift.
It is also a signal to the outside world that Burma’s new government may be much more willing than any of its predecessors to heed both public pressure and international opinion, both of which vehemently opposed the dam’s construction.
Almost simultaneously, Thein Sein offered even stronger signals that his was a very different Burmese administration: he freed political prisoners and invited Suu Kyi for direct talks with him.
Indeed, Suu Kyi now enjoys far greater freedom of movement than she has at any time since she received the Nobel Peace Prize 20 years ago, and the NLD recently announced that it will field candidates in the forthcoming by-elections to the country’s newly established parliament.
If Suu Kyi is permitted to campaign free of restraint, for both her own seat and to boost the electoral chances of her NLD colleagues, it will be clear that Thein Sein and his government are truly determined to bring their country in from the cold.
For both Suu Kyi and Thein Sein, every step from now on will be delicate, to be calibrated with the same care and deliberation that Mandela and de Klerk used in bridging their differences and leading their country out of isolation.
But the international community, too, must act with great care.
While Thein Sein would undoubtedly wish to see the myriad economic and political sanctions imposed on Burma quickly lifted, it is too soon for a general easing of such measures.
But the outside world should demonstrate that every clear move toward greater political openness will merit more international political and economic engagement.
The Japan Investment Bank’s decision to invest in port development in Burma – essential if the economy, too, is to be opened – is one positive sign that the world will keep pace with Thein Sein step for step.
And US President Barack Obama’s decision to send Secretary of State Hillary Clinton to Burma to meet Thein Sein is another clear sign that the world is ready to end the country’s isolation.
Closer to home, ASEAN’s recent decision to give Burma a chance to chair the organization in 2014 underscores its neighbors’ desire for the country’s full participation in Asia’s growing prosperity.
No one should rush to judgment yet, but Thein Sein’s decisions, at least so far, are beginning to resemble those of South Africa’s de Klerk when he initiated his country’s reform process.
Fortunately, Burma already has in Aung San Suu Kyi its very own Nelson Mandela.
A Devaluation Option for Southern Europe
CAMBRIDGE – This year is likely to mark a make-or-break ordeal for the euro.
The eurozone’s survival demands a credible solution to its long-running sovereign-debt crisis, which in turn requires addressing the two macroeconomic imbalances –&nbsp;external and fiscal –&nbsp;which are at the heart of that crisis.
The crisis has exposed the deep disparities in competitiveness that have developed within the eurozone.
From 1996 to 2010, unit labor costs in Germany increased by just 8%, and by 13% in France. Compare that to 24% in Portugal, 35% in Spain, 37% in Italy, and a whopping 59% in Greece.
The result has been large trade imbalances between eurozone countries, a problem compounded by large fiscal deficits and high levels of public debt in southern Europe (and France) – much of it owed to foreign creditors.
Does addressing these imbalances require breaking up the eurozone?
Suppose, for example, that Portugal were to leave and re-introduce the escudo. The ensuing exchange-rate devaluation would immediately lower the price of Portugal’s exports, raise its import prices, stimulate the economy, and bring about much-needed growth.
But a euro exit would be a messy affair. The resulting turmoil could very well trump any short-term gains in competitiveness from devaluation.
There is a remarkably simple alternative that does not require southern Europe’s troubled economies to abandon the euro and devalue their exchange rates.
It involves increasing the value-added tax while cutting payroll taxes.
Our recent research demonstrates that such a “fiscal devaluation” has very similar effects on the economy in terms of its impact on GDP, consumption, employment, and inflation.
A currency devaluation works by making imports more costly and exports cheaper. A VAT/payroll-tax swap would do exactly the same thing.
An increase in VAT raises the price of imported goods, as foreign firms face a higher tax.
To ensure that domestic firms do not have an incentive to raise prices, an increase in VAT needs to be accompanied by a cut in payroll taxes.
Moreover, since exports are exempt from VAT, the price of domestic exports will fall.
The desired competitiveness effects of exchange-rate devaluation can thus be had while staying in the euro.
This policy can also help on the fiscal front.
As is true of an exchange-rate devaluation, the positive impact on growth of an increase in competitiveness can strengthen the fiscal position by raising tax revenues.
Moreover, an important advantage of fiscal devaluations is that they generate additional revenues in proportion to the country’s trade deficit.
For countries that are suffering from weak competitiveness and, as a consequence, running trade deficits, this typically means more revenues, especially in the short run.
Like exchange-rate devaluations, fiscal devaluations create winners and losers.
Both act as a wealth levy: inflation means that bondholders suffer a real loss in proportion to their wealth and the size of the devaluation.
If taxes on capital are not adjusted, holders of domestic stocks suffer a comparable loss.
By contrast, many transfers, such as unemployment benefits, health benefits, and public pensions, are indexed to inflation, and thus maintain their real value.
The same is true of minimum wages.
These distributive effects play an important role in the politics of exchange-rate devaluations, and most of these effects appear in fiscal devaluations as well.
Fiscal devaluations already have some advocates.
Indeed, French President Nicolas Sarkozy’s government just announced one.
And concerns that a fiscal devaluation will conflict with euro rules can be met by simply pointing out that Germany’s government carried one out in 2007, though by another name, when it raised VAT from 16% to 19% and cut employers’ contribution to social insurance, from 6.5% to 4.2%.
In short, there are simple fiscal alternatives to exchange-rate devaluation that can address southern Europe’s short-term competitiveness problems.
To be sure, feasible fiscal devaluations would be limited in size.
But, together with debt restructuring, accommodative monetary policy, liquidity support from the European Central Bank, and much-required structural reforms, they can help to put these troubled economies on a sound footing without a euro breakup or a major austerity-induced recession.
A Dissident in China
TOKYO – 2009 was a good year for China.
The Chinese economy still roared ahead in the midst of a worldwide recession.
American President Barack Obama visited China, more in the spirit of a supplicant to an imperial court than the leader of the world’s greatest superpower.
Even the Copenhagen summit on climate change ended just the way China wanted: failure in its attempt to commit China, or any other industrial nation, to making significant cuts in carbon emissions, with the United States getting the blame.
The Chinese government, under the Communist Party, has every reason to feel confident.
So why did a gentle former literature professor named Liu Xiaobo have to be sentenced to 11 years in prison, just because he publicly advocated freedom of expression and an end to one-party rule?
Liu was co-author in 2008 of a petition, Charter 08, signed by thousands of Chinese, calling for basic rights to be respected.
Liu is not a violent rebel. His opinions, in articles published on the Internet, are entirely peaceful.
Yet he was jailed for “inciting subversion of state power.”
The notion that Liu might be capable of subverting the immense power of the Communist Party of China is patently absurd.
And yet the authorities clearly believe that they had to make an example of him, to prevent others from expressing similar views.
Why does a regime that appears to be so secure consider mere opinions, or even peaceful petitions, so dangerous?
Perhaps because the regime does not feel as secure as it looks.
Without legitimacy, no government can rule with any sense of confidence.
There are many ways to legitimize political arrangements. Liberal democracy is only a recent invention.
Hereditary monarchy, often backed by divine authority, has worked in the past.
And some modern autocrats, such as Robert Mugabe, have been bolstered by their credentials as national freedom fighters.
China has changed a great deal in the last century, but it has remained the same in one respect: it is still ruled by a religious concept of politics.
Legitimacy is not based on the give and take, the necessary compromises, and the wheeling and dealing that form the basis of an economic concept of politics such as that which underpins liberal democracy.
Instead, the foundation of religious politics is a shared belief, imposed from above, in ideological orthodoxy.
In imperial China, this meant Confucian orthodoxy.
The ideal of the Confucian state is “harmony.”
If all people conform to a particular set of beliefs, including moral codes of behavior, conflicts will disappear.
The ruled, in this ideal system, will naturally obey their rulers, just as sons obey their fathers.
After the various revolutions in the early decades of the twentieth century, Confucianism was replaced by a Chinese version of Communism.
Marxism appealed to Chinese intellectuals, because it was bookish, introduced a modern moral orthodoxy, and was based, like Confucianism, on a promise of perfect harmony.
Ultimately, in the Communist utopia, conflicts of interests would melt away.
Chairman Mao’s rule combined elements of the Chinese imperial system with Communist totalitarianism.
This orthodoxy, however, was also destined to fade away.
Few Chinese, even in the top ranks of the Communist Party, are convinced Marxists anymore.
This left an ideological vacuum, swiftly filled in the 1980’s by greed, cynicism, and corruption.
Out of this crisis came the demonstrations all over China, collectively known as “Tiananmen.”
Liu Xiaobo was an active spokesman in 1989 for the student protests against official corruption and in favor of greater freedom.
Soon after the bloody crackdown on Tiananmen, a new orthodoxy replaced Chinese Marxism: Chinese nationalism.
Only one-party rule would guarantee the continuing rise of China and put an end to centuries of national humiliation.
The Communist Party represented China’s destiny as a great power.
To doubt this was not just mistaken, but unpatriotic, even “anti-Chinese.”
From this perspective, Liu Xiaobo’s critical views were indeed subversive.
They cast doubt on the official orthodoxy, and thus on the legitimacy of the state.
To wonder, as many have, why the Chinese regime refused to negotiate with the students in 1989 – or to find some accommodation with its critics today – is to misunderstand the nature of religious politics.
Negotiation, compromise, and accommodation are the marks of economic politics, where every deal has its price.
By contrast, those who rule according to a shared belief cannot afford to negotiate, for that would undermine the belief itself.
This is not to say that the economic concept of politics is utterly strange to the Chinese – or, for that matter, that the religious notion of politics is unknown in the democratic West.
But the insistence on orthodoxy is still sufficiently strong in China to remain the default defense against political critics.
These things can change.
Other Confucian societies, such as South Korea, Taiwan, and Japan, now have thriving liberal democracies, and there is no reason to believe that such a transition is impossible in China.
But external pressure is unlikely to bring it about.
Many non-Chinese, including me, have signed a letter of protest against the jailing of Liu Xiaobo.
One hopes that this will lend comfort to him, and give a moral boost to Chinese who share his views.
But it is unlikely to impress those who believe in the current orthodoxy of Chinese nationalism.
Until China is released from the grip of religious politics, Liu’s ideals are unlikely to take root.
This does not bode well for China, or, indeed, for the rest of the world.
A Drug War on Auto-Pilot
THE HAGUE – The war in Afghanistan, now approaching its tenth year, may seem to many to have no end in sight, but Latin America has endured an even longer fight, one that has recently become much more bloody: the “war” against drug trafficking.
So rote – and so violent – has that war become that many people in Latin America now wonder which side is suffering the more pathological addiction.
The new strategy that US Secretary of State Hillary Clinton has been promoting to staunch the upward trend of narco-trafficking-related murders – which leaked Mexican government reports put at more than 22,000 since late 2006 – is to build “stronger, more resilient communities.”
Ciudad Juárez, a sprawling Mexican border town that is now the homicide capital of the world, would have to be high on the list.
Four bridges and innumerable tunnels and drainage canals connect Ciudad Juárez and El Paso, Texas.
Rival cartels sparring for control of a plaza, the name given to any trafficking route, butcher each other and the security forces.
There is apparently no shortage of young, unemployed men willing to join the carnage.
Addressing the deep-seated social and economic problems of a city like Juárez, however, is a lot harder than flooding its streets with 8,000 soldiers carrying assault rifles.
Mexican President Felipe Calderón has, in this respect, remained faithful to the script written in previous theaters in the drug war, whether in Bolivia, Colombia, or Peru, where governments have used military force and extradition to placate the US and punish those with the least voice and influence.
But the language used by the Obama administration to describe the violence and state corruption that snakes from the Andes to the US border is starting to capture new thinking on narcotics.
Three former Latin American presidents, Mexico’s second richest man, Ricardo Salinas, and the Supreme Court of Argentina, among others, have criticized the war on drugs as a manifest failure that has lowered street prices, fueled production, and undermined weak states.
More strikingly, both Bolivia and Ecuador are governed by presidents who suffered directly from the collateral insensitivities of the war on drugs.
Bolivia’s Evo Morales rose to prominence as leader of the country’s coca growers during a brutal campaign to wipe out their crops, the so-called Dignity Plan.
Ecuadoran President Rafael Correa’s father was jailed for smuggling drugs to the US when the future leader was five years old.
These leaders’ profound ambivalence toward the goal of a world free of illegal drugs is shared by the European Union, where restrictions on narcotics consumption have slackened over the past decade.
The past three US presidents, furthermore, have all admitted to consuming – to one extent or another – illegal psychoactive substances, while seven million Americans, according to the United Nations, are regular cocaine users.
But the inertia of a bureaucratic drug-enforcement superstructure (worth approximately $40 billion each in the US and the EU), sustained by a deep-seated fear of the “threat” posed by drugs and cartels, appears to push policy repeatedly towards the familiar option of repressive auto-pilot.
For example, US support for Mexico’s campaign against the cartels looks set in stone, with Congress apparently ready to provide $300 million for another year of military and security upgrading.
In Colombia, seven new joint military installations are planned, and support for US private contractors who have cornered the market in crop fumigation presumably will not be interrupted.
Nevertheless, as the flaws in the four-decade-old edifice of counter-narcotics become more visible, it is increasingly difficult to regard the risks of drug use as being greater than the damage done by repression.
Prohibition hikes the mark-up on prices – an astounding 15,000% in the case of cocaine traveling to Europe from Andean processing facilities.
While the war on drugs focuses on bringing down cartels and their kingpins, it perversely aids the health of their markets, which nestle within legitimate trade flows and respond to price incentives.
Interviewed by the Mexican magazine Proceso this year, the second-in-command of the giant Sinaloa cartel, Ismael Zambada, made the point clearly: “The narco problem involves millions of people.
How do you control it?
The capos can be jailed, killed, or extradited, but their replacements are already wandering around.”
The emergence of Latin America’s powerful drug mafias cannot be traced to the radical evil of certain individuals.
These people emerged under conditions created in deeply inequitable societies by a misapplied, inconsistent, and bureaucratic war.
Indeed, the furies of the Zetas in Mexico originate in the counter-insurgency training provided in the 1990’s to a select group of special-forces soldiers, who later deserted.
The Zetas’ star recruits in recent years have come from the Guatemalan military’s special forces, whose infamous induction technique involved biting off the head of a live chicken.
Meanwhile, in Jamaica and across the rural outposts of Central America, drug lords have become benefactors and heroes to the poor.
It is time for serious reconsideration of the status and regulation of illegal drugs, pointing to selective legalization, as well as reclassification of the market as a public-health, rather than a criminal, concern.
For now, policymakers across the Americas are tiptoeing towards the obvious.
A Global \
ATHENS – The International Monetary Fund’s belated admission that it significantly underestimated the damage that austerity would do to European Union growth rates highlights the self-defeating character of “orthodox” recipes to address the causes of the debt crisis that followed the financial crash of 2008-2009.
Conventional theory suggests that a single country (or group of countries) consolidating its finances can expect lower interest rates, a weaker currency, and an improved trade position.
But, because this cannot happen for all major economies simultaneously – one country’s (or group of countries’) austerity implies less demand for other countries’ products – such policies eventually lead to beggar-thy-neighbor situations.
Indeed, it was this dynamic – against which John Maynard Keynes fought – that made the Great Depression of the 1930’s so grim.
Today’s problems are compounded by a lack of sufficient private demand – particularly household consumption – in the advanced economies to compensate for demand losses stemming from austerity.
During the last two decades, consumption drove these countries’ economic growth, reaching historically high GDP shares.
Moreover, major advanced economies, such as the United States, Germany, and Japan, face longer-term fiscal problems in the form of aging populations or oversize welfare states, limiting their capacity to contribute to demand management.
Recent moves to ease monetary policy have been a step in the right direction; but, so far, they have not proved to be a game changer.
For domestic demand to act as an engine of growth, policies should shift resources from investment to consumption.
While the magnitudes involved are huge, they must be attained if an extended period of low growth, high unemployment, and declining living standards among the world’s poorest is to be avoided.
International economic policy coordination should be significantly strengthened in order to deal effectively with changes on such a scale.
Start with Europe.
It is by now patently obvious that austerity and domestic reforms are not enough to pull the eurozone’s periphery out of deep recession.
Growing awareness of the failure of current policies is causing social discontent, civil disorder, and political instability, with the recently concluded Italian elections and the growing popular resistance to Greek reform efforts serving as a bellwether.
Returning the eurozone’s peripheral economies to the path of growth requires more than structural reforms and fiscal consolidation.
It also requires a substantial reform of the monetary union’s system of economic governance, aimed at restoring financial stability and lowering borrowing costs, together with a boost in external demand in order to compensate for the effects of austerity.
Reforming governance implies significant progress toward economic unification: centralizing European debt through Eurobonds, mobilizing sufficient rescue funds, allowing the European Central Bank to intervene in the primary bond markets, and establishing both a fiscal and a banking union.
This is a tall order, in view of the reluctance of most EU member states to cede competences to European institutions.
But Europe should move more decisively in this direction.
Otherwise, speculation on member states’ national debt will persist, keeping borrowing costs at levels that are inconsistent with the conditions required to sustain economic recovery.
Concerning external demand, intra-European help in the form of reflationary policies in stronger economies is unlikely to prove sufficient, owing primarily to the fiscal and political conditions prevailing in Germany.
Implementing a Marshall Plan-type initiative by mobilizing EU budget resources and additional lending by the European Investment Bank to finance investments in weaker countries could be an alternative, but it lacks political support.
On a global scale, neither the US nor Japan is in a position to provide significant external stimulus.
Only the emerging and developing economies of Asia could effectively contribute to lifting global demand through a coordinated effort aimed at boosting domestic consumption, which, in turn, would stimulate additional investment.
Recent IMF experience suggests that, through appropriate coordination, private funds could be mobilized for big private-public partnership projects linking demand expansion with infrastructure investment.
In other words, a global “New Deal” – combining policies designed to achieve an orderly realignment of consumption and investment worldwide – seems to be required.
The advanced economies should promote productivity-enhancing structural reforms with renewed vigor.
The eurozone should solidify its currency union.
And the emerging and developing economies should support domestic sources of growth.
For such a deal to become possible, certain preconditions must be met.
First, international policy coordination by the G-20 must be tightened by creating a permanent secretariat to make policy proposals and recommendations concerning macroeconomic and financial developments.
The secretariat should actively cooperate with the IMF to benefit from its analysis, notably regarding exchange rates.
Second, global financial reform must proceed at a faster pace.
The financial sector requires tougher regulation, strengthened supervision, and internationally consistent resolution mechanisms to address the problems posed by very large, global institutions that are considered too big (or too complex) to fail.
Such reform is essential if the international financial system is to mediate the sizeable resource transfers that will underpin the required changes in the structure of global demand.
Finally, a new trade pact – possibly, but not necessarily, within the Doha Round – is needed to ensure the major trading powers’ access to foreign markets.
This is critically important for inspiring confidence in Asian countries, which might be persuaded to favor domestic, as opposed to external, sources of demand.
Moreover, trade liberalization will also increase consumer confidence worldwide.
The time is right for a new global settlement that targets growth, addresses crisis conditions in certain parts of the world, and rebalances the global economy to set it back on a path of strong and steady growth.
The Other Financial Crisis
NEWPORT BEACH – Two variants of financial crisis continue to wreak havoc on Western economies, fueling joblessness and poverty: the one that we read about regularly in newspapers, involving governments around the world; and a less visible one at the level of small and medium-size businesses and households.
Until both are addressed properly, the West will remain burdened by sluggish growth, persistently high unemployment, and excessive income and wealth inequality.
The sovereign-debt crisis is well known.
In order to avert a likely depression, governments around the world engaged in fiscal and monetary stimulus in the midst of the global financial crisis.
They succeeded in offsetting nasty economic dislocations caused by private-sector deleveraging, but at the cost of encumbering their fiscal balances and their central banks’ balance sheets.
While sovereign credit quality has deteriorated virtually across the board, and will most probably continue to do so, the implications for individual countries vary.
Some Western countries – such as Greece – had fragile government accounts from the outset and tipped quickly into persistent crisis mode.
There they remain, still failing to provide citizens with a light at the end of what already has been a long tunnel.
Other countries had been fiscally responsible, but were overwhelmed by the liabilities that they had assumed from others (for example, Ireland’s irresponsible banks sank their budget).
Still others, including the United States, faced no immediate threat but failed to make progress on longer-term issues.&nbsp;A few, like Germany, had built deep economic and financial resilience through years of fiscal discipline and structural reforms.
It is not surprising that policy approaches have also varied.
Indeed, they have shared only one, albeit crucial (and disappointing) feature: the inability to rely on rapid growth as the “safest” way to deleverage an over-indebted economy.
Greece essentially defaulted on some obligations.
Ireland opted for austerity and reforms, as has the United Kingdom.
The US is gradually transferring resources from creditors to debtors through financial repression.
And Germany is slowly acquiescing to a prudent relative expansion in domestic demand.
So much for the sovereign-debt crisis, which, given its national, regional, and global impact, has been particularly well covered.
After all, sovereigns are called that because they have the power to impose taxes, regulations, and, at the extreme, confiscation.
But the other credit crisis is equally consequential, and receives much less attention, even as it erodes societies’ integrity, productive capabilities, and ability to maintain living standards (particularly for the least fortunate).
I know of very few Western countries where small and medium-size companies, as well as middle-income households and those of more limited means, have not experienced a significant decline in their access to credit – not just new financing, but also the ability to roll over old credit lines and loans.
The immediate causes are well known.
They range from subdued bank lending to unusually high risk aversion, and from discredited credit vehicles to the withdrawal of some institutions from credit intermediation altogether.
Such credit constraints are one reason why unemployment rates continue to rise in so many countries – often from already alarming levels, such as 25% in Greece and Spain (where youth unemployment is above 50%) – and why unemployment remains unusually high in countries like the US (albeit it at a much lower level).
This is not just a matter of lost capabilities and rising poverty; persistently high unemployment also leads to social unrest, erosion of trust in political leaders and institutions, and the mounting risk of a lost generation.
Indeed, unemployment data in many advanced countries are dominated by long-term joblessness (usually defined as six months or more).
Skill erosion becomes a problem for those with prior work experience, while unsuccessful first-time entrants into the labor force are not just unemployed, but risk becoming unemployable.
Governments are doing too little to address the private credit debacle.
Arguably, they must first sort out the sovereign side of the crisis; but it is not clear that most officials even have a comprehensive plan.
Policy asymmetry is greatest for the countries most acutely affected by the sovereign-debt crisis.
There, the private sector has essentially been left to fend for itself; and most households and companies are struggling, thus fueling continued economic implosion.
Other countries appear to have adopted a “Field of Dreams” – also known as “build it and they will come” – approach to private credit markets, In the US, for example, artificially low interest rates for home mortgages, resulting from the Federal Reserve’s policy activism, are supposed to kick-start prudent financing.
The European Central Bank is taking a similarly indirect approach.
In both places, other policymaking entities, with much better tools at their disposal, appear either unwilling or unable to play their part.
As such, action by central banks will repeatedly fail to gain sufficient traction.
In fact, only the UK is visibly opting for a more coordinated and direct way to counter the persistent shortfalls stemming from the private part of the credit crisis.
There, the “Funding for Lending Scheme,” jointly designed by the Bank of England and the Treasury, seeks “to boost the incentive for banks and building societies to lend to UK households and non-financial companies,” while holding them accountable for proper behavior.
The UK example is important; but, given the scope and scale of the challenges, the proposal is a relatively modest one.
The program may stimulate some productive credit intermediation, but it will not make a significant dent in what will remain one of the major obstacles to robust economic recovery.
Proper access to credit for productive segments is an integral part of a well-functioning economy.
Without it, growth falters, job creation is insufficient, and widening income and wealth inequality undermines the social fabric.
That is why any comprehensive approach to restoring the advanced countries’ economic and financial vibrancy must target the proper revival of private credit flows.
Toxic Politics Versus Better Economics
NEW YORK – The relationship between politics and economics is changing.
Advanced-country politicians are locked in bizarre, often toxic, conflicts, instead of acting on a growing economic consensus about how to escape a protracted period of low and unequal growth.
This trend must be reversed, before it structurally cripples the advanced world and sweeps up the emerging economies, too.
Obviously, political infighting is nothing new.
But, until recently, the expectation was that if professional economists achieved a technocratic consensus on a given policy approach, political leaders would listen.
Even when more radical political parties attempted to push a different agenda, powerful forces – whether moral suasion from G7 governments, private capital markets, or the conditionality attached to International Monetary Fund and World Bank lending – would almost always ensure that the consensus approach eventually won the day.
In the 1990s and 2000s, for example, the so-called Washington Consensus dominated policymaking in much of the world, with everyone from the United States to a multitude of emerging economies pursuing trade liberalization, privatization, greater use of price mechanisms, financial-sector deregulation, and fiscal and monetary reforms with a heavy supply-side emphasis.
The embrace of the Washington Consensus by multilateral institutions amplified its transmission, helping to drive forward the broader process of economic and financial globalization.
Incoming governments – particularly those led by non-traditional movements, which had risen to power on the back of domestic unease and frustration with mainstream parties – sometimes disagreed with the appropriateness and relevance of the Washington Consensus.
But, as Brazilian President Luiz Inácio Lula da Silva demonstrated with his famous policy pivot in 2002, that consensus tended largely to prevail. And it continued to hold sway as recently as almost two years ago, when Greek Prime Minister Alexis Tsipras executed an equally notable U-turn.
But after years of unusually sluggish and strikingly non-inclusive growth, the consensus is breaking down.
Advanced-country citizens are frustrated with an “establishment” – including economic “experts,” mainstream political leaders, and dominant multinational companies – which they increasingly blame for their economic travails.
Anti-establishment movements and figures have been quick to seize on this frustration, using inflammatory and even combative rhetoric to win support.
They do not even have to win elections to disrupt the transmission mechanism between economics and politics.
The United Kingdom proved that in June, with its Brexit vote – a decision that directly defied the broad economic consensus that remaining within the European Union was in Britain’s best interest.
The referendum happened for one reason: in 2013, then-Prime Minister David Cameron feared that he would be unable to secure sufficiently his Conservative Party base in the general election that year.
So he pandered to Euroskeptic voters with the promise of a referendum.
The source of Cameron’s fear?
The political disruption caused by the UK Independence Party – an anti-establishment party that ended up winning only one seat in Parliament and subsequently found itself leaderless and in turmoil.
Now, it seems, the floodgates have opened.
At the recent Conservative Party annual conference, speeches by Prime Minister Theresa May and members of her cabinet revealed an intention to pursue a “hard Brexit,” thereby dismantling trading arrangements that have served the economy well.
They also included attacks on “international elites” and criticism of Bank of England policies that were instrumental in stabilizing the British economy in the referendum’s immediate aftermath – thus giving May’s new government time to formulate a coherent Brexit strategy.
Several other advanced economies are experiencing analogous political developments.
In Germany, a surprisingly strong showing by the far-right Alternative für Deutschland in recent state elections already appears to be affecting the government’s behavior.
In the US, even if Donald Trump’s presidential campaign fails to put a Republican back in the White House (as appears increasingly likely, given that, in the latest twist of this highly unusual campaign, many Republican leaders have now renounced their party’s nominee), his candidacy will likely leave a lasting impact on American politics.
If not managed well, Italy’s constitutional referendum in December – a risky bid by Prime Minister Matteo Renzi to consolidate support – could backfire, just like Cameron’s referendum did, causing political disruption and undermining effective action to address the country’s economic challenges.
Make no mistake: solid and credible policy options are available.
After years of mediocre economic performance, there is widespread agreement that a shift away from excessive dependence on unconventional monetary policy is needed.
As IMF Managing Director Christine Lagarde put it, “central banks cannot be the only game in town.”
And yet they have been.
As I argue in The Only Game in Town, published in January, countries need a more comprehensive policy approach, involving pro-growth structural reforms, more balanced demand management (including higher fiscal spending on infrastructure), and better cross-border policy coordination and architecture.
There is also a need, highlighted by the protracted Greek crisis, to address pockets of severe over-indebtedness, which can have crushing impact extending well beyond the directly affected.
The emergence of a new consensus on these points is good news.
But, in the current political environment, translating that consensus into action is likely to happen too slowly, at best.
The risk is that, as bad politics crowds out good economics, popular anger and frustration will rise, making politics even more toxic.
One hopes that enlightened political leadership takes the reins in time to make the needed mid-course corrections voluntarily, before unambiguous signs of economic and financial crisis force policymakers to scramble to minimize the damage.
A Rest Stop for Europe
PRINCETON – Last week, in a highly anticipated speech, German President Joachim Gauck cautioned against the blind pursuit of an “ever-closer” European Union, acknowledging that the growing inequality among member states is generating “a sense of unease, even unmistakable anger,” and increasing the risk of national humiliation.
He pointed out that, in addition to the economic crisis, there is “a crisis of confidence in Europe as a political project.”
While Gauck made clear that he remains decidedly pro-Europe, he highlighted the need for closer reflection about Europe’s future – and especially that of the eurozone.
Standing on the verge of greater integration, Europeans are hesitant, “unsure whether we should really stride out on the onward journey.”
Addressing this hesitation, he declared, will require a thoughtful, nuanced understanding of what “more Europe” actually means.
Gauck may not have gone far enough: At this point, an ever-closer union may be a political mirage.
Any meaningful progress toward stabilizing the eurozone would require a significant – potentially open-ended – financial commitment, and the EU is not politically ready to cross that threshold.
Repeatedly pretending to move forward, then pulling back at the critical point, exacerbates political uncertainty and economic vulnerability.
Rather than indecisively pursuing more unity, this may be the moment to restore effective sovereignty to national authorities in eurozone countries.
Such a move would alleviate anxiety in the short term, thereby giving Europeans the opportunity to regroup in preparation for future steps toward a more integrated Europe and a more resilient euro.
To this end, eurozone leaders must take three key steps.
The dysfunctional system of European fiscal governance should be dismantled; fiscal responsibility should be returned to member states; and, to minimize the risk of excessive future lending, private lenders should be required to bear the losses implied by unsustainable sovereign debt.
The case against European fiscal governance is straightforward.
Before the crisis, the single-minded emphasis on reducing national budget deficits to less than 3% of GDP led to extensive abuse.
Either the target was openly flouted, as it was in leading economies like Germany and France, or the data were manipulated to obscure problems (a common practice throughout the eurozone, not just in Greece).
And the belief in economic growth as a fiscal panacea led to unrealistically optimistic GDP forecasts.
When the crisis struck, the 3% deficit target became the focal point for unrelenting austerity – a form of what anthropologist Clifford Geertz described as “involution,” which occurs when a process intensifies rather than changes in response to external or internal pressure.
In other words, EU leaders began to complicate fiscal governance, ultimately creating an inefficient, inescapable labyrinth of regulation and bureaucracy.
As fiscal metrics become increasingly intricate, monitoring efforts will become ever easier to undermine.
The case for returning fiscal responsibility to national authorities is also strong – and not only because centralized fiscal authority has proved to be so inefficient.
With citizens of distressed countries bearing the fiscal burden of the crisis, the enduring presumption that they will not act responsibly is patronizing, at best.
And the current strategy of exchanging goodies for good behavior encourages game-playing and dilutes responsibility.
While the risk that governments will succumb to fiscal temptation remains, citizens’ current suffering is likely to deter future excesses.
National fiscal sovereignty would facilitate the final crucial step: building a more mature relationship with private lenders.
The eurozone was founded on the “no bailout” principle: if member states could not repay their debts, lenders would bear the losses.
But lenders chose – correctly, as it turned out – to disregard that threat.
Instead of enforcing the no-bailout principle and establishing a precedent, debtor countries used official loans to repay private creditors.
As a result, these countries have condemned themselves to continued austerity, low growth, and high debt, while diminishing any future incentive for private lenders to impose fiscal discipline on sovereign borrowers.
Only by shifting the burden of responsibility back onto private lenders can debtor countries escape this quagmire.
In the United States, each state is responsible for its fiscal management, without being forced to comply with a single, overarching template.
The states are not regulated by the federal government; they are disciplined by the knowledge that no one will repay their debts for them.
And the system seems to work: entering the crisis, US states had significantly lower deficit and debt ratios than the eurozone’s vulnerable member states.
So far, European integration has largely been a process of “falling forward,” with each stumble serving as a lesson from which a stronger union emerges.
But, while this uncertain approach may suffice as a basis for declarations of good intentions, it does not inspire the confidence required for countries to make the profound financial commitment that is now needed.
Europeans should have the chance to regain their footing.
Transferring fiscal responsibility back to national authorities would not only mean the end of counterproductive efforts to manage fiscal affairs centrally; it would also diminish the sense of frustration and lack of control that is fueling Euro-skepticism.
In short, taking a step back would provide an opportunity to reset, to reflect, and to plot the best course toward a more stable, more integrated Europe.
For a fiscal union to function – however unlikely that outcome may be – a solid foundation is crucial.
As Gauck explained, Europeans “are pausing to… equip [themselves] both intellectually and emotionally for the next step, which will require [them] to enter uncharted territory.”
Giving Europeans the time and space to choose more Europe would reinforce the core values upon which integration has rested for more than six decades.
Continuing to stumble forward, however, would inevitably lead to a debilitating, if not fatal, fall.
A European Cure for Balkan Depression
VIENNA – European politics is mostly shaped by events and anniversaries.
But while events are often unforeseeable, anniversaries are not.
Five years from now, Europe will be reflecting on the 100th anniversary of the outbreak of World War 1, which led to a loss of life almost without parallel and set in motion a chain of events that led to the creation of Europe as we now know it.
World leaders may have already reserved some days in August 2014 to mark the occasion.
It is easy to predict that Sarajevo will be the place where they will meet to look back on Europe’s savage twentieth century.
But how will Sarajevo look in five years?
Will it still be the capital of a country whose citizens view the future bleakly and whose politicians have totally lost touch with the electorate?
Or is there a hope that European leaders will use the anniversary to announce the successful integration of the remaining Balkan countries into the European Union?
A Balkan Monitor survey recently conducted by Gallup Europe gives suggests the state of public opinion in Serbia, Montenegro, Macedonia, Albania, Croatia, Bosnia and Herzegovina, and Kosovo 20 years on from the fall of the Berlin Wall and a decade after the end of the Kosovo war.
The findings seem to indicate that the next five years will be a make-or-break period for the region’s future development.
While the overwhelming majority of citizens are convinced that further armed conflict in the region is unlikely, the public’s mood – with the exception of Kosovars and Albanians – is pessimistic.
The future promises peace without development.
Trust in political elites and in national and European institutions has been steadily declining.
The majority of citizens have experienced a decline in living standards in the last year, and there remains a perception that people have more opportunities outside their own countries.
Pessimism about employment is alarmingly high among young people, while corruption and government mismanagement are regarded as being widespread.
All those who have made it their job to praise the stability in the region should look at these figures.
Indeed, it is striking that the majority of citizens of Bosnia and Herzegovina believe that their leaders are not interested in their country joining the EU.
An absolute majority of citizens in each of the surveyed countries are convinced that their country is heading in the wrong direction.
Less than one in 10 Croats (whose country could be joining the EU in the near future) believes that their country is heading in the right direction.
There are now two options for the region: one is a “shock integration” program that takes all of the Western Balkan states into the EU; the other is a journey into the unknown.
The hope that these countries can muddle through on their own is a dangerous illusion.
Stability alone can no longer be the EU’s only objective in the region.
The EU’s continuing presence as a colonial power in places like Bosnia and Herzegovina and Kosovo could cause even more problems in the future, especially if benefits are not forthcoming.
In particular, a delay in Serbia’s integration into the EU could bring Tito-inspired fantasies to the heart of the country’s foreign and security policy.
Thus, demoralization of Balkan society creates a dynamic of its own when the best and the brightest see their future outside of their own countries and where “stability” is just another name for political and economic stagnation.
If European leaders do plan to meet in 2014 in Sarajevo, they should act now.
The ratification of the Lisbon Treaty allows for an element of visionary realism in European politics, as there are no longer any institutional obstacles to the future enlargement of the EU.
Today, unlike a year ago, we know how many states are in the Balkans, and the Balkan Monitor results show that all of them want to join the Union.
What the EU has learned from the results of the last parliamentary elections in Bulgaria is that, contrary to conventional wisdom, the leverage of Brussels over new member states increases rather than diminishes after they join.
The EU’s decision to liberalize its visa regime for Serbia, Montenegro, and Macedonia – and the fact that George Papandreou, the major architect of the EU’s Balkan integration strategy, is back in power in Greece – is another source of optimism.
But it is now or never for the Balkans.
Visa liberalization can be a strategic step in the direction of “shock integration,” but if it is not followed by bold political action from the EU, it could merely become a re-packaging of the status quo .
In short, the moment has arrived for shaping events instead of simply marking anniversaries.
Closing Europe’s Strategy Gap
MADRID – The ongoing crisis in Ukraine has been a hot topic of analysis for almost a year.
But one question has largely escaped thorough examination: what Russia’s annexation of Crimea and invasion of eastern Ukraine indicates about the European Union’s foreign policy.
During the early stages of the crisis, Germany, which had bet heavily on Russia’s modernization, was averse to taking any consequential action.
But, as the crisis deepened, German Chancellor Angela Merkel worked to persuade her European counterparts to implement a broad and biting sanctions regime.
This certainly was a step in the right direction, but it did nothing to address the foreign-policy failings that helped spark the Ukrainian crisis and continue to undermine Europe’s response – namely, the EU’s misguided Neighborhood Policy (ENP) and its muddled approach to energy.
On both of these fronts, the EU’s lack of strategic vision has created the impression that Europe is repeatedly being outmaneuvered by Russian President Vladimir Putin.
It increasingly appears that Ukraine is becoming locked in a “frozen conflict” – Russia’s foreign-policy specialty.
Indeed, the situation in Ukraine represents a tactical victory for Russia, with the fragile but enduring ceasefire – and accompanying legislation that grants Donetsk and Luhansk considerable political autonomy – allowing Russia to entrench the conflict near the EU’s border.
Moreover, the delayed implementation of key elements of the EU’s association agreement with Ukraine is clear evidence that, at the moment, Russia dictates the terms of EU-Ukrainian engagement.
In Europe, the Kremlin has been able to pursue a successful divide-and-rule strategy, particularly in view of Hungary’s decision to suspend gas flows to Ukraine.
Prime Minister Viktor Orbán’s government, whose behavior in recent years has been at odds with the EU’s criteria for democracy, now openly approves of authoritarian regimes – and Putin’s, in particular – with serious potential consequences for European unity.
Nonetheless, the timing of the current ceasefire, which coincides with the installation of a new EU Commission, is advantageous, as is Putin’s shortsighted emphasis on tactical victories.
EU leaders should take advantage of the break in the fighting to stop reacting and start anticipating.
With a long-term strategic vision, the EU could overwhelm and ultimately undermine Putin’s short-term successes.
Such a vision must include a reconceptualization of the ENP.
The program’s mission – to help guide the political, social, and economic transitions of neighboring states – is not inherently problematic; the problem lies in the way that the mission has been interpreted and pursued.
For starters, the ENP assumes that all of the EU’s neighbors, both in the south and in the east, ultimately want to realize European values and structures in their own countries.
In other words, the ENP does not account for the developmental, cultural, and aspirational differences among the EU’s partner countries.
The ENP suffers operationally from its excessively technical approach and lack of strategic vision.
For example, before the Ukraine crisis, the European Commission was so focused on negotiating the technical features of the association agreement that it did not consider adequately the potential fallout of the process – such as, say, a response from Russia.
To be sure, the EU recognized its need for a coherent strategy, and attempted to resolve it by establishing the European External Action Service and the position of High Representative for Foreign Affairs.
But the EEAS ended up in a turf war with the European Commission, and outgoing High Representative Catherine Ashton did little to ease the tension, owing to her unwillingness to involve herself in intra-EU disagreements.
It is telling that Ashton has made progress exclusively in areas defined by ample consensus, such as the negotiations on Iran’s nuclear program and the pact between Kosovo and Serbia.
Further eroding Europe’s effectiveness is its fragmented approach to securing energy supplies.
With every country largely controlling its own energy policy, Europe’s energy market has become inefficient and excessively dependent on Russian supplies.
To the extent that there has been an EU-wide energy strategy, it has related to renewables, rather than the intersection of geopolitics and energy security.
But there is reason for hope.
The new Commission, which its president, Jean Claude Juncker, has restructured significantly, could provide Europe with the strategic leadership it so badly needs.
In fact, Juncker has already expressed a desire to integrate incoming High Representative Federica Mogherini into the Commission’s policy program.
The new structure – which tasks Mogherini with guiding and coordinating the work of multiple commissioners, including those responsible for trade, the ENP, and climate and energy – should strengthen the coherence and direction of EU policies, particularly after Mogherini completes her European Council-mandated assessment of the global strategic landscape.
But a restructured Commission is not enough to ensure a reset of Europe’s foreign-policy strategy.
For that to happen, Mogherini must assert herself as a leader, backed by Juncker and the new European Council president, Donald Tusk.
And, most important, all EU member states must recommit themselves to cooperation.
The Ukrainian people have demonstrated the power of Europe’s values.
Indeed, Europe has a large set of tools at its disposal; it just needs to figure out how to use them.
If it can, it will be better able to respond not only to the Russian challenge, but also to many of the other challenges that characterize today’s rapidly shifting global environment.
A Europe of Women?
PARIS – Are women in Europe on the verge of becoming an engine for political change?
In economic-development circles, experience and common sense suggest that progress, accountability, and hard work start with and depend on women.
Micro-credits, for example, are much more efficient when women receive and repay them.
Perhaps because they bear children and must find the means to feed them, women are now perceived as the best and most determined “agents of change.”
That seems to be as true now of European politics as it has been of economics in parts of Africa and Asia.
The results of Italy’s recent municipal elections could be a signal of an incipient electoral dynamic: it was women who voted Silvio Berlusconi’s party out of power in Milan, a city that he has long controlled (and the original seat of his power).
No direct link exists between that result and the dramatic Dominique Strauss-Kahn scandal in New York, but in the immediate aftermath of DSK’s arrest, Italian women and young voters decisively mobilized to defeat Berlusconi’s party (led in Milan, ironically, by a woman).
These voters could no longer stand the combination of machismo and vulgarity that had once served so well the man Italian humorists now call “Berlus-Kahn.”
When Berlusconi first came to power 17 years ago, he had the support of a majority of women.
They were not discouraged by his ambivalent perception of them (by turns celebrating their traditional domesticity and glorifying their sexual objectification).
But Italian society has changed: most women are now working, and they are no longer willing to accept Belusconi’s anachronistic and outrageous chauvinism.
Italian men may pity the aging, isolated leader, who looks increasingly like his wax effigy at Madame Tussaud’s.
But Italian women (indeed, women everywhere, it seems) feel only anger and humiliation over a man so obsessed with himself, his various criminal trials, and his vulgar pleasures that he appears to them to have no purpose left except to remain in power as long as possible.
Women, of course, are not alone in their opposition to Berlusconi, but they made the difference in Milan.
They are the incarnation of modernity, animated by a yearning for simple dignity and respect.
They are not alone in the vanguard of a new Europe of women.
As Iceland spiraled into bankruptcy, owing the irresponsible behavior of its mostly male political and financial elites, the people of Iceland decided that only a strong and responsible woman could redress the country’s problems.
So they elected one as President.
The depth and gravity of the current economic and social crisis in countries like Greece, Portugal, and Spain present women with a new opportunity.
Confronted with what many of them perceive as the equivalent of an “economic war,” women are playing an increasingly important role in maintaining their families’ financial security.
And the more widespread this becomes, the more women will seek a political role that reflects their economic clout.
Of course, women’s changing status may not translate immediately into growing political influence.
And the rest of Europe might never follow the example of Scandinavia, where gender equality has advanced much further than anywhere else.
But such a dynamic does now seem to be in motion.
Similarly, regardless of the outcome of DSK’s trial in New York, the case might represent a turning point in the treatment of women in Europe.
Public and private displays of atavistic machismo, one hopes, will no longer be considered acceptable.
In the Arab world, too, from Tunis to Cairo, young women have played an important role in the revolutionary process.
Their appetite for change – understandable, given the treatment of women in traditional Muslim societies – appears to be one of the main causes underlying the force of the revolutionary impulse in Tunisia and Egypt.
None of this is to argue that “women” are a universal force for positive change in Europe and around the world.
Consider, for example, Marine Le Pen, the new head of France’s National Front, Elena Ceaucescu, the sordid wife of the former Romanian dictator, or, more recently, Tunisian ex-President Zine El Abidine Ben Ali’s wife, Leila Trabelsi, who fled to Dubai with 1.5 tons of gold plundered from the central bank.
The point, simply, is that with so many people in so many countries demanding far-reaching change, the politics of gender is very much in play – in Europe and beyond.
The main question is whether the growing number of women in politics will deliver the different perspectives and modes of leadership that many voters (or protesters) now seem to crave.
A Euro Sabbatical
MUNICH – Under substantial external pressure, the eurozone’s crisis-hit countries are, at long last, bringing themselves to make painful cuts in their government budgets.
Salaries are being slashed and public employees sacked to reduce new borrowing to a tolerable level.
And yet, competitiveness in Greece and Portugal, in particular, is not improving.
The latest Eurostat figures on the evolution of the price index for self-produced goods (GDP deflator) show no tendency whatsoever in the crisis-stricken countries towards real devaluation. But real devaluation, achieved by lowering prices vis-à-vis their eurozone competitors, is the only way to re-establish these countries’ competitiveness.
A reduction in unit labor costs can also increase competitiveness only to the extent that it actually results in price reductions.
After all, it was price inflation in the crisis countries, fueled by massive inflows of cheap credit following the introduction of the euro, that resulted in their loss of competitiveness, ballooning current-account deficits, and accumulation of enormous foreign debt.
Now that capital markets are no longer willing to finance these deficits, prices should be going into reverse, but this, obviously, is not happening.
In 2010, inflation in some of the crisis countries lagged slightly behind that of their eurozone competitors.
The latest Eurostat figures for the third quarter of 2011, however, are already showing a different picture: the price level in Portugal and Greece has remained practically unchanged over the course of the year, and in Italy and Spain it even rose slightly (by 0.4% and 0.3%, respectively).
Only Ireland continued on a path of rapid deflation – as it has since the country’s real-estate bubble burst in 2006 – with a relative price decrease of 2.2%.
On the whole, Ireland has become cheaper relative to its eurozone competitors by a total of 15% over the course of the past five years.
This internal devaluation is paying off: while Ireland was still running a current-account deficit of 5.6% of GDP in 2008, the European Commission expects the outturn for 2011 to have been a 0.7%-of-GDP current-account surplus.
True, much of this is mere debt-service relief, given that Ireland was able to repay its foreign liabilities with self-printed money, for which it pays only 1% interest.
However, Ireland’s big trade surplus did improve further.
Ireland owes much of this turnaround to its efficient export sector, whose supporters were able to enforce a political U-turn.
Greece, on the other hand, is under the influence of a strong import lobby.
As the Greek economics minister, Michalis Chrysochoidis, has said, this is attributable to European Union subsidies, which drove entrepreneurs to follow the easy money into the import sector.
Now these importers form a powerful bulwark against any policy that causes deflation, even though lowering prices – and thereby redirecting Greek demand from foreign to domestic products and helping tourism – is the only way to put the Greek economy back on its feet.
Since Greece’s current-account deficit as a share of GDP was three times higher than Ireland’s, Greek prices would have to fall by about half to achieve the same kind of success.
It is inconceivable that Greece could manage that within the eurozone without widespread social unrest, if not conditions approaching those of civil war.
But it isn’t just importers who are blocking real devaluation. Unions, too, are resisting the necessary wage reductions, and public and private debtors fear the prospect of insolvency if their assets and revenues are assessed at a lower value, while their debts remain unchanged.
The situation is intractable.
Many people regard debt relief and socialization of debts as the only way out.
This help has been given.
The recent agreement gave Greece relief of €237 billion ($316 billion), about 30% more than Greece’s net national income of roughly €180 billion euros.But such help only entrenches the wrong prices – and thus the economy’s lack of competitiveness.
The debts will re-emerge like a tumor, growing year by year, while undermining the creditworthiness of stable eurozone countries.
If that happened, the euro would eventually collapse.
Only a price reduction would create current-account surpluses and enable the crisis countries to pay off their foreign debts.
It is time for Europe to come to terms with this remorseless truth.
Those crisis countries that do not want to take it upon themselves to lower their prices should be given the opportunity to leave the eurozone temporarily in order to devalue prices and debts.
In other words, they should take a kind of euro sabbatical – a proposal that has now also been taken up by American economist Kenneth Rogoff.
After the ensuing financial thunderstorm died down, the sun would come out again very quickly.
The creditor countries would have to shoulder big losses from write-downs, but they would still end up with more than they would have gotten had the crisis countries remained within the eurozone, because these countries’ new prosperity, gained by leaving, offers the only chance of recovering any assets at all.
A Fair Deal for Turkey
Turkey has been given what looks like an ultimatum from the EU Commission: open your ports for ships from Cyprus within a month, or you may risk a halt to the EU accession talks now underway.
At the same time, the Commission’s latest report on Turkey’s progress toward accession notes that political reforms have slowed down, further calling into question the country’s future EU membership.
The Commission’s progress report will be dealt with by the European Council next month.
At that meeting, European leaders should ask themselves the following questions: Has the EU given Turkey a fair deal in the case of Cyprus?
Has the EU’s behavior been consistent in supporting political reform in Turkey?
What are the EU’s long-term interests vis-à-vis Turkey?
If the answers to the first two questions are “no” – as I believe they are – the third question becomes vitally important.
True, Turkey has closed its ports to ships from (Greek) Cyprus, and this is a violation of agreements.
But it is also true that the northern Turkish part of Cyprus is denied access to free trade and other benefits from EU-membership.
This is because Cyprus remains a divided island.
It was assumed that Cyprus should be united when the country joined the EU in 2004.
A United Nations plan for unification was accepted by the Turkish part.
But the Greek Cypriots voted against the plan because their leaders did not live up to the implicit deal with the EU to support it.
Nevertheless, Cyprus became an EU member – but only the Greek part.
This was clearly a mistake, because it made the EU part of the conflict.
It gave Greek Cypriot leaders the possibility of blocking progress in negotiations between the EU and Turkey.
So how can Turkey under these conditions maintain confidence in the EU’s fairness?
Political and legal reforms in Turkey in recent years have been remarkably far-reaching, for they have clearly been spurred by Turks’ wish to move closer to the EU.
But Turkish public support for EU membership has fallen dramatically as Turks have grown to feel that they are not being given a fair deal.
This has given new strength to those who want Turkey to develop in another direction, towards a more Islamic society instead of a modern secular state.
Therefore, the recent lack of progress in Turkey’s reform process can to a large extent be explained by the EU’s behavior.
This leaves us with the third question: what kind of Turkey does the EU want?
There should be no doubt about the answer: it is clearly in the EU’s interest to see Turkey’s democracy and economy continue to strengthen.
More than 40 years ago, it was promised that once Turkey lives up to the preconditions for membership, it will be welcome in the EU.
It is high time that European leaders take this promise seriously.
It is a sad fact that a large majority of voters in the EU are against Turkish membership.
But they are reacting to the current situation.
When they are asked if they would like a reformed Turkey as a partner – a Turkey that lives up fully to the conditions for membership described in the Copenhagen Criteria (democracy, rule of law, respect for human rights, and an effective market economy) – many more are inclined to say yes.
European leaders must therefore take up two challenges.
First, they should say clearly to their own voters that the EU must live up to its promises to Turkey, and that this is in the larger interest of all Europeans.
Second, they should give Turkey a fair deal in the negotiations.
The first litmus test on European leadership concerns the practical problem of access to harbors.
Here the Finns, who chair the EU right now, have taken an initiative to implement a pragmatic solution that takes into consideration both sides in the conflict.
The Finnish initiative should be given strong support from all European leaders.
At the same time, a new effort should be made to bring life to the UN’s proposals regarding Cyprus.
If this means putting pressure on some actors within the EU’s own ranks, so be it.
A Farewell to (Glorious) War
In recent days, Italy’s government fell after losing a parliamentary vote on the country’s troop deployment in Afghanistan, while Britain and Denmark announced that they are to begin withdrawing their troops from Iraq.
Whereas the Bush administration is deploying an additional 21,000 American soldiers in Iraq, and is pushing for more allied troops in Afghanistan, America’s allies are rejecting its Middle East policy.
They are increasingly convinced that “victory” will be elusive in any asymmetric conflict between states, however powerful, and religiously driven armed insurgents.
Donald Rumsfeld’s dogma of military “transformation” – the technological upgrading of an army’s capacity to enable decisive victory with fewer troops – failed resoundingly in Iraq.
Nor could Israel, with its overwhelming technological advantage, defeat Hezbollah in Lebanon.
More rockets and missiles fell on northern Israel in 33 days than hit Britain during all of World War II.
So the Israelis now must reckon with an entirely new phenomenon: an asymmetric entity, Hezbollah, with nation-state firepower.
So the fierce debate over whether to increase the size of American ground forces in Iraq is beside the point.
Neither the Soviet experience in Afghanistan in the 1980’s nor NATO’s today vindicates the claim that troop numbers are what matter most on the modern battlefield.
When geo-strategic military front lines are non-existent, as in Kosovo, Afghanistan, and Iraq, mass no longer equals victory.
The great military thinker Carl von Clausewitz’s notion of “decisive battles” as the “center of gravity” of war is simply irrelevant to conflicts that have no visible “center of gravity.”
Indeed, while wars from the time of Hannibal’s defeat of the Romans in 216 B.C. to the Gulf War of 1991 had this center of gravity, with a massive concentration of force capable of bringing an enemy to its knees, such industrial inter-state wars have now become an historical anachronism.
Most states nowadays lie within borders that are widely accepted as legitimate, and they increasingly abide by international norms of behavior in times of war.
In fact, the obligation of states to abide by humanitarian rules of conduct while their enemies are free to barbarize warfare is what makes asymmetric wars especially insoluble.
Moreover, in an era of global media and international war crimes courts, the criteria for states’ use of military force have become more complex than ever.
Inter-state combat may still occur where strategic front lines can be found, such as Israel’s border with Syria, India’s border with Pakistan, and the border dividing the two Koreas.
In such cases, war, as the Egyptians showed in 1973, might still serve as an avenue to resolving a conflict.
The Syrians might be tempted to launch an offensive against Israel with the objective of breaking the deadlock over the future of the Golan Heights.
However, in the case of Kashmir, the asymmetric conflict currently fought by proxies and terrorist groups might not degenerate into all-out war precisely because India and Pakistan have mutual nuclear deterrence.
This changing nature of the battlefield essentially means that war as a conclusive event in an international conflict has become obsolete.
The facile Clausewitzian wisdom that military action ultimately leads to a political solution is no longer convincing.
“Victory” cannot bring peace, simply because there will always be a war after the war.
Thus, for example, the conventional war in Kosovo lasted for two months, only to usher in a six-year asymmetric conflict.
Likewise, America’s three-week “shock and awe” campaign in Iraq in 2003 ended in “victory,” but opened the gates of hell for occupiers and ordinary Iraqis alike.
And six months after the merciless pounding of southern Lebanon, Hezbollah is as strong as it was before.
Nor does the return of the Taliban in Afghanistan six years after their overthrow now seen too far-fetched.
It is during the war after the war that the occupier’s inferiority is revealed, with constant reinforcements increasing the number of targets for the insurgents far more quickly than the occupier can adapt to the changing battlefield.
The insurgents in Iraq, as the British admit, were able in just three years to cope with their enemies’ technological superiority in a way that the IRA in Northern Ireland was unable to do in 30 years.
The Iraq war and Israel’s wars with Hamas and Hezbollah show the limits of what military power can achieve, as well as vindicate diplomacy and conflict resolution.
When it comes to tackling complex political and cultural conflicts, forging international and regional alliances around a legitimate objective is more important than sheer military capacity.
That said, it would be dangerously naïve to believe that the exercise of power and the capacity to intimidate are unnecessary.
But the objectives of the use of force need to be linked to the recognition that in today’s asymmetric conflicts, victory is no longer achieved on the battlefield.
Only better-informed foreign policies that can address the genuine anxieties of civilizations in crisis will yield more sustainable results.
Affirmative Action for Europe
The violence in France, fueled by staggering unemployment and ruthless policing, reflects the utter failure of the French model of social integration.
But violence elsewhere in Europe, such as the London bombings of July and the brutal murder of Dutch filmmaker Theo van Gogh on the streets of Amsterdam in November 2004, had already made Europe’s failure to integrate its minorities painfully clear.
As the riots in France fade, French politicians are agonizing about how to proceed.
Forty years ago, after legal segregation of blacks and whites formally ended in America, the United States was confronted by similar problems.
America’s response shows, however, that integration cannot be viewed as a one-way street.
In addition to imposing demands and constraints on minorities to join the mainstream, society must be willing to demand of itself that it make room for all its citizens.
As a potential model to be followed, Europe should look at the so-called “affirmative action” policies that America enacted to provide opportunities to blacks.
Affirmative action, or “positive discrimination,” as some have called these policies, began with university admissions.
But, in the early 1970’s, President Richard M. Nixon expanded the scope of affirmative action.
As a result, ethnicity began to be weighed as a positive factor not only in university admissions, but also in public procurement decisions, credit facilities for small enterprises, and government hiring.
The rational for affirmative action in those early years was the fact that, after a long history of systemic injustice, merely outlawing discrimination based on race or gender would not ensure equal opportunity for all.
Such programs are often viewed as contradicting a basic American value, namely that admissions, lending, and hiring decisions should be based on the merits of the individual, not group distinctions.
But they remain in existence three decades later.
Indeed, leading American companies, like General Motors, General Electric, and Walmart, have created affirmative action programs for hiring and selecting suppliers at their own initiative.
Similarly, anchormen and anchorwomen from all ethnic backgrounds populate American television news programs.
In France, by contrast, the appointment of the black anchorwoman Audrey Pulvar was big news on its own, because most of her colleagues in France are white.
Affirmative action in the US has been effective in creating a large African-American middle class.
The percentage of black households earning over $50,000 a year (adjusted for inflation) has more than tripled over the last four decades, from 9.1% in 1967 to 27.8% in 2001.
Indeed, in the US, more people of color and women hold top jobs in the public and private sector than anywhere else in the world.
The fact that a large black underclass remains – something the recent floods in New Orleans revealed in a horrifically dramatic way – is mainly the result of failing school systems.
Affirmative action programs, of course, have always been vulnerable to attack by those who can’t benefit from them.
In 2003, a white student asked the US Supreme Court to declare that the use of race in the University of Michigan’s admission policies violated the Equal Protection Clause of the Fourteenth Amendment of the US Constitution.
The Supreme Court, however, ruled that the program was constitutional, citing a “compelling state interest” in racial diversity.
“Effective participation by members of all racial and ethnic groups in the civil life of our nation,” the court said, “is essential if the dream of one nation, indivisible, is to be realized.”
In reaching its decision, the Supreme Court took into account a legal brief submitted by 60 major American businesses, led by General Motors, asking that affirmative action be upheld.
They argued that the skills needed in today’s global marketplace can only be developed through exposure to a wide diversity of people.
Retired military officers and commanders told the court that affirmative action was essential to maintaining an integrated officer corps.
What America’s affirmative action programs may not do is set quotas for minorities, as this prevents competition between different groups.
But, in comparing groups, it is permitted to use an individual’s status as member of an under-represented minority in his or her favor.
As a result, a university may select a black student with a satisfactory score on the admissions test, even if there is a white student with a better score.
From the current French viewpoint, however, laws and regulations based on ethnicity are regarded as an unwelcome encroachment on the Republican ideal.
French President Jacques Chirac vehemently opposes quotas for immigrants, out of fear that such a policy would stigmatize groups.
And French businesses don’t see it as their role to solve the problems of the suburbs.
Moreover, French Interior Minister Nicolas Sarkozy hasn’t done much except hand out some special grants to the smartest immigrants from the suburbs.
France does have affirmative action programs, but they address poverty, not ethnicity.
If European politicians are serious about preventing a schism between population groups, affirmative action is essential – not only at the workplace, but also for small business loans, home loans, public procurement, and school admissions.
Tony Blair, who in July was faced with the shortcomings of integration in the UK, should take advantage of the country’s current presidency of the European Union to make affirmative action programs the top priority at next month’s summit of European government leaders in Brussels.
Affordable Green Energy
COPENHAGEN – Public skepticism about global warming may be growing, but the scientific consensus is as solid as ever: man-made climate change is real, and we ignore it at our peril.
But if that issue is settled (and it should be), there is an equally large and important question that remains wide open: what should we do about it?
One prescription that is bandied about with increasing frequency certainly sounds sensible: the world should drastically cut the amount of greenhouse gases that it pumps into the atmosphere each day.
Specifically, we are told, the goal should be a 50% reduction in global carbon-dioxide emissions by the middle of the century.
Even its backers concede that achieving this target won’t be easy – and they are right.
In fact, they are so right that they are wrong.
Allow me to explain.
Our dependency on carbon-emitting fuels is more than enormous.
It is overwhelming.
For all the talk about solar, wind, and other hyped green-energy sources, they make up only 0.6% of global energy consumption. Renewable energy overwhelmingly comes from often-unsustainable burning of wood and biomass by people in the Third World.
Fossil fuels account for more than four-fifths of the world’s energy diet.
So, in order to cut global carbon emissions in half by the middle of the century, we would obviously have to start getting a lot more of our energy from sources that don’t emit carbon.
Can we do this?
According to the International Energy Agency, here’s what it would take to achieve the goal of cutting emissions by 50% between now and mid-century:
30 new nuclear plants; 17,000 windmills; 400 biomass power plants;Two hydroelectric facilities the size of China’s massive Three Gorges Dam; and42 coal and gas power plants with yet-to-be-developed carbon-capture technology.Now consider this: this list does not describe what we would have to build between now and 2050, but what we would have to build each and every year until then!
One more thing: even if we managed to do all this (which we obviously cannot), the impact on global temperatures would be hardly noticeable by 2050.
According to the best-known climate-economic model, this vast undertaking would likely wind up reducing global temperatures by just one-tenth of one degree centigrade (one-fifth of one degree Fahrenheit), while holding back sea-level rises by only one centimeter (less than half an inch).
That’s not a lot of bang for the buck.
Indeed, the projected costs of this approach – some $5 trillion annually by mid-century – are so much greater than its likely benefits that it makes no sense to call it a solution at all.
Fortunately, there is a better, smarter way to deal with global warming.
What if, instead of spending trillions of dollars trying to build an impossible number of power plants – or, more likely, condemning billions of people around the world to continued poverty by trying to make carbon-emitting fuels too expensive to use – we devoted ourselves to making green energy cheaper?
Right now, solar panels are so expensive – about 10 times more than fossil fuels in terms of cost per unit of energy output – that only well-heeled, well-meaning (and, usually, well-subsidized) Westerners can afford to install them.
But think where we’d be if we could improve the efficiency of solar cells by a factor of ten – in other words, if we could make them cheaper than fossil fuels.
We wouldn’t have to force (or subsidize) anyone to stop burning coal and oil.
Everyone, including the Chinese and the Indians, would shift to the cheaper and cleaner alternatives – and global emission targets would automatically be met.
Can we achieve this technological miracle over the next 20 to 40 years?
In a word, yes.
The price of solar energy has been dropping steadily for 30 years – by about 50% every decade – and we could likely accelerate that decline further with sufficiently large investments in research and development.
How large?
If we were willing to devote just 0.2% of global GDP (roughly $100 billion a year) to green-energy R&amp;D, I believe that we could bring about game-changing breakthroughs not just for solar power, but also for a wide variety of other alternative-energy technologies.
This belief in the potential of technological progress strikes some climate activists as naïve or even delusional.
But is it really?
Consider one of the miracles of the modern age – the personal computer.
These devices didn’t become household items because governments subsidized purchases or forced up the price of typewriters and slide rules.
No, what happened is that, largely as a result of the space race, the United States government poured lots of money into R&amp;D for solid-state physics and electronics engineering. The resulting breakthroughs not only got Neil Armstrong to the moon in 1969, but also made it possible for Apple to introduce the first Mac in 1976 and IBM to debut the first PC five years later.
We can do the same for clean energy.
Forget about subsidizing inefficient technologies or making fossil fuels too expensive to use. Instead, let’s fund the basic research that will make green energy too cheap and easy to resist.
Afghanistan Is Lost Without Better Governance
NEW YORK – President Obama's recent trip to Afghanistan highlighted the growing American and international perception that without better governance Afghanistan will fail.
As President Obama apparently made clear in his late night meeting with President Hamid Karzai, no matter what other progress is made, America and its allies cannot succeed in Afghanistan unless the Afghan government succeeds—and that government is moving in the wrong direction.
Until this changes, all other efforts will ultimately be in vain and current levels of international engagement with Afghanistan will become unjustifiable.
The United States and its Afghan and NATO allies have demonstrated unmistakable progress in Afghanistan this year.
The ongoing Marja campaign, the arrest of Mullah Abdul Ghani Baradar and two Taliban "shadow governors" in Pakistan, and the recent drone strike hitting top leaders of the Al Qaeda-affiliated Haqqani network are all clear steps in the right direction.
President Obama has defined America's goals in Afghanistan as denying Al Qaeda a safe haven, reversing the Taliban's momentum, and helping the country's security forces and government "take lead responsibility for Afghanistan’s future."
To this end, Obama launched an 18-month military "surge" with the backing of other NATO member countries, to be followed by the beginning of withdrawal.
To achieve these goals in such a short time, NATO and its Afghan partners must overcome three enormous obstacles.
First, they must fight far more successfully against the Taliban to create space for rebuilding and possible negotiation.
Second, they must convince Pakistan to begin actively opposing the Afghan Taliban and denying them the safe haven and support they currently receive in Pakistan.
Third, they must support the emergence of a legitimate Afghan government that is not, unlike the current government, seen as corrupt and ineffectual by its citizens.
Because the NATO strategy's success requires significant progress on each of these fronts, even the current preliminary signs of military progress and in Pakistan's relations with the Afghan Taliban will be for naught if Afghanistan's government cannot establish its legitimacy domestically.
Recent efforts by President Hamid Karzai’s administration to limit its public accountability demonstrate that the Afghan government in its current form lacks either the capacity or the willingness to do so.
For at least a year prior to the August 2009 elections, NATO officials recognized that ordinary Afghans' disgust with their government's massive corruption was among the Taliban's most effective recruitment tools.
At that time, these officials argued that the elections would give Afghanistan’s leaders a clear mandate for reform.
The deeply discredited elections put an end to those hopes.
The original flaw of the 2009 elections was structural. There was no voter list, and so it was nearly impossible to prevent ballot-stuffing.
The body empowered to conduct the vote, the Independent Election Commission, was run by commissioners all appointed by and partial to one candidate, Karzai.
One institution, the Electoral Complaints Commission—a hybrid Afghan-international oversight body with a majority vote controlled by United Nations-appointed commissioners—retained its credibility throughout the process.
Only the presence of the ECC, particularly its international commissioners, and the hope that it would ensure at least some fairness into the process prevented the electoral controversy from erupting into open conflict.
As flawed as the elections were and as contentious as the outcome ultimately was, the situation would have been far worse without the ECC.
After the election, many hoped that Karzai would recognize the need to build a more accountable government to help secure both Afghanistan's future and the future of international military and financial support.
In a high-profile speech in London this past January, Karzai pledged to make progress in fighting corruption and promoting government accountability.
Instead, the opposite appears to be happening.
Since his London speech, Karzai has actively opposed efforts to attack official corruption, sought to appoint warlords to his cabinet, failed to promote civil society, and weakened processes aimed at increasing the representation of women in parliament.
To make matters worse, Karzai issued a decree on February 13 permitting him to appoint all of the ECC's members, a measure clearly designed to strengthen the patronage system and weaken opposition movements’ prospects in future elections and a strong demonstration that his administration is not serious about establishing greater government accountability.
NATO and the international community must do everything possible to foster accountable government at all levels in Afghanistan.
Although Afghanistan's government does not need to be fully centralized, Afghanistan cannot succeed if the central government fails.
For this reason, unless the Karzai government changes course there is no justification for NATO member countries to risk the lives of their soldiers and commit other valuable resources to the struggle in Afghanistan if the Afghan government’s corruption and legitimacy deficit make current progress unsustainable and achievement of NATO’s goals impossible.
Karzai is free to lead his country as he pleases, but America and its allies cannot and should not maintain their current levels of commitment unless his government can establish itself as a viable partner.
The 18-month clock is ticking.
No Exit from Afghanistan
NEW DELHI – Despite frequent turmoil and repeated invasions, Afghanistan has remained virtually unchanged for centuries.
Nearly 120 years ago, Winston Churchill described the futility of warfare in the region: “Financially it is ruinous.
Morally it is wicked.
Militarily it is an open question, and politically it is a blunder.”
Churchill’s assessment undoubtedly rings true for many United States and NATO officials today, as they attempt to coordinate an exit from America’s longest overseas combat commitment in history.
While the war in Afghanistan may have resulted in fewer American deaths and injuries than previous US wars, the human cost remains substantial – especially after factoring in Afghan deaths and injuries.
Moreover, trillions of dollars have been wasted, with the few positive effects of the US-led military intervention already beginning to fade, and its many adverse consequences continuing to destabilize the region.
US President Barack Obama is now trying to negotiate a new “status of forces” agreement with the Afghan government in order to establish how many US troops will remain in Afghanistan and the terms of their deployment.
But the reality is that the US is scuttling from a conflict that it has lost, just as it did in Vietnam almost 40 years ago, leaving the beleaguered population to its own devices.
Rather than admit defeat, US officials are resorting to diversionary rhetoric.
For example, speaking recently in New Delhi, Secretary of State John Kerry said that the key to stabilizing Afghanistan is to build a “new silk road” connecting it with central Asia – a cynical contrivance apparently aimed at cloaking America’s failure in illusions of future commerce.
Kerry’s insistence that the US is not withdrawing, but “drawing down,” is a similarly transparent attempt at manipulation.
To be sure, America’s presence in Afghanistan has spawned important regional linkages; unfortunately, they are not the kind that support economic renewal.
The last decade of war and lawlessness has facilitated the Taliban’s proliferation across Pakistan and Afghanistan, leading the Taliban to consider itself an indefatigable force – a belief that could lead its leaders to undercut any progress toward stability.
In fact, the Taliban’s confidence already drove them to disrupt plans for peace talks with the Afghan government.
After agreeing to establish an office in Qatar exclusively to host the talks, in June the Taliban opened a quasi-embassy of the “Islamic Emirate of Afghanistan.”
The Afghan government responded by suspending talks with the Taliban, as well as the status-of-forces negotiations with the US.
Pakistan recommends seeking an alternate venue for the negotiations with the Taliban, rather than abandoning reconciliation efforts altogether.
This bodes well for the resumption of talks, given that Pakistan played a leading role in facilitating the Taliban’s emergence and is now home to the Afghan Taliban’s ruling council, including its leader, Mullah Omar, along with the Pakistani Taliban.
India’s former ambassador to Afghanistan, Vivek Katju, is confident that Afghan President Hamid Karzai’s anger at the Taliban’s gambit in Qatar will not delay negotiations for long.
(Indeed, Karzai has reportedly already met with Taliban representatives for secret talks aimed at restarting the stalled peace initiative.)
Katju attributes the talks’ inevitable resumption to America’s “strategic desperation,” which is so acute that the US would be unlikely even to follow through on Kerry’s pledge to call off the talks if any link to Al Qaeda were found.
After all, the US has already accepted the Taliban’s unrealistic assurances that it will not use Afghanistan as a base from which to “foment trouble” – that is, execute terrorist attacks – elsewhere.
Fortunately for the US, the Taliban is no longer a homogeneous group.
A decade of running and hiding from unrelenting surveillance and targeted drone attacks has caused the movement to splinter.
Yet, as the security expert Sajjan M. Gohel has observed, “the displaced and disillusioned Taliban youth of today” have “found solace and purpose in an extremely radical interpretation of Islam.”
The Taliban may no longer be a unified force, but they clearly remain a dangerous one.
All of these developments have put India in a difficult position.
In Afghanistan, America’s military was so tactically dependent on Pakistan that, on several occasions, the US encouraged India to curtail development projects, such as rebuilding Afghanistan’s infrastructure.
Following America’s military withdrawal, Afghanistan will most likely revert to pre-war conditions; Pakistan will revive state-sponsored terrorism against India; and extremism will spill into the Indian state of Jammu and Kashmir.
In order to make the best of a grim situation, India must be prepared to protect its own interests at all costs.
After all, as the US extricates itself from its Afghan quagmire, its own national interests will continue to trump all other considerations.
But China, Pakistan, and Iran also have their own important national-security interests in Afghanistan that each will now do their utmost to guarantee.
So, while US troops may be leaving Afghanistan, an end to the violence spawned by America’s war remains nothing more than a distant dream – especially for Afghanistan’s South Asian neighbors.
Afghanistan’s Customary Anguish
FARAH , AFGHANISTAN – When the problems riddling Afghan society are listed – violence, insecurity, corruption, religious fundamentalism – one dominating factor is usually left out: the influence of customary law.
In Afghanistan, there are three principal legal references:   constitutional law, the Koran, and the system of customary law known as Farhang , the most dominant and strictest version of which is called Pashtunwali (the way of the Pashtuns).
Originally an ancient honor code, Farhang ensures the dominance of the oldest male of any household, followed by married sons, unmarried sons, and grandsons, then wives (with the youngest at the bottom).
Collective decisions are taken by patriarchs in councils called jirgas , where all have to be in agreement.
This agreement includes including collaborating or not with the Taliban, cooperating with the Coalition forces, accepting or refusing poppy eradication in a village.
Everything else is left to patriarchal discretion.   Here, no one will intervene except to reinforce the application of   the patriarch's rights – say, in stoning a supposedly wayward girl, or turning a blind eye to so-called “honor killings” of women.
Every act of an Afghan male’s life is integrated in a form of reciprocity, in which nothing is free.
Melmastia , the basic tenet of hospitality means “I will give you shelter if you ask me to, even if you are a fugitive murderer; but, in exchange, you fight my battles.”
This sense of customary obligation is why so many of President Hamid Karzai’s cronies remain in place and Taliban leaders remain safe.
Women are excluded from collective decision-making, as they are mere objects.
Girls are literally sold upon marriage (the father is paid money for his daughter’s labor and reproductive capacity) and join their husband’s household.
The younger the girl, the higher the price.
Marriage, especially in the provinces, is routinely consummated on pre-pubescent bodies.
Yet women are precious in their own way.
A family’s principal “cultural capital” is its honor, which is ensured by denying women any opportunity to highlight male failings and therefore tarnish clan respectability.
As a result, women must be strictly secluded and made invisible when in public, for they are personally responsible for the desire that they could ignite in schools, hospitals, parks, or markets.
The all-covering burqa ensures sufficient anonymity to permit women a certain amount of freedom in public space.
Every female simultaneously carries her father’s and her husband’s honor, and will stoically submit to all forms of violence committed in its name.
This may mean dying in childbirth rather than risking the “dishonor” of giving birth in a public place, a hospital, in front of strangers.
Going to court is practically unheard of, as it would mean renouncing family practices.
From the male point of view, resorting to outside police or judicial intervention would signify an inability to fight one’s own battles – an admission of defeat and a symbolic castration.
This helps explain the intense corruption present in Afghan courts, where “honor” can be redeemed by bribing a judge to have a rapist or murderer released.
As violence is strictly a private matter, relinquishing justice to state institutions could be an unacceptable humiliation.
Customary law is not rigid in that it is made to fit round the demands of global economy.
It has become more rigorous in it s applications due to the influence of
For example, while the Koran allows for a measure of female inheritance, tribal custom does not authorize it, which explains the popularity of tribal councils to resolve inheritance problems and cheat women out of their rights.
Similarly, whereas the Koran requires four eyewitnesses as proof of adultery, mere suspicion of some unregulated, potentially sexual conduct by a woman warrants stoning under customary law.
Yet an awareness of alternatives is seeping in through the media, even in remote provinces.
Iranian films and the much loved Indian TV serials, not to mention the occasional American film, influence peoples' expectations.
Add to that the experience of having lived abroad as refugees in Pakistan and Iran.
Girls know that there are options to an unacceptable way of life: women are increasingly demanding more from life than what custom ordains.
This is especially true for those who have lived in Iran, a totally Muslim environment that allows women the freedom to study and work as well as access to adequate healthcare and family planning.
Once back in rural Afghanistan, forced into brutal marriages, many desperate women – especially returnees from Iran – resort to self-immolation.
Violence and murder of women are on the increase, perpetrated by men who feel that these alternatives pose a threat to their authority.
The West imagines that religion is the central issue in Afghanistan.
But the heart of the matter is the preservation of ancient patriarchal rights that go back to Biblical times, reformatted to fit the demands of globalized capitalism.
Governments and international aid organizations have failed to take into consideration the role of Farhang , perhaps because the power of unwritten law remains largely inconceivable in the West.
But Afghanistan cannot begin to solve its many problems until it criminalizes the privatized violence of this antiquated code.
Afghanistan’s Drug-Friendly Environment
Afghanistan’s President Hamid Karzai has stepped up international fundraising efforts in recent weeks, seeking a fresh package of military and reconstruction aid from the United States, together with stronger strategic guarantees.
But Karzai’s relationship with his sponsors has begun to sour, in part owing to charges that his government has failed to stop the resurgence of Afghanistan’s huge opium trade.
Underlying the opium trade issue is a security threat of another kind, one overlooked since the US-led invasion toppled the Taliban regime in 2001, despite the grave risk it poses to Afghanistan’s long-term stability, and that of the region.
In countries like Afghanistan, where 80% of the population lives on what they grow and many communities live far from any water source, environmental damage can be both economically devastating and politically momentous.
That lesson should have been absorbed and understood, not least by American strategists, long before the Taliban’s fall.
After all, desertification and deforestation helped fuel the rise, two decades earlier, of the Maoist guerilla group Sendero Luminoso (Shining Path) in Peru.
Sendero, which supplemented its income with drug production and timber smuggling, deliberately chose drought-weakened and deforested mountain villages as the stronghold of its insurgency.
Similarly, the Maoist insurgency in Nepal, which has claimed 10,000 lives, exploits the desperation of mountain villagers hit by flash floods – the result of deforestation higher up.
No Maoist group could ever gain a toehold in Afghanistan’s parched Pashtun south (these were, after all, people who, bare-knuckled, smashed the Soviets).
But the Taliban’s rapid rise in the 1990’s was inextricably linked to the failure of irrigation systems.
Villagers whose crops shriveled and whose livestock died in a prolonged drought saw joining the Taliban as an economic opportunity.
Had there been more irrigation, the Taliban’s gains might have been far less impressive.
The Taliban are now an increasingly spent force, but lack of water reinforced the logic of opium production across its former strongholds in the south.
Irrigation has failed or is inadequate in Helmand, Uruzgan, and Kandahar – three of the top five opium-producing provinces – where indebted farmers are hooked by the economics: opium brings in eight times as much cash as wheat and uses less water.
Without serious investment in irrigation, including construction of reservoirs to make use of the snowfall in the Hindu Kush, and in new cash crops such as saffron and rose oil, Afghanistan’s drift toward narco-statehood will continue, with all the instability that this implies.
Clear-cutting of old growth forests in the mountains bordering Pakistan may prove as problematic.
Agriculture there has been damaged by the cutting of walnut, apricot, and mulberry trees for winter fuel, and by a failure to replant poplar, willow, and tamarisk – the trees that hold fragile meadows in place.
These sorts of trees can be restored, given a concerted campaign and investment in nurseries to produce local varieties.
Loss of the ancient cedar, pine, fir, and oak forests on the slopes above is another matter.
This year’s snowmelt caused landslides and flooding – a warning of more soil erosion and destruction of arable land to come; hundreds died and thousands lost their livelihoods.
Forestry has always been a problem in Afghanistan.
In 1960, the United Nations Food and Agriculture Organization spoke of wasteful logging practices, such as “head-skidding” (in which a log is rolled downhill, ripping up plants and soil).
Aerial photographers were called in, and a large budget was set aside.
But, in 1976, the FAO admitted in a new plan that forest and watershed management activities had “turned out to be quite limited.”
The 1976 plan called for sustainable logging and basic forest-fire control, but war intervened, costing Afghanistan half its forest cover.
Up to 60% of the old growth forest in Nangahar, the second largest opium-producing province, may have been cut during the war years.
Mujahedin factions and later the Taliban exported stands of fine-grained cedar by the truckload from Nangahar and surrounding provinces to Pakistan, often in return for arms.
Illegal logging continues today, with only ineffectual efforts made to stop it.
At the current rate, Afghanistan’s old growth forest could vanish within a decade.
The UN acknowledges the problem but is (rightly) unwilling to risk sending forestry experts into a tribal region where American and allied troops venture only in armored convoys.
Safety concerns and cost also limit intervention by international conservation organizations.
A new initiative called the Green Corps includes 300 forest rangers charged with stopping illegal logging, and the ministry hopes to boost their numbers within a year. But the initiative is unlikely to have much effect.
Illegal logging crews number 200 or more.
They have chain saws and trucks. They are armed and work with the backing of drug and emerald smugglers – and often of local officials.
The price of plank cedar in Lahore is incentive enough to corrupt, or kill, any Green Corps men brave enough to stand in their way.
Environmental issues are of paramount importance in marginal countries because their impact on human survival is immediate and direct.
The inadequate response to pressing questions of natural resource management, whether of water or trees, merely strengthens the hands of opium dealers and malcontents in what is already the most disaffected and sensitive part of Afghanistan – the clear-cut mountain slopes where intelligence officers believe Osama bin Laden is most likely holed up.
Afghanistan’s Feminist Revolution
On April 16, more than 300 Afghani women – many of them students – marched together in Kabul in protest of a new law passed by Parliament that would impose a series of Taliban-like restrictions on women.
The law would permit marital rape, limit women’s movements – say, for work or study – without male permission, and even make it illegal for a woman to refuse to dress as her husband wishes.
The women, facing a crowd of furious men calling them “whores” and other epithets, marched two miles under a rain of abuse and delivered their petition against the law to legislators.
Both houses of Parliament had approved the law, and President Hamid Karzai signed it.
The law now affects only the Shia minority, but threatens to affect pending legislation that could restrict the rights of non-Shia women as well.
When Western media sought quotes from the women, they frequently heard a Western-style feminist refrain: “These laws would make women into a kind of property.”
In the West, the counterpoint to the notion of woman as property has been a highly individualistic demand for personal autonomy – decision-making based primarily on a woman’s own wishes, rather than as wife, mother, community member, or worshipper.
But, while some Western feminist insights may be useful to Afghani women and other women in the developing world as they resist certain forms of male oppression, we should not assume – as Western feminists often have – that our job is to proselytize “our” feminism.
On the contrary, the feminism expressed by women such as these Afghani heroines should educate us in the West about our own shortcomings.
The core theory with which emerging feminists in more traditional and religious societies are working is far different from that of Western feminism – and in some ways far more profound and humane.
In India, for example, feminists articulated to me a vision of women’s equality that was family-centered rather than self-centered, and that valued service to community rather than personal gratification.
They did not see their struggle as a cultural or ideological clash between men and women, but rather as a very practical effort to live free from violence and sexual assault, forced child marriage and bride-burning, and legal exclusion from parity.
The emerging consensus in India in support of greater rights and freedoms for women, while certainly causing some upheaval and adjustment (especially within the growing middle classes) has not yet – and might never – poison the basic trust and warmth between men and women.
Nor does it seem likely to emulate the splintered, individualized, solitary society – and the commodified sexual revolution – that Western, self-based feminism reflects.
This version of feminism – the notion that women can claim equality and still have a valued role in the home, prize family above all, and view rights in the context of community and spirituality – seems like a much-needed corrective to some of Western feminism’s shortcomings.
Ideally, men’s drive for progress in the developing world would also evolve, uniting the idea of the autonomous self with support for family, community, and other ties, and Western men would learn from this as well.
Moreover, intellectually, these women remind us that Western feminism did not have to evolve the way it did, and can still change and grow to embrace a more satisfying and humane definition of equality.
Simone de Beauvoir, whose seminal book
The good news for all women, East and West, is that President Karzai, under intense international criticism – and not just Western criticism – changed the law less than one week after the march.
This global uproar is a testament to how three decades of Western feminist challenges to leadership have changed the world for the better.
But our (Western) moment of feminist leadership is over now – for good reasons.
We know by now what our problems are as women in the West, and we know the blueprint for solving them.
What we lack now is not analysis, but the organizational and political will to do so.
So the leadership role is shifting to women in the developing world.
Their agenda is more pressing, and their problems, frankly, far more serious than ours, which makes it much more urgent for them to develop theories appropriate to the challenges they face.
If one of those courageous Afghan women who marched in Kabul wrote – as I hope she or one of her sisters in the developing world is doing right now – the seminal text for the next 50 years on non-Western feminism, it would no doubt be equality-driven and practical.
And perhaps, in its likely view of the world as being more than the sum of consuming, competing autonomies, or gender warfare, it would be a valuable challenge to truisms that we Western feminists – and the men who love us – have thought we had to take for granted.
Afghanistan’s Opium War
When NATO leaders meet for their summit in Riga at the end of this month, there will be a ghost at the feast: Afghanistan’s opium.
Afghanistan is in danger of falling back into the hands of terrorists, insurgents, and criminals, and the multi-billion-dollar opium trade is at the heart of the country’s malaise.
Indeed, NATO’s top general, James Jones, has called drugs the “Achilles heel” of Afghanistan.
This year’s record harvest of 6,100 tons of opium will generate more than $3 billion in illicit revenue – equivalent to almost half of Afghanistan’s GDP.
Profits for drug traffickers downstream will be almost 20 times that amount.
Opium money is corrupting Afghan society from top to bottom.
High-level collusion enables thousands of tons of chemical precursors, needed to produce heroin, to be trucked into the country.
Armed convoys transport raw opium around the country unhindered.
Sometimes even army and police vehicles are involved.
Guns and bribes ensure that the trucks are waved through checkpoints.
Opiates flow freely across borders into Iran, Pakistan, and other Central Asian countries.
The opium fields of wealthy landowners are untouched, because local officials are paid off.
Major traffickers never come to trial because judges are bribed or intimidated.
Senior government officials take their cut of opium revenues or bribes in return for keeping quiet.
Perversely, some provincial governors and government officials are themselves major players in the drug trade.
As a result, the Afghan state is at risk of takeover by a malign coalition of extremists, criminals, and opportunists.
Opium is choking Afghan society.
Within Afghanistan, drug addiction is rising.
Neighbors that used to be transit states for drugs are now major consumers, owing to similar dramatic increases in opium and heroin addiction.
Intravenous drug use is spreading HIV/AIDS in Iran, Central Asia, and the former Soviet Union.
In traditional Western European markets, health officials should brace for a rise in the number of deaths from drug overdoses, as this year’s bumper opium crop will lead to higher-purity doses of heroin.
What can be done?
First, the veil of corruption in Afghanistan must be lifted.
Afghans are fed up with arrogant and well-armed tycoons who live in mansions and drive top-of-the range Mercedes limousines – this in a country where barely 13% of the population have electricity and most people must survive on less than $200 a year.
It is time for the Afghan government to name, shame, and sack corrupt officials, arrest major drug traffickers and opium landlords, and seize their assets.
Donors have trained police and prosecutors and built courts and detention centers.
Now it is up to the government to use the judicial system to impose the rule of law.
It will be difficult, but not impossible, to re-establish confidence in the central government.
Putting major drug traffickers behind bars at the new maximum-security prison at Pul-i-Charki, near Kabul, would be a good start.
Of course, Afghanistan does not bear sole responsibility for its plight.
The heroin trade would not be booming if Western governments were serious about combating drug consumption.
It is a bitter irony that the countries whose soldiers’ lives are on the line in Afghanistan are also the biggest markets for Afghan heroin.
Furthermore, Afghanistan’s neighbors must do more to stop insurgents, weapons, money, and chemical precursors from flowing across their borders into the country.
Coalition forces should take a more robust approach to the drug problem.
Counter-insurgency and counter-narcotics are two sides of the same coin.
Improving security and the rule of law must include destroying the opium trade.
Allowing opium traffickers to operate with impunity gives them a free hand to raise money to pay for the arms and fighters battling the Afghan army and NATO forces.
The United Nations Security Council has authorized the International Security Assistance Force to take all necessary measures to fulfill its mandate.
NATO troops should be given the green light to help the Afghan army fight opium – destroy the heroin labs, disband the opium bazaars, attack the opium convoys, and bring the big traders to justice.
And they should be given the tools and manpower to do the job.
There is no point in trying to win the hearts and minds of major drug traffickers.
Farmers are a different story.
Forced eradication risks pushing farmers into the hands of extremists, and thus will not lead to the sustainable reduction of opium fields.
Indeed, as we have seen in some Andean countries, it can be counter-productive.
Therefore, security and development must go hand in hand.
To achieve this, Afghanistan needs more development assistance.
International support so far has been generous, but it is still well below per capita equivalents for other post-conflict situations – and the need is much greater.
Farmers will be weaned off opium over the long term only if they have sustainable livelihoods.
At the moment, Afghanistan’s drug lords are prospering, and rural communities are suffering.
That situation needs to be reversed.
We must punish the traffickers and reward the farmers.
We cannot afford to fail in Afghanistan.
Recent history has given us graphic evidence of what would happen if we do.
But any solution in Afghanistan depends on eliminating its opium.
Afghanistan’s Terrorized Women
KABUL – Recently, the Afghan Independent Human Rights Commission (AIHRC) office in Kudoz province reported the rescue of a young woman who had been imprisoned in her in-laws’ dungeon for seven months.
Fifteen-year-old Sahar Gul was forced to marry an older man who serves in the Afghan army. She was then kept in the dungeon by her husband’s family and brutally tortured for months, because she refused to work as a prostitute.
Over the past ten years, the AIHRC has received more than 19,000 complaints related to violence against women.
Despite making some progress in investigating the complaints and referring them to the justice system, as well as in raising public awareness about the issue, the challenges remain huge.
Since 2002, many efforts have been made to improve women’s lives in Afghanistan.
The country has enacted several new laws and established a fairly advanced legal framework to end discrimination against women, including a new law that criminalizes any act that results in violence against women.
But laws and policies alone are not sufficient to protect women from horrific domestic abuse.
Indeed, the Gul case is hardly the only well-publicized case.
There was also Gulnaz, a young woman who was jailed for adultery after being raped by a relative (she was recently released after a presidential pardon, but may be forced to marry her attacker).
The husband of another young woman, Aisha, cut off her nose and ears when she ran away.
First, the country has inherited a patriarchal tribal tradition that assumes women’s inferiority. Women are therefore deprived of their basic rights and freedoms.
Second, there is a strong political incentive to deprive women of their rights.
Radical groups receive immense support from the large share of the population that opposes women’s rights.
The Taliban, for example, have consistently used an anti-women policy to appeal to tribal and rural people.
Third, family pride and honor are deemed more important than a woman’s individual well-being and safety.
For example, if family members beat or abuse a woman, she has few options.
Often, her only choice is to remain silent or risk disgracing the family.
If she does report the matter to the authorities, the case will almost certainly never be properly investigated, nor the perpetrators ever prosecuted.
Gul, for example, complained to the police about her abusive in-laws, but she was returned to the family when some of their influential contacts intervened.
Fourth, laws are often arbitrarily applied, and sharia (Islamic law) frequently takes precedence over civil legislation, resulting in widespread impunity for crimes of violence against women.
For example, in October 2010, the Afghan Supreme Court ruled that women who run away from home can be charged with prostitution, unless they go to the police or an immediate relative's home.&#160;It is this mindset that led to Gul’s victimization.
Finally, while the Taliban lost power ten years ago, discrimination and violence against women has occurred in Afghan society for centuries.
Thus, despite some progress, public and official sensitivity to violence against women is only slowly emerging.
The Afghan government must take several steps to protect women fully.
Above all, perpetrators of violence against women should be prosecuted and tried under due process of law.
This will require strengthening the rule of law and ending the prevailing culture of impunity.
That, in turn, requires educating the public further about human rights and women’s rights through school textbooks, continuing education courses, and a vigorous media campaign.
It also requires persuading representatives and policymakers to develop policies and allocate budget revenues to combat violence against women, and training police and judges to handle cases of violence against women without deferring to claims of family honor.
Perhaps most importantly, non-constitutional justice systems, such as sharia, must be monitored and checked, if not prohibited altogether.
As for Sahar Gul, her case must be thoroughly investigated, and the police and judiciary must commit to bringing her torturers to justice.
Furthermore, Gul’s case, and others like it, should be studied in order to understand the roots of such crimes.
Until Afghanistan’s leaders begin to address this problem seriously, our country will continue to bear the scar of violence against women on its face.
A Flat World and a Round Ball
With the final stage of the World Cup approaching, now is a good opportunity for a mid-tournament appraisal.
This year’s Cup, unlike the previous one in Japan and South Korea in 2002, didn’t witness any real upsets in the first round.
Switzerland and Australia surprisingly reached the elimination round, and the Asian and African teams disappointed somewhat, with only Ghana advancing.
There have been just two ugly matches so far, full of fouls, nasty attacks, and unnecessary aggression, as well as numerous yellow and red cards: Italy vs. the US, and Portugal vs. the Netherlands.
Otherwise, we’re experiencing a wonderful Cup in Germany, in terms of both sportsmanship and the overall atmosphere.
As for Germany and the Germans, one hardly recognizes one’s own country and people.
Even Mother Nature has played along.
After a long winter and a non-existent spring, summer started promptly with the first kick-off – and virtually overnight, Germany has flaunted its sunniest and most delightful side.
The weather is Mediterranean, and all of a sudden, so are the people.
The Cup’s organization has been exceptional (as was to be expected), with excellent police work giving hooligans hardly a chance.
The whole of Germany has been celebrating a never-ending party with guests from all over the world (which was not expected).
And the German team has put on a wonderful display of heart warming and modern offensive soccer (which nobody could have expected!).
More importantly, not only in the German team, but also in the country as a whole, a young, cool, laid-back, and carefree Germany is raising its head – a Germany that is cosmopolitan, friendly, and good-humored.
Years of bad news appear to have passed the Germans by without a trace.
Doctors are on strike, taxes are on the rise, the parties in government are mauling each other, and Chancellor Angela Merkel herself proclaimed in a prominent speech that the country is in disastrous shape.
But the Germans, undaunted by it all, simply keep celebrating one great soccer party with their newfound friends from all over the world.
The black, red, and gold German tricolor adorns the entire country as never before, but almost nowhere are there nationalist undertones.
In fact, the flags of many nations fly alongside German.
In Berlin, as in other large German cities, taxis sport the flags of their drivers’ home countries – from Angola to Saudi Arabia.
Fans don not just their nations’ flags, but also fantastic costumes evocative of their home countries’ colors.
Flags are flown in hope of victory, but also serve to dry the tears of defeat.
In short, Germany during the World Cup is reminiscent of a Shakespearean midsummer night’s dream, with a touch of Woodstock to boot.
Outside the stadiums, public screenings of the games have become joyous mass “happenings.”
And how is the soccer?
This World Cup demonstrates three main developments that the sport has undergone.
First, Europe and South America are more dominant than four years ago and remain the unchallenged great powers of international soccer.
So we must hope that the World Cup in South Africa in 2010 will finally bring greater global parity.
Second, international soccer is witnessing the advent of a new generation.
Spain, Argentina, and Germany, to name but a few countries, have put forward very young teams that have played an impressive game.
On the French, English, and Portuguese teams, too, it is the young players that have shone – despite the continuing presence of Zidane, Beckham, and Figo.
Even the Brazilian squad is looking more aggressive and likely to score with young players like Robinho and Juninho than with their aging champions from 2002.
This generational change is accelerated by a third development.
At the top international level, soccer has become faster and more athletic, and the top teams can shrink space on the field more effectively.
A team that is unable to keep going at full speed for the full 90 (or more) minutes, switch from defense to offense quickly with the whole team, and maintain control of the ball to restrict their opponents' movements won’t stand much of a chance.
Here, soccer parallels today’s globalized markets, which make similar restructuring of national economies necessary.
Unlike economic globalization, however, it remains to be seen whether this new, fast-paced style of soccer will prevail (after all, the young blood of Spain lost to the Old Boys of France).
The sport and its fans will certainly profit if it does.
For now, we have a World Cup filled with soccer that is being shaped by a new, young generation both on and off the playing field – light-hearted, enthralling, and beautiful to watch.
Let’s hope that when the last whistle blows at the final in Berlin on July 9, we Germans retain as much of this positive spirit as possible.
Germany urgently needs this kind of optimism, because, unfortunately, two universal principles will continue to apply in the future: first, the winter will return, and, second, the ball is round and the next game is always the most difficult.
A Free Lunch for America
BERKELEY – Former US Treasury Secretary Lawrence Summers had a good line at the International Monetary Fund meetings this year: governments, he said, are trying to treat a broken ankle when the patient is facing organ failure.
Summers was criticizing Europe’s focus on the second-order issue of Greece while far graver imbalances – between the EU’s north and south, and between reckless banks’ creditors and governments that failed to regulate properly – worsen with each passing day.
But, on the other side of the Atlantic, Americans have no reason to feel smug.
Summers could have used the same metaphor to criticize the United States, where the continued focus on the long-run funding dilemmas of social insurance is sucking all of the oxygen out of efforts to deal with America’s macroeconomic and unemployment crisis.
The US government can currently borrow for 30 years at a real (inflation-adjusted) interest rate of 1% per year.
Suppose that the US government were to borrow an extra $500 billion over the next two years and spend it on infrastructure – even unproductively, on projects for which the social rate of return is a measly 25% per year.
Suppose that – as seems to be the case – the simple Keynesian government-expenditure multiplier on this spending is only two.
In that case, the $500 billion of extra federal infrastructure spending over the next two years would produce $1 trillion of extra output of goods and services, generate approximately seven million person-years of extra employment, and push down the unemployment rate by two percentage points in each of those years.
And, with tighter labor-force attachment on the part of those who have jobs, the unemployment rate thereafter would likely be about 0.1 percentage points lower in the indefinite future.
The impressive gains don’t stop there.
Better infrastructure would mean an extra $20 billion a year of income and social welfare.
A lower unemployment rate into the future would mean another $20 billion a year in higher production.
And half of the extra $1 trillion of goods and services would show up as consumption goods and services for American households.
In sum, on the benefits side of the equation: more jobs now, $500 billion of additional consumption of goods and services over the next two years, and then a $40 billion a year flow of higher incomes and production each year thereafter.
So, what are the likely costs of an extra $500 billion in infrastructure spending over the next two years?
For starters, the $500 billion of extra government spending would likely be offset by $300 billion of increased tax collections from higher economic activity.
So the net result would be a $200 billion increase in the national debt.
American taxpayers would then have to pay $2 billion a year in real interest on that extra national debt over the next 30 years, and then pay off or roll over the entire $200 billion.
The $40 billion a year of higher economic activity would, however, generate roughly $10 billion a year in additional tax revenue.
Using some of it to pay the real interest on the debt and saving the rest would mean that when the bill comes due, the tax-financed reserves generated by the healthier economy would be more than enough to pay off the additional national debt.
In other words, taxpayers win, because the benefits from the healthier economy would more than compensate for the costs of servicing the higher national debt, enabling the government to provide more services without raising tax rates.
Households win, too, because they get to buy more and nicer things with their incomes.
Companies win, because goods and workers get to use the improved infrastructure.
The unemployed win, because some of them get jobs. And even bond investors win, because they get their money back, with the interest for which they contracted.
So what is not to like?
Nothing.
How, you might ask, can I say this?
I am an economist – a professor of the Dismal Science, in which there are no free lunches, in which benefits are always balanced by costs, and in which stories that sound too good to be true almost inevitably are.
But there are two things different about today.
First, the US labor market is failing so badly that expanded government spending carries no resource cost to society as a whole.
Second, bond investors are being really stupid.
In a world in which the S&amp;P 500 has a 7% annual earnings yield, nobody should be happy holding a US government 30-year inflation-adjusted bond that yields 1% per year.
That six-percentage-point difference in anticipated real yield is a measure of bond investors’ extraordinary and irrational panic.
They are willing to pay 6% per year for “safety.”
Right now, however, the US government can manufacture “safety” out of thin air merely by printing bonds.
The government, too, would then win by pocketing that 6% per year of value – though 30 years from now, bondholders who feel like winners now would most likely look at their portfolios’ extraordinarily poor performance of over 2011-2041 and rue their strategy.
A French Presidential Primer
The late British Prime Minister Harold Wilson used to quip that “a week is a long time in politics.”
So, in the 30 or so weeks between now and the next French presidential election, any prediction made today could be reversed, and reversed again, before the vote.
But two candidates have emerged as clear and constant favorites in opinion polls: Nicolas Sarkozy on the right and Ségolène Royal on the left.
In fact, they have more in common than meets the eye, for each speaks of a rupture with the past while incarnating a form of continuity.
For Sarkozy, “rupture” reflects both mundanely tactical and deeply personal choices.
The 12 years of Jacques Chirac‘s presidency, together with France’s tradition of alternation in power, suggests a victory for the left.
Positioning himself as the candidate who represents a sharp break with today’s unpopular politics is the only means to escape that fate.
This is reflected in Sarkozy’s openly pro-American stance – an act of political courage in a France where anti-Americanism is running high.
Sarkozy’s message is that Chirac and Villepin were right in substance to oppose America’s military adventure in Iraq, but that their style was disastrously wrong.
Thus, his deep admiration for “American values,” while sincere, implies no embrace of President George W. Bush.
It also reassures the French business community, which was shocked by Dominique de Villepin’s flamboyant opposition to the United States when he was Chirac’s foreign minister.
At home, Sarkozy has aimed his message particularly at the young, issuing a patriotic call to the values of work and discipline, a counter-revolutionary revolution.
The revolution that must be overcome is that of May 1968, whose leaders and supporters, according to Sarkozy, may have lost politically to de Gaulle, but deeply weakened France over the succeeding decades with their emphasis on “false values.”
By contrast, rebelling against one’s parents’ generation and rediscovering traditional moral stances will save France – a message that is highly applicable to issues, such as education and immigration, that may dominate the electoral campaign.
In the case of Royal, the meaning of “rupture” is both more obvious and more visible.
She is seeking to become the first woman President of the French Republic.
To achieve her goal, she prefers to emphasize her “essence,” thereby countering Sarkozy’s stress on his record as a “doer.”
Her appeal to voters is simple: “I am a woman, and you have never tried a woman, so be modern and try one now.”
Hiding behind the originality (in French presidential politics) of her gender, Royal has avoided specifying a detailed program.
When challenged by inquisitive journalists demanding greater precision about her policy agenda, her highly effective line of defense (so far!) has been: “You would not dare to ask me such a question if I were not a woman!”
Thus, Royal’s program is her popularity.
In foreign policy, one can only guess what her priorities would be.
As far as Europe is concerned, she seems as “agnostic” as Sarkozy, who, like her, incarnates a new generation of “post-European” leaders.
In terms of values, Royal, too, seems to represent a rupture with May 1968, with her emphasis on discipline and family.
According to public opinion polls, Royal is the clear favorite of the left and the only candidate able to defeat Sarkozy.
Her support is particularly strong among women voters.
For the Socialist Party, which is eager to return to power but has not yet recovered from the humiliating defeat of Lionel Jospin in the first round of the presidential election in 2002, the question is whether it can afford to resist the wave of favorable public opinion behind Royal.
In the opinion of Royal’s many opponents among Socialist leaders and militants, the dominance of the media in the political process is leading to mediocrity: the qualities required to be elected are becoming nearly incompatible with those needed to govern.
According to Royal’s Socialist critics, the “Hollywoodization” of politics from which she benefits entails a new approach in which leaders follow and followers lead.
But the same criticism can be directed at Sarkozy.
Moreover, both candidates embody continuity – with Chirac’s Gaullist side for Sarkozy and with François Mitterrand for Royal – as much as rupture.
Royal openly claims Mitterand’s legacy as she searches for legitimacy, while Sarkozy’s rejection of Chirac’s legacy has more to do with form than substance.
To a large extent, Sarkozy can be seen as Chirac with more, whereas Royal is clearly Mitterrand with less.
When the voters decide in the spring of 2007, their choice may depend more on negative than positive considerations, as it did in 2002, when Chirac faced the odious nationalist Jean-Marie Le Pen in the second round.
As in 2002, the winner next year will be whomever the electorate dislikes or fears less.
But one way or the other, personalities will prevail over programs.
A Fresh Start for China and Japan?
Edmonton – Chinese President Hu Jintao will make a high-profile visit to Japan from May 6-10, making him the second Chinese head of state ever to travel there.
The trip is being carefully managed by both countries, and is being watched closely around the world, with good reason: Sino-Japanese relations over the past decade have been turbulent, to say the least.
When Hu’s predecessor, Jiang Zemin, traveled to Japan ten years ago, bilateral relations were deteriorating: China was unhappy with the Japanese government’s refusal to extend the same apology offered to South Korea for past aggression; Japan was worried about a rising China and thus turning more confrontational.
The Japanese media’s coverage of the visit was overwhelmingly negative, and it was remembered as a public-relations disaster.
Hu succeeded Jiang in 2002, almost as former Prime Minister Junichiro Koizumi was coming to power in Japan, and encouraged “New Thinking” in China’s Japan policy, which would entail moving away from historical grievances and promoting better ties.
But, instead of accepting China’s olive branch, Koizumi implemented a more nationalistic agenda, including annual visits to the Yasukuni Shine, which is regarded as a symbol of Japanese militarism by Japan’s neighbors.
His hard-line approach isolated Japan and angered China, leading to an outburst of anti-Japanese demonstrations in China in 2005.
But both Japan and China recognize that further tension will serve neither country’s long-term interests.
Koizumi’s successors, Prime Ministers Shinzo Abe and Yasuo Fukuda, have sought to engage China over the past two years, with summits in Beijing and a successful visit by Chinese Premier Wen Jiabao to Japan last year.
Hu’s trip is likely follow the example set by Wen.
He will emphasize common strategic interests, highlight mutual economic benefits, generate positive public opinion, and promote further exchanges.
Japan is not only one of China’s largest trade and investment partners, it is also the most powerful neighbor with which China wants to be on good terms, partly to showcase that China’s rise is not a threat to Asia and the rest of the world.
Japan, whose economic recovery is attributable largely to its deepening ties with China in recent years, is also eager to demonstrate that it regards China not as a threat but as an opportunity, as least in economic terms.
It was 30 years ago that former Prime Minister Takeo Fukuda, the father of today’s prime minister, signed a Peace and Friendship Treaty with China.
The two governments will certainly use Hu’s visit to celebrate the anniversary with new programs designed to enhance bilateral understanding and friendship.
But, unlike three decades ago, when the Japanese regarded China as one of their most favored countries, public opinion in both countries nowadays registers more negative feelings than positive ones.
Behind the smiles, the polite interactions, and the cautiously worded diplomatic language, strong undercurrents of suspicion remain.
One problem is the disputed waters of the East China Sea.
Despite new joint projects in energy efficiency and environmental protection, areas in which China ranks Japan as the best performer among industrialized countries, the two sides remain in bitterly divided over these territorial waters, which contain huge potential oil, gas, and other mineral deposits. Even after many rounds of talks, no resolution is in sight, and Hu’s visit is not expected to produce any breakthroughs.
Then there are strategic suspicions.
Fukuda has dropped Abe’s talk about an “arch of freedom” – an effort to forge a bloc with the United States, Australia, and India.
But Japan remains concerned about China’s rapidly modernizing military, while China worries about a potential US-Japan containment strategy for China, especially in the case of a crisis in the Taiwan Straits.
So, although both sides endorse the idea of a “mutually beneficial strategic relationship,” and despite progress bilateral on military exchanges, mutual trust and confidence-building have a long way to go.
Moreover, today’s “warm politics, cool economics” trend is the reverse of the “cold politics, warm economics” pattern under Koizumi.
Last year, Japan’s committed investment projects in China fell 24% from 2006, while actual investment volume decreased by 25%, partly owing to regulatory changes in China regarding foreign investment.
Recent food safety issues, such as the “poisoned dumplings” cases, have clearly heightened the Japanese public’s sensitivity about Chinese exports.
Finally, historical issues could still resurface to cause new problems.
While Fukuda has made it clear that he will not visit the Yasukuni Shrine, 160 other parliamentarians paid homage at the site last month, an indication that conservative forces in Japan remain strong and that future prime ministers may not abstain from visiting Yasukuni.
And Japan has so far failed to live up to its treaty obligations to clean up between 700,000 and two million chemical weapons that were abandoned in China by the Japanese army at the end of World War II, another potential flash point if any of these weapons causes casualties in China.
A Fresh Start for Europe
As Europe’s leaders gather in Portugal to put the finishing touches on the new, slimmed down, Reform Treaty, it might be helpful if they all pretended that the last 50 years of European integration had never taken place.
Let’s then imagine what Europe needs to do to confront its most pressing challenges, especially if it were able to do so without the political constraints of 50 years of EU deal-making and ramshackle institution-building.
On top of that, let us make a major leap of imagination and suppose that even though this scenario of the EU at “Year Zero” means we would not have a half-century of intra-European cooperation to draw on, the nations that today make up the EU would nevertheless be keen to adopt far-reaching joint policies.
Let’s suspend our disbelief, then, and try to imagine what Europe could and should be doing to tackle some of the most far-reaching and obstinate policy challenges that will determine whether the next 50 years are as constructive as the last.
Or, to put it another way, let’s look at our problems in the light of the EU’s existing mechanisms and its potential for creating far-reaching new policies, and then let’s ask ourselves why the EU isn’t realizing its own potential and delivering the goods.
Broadly, we see three areas in which Europe’s policymakers at both the national and EU levels can do better: global challenges where Europe could show greater leadership, the creation and strengthening of human capital within the EU and worldwide, and improvement in the effectiveness of the EU’s own political machinery.
Europe needs a clearer and more recognizable global agenda.
It needs to build substantially on its leadership on climate change by adopting much tougher EU goals, and then use its international economic and trade clout to champion new global emissions standards that scientific opinion can accept as meaningful.
On conflict and security issues, Europe should be advancing to a new phase in which it takes much clearer and unambiguous positions on issues ranging from nuclear proliferation to sanctions against Burma’s military regime.
The purpose must be to establish Europe as a forceful and fair-minded player on the world stage, rather than as a “broad church” in which different viewpoints co-exist.
The aim should be that “soft power” instruments like EU development aid and economic partnerships would be linked with a growing sense of political and security outreach to ensure Europe is a global player to be reckoned with.
That means, of course, that the EU should seek to widen its transatlantic thinking so that the EU and the United States cooperate more closely on defining – and thus protecting – their common interests in a world where together they account for little more than 10% of the total population.
These points are far from a blanket criticism of the EU’s efforts to create a common foreign and security policy.
But they are intended to underline what many people in Europe know very well, which is that the speed with which problems concerning international development and conflict are growing easily outpaces the EU’s policy responses so far.
Building more human capital in Europe and worldwide is a crucially important element in future EU activities.
Education is by far the most profitable investment Europe can make, so it should be launching its most ambitious strategy ever to create a new knowledge dynamic and employment inside the EU while helping to expand greatly education in the world’s poorest countries.
Europe also must at last grasp the nettle of immigration policy – something that has persistently eluded generations of political leaders.
Agreed EU-wide immigration rules are needed to reconcile shrinking Europe’s hunger for imported labor with widespread fears of cultural tensions and social unrest.
It won’t be easy to create a fairer and more multi-cultural Europe, but failure to address this problem openly will carry an even heavier price.
By much the same token, Europe’s governments should be making a determined new effort to strengthen Europeans’ sense of a shared history and common values.
A stronger European identity is the soundest basis for creating the more multi-cultural society that demographers regard as inevitable.
Meanwhile, doubts still surround the political and institutional machinery the EU will need to realize these and other ambitious goals.
Sighs of relief greeted EU leaders’ mid-year agreement on a Reform Treaty aimed at overhauling the Union’s decision-making mechanisms, but it is still uncertain whether the new pact will survive the ratification process in 27 countries.
We believe, though, that the increased use of qualified majority voting by member governments embodied in the new treaty should also be applied to the ratification process itself.
That way, if a small minority of EU governments prove unable to ratify the treaty, it would not be torpedoed the way that its predecessor, the Constitutional Treaty, was in 2005.
How to Help the African Dust Bowl
SEATTLE – Picture a small farm under a blazing hot sky.
An intense drought is afflicting the surrounding region, prospects for the next harvest are bleak, and the financial system lacks the capacity to provide the loans farmers need to get by.
This scenario describes today’s southern Africa, which is in the grips of an epic drought.
As it happens, it also describes eastern Nebraska in the “Dust Bowl” years of the early 1930s – a period through which my own family lived.
My father, Ralph Raikes, was the first in his family to graduate from college.
After working for Standard Oil in California, he stopped by his parents’ farm on his way to Cambridge, Massachusetts, where he planned to pursue graduate studies at MIT.
He never made it.
He had to stay in Nebraska and help my grandfather save the family farm from the banks, which had already repossessed one-third of the land.
The most important change my father made was in his mindset: he came to think of the farm not as a subsistence operation, but as a family business.
He turned to the University of Nebraska, where he had received his undergraduate degree, and acquired hybrid corn and other improved seeds that the university was developing.
Then he tracked inputs and weather conditions, which was rarely done at that time.
My father realized that he couldn’t go it alone, and that he would need better access to financing.
So he helped guide – first as a customer, and later as an adviser and director – Farm Credit, a national banking cooperative network, in its efforts to help local farmers weather the Dust Bowl years.
He also helped found the Nebraska Farm Business Association, which aggregated the data that he and his peers collected, so that they could determine best practices.
And he worked together with my mother, Alice, who ran the family poultry business.
Farm Credit and the University of Nebraska’s labs and greenhouses emerged out of United States government programs that had been created to improve the agriculture sector’s performance.
That sector was under water in 1933; with one-quarter of the population living on farms at the time, more investment was needed.
That year, Congress passed the first “farm bill,” the Agricultural Adjustment Act, which boosted investment in the rural economy and helped lift farm income by 50% within two years.
Federal farm programs treated farming as a business enterprise, enabling businessmen like my father to prosper.
Eighty years later, African farmers need to make the same switch, by treating their subsistence operations as family-owned enterprises.
And, like my father during the Dust Bowl years, they have novel means at their disposal: a wide range of new seeds and other technologies have been developed for African family farms – those with 4-5 acres or less – to use in the field.
In October, a group of scientists received the World Food Prize for producing and disseminating a sweet potato variety that adds vitamin A to Sub-Saharan Africans’ diets, and other new seed varieties are helping farmers survive the harvest-crushing drought.
But, as a recent report from the Alliance for a Green Revolution in Africa (AGRA) makes clear, government investment must follow the science.
Agriculture comprises almost two-thirds of Sub-Saharan Africa’s workforce, and in 2003 the African Union called for countries to increase their investment in the sector to an ambitious 10% of all government spending.
Only 13 countries answered that call, but their investments – in research and development, services that help farmers take advantage of new research findings, credit and financing initiatives, commodity exchanges, and other marketing efforts – have already paid dividends.
Those 13 countries have experienced marked improvements in agricultural production, per capita GDP, and nutrition.
Government investment paves the way for private-sector investment, and it could be a game-changer for African farmers, who have operated at subsistence levels for far too long.
Only about 6% of rural households in Sub-Saharan Africa receive loans from financial institutions.
Moreover, almost two-thirds of African farmland soil is missing key nutrients, and many farmers lack the technical knowledge and resources to restore their land’s fertility, leaving them unable to take full advantage of new technologies.
African farmers growing new crop varieties are increasing their yields by only 28%, compared to 88% for farmers in Asia.
My parents made certain that all five of their children graduated from college.
Like them, farmers everywhere want to ensure that their children lead healthy, prosperous lives; and they all recognize the importance of education.
The farmers I have met around the world often just want to sell enough extra produce to pay their health bills and put their children through school.
They take advantage of opportunities when they arise, and they position their children to reap larger profits in the future.
One hopes that an American story of economic progress, like that of my family, will soon be an African story, too.
With so many new innovations becoming available, Africa’s family farmers need their governments to invest in their future.
If they do, that future will look much better than today’s dusty and desperate reality.
Africa at Risk
ADDIS ABABA – Climate change will hit Africa – a continent that has contributed virtually nothing to bring it about – first and hardest.
Aside from Antarctica, Africa is the only continent that has not industrialized.
Indeed, since 1980’s the industrialization that had taken place in Africa has by and large been reversed.
Africa has thus contributed nothing to the historical accumulation of greenhouse gases through carbon-based industrialization.
Moreover, its current contribution is also negligible, practically all of it coming from deforestation and degradation of forests and farmland.
Yet climate change will hit Africa hardest, because it will cripple the continent’s vulnerable agricultural sector, on which 70% of the population depends.
All estimates of the possible impact of global warming suggest that a large part of the continent will become drier, and that the continent as a whole will experience greater climatic variability.
We know what the impact of periodic droughts have been on the lives of tens of millions of Africans.
We can therefore imagine what the impact of a drier climate on agriculture is likely to be.
Conditions in this vital economic sector will become even more precarious than they currently are.
Africa will not only be hit hardest, but it will be hit first.
Indeed, the long dreaded impact of climate change is already upon us.
The current drought covering much of East Africa – far more severe than past droughts – has been directly associated with climate change.
The upcoming climate negotiations ought to address the specific problems of Africa and similarly vulnerable poor parts of the world.
This requires, first and most importantly, reducing global warming to the apparently inevitable increase of two degrees Celsius, beyond which lies an environmental catastrophe that could be unmanageable for poor and vulnerable countries.
Second, adequate resources should be made available to poor and vulnerable regions and countries to enable them to adapt to climate change.
Climate change, which was largely brought about by the activities of developed countries, has made it difficult for poor and vulnerable countries to fight poverty.
It has created a more hostile environment for development. No amount of money will undo the damage done.
But adequate investment in mitigating the damage could partly resolve the problem.
Developed countries are thus morally obliged to pay partial compensation to poor and vulnerable countries and regions to cover part of the cost of the investments needed to adapt to climate change.
Various estimates have been made of the scale of investment required by those countries.
One conservative estimate – which has a reasonable chance of being accepted precisely because it is conservative – calls for $50 billion per year as of 2015, increasing to $100 billion by 2020 and beyond.
A transitional financing arrangement would be put in place for the period 2010-2015.
Some argue that developed countries cannot come up with such sums, particularly given their current economic challenges.
But no one has so far argued that the cost of damage caused to the development prospects of poor countries and regions is less than the amount of compensation being offered to cover adjustment costs.
The reason is obvious: the damage caused is many times higher than the compensation being requested.
Nonetheless, it is argued, whatever the real cost of the damage, developed countries currently cannot afford to provide that kind of money.
But we all know that these countries and their national banks were able to spend trillions of dollars in a few months to bail out their bankers, who earned super-profits when the going was good.
When the good times ended, taxpayers and governments were prepared to rescue them and to ensure that they continued to receive their extraordinary bonuses.
If the developed world is able to pay trillions of dollars to clean up its bankers’ mess, how is it possible that it cannot afford to pay billions of dollars to clean up a mess that it created, and that is threatening the survival of whole continents?
Clearly this is not about the availability of resources. It is about the inappropriate priorities in how resources are allocated.
It is about moral values that make it appropriate to rescue bankers, who expect everyone but themselves to pay for the mess they created, and inappropriate to compensate the world’s poorest people, whose survival is threatened precisely because of the mess created by developed countries.
I cannot believe that people in developed counties, when informed about the issues, would support rescuing bankers and oppose partial compensation for poor countries and regions.
I cannot believe that they will let such an injustice occur.
If they are not expressing their outrage over the injustice of it all, it can only be because they are inadequately informed.
Africa, Climate Change, and the G-8 Summit
British Prime Minister Tony Blair has declared that the two issues at the center of the G-8 Summit this July will be African poverty and global climate change.
These may seem to be distinct issues. In fact, they are linked.
A trip I took to a village in the Tigre region in northern Ethiopia shows why.
One morning, I was taken to a dry riverbed at the village’s edge.
Farmers were digging a pit in the riverbed, down to the water table approximately two meters below ground level.
They explained that until recently this was a perennial river – one that flows throughout the year – but now the river stops flowing during the dry season.
Only when the annual rains begin in the summer does water reappear in the river bed.
Until then, water-starved communities dig for water, if they can find it and if they can afford to pump it out.
In northern Ethiopia, as in much of Africa, the rain cycle has changed markedly in recent years.
Ethiopian village life has long depended on two crops, one during a short rain in March and April, and the main crop during the long rain in the summer months.
In recent years, the short rains have failed entirely, and long rains have been erratic.
Hunger is omnipresent.
Perhaps half of the children are severely underweight.
Much of arid sub-Saharan Africa, notably in the Sahel (the region just south of the Sahara desert), has experienced a pronounced drop in rainfall over the past quarter-century.
This decline coincided with a rise in the surface temperature of the neighboring Indian Ocean, a hint that the decline in rainfall is in fact part of the longer-term process of man-made global warming.
Failures of rainfall contribute not only to famines and chronic hunger, but also to the onset of violence when hungry people clash over scarce food and water.
When violence erupts in water-starved regions such as Darfur, Sudan, political leaders tend to view the problems in narrow political terms.
If they act at all, they mobilize peacekeepers, international sanctions, and humanitarian aid.
But Darfur, like Tigre, needs a development strategy to fight hunger and drought even more than it needs peacekeepers. Soldiers cannot keep peace among desperately hungry people.
One course of action must be to help impoverished African regions to “adapt” to climate change and to escape the poverty trap.
Water-stressed regions like Ethiopia and Sudan can adapt, at least in part, through improved technologies such as “drip irrigation,” rainwater harvesting, improved water storage facilities, deep wells, and agro-forestry techniques that make best use of scarce rainfall. Better land-management practices (the re-planting of degraded forests, for example) can recharge underground water aquifers.
Poor countries cannot afford these technologies on their own.
Nor should they have to.
Help for poor countries in Africa and elsewhere to adapt to climate change should not be described as charity or aid, but rather as compensation for damages being imposed on the poorest people on the planet.
Greater help for these countries to escape from extreme poverty has been promised for decades but has not been delivered.
In addition to adapting to climate change, the world must also reduce future risks to the planet by cutting back on emissions of greenhouse gases, which are the source of man-made climate change.
While adaptation to climate change is necessary – because it is already occurring – this is not enough.
If the world fails to mitigate future climate change, the effects of rising temperatures, increasing droughts, more numerous and severe tropical storms, rising sea levels, and a spread of tropical diseases will pose huge threats to the entire planet.
The famines in Ethiopia and the violence in Darfur suggest what can lie ahead.
The best way to reduce long-term climate change is to reduce carbon emissions.
There are at least three options: shift to non-carbon energy sources such as solar or nuclear energy; capture and dispose of the carbon dioxide emitted at carbon-based power plants; economize on energy use, for example by shifting to hybrid automobiles and trucks.
Most likely, all three of these methods will have to play a role.
The effort to reduce greenhouse gases will require decades of action, but, given the long lead times in overhauling the world’s energy systems, we must start now.
Rich countries need to lead the way.
It is ironic that the United States, which portrays itself as a friend of democracy and impoverished countries, gives the smallest share of its GNP in aid among the rich countries, and also refuses to participate in global efforts to reduce greenhouse gas emissions.
This is especially ironic because African countries like Ethiopia stand steadfastly and bravely with the US in the fight for freedom and against terrorism, even as they struggle with hunger, disease, and famine.
Moreover, countries like Ethiopia are making valiant, indeed remarkable, efforts to overcome their problems, despite the lack of adequate, and long-promised, help from the world’s richest countries.
Africans suffering from hunger and drought, and indeed poor people everywhere, have a right to ask much more of the US and other rich countries.
Tony Blair is right to call on his rich-country colleagues to follow through on their unfulfilled promises.
Africa’s Path from Poverty
BEIJING – All low-income countries have the potential for dynamic economic growth.
We know this because we have seen it happen repeatedly: a poor, agrarian economy transforms itself into a middle- or even high-income urban economy in one or two generations.
The key is to capture the window of opportunity for industrialization arising from the relocation of light manufacturing from higher-income countries.
That was true in the nineteenth and twentieth centuries, and it remains true today.
Japan seized its opportunity in the years following World War II, using labor-intensive industries, such as textiles and simple electronics, to drive its economy until rising labor costs eroded its comparative advantage in those sectors.
That shift then allowed other low-income Asian economies – South Korea, Taiwan, Hong Kong, Singapore, and to some extent Malaysia and Thailand – to follow in Japan's footsteps.
China, of course, is the region's most recent traveler along this well-trodden path.
After more than three decades of breakneck economic growth, it has transformed itself from one of the poorest countries on earth to the world's largest economy.
And now that China, too, is beginning to lose its comparative advantage in labor-intensive industries, other developing countries – especially in Africa – are set to take its place.
Indeed, ever since the Industrial Revolution, the rise of light manufacturing has driven a dramatic rise in national income.
The United Kingdom's economic transformation started with textiles.
In Belgium, France, Sweden, Denmark, Italy, and Switzerland, light manufacturing led the way.
Similarly, in the United States, cities like Boston, Baltimore, and Philadelphia became centers for producing textiles, garments, and shoes.
Until recently, few believed that Africa, too, could become a center for modern manufacturing.
But, with the right policies, there is no reason why African countries could not follow a similar trajectory.
Consider land-locked Ethiopia, which only ten years ago seemed to be an especially bad bet.
But then the country built an industrial park near Addis Ababa and invited the Chinese shoemaker Huajian to open a factory there.
Huajian opened its doors in January 2012 with two production lines and some 600 workers.
By the end of the year, it had employed 2,000 Ethiopians and doubled the country's exports of leather shoes.
Today, the company has 3,500 workers in Ethiopia producing more than two million shoes a year.
In 2013, spurred by Huajian's success, the Ethiopian government created a new industrial park, with space for 22 factory units.
Within three months, all of them had been leased by export-oriented companies from Turkey, Korea, Taiwan, China, and elsewhere.
The World Bank has provided $250 million to support the continued construction of these industrial parks.
The Ethiopian success story is just the start.
As investors learn more about Africa, they will increasingly see what it has to offer.
Indeed, the cost of labor in Africa is competitive enough that Ethiopia could attract companies from countries as poor as Bangladesh.
Africa has a surplus of agricultural labor and too few other jobs.
As foreign firms launch operations in the labor-intensive sectors in which Africa has a comparative advantage, they will train the local workforce.
Some workers will become managers.
They will become familiar with the technology and learn how to maintain consistent quality in the production line.
They will establish contacts with international buyers and investors.
And, eventually, some of them will be able to raise capital and start firms of their own – export companies owned and operated by Africans.
Mauritius shows the path ahead.
In the 1970s, the government set up industrial parks to process textiles and garments for export.
At the time, most of the owners were from Taiwan or Hong Kong; today, more than 70% of the island's industrial companies are locally owned.
A carefully focused export strategy is crucial.
The international development community and many African governments want to work toward regional integration, linking the markets of 55 African countries.
This might have its advantages, but it should not be a priority.
Africa today accounts for just 1.9% of global GDP, compared to 21% for the United States and 23% for Europe.
Developing countries must use their limited resources in the most effective way, and there is no question where the most attractive opportunities in Africa are to be found.
For example, instead of investing heavily in the infrastructure needed for regional integration, a country like Ethiopia would be better off building industrial parks and linking them by road to ports in Djibouti.
With the right growth strategy, far-reaching change can come within a person's lifetime – sometimes more than once.
My native Taiwan is now a high-income economy.
But when I was born there, in 1952, the island was poorer than almost every country in Africa.
Then it happened to me again.
I moved to mainland China in 1979, when the country's per capita income was less than one-third of Sub-Saharan Africa's.
Today, China has become an upper-middle-income country, and it is on track to become a high-income country by 2020.
My hope is that I can witness a third economic transformation in my lifetime, this time in Ethiopia and other countries in Africa.
If they stay on the tried and tested path of those who have gone before, there is every chance that I will.
The Promise of Digital Health
BASEL – Africa has changed remarkably, and for the better, since I first worked as a young doctor in Angola some 20 years ago.
But no change has been more obvious than the way the continent has adopted mobile technology.
People in Africa – and, indeed, throughout low- and middle-income countries – are seizing the opportunities that technology provides, using mobile phones for everything from making payments to issuing birth certificates, to gaining access to health care.
The benefit of mobile technologies lies in access.
Barriers like geographical distance and low resources, which have long prevented billions of people from getting the care they need, are much easier to overcome in the digital age.
And, indeed, there are countless ways in which technology can be deployed to improve health-care access and delivery.
Of course, this is not new information, and a growing number of technology-based health initiatives have taken shape in recent years.
But only a few have reached scale, and achieved long-term sustainability; the majority of projects have not made it past the pilot phase.
The result is a highly fragmented landscape of digital solutions – one that, in some cases, can add extra strain to existing health systems.
The first step to addressing this problem is to identify which factors breed success – and which impede it.
Here, perhaps the most important observation relates to how the solution is linked to the reality on the ground.
After all, technology is an enabler for the innovation of health-care delivery, not an end in itself.
Solutions that focus on end-users, whether health practitioners or patients, have the best chance of succeeding.
Fundamental to this approach is the recognition that what users need are not necessarily the most advanced technologies, but rather solutions that are easy to use and implement.
In fact, seemingly outdated technologies like voice and text messages can be far more useful tools for the intended users than the latest apps or cutting-edge innovations in, say, nanotechnology.
Consider the Community-based Hypertension Improvement Project in Ghana, run by the Novartis Foundation, which I lead, and FHI 360.
The project supports patients in self-managing their condition through regular mobile medication reminders, as well as advice on necessary lifestyle changes.
This approach is successful because it is patient-centered and leverages information and communication technology (ICT) tools that are readily available and commonly used.
In a country where mobile penetration exceeds 80% but only a few people have smartphones, such simple solutions can have the greatest impact.
For health practitioners, digital solutions must be perceived as boosting efficiency, rather than adding to their already-heavy workload.
Co-creating solutions with people experienced in delivering health care in low-resource settings can help to ensure that the solutions are adopted at scale.
For example, the telemedicine network that the Novartis Foundation and its partners rolled out with the Ghana Health Service was a direct response to the need, expressed by health-care practitioners on the ground, to expand the reach of medical expertise.
The network connects frontline health workers with a simple phone call to consultation centers in referral hospitals several hours away, where doctors and specialists are available around-the-clock.
From the outset, the project was a response to an expressed need to expand the reach of medical expertise, and was fully operated on the ground by Ghana Health Service staff, which made this model sustainable at scale.
To realize the full potential of digital health, solutions need to be integrated into national health systems.
Only then can digital technology accelerate progress toward universal health coverage and address countries’ priority health needs.
Collaboration across the health and ICT sectors, both public and private, is essential.
Multidisciplinary partnerships driven by the sustained leadership of senior government officials must guide progress, beginning at the planning stage.
Intra-governmental collaboration, dedicated financing for digital health solutions, and effective governance mechanisms will also be vital to successful strategies.
Digital technologies offer huge opportunities to improve the way health care is delivered.
If we are to seize them, we must learn from past experience.
By remaining focused on the reality of end-users and on priority health needs, rather than being dazzled by the latest technology, we can fulfil the promise of digital health.
Africa Still Rising
JOHANNESBURG – Is the honeymoon over for African economies?
Less than a decade ago, it seemed that the continent’s economic dreams were beginning to come true, with many countries experiencing impressive GDP growth and development.
Now, as the harsh reality of the continent’s vulnerability to challenging external conditions has set in, sustaining that growth has proved difficult.
Encumbered by slowing growth in China, a collapse in commodity prices, and adverse spillover from numerous security crises, Africa’s overall annual GDP growth averaged just 3.3% in 2010-2015, barely keeping up with population growth – and down sharply from the 4.9% recorded from 2000 to 2008.
But a deeper look suggests that things may not be as bad as they seem, for two key reasons.
First, though average growth has declined, some African economies have thrived in recent years.
Indeed, aggregate GDP has been dragged down since 2010 by faltering growth among oil exporters and security-related crises in the Sahel and North Africa; but in the rest of Africa, GDP growth has accelerated, from 4.1% in 2000-2010 to 4.4% in 2010-2015.
Second, Africa is undergoing a profound long-term transformation, characterized by rapid digitization, urbanization, and growth in the working-age population, which will outnumber the labor force of China and India by 2034.
That demographic trend could unlock future growth by advancing economic diversification, spurring domestic consumption, and supporting industrialization.
In fact, today’s high-growth countries – including Côte d’Ivoire, Ethiopia, Kenya, and Tanzania – have made substantial progress in reducing their dependence on commodity exports, in favor of trade, investment, and domestic consumption.
And many lower-growth countries could head down a similar path.
New research by the McKinsey Global Institute (MGI) shows that spending by Africa’s consumers and businesses already totals $4 trillion.
By 2025, private spending could reach $5.6 trillion – $2.1 trillion by households, and $3.5 trillion by businesses.
This represents a huge opportunity for Africa���s manufacturers.
We believe that Africa can almost double its manufacturing output, to nearly $1 trillion, by 2025, with about 75% of that growth tied to production for local markets.
The question is whether manufacturers will manage to exploit the growth potential that lies in front of them.
African firms have not yet proved capable of meeting existing domestic demand.
Africa still imports about one-third of the food, beverages, and similar processed goods it consumes, whereas the Association of Southeast Asian Nations imports about 20%, and South America’s Mercosur trade bloc imports just 10%.
Africa even imports 15% of the cement it uses, despite having abundant raw materials to make it at home.
To be sure, African business has made great strides in recent years.
Today, 400 African companies have annual revenue of more than $1 billion, and 700 have annual revenue of more than $500 million.
On the whole, these large companies are growing faster – and generating higher profits – than their global peers.
But there is still a long way to go.
Large African (excluding South African) firms’ average annual revenue of $2 billion is half that of large firms in Brazil, India, Mexico, and Russia.
And Africa only has about 60% of the large firms it needs to put it at the same level as the emerging economies.
One key factor limiting firms’ growth is the fragmented nature of the African market, which currently comprises mostly small economies with only limited economic and political linkages.
There are eight partly overlapping regional trade zones, none of which includes more than half of Africa’s countries.
Only Egypt, Morocco, Nigeria, and South Africa rank in the top 100 of MGI’s Global Connectedness Index.
Beyond excessive trade barriers, Africa suffers from inadequate transport links and limits on the free movement of people.
Africans need visas to travel to more than half the countries on their own continent.
The recent launch of the African Union passport is a step in the right direction – but it is only one step.
A more integrated market would not only enable African companies to create the economies of scale they need to compete; it would also be far more appealing to institutional investors.
Building such a market must therefore be a top priority for African leaders, as they seek to unleash the continent’s economic potential.
Equally important, Africa’s leaders must work to improve the business environment.
Though some progress has been made on this front in the last two decades, non-tariff barriers remain high.
Indeed, regulatory issues are still cited as a serious deterrent to investment.
Many African businesses – nearly half of companies in Nigeria, and more than one-third in Angola and Egypt – highlight unreliable electricity supplies as a major challenge.
And almost 40% of firms surveyed by the World Bank lament the constraints imposed by competition from informal firms.
Some of these issues could be addressed relatively quickly.
Consider the strides Rwanda has made since 2007, when it established a development board to improve its business environment.
In less than a decade, that board has led the creation of a “one-stop center” to facilitate investment, has overseen streamlined issuance of construction permits, and has pressed successfully for a fixed fee for property registration, the extension of customs hours, and risk-based customs inspections.
As a result, Rwanda’s global ranking for the ease of doing business jumped from 143 in 2008 to 32 in 2014.
This success can surely be replicated elsewhere in Africa.
Despite the challenges some African countries face, the continent’s economic potential remains massive, thanks to favorable demographic dynamics, fast-growing cities, burgeoning domestic markets, and a digital revolution.
With the right policies, a relentless focus on execution, and a great deal of determination, Africa can still rise.
Africa’s Vaccination Test
BOSTON – In February in Addis Ababa, African health ministers signed a widely celebrated declaration of their commitment to keeping immunization at the forefront of efforts to save the continent’s children from death and disease.
Fulfilling that commitment will be no easy feat.
Immunization is not just a health issue; it is also an economic challenge.
The case for vaccination is strong.
Globally, an estimated 2-3 million child deaths and 600,000 adult deaths are prevented annually through immunization.
Moreover, immunization is considered one of the most cost-effective public-health interventions for reducing child morbidity, mortality, and disability.
A recent study estimates that every dollar spent on vaccination will save $16 in costs of illnesses averted.
Accounting for the value individuals place on longer and healthier lives, net returns on investments in immunization soar to some 44 times the cost.
And net returns exceed costs for all vaccines.
Significant progress has been made.
In 2014, 86% of children were immunized against diphtheria, tetanus, and pertussis, compared to less than 5% in 1974.
And there have been extraordinary advances in the number and kinds of vaccines that are available.
Yet, worldwide, an estimated 18.7 million infants are not being reached by routine immunization services.
The problem, of course, is access.
Detailed analysis of immunization reveals significant disparities within and across countries.
More than 60% of the non-immunized infants live in just ten countries: the Democratic Republic of the Congo (DRC), Ethiopia, India, Indonesia, Iraq, Nigeria, Pakistan, Philippines, Uganda, and South Africa.
Routine immunization coverage remains particularly low in Africa; indeed, it has stagnated over the last three years, against a backdrop of weak and under-resourced health systems.
As a result, one in five African children still do not receive lifesaving vaccination.
In 2014, an estimated 42% of all global deaths from measles were in Africa.
Most of Africa’s under-immunized children live in Nigeria, Ethiopia, the DRC, South Sudan, and Guinea.
Poor people, those living in rural areas, and families with lower education levels comprise the majority of those who are not reached.
Clearly, money is a leading factor shaping immunization outcomes.
Beyond inadequately financed health systems, which remain weak and inefficient, especially in rural areas, African countries face challenges in affording new, more expensive vaccines.
New vaccines should be enabling us to save more lives.
Yet Médecins Sans Frontières estimates that the introduction of new vaccines made it 68 times more expensive to vaccinate a child in 2014 than in 2001 in most African countries.
Another study showed that in 2001, the total cost of the original set of six World Health Organization-recommended vaccines was less than one dollar.
In 2014, the number of WHO-recommended vaccines had risen to 11 – and the cost had reached about $21 for boys and $35 for girls.
The added costs of delivery, currently estimated at about $25 per child, bring the total cost of fully immunizing a child today to $50-60.
That same study found that, in many low- and middle-income countries, immunization budgets are currently insufficient to sustain vaccination programs, much less incorporate the new costlier vaccines.
As several health ministers pointed out in Addis Ababa, high vaccine prices force poor countries’ governments to make tough choices about which deadly diseases they can afford to prevent.
For some countries, the situation is about to get worse, as Gavi, the international group which has helped to finance the dramatic global expansion of new vaccines, phases out support for countries deemed to have “graduated” from assistance.
Without eligibility for the lower prices obtained by Gavi, many of these countries may not be able to afford newer vaccines.
In order to cope with this challenge, African political leaders have committed to invest in the continent’s capacity to develop and produce its own vaccines.
But this is a long-term strategy that will require coordinated regional investment planning, market development, and stronger regulatory capabilities.
In the short to medium term, African countries would do well to look into the power of collective bargaining to strike better deals for needed vaccines.
While Africa can and should do more to improve vaccination, the global community also has a responsibility to make a concerted effort to bring down vaccine costs.
The recently announced reduction in the price of pneumococcal vaccine is a step in the right direction, but it is not enough.
Without collective action, equitable and sustained access to immunization in Africa will remain a major problem – and children’s lives will continue to be lost.
Africa’s Avoidable AIDS Crisis
NEW YORK – At Uganda’s largest AIDS clinic, I recently witnessed a remarkable celebration of life. The performers were a troupe of young African singers, drummers and dancers, ranging in age from roughly eight to 28.
&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160; “This is a land,” they sang,
&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160; “Where beautiful people
&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160; Laugh and dance in harmony.
&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160; Africa.
O Africa.”
And, indeed, these young people laughed and danced not only in harmony but with a joie de vivre that lit up their faces and filled us all with happiness.
Listening, it was hard to imagine that they could easily be dead – and would be, if not for this clinic.
Each of those splendid performers is living with HIV.
Some arrived at the clinic so ill that they could scarcely walk.
Others showed few symptoms but, having tested positive, came to be treated.
They were mothers and fathers, sisters and brothers, children and grandparents.
All were alive and healthy for one reason only: the Joint Clinical Research Center in Kampala, and the drugs that it provides them.
Uganda was the epicenter of the AIDS epidemic. There the scourge began in earnest; there (as elsewhere in Africa) it exacts its highest toll.
Yet Uganda is also a success story.
A decade ago, fewer than 10,000 people were taking the new generation of antiretroviral drugs that suppress the disease and offer the promise of a normal life.
Today, that figure is 200,000, thanks in large measure to generous support from the United States (under its PEPFAR program) and the Global Fund in Geneva.
We have seen similarly encouraging progress elsewhere.
Botswana, among others, has invested heavily to offer universal treatment, and now is well on its way to ensuring that no baby is born with HIV – a reality in developed countries, but not so in Africa, where 400,000 children are born with the disease each year.
South Africa, with the largest number of people living with HIV, has spent nearly $1 billion over the past year in an ambitious counseling and testing campaign to roll back the epidemic.
But there is a new and growing danger that these advances might not be sustained.
Peter Mugyenyi, who runs the Joint Clinical Research Center, told me that part of the problem is the sheer weight of numbers.
In Uganda, only about half of those with HIV/AIDS are being treated.
Meanwhile, money for treatment is drying up.
Because of the global recession, some international donors are threatening to cap their financial support.
Countries such as Malawi, Zimbabwe, and Kenya, as well as Uganda, are requesting assistance for emergency drug supplies.
In Kampala, Dr. Mugyenyi has begun placing new patients on a waiting list.
As many as seven million Africans who should be getting treatment for HIV are not.
Worldwide, the number is about 10 million.
Compounding the problem: donors have also been shifting their focus from AIDS to other diseases, because there is a sense that more lives can be saved more cheaply.
At a time when we should be scaling up to meet the AIDS challenge, we are dialing back.
In our global war on AIDS, the international community is on the verge of snatching defeat from the jaws of victory.
Those who rallied to the fight are alarmed. They fear that the impressive gains of the last decade will be lost.
“We are sitting on a time bomb,” Dr. Mugyenyi told me.
Every day, he is forced into moral choices that no one should have to make.
How do you choose to treat a young girl but not her little brother?
How do you turn away a pregnant mother, sitting with her children, crying for help?
Surely we can do better.
In Kampala, I promised my young friends that I would do everything I could to help.
In Washington recently, the United Nations rolled out an action plan that should dramatically accelerate progress on maternal and child health, including HIV.
At the International AIDS Conference in Vienna, in July, I hope that the international community will rally around UNAIDS’ launch of Treatment 2.0 — the next generation of HIV treatment, which must be more affordable, more effective, and accessible to all.
As chair of this year’s replenishment of the Global Fund, I urge all donors to see to it that countries such as Uganda get the support they need, so that Dr. Mugyenyi and other front-line soldiers in the fight against AIDS need not make those difficult choices.
I left Uganda with a snatch of song that still echoes within my heart.
Its inherent truth would be obvious, had you been there to see:&#160;
&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160; We are still useful.
&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160; To our countries, to our families.
&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160; All we need is a way to live our days,
&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160; All we need is to survive in Africa.
Yes, times are hard.
That is all the more reason to act out of compassion and with generosity.
Africa’s Diaspora to the Rescue
DAKAR – There is something dismally familiar about the tide of news reports concerning Africa’s increased suffering – more poverty, malnutrition, civil strife, and death – in the face of the recent global financial crisis.
Almost everywhere, the media translates academic conclusions into graphic illustrations of brutality and despair in places such as Guinea and the Democratic Republic of Congo.
But there is another, woefully under-reported, side to the story.
African countries that were locked out of international capital markets for most of the past five decades have largely been spared the twin woes of financial turmoil and economic downturn.
The continent’s economies experienced a slowdown, but not a recession.
Indeed, according to McKinsey &amp; Company, Africa was the third-largest contributor to world economic growth in 2009, after China and India.
Moreover, several African countries have received ratings from credit agencies, which has opened up global financial centers to them.
In some cases, these ratings have proved equivalent to or higher than those of countries such as Turkey or Argentina.
Stock exchanges are being established across the continent.
Furthermore, countries such as China, India, and Brazil has provided a platform for increased exports and the inception of a model of cooperation based on trade, investment, and technology transfer, rather than “aid.”
China-Africa trade alone increased from $10 billion in 2000 to $107 billion in 2008, and billions of dollars are being invested in oil production, mining, transportation, electricity generation and transmission, telecommunications, and other infrastructure.
These developments have combined to improve African countries’ macroeconomic performance dramatically.
Inflation has been halved since the 1990’s, and foreign-exchange reserves have increased 30%.
Public finances showed a 2.8%-of-GDP surplus in 2008, compared to a 1.4%-of-GDP deficit in 2000-2005.
Savings rates are between 10% and 20%, and external debt has decreased from 110% of GDP in 2005 to 21% in 2008.
Since 2000, sub-Saharan African countries have achieved economic growth of 5-7%.
Many factors have contributed to this upturn.
Emerging-market demand has pushed up commodity prices.
Urbanization has given rise to a dynamic informal sector.
Improved governance, higher food production, increased inter-regional trade, debt cancellation, better use of official development assistance (ODA), and thriving telecommunications and housing markets have helped as well.
But transfers from the African diaspora stand out as the most significant contributing factor.
A study commissioned by the Rome-based International Fund for Agricultural Development indicates that more than 30 million individuals living outside their countries of origin contribute more than $40 billion annually in remittances to their families and communities back home.
For sub-Saharan African countries, remittances increased from $3.1 billion in 1995 to $18.5 billion in 2007, according to the World Bank, representing between 9% and 24% of GDP and 80-750% of ODA.
Migrants’ remittance behavior is essentially dictated by the regulatory environment and the quality – in terms of speed, cost, security, and accessibility – of products and services offered by banks, money-transfer companies, micro-finance institutions, and informal operators.
In this respect, there are three different strategies in place in Africa.
The Anglophone strategy focuses on freeing up the remittance market by encouraging competition, relaxing regulatory constraints for non-bank operators, offering financial incentives, encouraging technical and financial innovation, and stimulating collaboration among market players.
This approach, also adopted by Italy, contributes to reducing costs and increasing the overall volume of funds for beneficiaries.
The Hispanic approach emphasizes migrants’ involvement in banking by offering a range of banking services in both the country of origin and the host country, products of specific interest to migrants, and low commissions on foreign transfers.
This approach, widely developed by Morocco and the Portuguese-speaking world, is epitomized by the zero-commission policy initiated by the Spanish bank Santander and its Moroccan counterpart, Attijariwafa Bank.
Finally, the Francophone approach relies on two types of monopoly.
The first is enjoyed by Western Union, which controls up to 90% of the total formal transfer volume within Africa’s 16-member Franc Zone.
Western Union charges fees as high as 25% on transfers to these countries, compared to an average global benchmark of 5%, and has required that Franc-Zone countries sign exclusivity agreements, thereby preventing foreign-exchange bureaux, post offices, and micro-finance institutions from carrying out money transfers.
The second monopoly is exercised in the banking sector.
France has a veto within the boards of directors of the Franc Zone’s two central banks, while two French commercial banks, BNP-Paribas and Société Générale, exercise a quasi-monopoly on lending programs, mainly centered on short-term trade financing and the needs of governments, public and private companies, and the elite.
All other local banks have adopted the same approach, severely restricting access to financial services for households and entrepreneurs.
Despite the increasing importance of remittances from Italy, Spain, and the United States, the largest share in absolute terms still originates from France.
There is thus a real need in the Franc Zone for a financing institution that would convert migrant remittances into productive investments, thereby generating jobs and wealth, and that would broaden access to banking services, mortgages, insurance products, pension plans, and technical assistance.
Official statistics for 2009 are likely to show that migrants’ remittances fell sharply, as the global recession severely eroded job opportunities abroad.
That makes it all the more important that African countries, many of which have laid a strong groundwork for sustainable growth, have a financial system in place that can leverage remittances effectively as the global economy recovers.
Africa’s Dictator-Diplomat
BRUSSELS – The recent death in Brussels of Ethiopian Prime Minister Meles Zenawi finally brings to light what lay behind his mysterious two-month disappearance from public life.
Ethiopia’s government had strenuously denied rumors of serious ill health caused by liver cancer.
Now that the worst has, indeed, proven true, Ethiopia and all of East Africa will need to learn to live without the stabilizing influence of its great dictator-diplomat.
Meles was certainly both.
Ethiopia has undergone a remarkable transformation under his strongman rule since 1991, when his Tigrayan minority group from the country’s north came to power with the overthrow of the odious Communist Derg led by Mengistu Haile Mariam (still enjoying a comfortable retirement in Robert Mugabe’s Zimbabwe).
Initially serving as the president of the first post-Derg government, and then as Ethiopia’s prime minister from 1995 until his death, Meles (his nom de guerre in the revolution) oversaw 7.7% annual GDP growth in recent years.
Strong economic performance is somewhat surprising, given his party’s interventionist policy approach, but Meles showed himself to be a consummate pragmatist in attracting investment – particularly from China – to drive growth.
Meles’s own political provenance as the leader of the Tigrayan People’s Liberation Front was Marxist-Leninist.
But, when the Cold War ended, so, too, did his dogmatism.
To his credit, child mortality was reduced by 40% under his government; Ethiopia’s economy became more diversified, with new industries like car manufacturing, beverages, and floriculture; and major infrastructure projects, including Africa’s largest hydroelectric dam, were launched.
Once a basket-case associated in the world’s eyes only with famine and drought, Ethiopia has become one of Africa’s largest economies – and without the benefit of gold or oil.
Perhaps more important than Meles’s domestic achievements was his diplomatic record.
He was an indispensable ally of the West in the fight against Islamist terrorism, culminating in Ethiopia’s military operation in neighboring Somalia in 2006.
More recently, Meles coordinated efforts with Kenya to stage limited strikes against the al-Shabaab militia, which has waged an unrelenting war to turn Somalia into a fundamentalist Islamic theocracy.
At the same time, Meles courted China as both an investor and as a hedge against the West’s criticism of his human-rights record.
And yet he controversially but rightly held out a hand of friendship to the breakaway region of Somaliland, before it became fashionable, and went as far as he could short of formal re-recognition of that ray of democratic hope in the Horn of Africa.
Meles will be sorely missed in Hargeisa, as he planned to run a Chinese-financed gas pipeline through Somaliland territory from the Ogaden to the coast.
More important, Meles put Addis Ababa on the map as the home of the African Union, and as a capital where Africa’s worst problems could be discussed in a pragmatic manner, unburdened by colonial grudges.
Meles himself became a major diplomatic player, particularly over climate-change policy, and most recently was active in mediating border and natural-resource disputes between Sudan and the newly independent (and oil-rich) South Sudan.
He will be remembered for accepting the painful secession of Eritrea in 1993, rather than prolong the civil war, and for his efforts to reach an agreement with Egypt over the use of the Blue Nile waters.
The great stain on Meles’s record will always be his intolerance of dissent.
To be sure, his human-rights record was far better than the Derg’s.
For example, he allowed a private press to flourish, and in 2000 he became the first Ethiopian leader to hold multi-party parliamentary elections.
Moreover, compared to neighboring Eritrea under President Isaias Afewerki or Omar al-Bashir’s Sudan, his regime was by no means the worst offender in the region.
Nor was there much evidence of personal enrichment or widespread corruption.
Nevertheless, following a violently contested parliamentary election in 2005, in which more than 30 parties participated, Meles demonstrated open contempt for democratic pluralism and press freedom, jailing several journalists in recent years.
At the same time, he imposed increasingly strict central control on his ethnically and linguistically diverse country.
Although nominally governed by “ethnic federalism,” where this threatened secession, as in Oromia or the Ogaden, Meles was quick to ignore the constitutional set-up.
Although he strengthened religious freedom and peaceful coexistence between Muslims and Christians, the human-rights situation in Ethiopia remained poor.
For example, groups like Freedom House and Human Rights Watch have documented widespread official repression of the Oromo people.
And yet Meles is irreplaceable – unmatched intellectually as an African leader (he dropped out of medical school, but went on to teach himself impeccable English and obtain European university degrees by correspondence), and unmatched politically at home, with no obvious successor groomed to replace him.
In the Horn of Africa, there is no leader of his stature who could ensure the stability and strong governance that the region so desperately needs.
Hailemariam Desalegn, Meles’s foreign minister, will take over Ethiopia’s government.
But there will be considerable concern in the West about the danger of a power vacuum or struggle in a geopolitically vital but fractious country –&nbsp;and just when neighboring Somalia is supposed to be undergoing a transition to a new parliament and elected government.
For his admirers and critics alike, Meles leaves behind a potent political legacy.
He will be remembered as an African leader of major historical significance: visionary, despotic, and indispensable.
Africa’s Economic House Divided
DAKAR – The world economic downturn and financial-market tremors have strained budgets across Africa.
With the exception of Ghana, and a few other states, in 2009 most African countries’ fiscal balances deteriorated.
But, thanks to prudent management of public finances during previous periods of robust growth, a significant number of African countries have endured the current crisis in better fiscal shape than during past crises.
In 2009, aggregate GDP growth in Africa averaged 1.6%, down from about 5.7% during the 2002-2008 period – but growth all the same.
Moreover, several African countries continued to implement long-term reforms to improve their business and investment climate, despite the daunting challenges presented by the crisis.
Now that international trade and global industrial production are on the mend, sub-Saharan economies look set for more robust growth, as demand for and prices of oil and other minerals rebound and general economic activity resumes.
Of course, numerous downside risks – adverse weather shocks, military conflict, and political turmoil – still can undermine the hard-earned benefits of this social and economic record.
But it is the dichotomized nature of their economies and finances that represents Africa’s most intractable structural imbalance.
Frankly, two Africa’s are emerging: a modern economy and a cash-based economy.
Across Africa, almost all governments praise – some honestly, some not – economic modernization as the cornerstone of prosperity and the yardstick by which their effectiveness should be measured. Many boast of the modernity of the financial infrastructure of their economies, which is based on an entire set of legal, regulatory, accounting, credit reporting, and payment and settlement systems.
National payment systems operate electronic-based payment products and services.
A high-value inter-bank funds-transfer system settles transactions in real time, eliminates credit risk between system participants, increases circulation of funds, and enhances monetary-policy implementation.
Banks are provided with a facility to monitor their positions in real time and hence make cost-effective investment decisions.
So far, only a few registered financial institutions, primarily offshoots of Western commercial banks, have access to such payment-system facilities.
Non-banking financial institutions such as foreign exchange bureaus, post offices, and micro-finance lenders are not admitted, even when they are financially sound and sustainable.
The effects of banks’ hijacking of national payment systems to service only the modern economy are compounded by the exclusive agreements that banks and money-transfer companies such as Western Union have signed with most African countries.
These agreements lock out non-banking entities from the highly lucrative market for migrant remittances from the African diaspora, which remain a key engine of growth.
Yet rapid urbanization everywhere in Africa has given rise to a dynamic informal sector unconnected to the modern economy.
Although marginalized by African officials, this cash-based economy is a major contributor to the continent’s productive capacity.
It employs more than 90% of the workforce and is home to 75% of the retailers.
But, despite the pivotal economic role that the informal sector plays, it has no access to conventional bank loans.
Micro-finance institutions provide the only credit lines open to informal operators.
The micro-finance business model is based on lending that is guaranteed by the group.
This translates into a solidarity network and a support mechanism that mitigates credit risk and encourages payment discipline. Credit repayment in well-managed micro-finance institutions is around 95%. All studies undertaken in the area have also revealed that women are not only the most active among informal-sector entrepreneurs, but they are also quicker to meet their commitments.
African states must now recognize that modernizing their informal sectors by integrating them into the modern economy can be a major development tool. Yet only a few countries have started moving in that direction.
Nigeria has refrained from signing any exclusive agreements with Western Union and others, and its newly consolidated banking industry is making significant inroads across the region.
Rwanda, too, has enacted regulations that eliminate exclusive agreements, opening doors for micro-finance institutions to become payment-service providers.
The South African Reserve Bank has created a special platform within its national payment system for micro-finance institutions and non-banks.
Malawi’s national payments system is directly accessible to non-bank participants, including third-party service providers.
Giving micro-finance institutions access to national and regional payments systems and electronic retail facilities will go a long way toward meeting the requirements of the retail and business sector in terms of banking facilities.
It will also help facilitate access by the poorest to financial services, thus helping to reduce the high proportion of the un-banked population.
All of this will invariably spur development and integration of national financial systems and intra-regional trade.
This will be a welcome development, because a large proportion of intra-regional trade is carried out by informal operators and small and medium enterprises that do not have access to the banking system.
Moreover, economic integration and increased intra-regional trade are the best entry point into global markets for all countries.
When it comes to analyzing what ails Africa, it is customary to dwell at length on the continent’s traumatic past.
But it strains the imagination to link Africa’s colonial-era pains with the willingness of African leaders to spend a fortune to equip their countries with state-of-the-art settlement systems, and then proceed to exclude their citizens from using them.
Abraham Lincoln once said that a house divided cannot stand.
There is an economic corollary to this: an economic house divided cannot prosper.
Africa’s Hard Black Gold
LAGOS - Few infrastructure services in the developed world may be as taken for granted as electric power.
To consumers in industrialized countries, uninterrupted power supply is a given.
Not so in much of Africa, which experiences some of the world’s greatest power deficits, and where only two in ten people have access to electricity.
According to the International Monetary Fund’s most recent Regional Economic Outlook for Sub-Saharan Africa , in 2007 alone, nearly two-thirds of the countries in the region experienced an acute energy crisis marked by frequent and extended electricity outages.
There is no shortage of hydropower plants for electricity generation in Africa.
However, many of these plants are unable to keep up with rapid population growth and attendant increases in demand.
Furthermore, they are prone to frequent drought, which reduces their output significantly, leaving many as little more than decorative infrastructure landmarks.
Increasingly burgeoning populations in countries like Nigeria and Ghana imply a greater extraction of water resources for power generation.
Rapid expansion of agricultural activity is requiring more and more water all across the continent.
Other resources like fuel oil, diesel, light crude, solar, and gas are also available as means of electricity generation, but their costs are all quite prohibitive.
These factors make a good argument for coal as a cheap alternative source of Africa's power.
Coal has historically played a crucial role as a source of energy worldwide, and has several important advantages over other fossil fuels.  First is its relative abundance.
The current level of proven coal reserves worldwide stands at roughly 850 billion tons.
Africa has about 50 billion tons.
Coal is also much more widely distributed geographically than any other fossil fuel.
Worldwide energy demand has increased by more than 50% since 1980, and is expected to grow annually by 1.6% between now and 2030.
More than 70% of this new demand will come from developing countries, with fossil fuels projected to account for about 80% of total energy demand by the end of this period.
Coal is the world’s fastest growing fossil fuel, with annual production increasing by 6.4% since 2004.
It is already the dominant source of power generation in some very important energy-consuming nations.
Much of the future increases in coal-fired electricity generation will come from strategically important developing countries like China and India.
In 2006 alone, China added about 93,000 megawatts of coal- fired electricity generating capacity, and this trend is expected to continue as the country tries to meet its huge energy needs.
Even in many developed countries, coal still accounts for a large share of power generation.
Coal plants currently provide more than half of America’s electricity supply.
Denmark, which houses some of the most efficient coal-fired power plants in the world, equally relies on coal for half of its electricity production.
The same is true for Germany, which is home to some of the most efficient pulverized coal combustion units in Europe.
Poland uses coal for 98% of its electricity production, and South Africa uses coal for about 50% of its electricity production.
Against this picture then, it is hard not to expect developing countries to exploit their abundant coal resources to generate power for their own development, especially given that modern technology can help produce coal cleanly.
Some argue that gas might be a better alternative to hydro or coal, but for countries that must import much of their gas the benefits of a stable and reliable source of cheap fuel in the form of coal present a very strong counter-argument to the capital costs of a gas plant.
Unlike prices for coal, which is abundant and dispersed geographically, gas prices are subject to significant volatility, and the long-term trend in the face of fossil fuel depletion is uncertain.
In contrast, coal prices are more stable, and may remain that way for a long time.
Apart from electric-power generation, coal also has wide application in a number of industries.
It is pivotal in both steel and cement production.
Moreover, the use of wood by Africa’s growing population is causing increasingly rapid deforestation in many countries.
There is significant potential domestic demand for coal briquettes to replace wood for cooking and domestic and industrial heating.
The demand outlook thus appears favorable for the coal industry, creating significant investment opportunities.
Clearly, there are environmental drawbacks from the use of coal as an energy resource, and these concerns are far too important to overlook.
The massive reserves notwithstanding, coal is still a finite resource.
It must be mined with greater efficiency and with a view to mitigating the environmental impact.
Fortunately, much greater attention is paid today to mine safety and the management of the by-products of coal use.
With acid rain and other public-health hazards linked to coal combustion, more technologies are emerging for reducing harmful emissions from power plants.
Fueled by research, the past few years have witnessed the development of increasingly cleaner and more energy-efficient coal-fired generation plants and the retirement of older technologies, especially in the developed world.
Developing countries have lagged behind in this process, but, with the common threat of global warming, there is now growing pressure to adopt conservation policies.
Africa's mineral-rich countries must exploit their abundant natural resources.
They must use coal to advance their economic development.
Failure to do so would be a missed opportunity at a time when African countries must avail themselves of all available resources for poverty reduction.
Africa’s Immunity
ACCRA – The United States suffers rising job losses.
Britain nationalizes its banks.
Once high-flying small economies like Ireland, Hungary, and Iceland break down.
Even robust China and India are experiencing slower growth, curtailed ambitions, and broken dreams.
Yet, in sub-Saharan Africa, there are few hints of the global financial crisis that is consuming the capitalist world.
In fashionable African cities, residential home prices remain stratospheric.
A typical Western-style house in Kampala or Accra, for example, now costs an astonishing two to three times the price of a comparable home in, say, Cleveland or other cities in the American heartland.
While home prices are crashing from Madrid to Dublin and Miami to Los Angeles, African prices remain near or at record-high levels.
African banks, meanwhile, are rock-solid compared to their debt-heavy counterparts in the US and Europe.
While international bankers went bust by making legions of bad loans, African bankers stuck to earning profits the old-fashioned way: paying very little to depositors, and earning a big “spread” by buying guaranteed government debt, which yielded healthy returns.
Even government deficit spending – long the bane of Africa – seems positively puny compared to the massive debts that the US and some European countries face.
The new Obama administration is proposing spending plans that would create a record US deficit of more than one trillion dollars – and this coming on top of the outgoing Bush administration’s record deficit.
And yet there are good reasons to believe that it is just a matter of time before Africa and its peoples experience the ill effects of the global crisis.
From Ghana to Kenya, governments are having increased difficulty in raising money for infrastructure projects and selling official debt.
Foreign investment in sub-Saharan Africa, which reached record levels in recent years, is retreating, which is evidence of investor caution, not any underlying lack of optimism about the region.
And exports of raw materials to China, India, Europe, and the US – a key factor in Africa’s recent growth surge – may suffer simply because the global slowdown means less consumption everywhere.
All of these factors suggest that an African financial bust is possible.
Popular equity investments, such as shares in Safaricom, are already trading at unexpectedly low levels.
If real estate prices were to fall dramatically, a chain reaction could occur, taking down big and small investors alike, and over time causing wide suffering to ordinary Africans.
Even assuming stability in real estate prices, the global crisis surely will cause a fall in remittances by Africans working good jobs in Europe, the US, Canada, Australia, and the Middle East.
Remittances are already believed to be falling, which makes sense: immigrants in rich countries are and will be disproportionately hurt by slowing economic activity.
Immigration itself may even slow dramatically, depending on the length and depth of the economic slowdown.
Fewer Africans working in rich countries will automatically translate into less money circulating in African countries.
The decline in remittances, however, cuts both ways.
Remittances have long spurred inflation in many parts of Africa.
A Ugandan doctor working in Norway, for instance, cares little about the cost of a beer in Kampala.
He is also willing – and able – to pay more than a local doctor for services and, of course, a home in Uganda.
Fewer remittances flowing into Uganda could mean less economic activity – or simply lower prices.
The financial meltdown in the US, which incubated the global crisis, is either coming under control or threatening to mutate into a new, more virulent form that could destroy not only America’s paper economy of trading and brokering, but also its real economy of goods and services.
President Barack Obama, acting as if the latter scenario remains likely, is betting on large-scale government spending to prop up the real economy.
If his administration succeeds, the chances that Africa will remain relatively unscathed will grow.
Even if Obama fails, however, Africans should escape the worst of the global crisis, for both good reasons and bad.
The good reasons have to do with African self-reliance and a growing awareness among scholars and policymakers that trade within the region – especially between urban and rural Africa – will ultimately deliver enormous benefits.
Another factor working in Africa’s favor is its private companies’ and consumers’ low dependence on borrowed money.
People tend to pay cash for goods and services, however costly.
In the US, loans for cars and homes – loans that now aren’t being paid back – are the major factor behind the financial crisis.
In Africa, very few people borrow money for such purchases.
Africa’s cash-based economy has in the past constrained development.
After all, by allowing people to spend more than they have, borrowed money can fuel growth.
But today, Africa’s pay-as-you-go practices are a powerful defense against financial contagion.
Another way of looking at Africa’s paradoxical economic position is to admit that the region’s historical marginalization within the international financial system – so costly in times of global plenty – is proving to be an unexpected benefit when the wealthiest of the world are sick unto death.
Ensuring Africa’s Continued Rise
LAGOS – Africa’s rise is in danger of faltering.
After years during which the continent’s economy grew at an average annual rate of 5%, global uncertainty, depressed commodity prices, and jittery external conditions are threatening to undermine decades of much-needed progress.
Ensuring the wealth and wellbeing of the continent’s residents will not be easy; but there is much that policymakers can do to put Africa back on an upward trajectory.
First and foremost, policymakers must secure the financing needed to pursue sustainable development in an uncertain global environment.
The World Bank estimates that Africa will require at least $93 billion a year to fund its infrastructure needs alone.
Climate-friendly, sustainable infrastructure will cost even more.
And yet, as long as global growth remains weak, Africans cannot count on developed countries to fully honor their commitments to help attain the Sustainable Development Goals.
Africa must rapidly develop its own resources, beginning by nearly doubling tax revenues.
Across Sub-Saharan Africa, tax revenues account for less than one-fifth of GDP, compared to more than one-third in OECD countries.
This means there is plenty of room for improvement.
From 1990 to 2004, for example, Ghana reformed its tax system and raised revenues from 11% to 22% of GDP.
Admittedly, such progress is difficult; in Nigeria, we saw an opportunity in raising non-oil tax revenues, but struggled to seize it.
Another source of domestic resources is the roughly $380 billion in pension assets held by just ten African countries.
Policymakers should be leveraging these considerable sums.
At the same time, African countries will have to find a way to diversify their economies.
Diversification requires investment in the future, in the form of education and well-developed infrastructure, including telecommunications, power, roads, rail, and water.
There are plenty of models to follow: Dubai, Singapore, Thailand, Malaysia, Mexico, Indonesia, and South Korea are all admired by Africans as economies that managed to transform themselves.
Dubai, for example, set out more than three decades ago to prepare for a future without oil.
The government implemented a step-by-step transformation of the country into a service economy, putting in place the infrastructure and incentives necessary to build up financial services, tourism, medical services, real estate, media, arts, and culture.
South Korea and Singapore, which had few natural resources on which to rely, are no less inspiring.
The secret behind these countries’ success is relentlessly focused leaders, whether entrenched but benign dictators or democratically elected politicians with a shared vision of a broad-based economy.
Sub-Saharan Africa has paths for diversified growth that many of the trailblazers did not: value-added agriculture and agro industry, the processing of mineral resources, petrochemical complexes, manufacturing of durable and consumer goods, tourism and entertainment, and an emerging information-technology sector.
As the necessary measures for diversification are implemented, policymakers must ensure that the economic growth they are pursuing creates jobs.
Sadly, this has not always been the case.
Much of the recent growth has benefited only a few, leaving many behind – most notably young people and women.
From 2006 to 2013, inequality rose in many of the continent’s most important economies, including South Africa, Nigeria, Ghana, Tanzania, and Rwanda.
These were challenges that we were starting to address in Nigeria when I was finance minister.
We knew that we needed not just to secure growth, but also to improve the quality of that growth.
To that end, policymakers must ensure that growth is channeled into sectors that create jobs, such as agriculture, manufacturing, and services.
They may also have to redistribute income and strengthen social safety nets to protect better those at the bottom of the ladder.
Matching skills to job opportunities will be crucial.
Some 70% of Africa’s population is under 30, and the continent is home to half the world’s primary-school-age children who have been deprived of the opportunity to study.
Offering Africa’s children basic reading, writing, and technology skills, as well as vocational, technical, and entrepreneurial training, must be a top priority.
Weak health-care systems must also be strengthened in order to tackle the endemic diseases that sap productivity, such as malaria, as well as improving preparedness for outbreaks of deadly epidemics.
The stakes are high.
The World Bank estimates the Ebola outbreak shrank the economies of Sierra Leone, Guinea, and Liberia by 16%.
As the world economy sputters, African countries will have to develop trade with one another.
In 2013, African goods and services accounted for just 16% of trade within the continent, and just over 3% of world trade.
One problem is that most African countries produce the same type of commodities and trade them with very little value-added.
Policymakers must encourage greater specialization; differentiated goods and services will add value and volume to trade.
Logistics pose another obstacle to intra-African trade.
Policymakers must make it easier to move goods across borders, by improving connectivity between countries and reducing bureaucratic hurdles and administrative costs.
For example, road transport tariffs across Africa are estimated at $0.05-$0.13 per ton-kilometer, compared to the average of $0.01-$0.05 for all developing countries.
The Rift Valley Railway project, which will eventually link Mombasa on the Kenyan coast to Kampala in Uganda, is a good example of the benefits that investments in transportation could provide.
The African Development Bank estimates that it will double the volume of trade between the two countries, while reducing marginal costs by 30%.
As they make these investments, policymakers must not forget that much of Africa’s recent growth can be credited to good macroeconomic policies and sound economic management.
Extending the continent’s rise will require strengthening the continent’s economic fundamentals.
This means ensuring that prices in the economy are correct, starting with the exchange rate.
Some countries may need temporary controls to curb damaging capital outflows, but policymakers should aim for a market-based exchange rate and a solid plan for governing inflation, debt, foreign-exchange reserves, current accounts, and fiscal balances.
Africa’s potential can hardly be overstated.
The continent is well placed to build diversified economies based on low-carbon, sustainable infrastructure.
But policymakers cannot simply assume that Africa’s rise will continue.
They must take the right steps to ensure that it does.
Africa’s Urban Farmers
NAIROBI – When I met Eunice Wangari at a Nairobi coffee shop recently, I was surprised to hear her on her mobile phone, insistently asking her mother about the progress of a corn field in her home village, hours away from the big city.
A nurse, Wangari counts on income from farming to raise money to buy more land – for more farming.
Even though Wangari lives in Kenya’s capital, she is able to reap hundreds of dollars a year in profit from cash crops grown with the help of relatives.
Her initial stake – drawn from her nursing wages of about $350 a month – has long since been recovered.
Wangari is one of thousands of urban workers in Kenya – and one of hundreds of thousands, even millions, across Africa – who are increasing their incomes through absentee agriculture.
With prices for basic foodstuffs at their highest levels in decades, many urbanites feel well rewarded by farming.
Absentee agriculture also bolsters national pride – and pride in traditional diets – by specializing in vegetables specific to the region.
“For too long our country has been flooded with imported food and Westernized foods,” Wangari says. “This is our time to fight back – and grow our own.”
Across Africa, political leaders, long dismissive of rural concerns, have awakened to the importance of agriculture and the role that educated people, even those living in major cities, can play in farming.
In Nigeria, former President Olusegun Obasanjo has a huge diversified farm and has pushed for policies to help absentee farmers prosper.
In Uganda, Vice President Gilbert Bukenya routinely travels the country, promoting higher-value farming, such as dairy production.
Perhaps the most visible political support for absentee agriculture is in Liberia, a small West African country where civil war destroyed agriculture, rendering the population dependent on food imports, even today.
President Johnson-Sirleaf, recognizing that educated people could contribute much to an agriculture revival, launched her “Back to the Soil” campaign in June 2008 in large part to encourage urban dwellers to farm.
To be sure, absentee farming by elites and educated urban workers can’t solve all of Africa’s urgent food needs.
Moreover, absentee farmers face unexpected problems.
Because they don’t visit their fields often, they rely heavily on relatives and friends.  When I decided to farm wheat for the first time this spring on leased land in my childhood village, my mother agreed to supervise plowing, planting, and harvesting.
Without her help, I might not have farmed at all.
Even with mother’s help, I have worries.
Although I grew up around wheat fields, my knowledge of farming is thin.
Fertilizer and spraying were both more expensive than I thought.
While my wheat stalks are sprouting on schedule, I now fear that at harvest time – in November – prices will fall and I won’t recoup my costs.
One key tool is the mobile phone.
My hopes for success are buoyed by my ability to call my mother inexpensively and discuss the farm.
We even decided over the phone what kind of pesticide to use and which tractor company to hire.
Because they know both the tastes of fellow city dwellers and rural conditions, many urban farmers are succeeding.
In fact, some city dwellers don’t even bother with acquiring land or gaining distant help. Certain crops can be grown in their own homes.
James Memusi, an accountant, grows mushrooms in a spare bedroom, selling them to nearby hotels and supermarkets.
Nevertheless, most people living in Africa’s cities have access to land in the countryside, which is why Liberia’s government rightly highlights the potential for farm expansion.
In a new advertising campaign rolled out this summer, the authorities declared, “The soil is a bank; invest in it.”
In Liberia, the main push is to reduce imports of staples such as rice and tomatoes.
In more prosperous countries, African elites are motivated by a complex interplay of national pride, dietary concerns, and the pursuit of profit.
In Zambia, for example, Sylva Banda ignited a craze for authentic traditional meals two decades ago with a chain of popular restaurants.
Now, ordinary Lusakans want to cook similar meals in their own homes, driving demand for farmers who produce such delicacies as dried pumpkin, “black jack” leaves, and fresh Okra.
Similarly, in Nairobi, Miringo Kinyanjui, another woman entrepreneur, is supplying unrefined – and more nutritious – maize and wheat flour.
In another move to distinguish her ingredients from Western versions, Kinyanjui also sells through grocery stores flour flavored with Amarathan, a green vegetable that grows around Kenya.
The revival of traditional foods has attracted the attention of large multinational corporations.
Last year, Unilever’s Kenyan branch ran a “taste our culture” campaign in support of its line of traditional East African herbs and spices.
Such campaigns go hand-in-hand with expanded farming, because sellers of these foods prefer nearby growers – even if these growers increasingly live in the city.
After Assimilation
Human migration is as old as history. Even migration to distant places and remote cultures is nothing new.
In the nineteenth century, millions of Europeans sought liberty and prosperity in the Americas, notably in the United States.
What is new today is the scale of migration, often across huge cultural divides - and often without a definite aim.
The African boat people in the Mediterranean are often not even sure whether they want to be in Italy, Germany, or Britain.
Even those who are certain, like North Africans in Spain and France, or Turks in Germany, had as their priority escaping the hopelessness of their home countries, not arriving at a particular destination.
This modern form of migration raises massive problems for countries on the receiving end. In Europe, it is probably the most serious social issue today, because no one has a clear idea about how to manage the resulting clash of cultures.
Once upon a time, North America, notably the US, seemed to provide the answer.
It was that of the "melting pot": different peoples made their own contribution to American culture, but, above all, they made every effort to accept what they found and integrate.
"No," the Russian woman who came to the US in the early twentieth century replied to the grandchild who asked whether her ancestors arrived with the Pilgrims on the Mayflower. "Our ship had a different name, but now we are all Americans."
More recently, this has changed, giving rise to a process described by Arthur Schlesinger, the historian and former aide to President John F. Kennedy, in his book
Even in Israel, the last true immigration country - at least for Jews - assimilation is no longer so easy.
Recent newcomers from Russia have their own political party, and old Europeans have become a distinct minority.
Israel and America continue to have mechanisms to integrate new migrants.
Language is an important underlying factor, and in Israel, there is the army, while in America, the values embodied in the Constitution still represent a shared secular faith.
But these mechanisms are weakening everywhere, and are virtually non-existent in European countries.
Modern societies are characterized by acute problems of belonging.
They don't offer the implicit, unconscious ties of community that citizens felt in the past. As a result, people have begun to cling to other, more primordial group identities.
They resist assimilation, fearing that it will rob them of their identity without offering a new one.
What then is the alternative to assimilation?
The "salad bowl" of so-called multiculturalism is no real alternative, because it does not provide the necessary glue that binds communities together.
All the ingredients remain separate from the outset.
The only viable alternative for which there are examples is probably that of London or New York. The main characteristic of this alternative is the coexistence of a common public sphere shared by all and a considerable degree of cultural separation in the "private" sphere, notably in residential areas.
The public space is multicultural in terms of people's backgrounds, but is governed by agreed values, even a common language, whereas the people's private lives are - to use an ugly word - ghettoized.
In theory, this is a distinctly second-best solution to the cultural consequences of migration; in practice it is the best answer we have.
But it cannot be had for nothing.
Even the necessary minimum of a common language requires a deliberate effort, to say nothing of certain rules of behavior.
Living in London, I marvel at the way in which we Londoners have come to terms with Indian family shops and West Indian-run public transport, while not asking many questions about whole districts that are Bangladeshi or Chinese.
No one has yet found a name for this new version of the "separate but equal" doctrine that some of us fought so hard against in the 1960's: separate private lives in a common public space that is equal for all.
This is clearly easier in London and New York than it is in smaller towns or even in the capitals of countries where the world language of English is not spoken.
Berlin's Turkish community and the North African communities around Paris seem increasingly separate, with their own public sphere and often language.
Where this happens, an explosive condition can arise, a kind of separatism within, not by historically separate groups but by newcomers against natives.
If we are forced to abandon the hope of assimilation, our efforts should concentrate on creating a public space to which all contribute and that all enjoy.
Ideally, this should be an expanding public space, for in the end, the element of unity in a modern society is the guarantee of its citizens' liberty.
After Austerity
NEW YORK – This year’s annual meeting of the International Monetary Fund made clear that Europe and the international community remain rudderless when it comes to economic policy.
Financial leaders, from finance ministers to leaders of private financial institutions, reiterated the current mantra: the crisis countries have to get their houses in order, reduce their deficits, bring down their national debts, undertake structural reforms, and promote growth.
Confidence, it was repeatedly said, needs to be restored.
It is a little precious to hear such pontifications from those who, at the helm of central banks, finance ministries, and private banks, steered the global financial system to the brink of ruin – and created the ongoing mess.
Worse, seldom is it explained how to square the circle.
How can confidence be restored as the crisis economies plunge into recession?
How can growth be revived when austerity will almost surely mean a further decrease in aggregate demand, sending output and employment even lower?
This we should know by now: markets on their own are not stable.
Not only do they repeatedly generate destabilizing asset bubbles, but, when demand weakens, forces that exacerbate the downturn come into play.
Unemployment, and fear that it will spread, drives down wages, incomes, and consumption – and thus total demand.
Decreased rates of household formation – young Americans, for example, are increasingly moving back in with their parents – depress housing prices, leading to still more foreclosures.
States with balanced-budget frameworks are forced to cut spending as tax revenues fall – an automatic destabilizer that Europe seems mindlessly bent on adopting.
There are alternative strategies.
Some countries, like Germany, have room for fiscal maneuver. Using it for investment would enhance long-term growth, with positive spillovers to the rest of Europe.
A long-recognized principle is that balanced expansion of taxes and spending stimulates the economy; if the program is well designed (taxes at the top, combined with spending on education), the increase in GDP and employment can be significant.
Europe as a whole is not in bad fiscal shape; its debt-to-GDP ratio compares favorably with that of the United States.
If each US state were totally responsible for its own budget, including paying all unemployment benefits, America, too, would be in fiscal crisis.
The lesson is obvious:&#160; the whole is more than the sum of its parts.
If Europe – particularly the European Central Bank – were to borrow, and re-lend the proceeds, the costs of servicing Europe’s debt would fall, creating room for the kinds of expenditure that would promote growth and employment.
There are already institutions within Europe, such as the European Investment Bank, that could help finance needed investments in the cash-starved economies.
The EIB should expand its lending.
There need to be increased funds available to support small and medium-size enterprises – the main source of job creation in all economies – which is especially important, given that credit contraction by banks hits these enterprises especially hard.
Europe’s single-minded focus on austerity is a result of a misdiagnosis of its problems.
Greece overspent, but Spain and Ireland had fiscal surpluses and low debt-to-GDP ratios before the crisis.
Giving lectures about fiscal prudence is beside the point.
Taking the lectures seriously – &#160;even adopting tight budget frameworks –&#160;can be counterproductive.
Regardless of whether Europe’s problems are temporary or fundamental – the eurozone, for example, is far from an “optimal” currency area, and tax competition in a free-trade and free-migration area can erode a viable state – austerity will make matters worse.
The consequences of Europe’s rush to austerity will be long-lasting and possibly severe.
If the euro survives, it will come at the price of high unemployment and enormous suffering, especially in the crisis countries.
And the crisis itself almost surely will spread.
Firewalls won’t work, if kerosene is simultaneously thrown on the fire, as Europe seems committed to doing: there is no example of a large economy – and Europe is the world’s largest – recovering as a result of austerity.
As a result, society’s most valuable asset, its human capital, is being wasted and even destroyed.
Young people who are long deprived of a decent job – and youth unemployment in some countries is approaching or exceeding 50%, and has been unacceptably high since 2008 – become alienated.
When they eventually find work, it will be at a much lower wage.
Normally, youth is a time when skills get built up; now, it is a time when they atrophy.
So many economies are vulnerable to natural disasters – earthquakes, floods, typhoons, hurricanes, tsunamis –&#160;that adding a man-made disaster is all the more tragic.
But that is what Europe is doing.
Indeed, its leaders’ willful ignorance of the lessons of the past is criminal.
The pain that Europe, especially its poor and young, is suffering is unnecessary.
Fortunately, there is an alternative.
But delay in grasping it will be very costly, and Europe is running out of time.
After Kyoto
The Kyoto Protocol treaty has now entered into force for the 126 nations who have joined it so far.
Now is the time to start thinking about how to engage all nations, including large emitters, in conversations about what to do after the treaty’s expiration in 2012.
This is exactly what the European Commission did recently by providing its first strategy for a post-Kyoto era, which will be discussed by the European Council next March.
While the Kyoto Protocol represents only a modest reduction of carbon emissions in industrialized countries – 5.2% between 2008-2012 relative to 1990 levels, with varying targets for individual countries – real progress can be made in sustaining development efforts and preserving our planet.
But first, all countries must integrate climate concerns into policy planning, and improve their governance in key sectors such as energy, infrastructure, and transport.
In other words, we must act in accordance with the recognition that climate change and its effects on people in both rich and poor countries remains a threat to global security.
At the end of the day, the long-term approach is likely to include a rules-based system, an incentives system, and investments in technology change.
Increasingly, adaptation at the national level will be recognized as a major issue that will require appropriate funding.
Dealing with the impacts of climate change and with emission reductions should not be mutually exclusive, but complementary.
Looking ahead to the post-Kyoto world offers us the chance to start a new dialogue and to look at new options on climate change.
Nations could set the more ambitious goal of limiting the long-term change in the earth’s temperature, and then assign emissions rights among countries in such a way that will eventually limit temperature increases to an acceptable level.
This would require increasing investments in energy research and development for new and improved technologies – a process that needs to be supported by stronger public-private partnerships.
Up to now, with only 15% of the world’s population, rich countries have been responsible for more than 75% of global carbon dioxide (CO2) emissions, and thus most of the environmental damage.
However, it is the developing countries – and thus the world’s poor – who are most vulnerable.
It is unrealistic to ask poor countries, where more than 1.6 billion people do not have access to clean energy and technologies, to bear the costs associated with the much needed technological change.
Working with partners, the World Bank is supporting financial strategies to assist developing countries in meeting the costs caused by climate change.
To date, over $1 billion dollars in Global Environment Facility (GEF) grants, together with about $8 billion in co-financing, have been committed to programs related to climate change.
While the regulatory mechanisms of both Kyoto and the European Trading Scheme have contributed to the establishment of an emerging market for carbon trading, interested parties are now concerned about the immediate future.
Without a regulatory framework beyond 2012, the window of opportunity for initiating project-based transactions will close by 2006/2007.
Given the long lead time between project preparation and the first benefits of emissions reductions, project developers have only a few years to act before carbon payments cease to make a meaningful contribution to project finance in the current context.
Developing infrastructure projects is a long process that requires 3-7 years from identification, through licensing, financing, and construction, and finally to the first certification of carbon emission reductions.
Therefore, projects need to be operational at the latest by 2007.
The World Bank has been instrumental in advancing carbon finance as a viable development tool, and in facilitating private-sector participation in the market.
The Bank is focused on representing the interests of its borrowing countries, helping them to develop assets for carbon trading according to their own priorities.
But, without a commitment by governments to limit greenhouse gas emissions beyond 2012, the carbon market will remain uncertain, and the private sector – vital to the market’s success – is unlikely to expand its participation in a meaningful and sustained way.
According to a recent World Bank-supported survey of companies interested in carbon finance, only one in five respondents declared that they were interested in buying post-2012 emissions reductions.
Now is the chance to look forward and enlist the global community – with no exclusions, although with differentiated responsibilities – in the pursuit of a more secure world, one that avoids the dire risks of environmental degradation and social conflict implied by inaction.
After Paris
NEW YORK – The attacks in Paris by individuals associated with the Islamic State, coming on the heels of bombings in Beirut and the downing of a Russian airliner over the Sinai Peninsula, reinforce the reality that the terrorist threat has entered a new and even more dangerous phase.
Just why the Islamic State decided to stage its attacks now is a matter for conjecture; it may well be that it is going global to compensate for its recent loss of territory in Iraq.
But whatever the rationale, what is certain is that a clear response is warranted.
Actually, the challenge posed by the Islamic State calls for several responses, as there is no single policy that promises to be sufficient.
Multiple efforts are needed in multiple domains.
One is military.
More intense attacks from the air against Islamic State military assets, oil and gas facilities, and leaders are critical.
But no amount of air power on its own will ever get the job done.
A substantial ground component is needed if territory is to be taken and held.
Unfortunately, there is no time to build a partner force on the ground from scratch.
This has been tried and failed, and Arab states are unable or unwilling to constitute one.
The Iraqi army has also come up short.
Iran-backed militias only make matters worse.
The best option is to work more closely with Kurdish troops and select Sunni tribes in both Iraq and Syria.
This means providing intelligence, arms, and being willing to send more soldiers – more than the 3,500 Americans already there, and possibly on the order of 10,000 – to train, advise, and help direct a military response.
Such an effort must be collective.
It can be informal – a “coalition of the willing” that would include the United States, France, the United Kingdom, Arab states, and even Russia under the right circumstances – or carried out under NATO or United Nations auspices.
The packaging matters less than the results.
Symbolic declarations of war, though, ought to be considered with caution, lest the Islamic State appear to be winning every day it does not lose.
A diplomatic component is no less essential to any response.
Syrian President Bashar al-Assad is a recruiting tool for the Islamic State and must go.
But any successor government must be able to maintain order and not permit the Islamic State to exploit a power vacuum, as it has done in Libya.
Moreover, orderly political change can be brought about only with Russian and Iranian support.
One near-term option worth exploring is a coalition government still headed by a representative of the Alawite minority, a concession that could well be the price of moving Assad out of power.
In principle, and over time, a more representative national government could come about, although talk of holding elections in 18 months is fanciful under any scenario.
But reaching a compromise along these lines could well be impossible.
This is why increased military effort is needed to bring about larger and more secure enclaves that could better protect civilians and take the fight to the Islamic State.
Syria is not a normal country in any sense, and it will not be for a long time, if ever.
A Syria of enclaves or cantons is a more realistic model for the foreseeable future.
Other indispensable elements of any effective strategy include expanded help for or pressure on Turkey to do much more to stem the flow of recruits to the Islamic State.
And Turkey, along with Jordan and Lebanon, need more financial assistance as they shoulder the bulk of the refugee burden.
Arab and Muslim leaders can do their part by speaking out to challenge the Islamic State’s vision and delegitimize its behavior.
There is also a domestic dimension to policy.
Homeland security and law enforcement – increasing protection both at borders and within them – will have to adjust to the increased threat.
Retail terrorists – individuals or small groups carrying out armed attacks against soft targets in open societies – are extremely difficult to deal with.
The threat and the reality of attacks will require greater social resilience and quite possibly a rebalancing of individual privacy and collective security.
What is also required is a dose of realism.
The struggle against the Islamic State is not a conventional war.
We cannot eradicate or destroy it any time soon, as it is as much a network and an idea as it is an organization and a de facto state that controls territory and resources.
Indeed, terrorism is and will continue to be one of the scourges of this era.
The good news, though, is that the threat posed by the Islamic State to the Middle East and the rest of the world can be dramatically reduced through sustained, concerted action.
The main lesson of the attack on Paris is that we must be prepared to act over time and place alike.
After Pax Americana?
NEW YORK – It has become popular to suggest that when the dust settles from the global financial crisis, it may become clear that the United States-led post-war world has come to an end.
If so, the global system that has secured peace, security, openness, and economic growth over the past six decades could be in grave danger.
Inspired by American leadership since World War II’s end, Europe, then Japan, then much of Asia and the world rose to new levels of prosperity; the world economy globalized upon the foundation of international institutions, norms, and standards; and foreign students educated in American universities returned home with new ideas about free markets, entrepreneurship, and democracy.
The US military’s protective umbrella gave large swaths of the world a vacation from war, making it easier for them to focus on economic growth and regional integration.
America not only took the lead role in building the institutions of a globalizing world – the United Nations, World Bank, IMF, NATO– it also became the model that many other countries looked to for inspiration.
After eight years of compromised American leadership, a botched war of choice in Iraq, failure to take the lead in global efforts to address climate change, Abu Ghraib, Guantánamo Bay, running up a $10 trillion debt, and igniting a global financial crisis – America’s once-glittering model has lost a good deal of its luster and America’s leadership has been questioned by many.
The point was driven home at the 7th Asia-Europe Meeting (ASEM) in Beijing this autumn, where European and Asian leaders began exploring ideas for a new global financial structure.
For much of the past 60 years, it would have been impossible to hold such a fundamental dialogue without US participation. Today, it is almost becoming a new global norm that neither the international committee nor the US is prepared for.
Despite talk about American decline, the world is not prepared for a post-American era.
As irksome as some of America’s actions have been, particularly over the past eight years, America remains the world’s most critical champion of the progressive values that have lifted hundreds of millions of people out of abject poverty and political repression.
If the US were to play a relatively smaller role in world affairs, and no other system was created to pick up the slack, these values could be at risk.
Although many states now hide behind an alleged universal principle of inviolable state sovereignty, for example, would the international community really want to go back to the old model where states did whatever they wanted to their citizens within the confines of their own borders?
Do countries around the world believe that they will be better off if the global trade system breaks down or international shipping lanes become less secure?
Are countries like China willing to step up and pay their fair share of dues to keep the UN running (China currently pays 2.1% of UN dues, compared to more than 25% for the US), or to capitalize revised international financial institutions or the Global Fund to Fight AIDS, Tuberculosis, and Malaria in a meaningful way?
Unless other countries become more willing to step forward for the common good, a post-American world could quickly become a far more frightening environment than what it would replace.
To make its case for a continued global leadership role, America must, however, step up to the plate.  While the go-it-alone impulse of the Bush administration has been discredited by its consequences, the inverse lessons regarding how important collaborative action is in today’s interconnected world are still being learned.
Even at the apex of American power, America’s greatness was always based on inspiring others, and the opportunities for building market share in that particular category remain unlimited.
It is impossible to overestimate how significant a step Barack Obama’s election is in this direction, but America’s actions over the coming years will be the ultimate determinant of whether the power of America’s model can be restored.
America can and should, for example, become the global leader combating climate change through major investments in alternative energy, conservation, and energy efficiency, and by taking strong actions at home to reduce America’s greenhouse gas emissions.  It should transform its immigration policy to recruit the best and brightest people from around the world to move to the US and become citizens, and remain the world’s leading champion of open markets, especially during the current financial crisis.
Closing the prison at Guantánamo and reaffirming America’s commitment to international law and human rights will also be an important step in this direction.
The world wants to believe in an America that lives up to its own best values.
The prospect of a truly global community of nations working together to achieve the greater good for all is indeed exciting.
But, although America has been far from perfect over the last six decades, the end of the pax Americana has the potential to create a dangerous void in international affairs.
If the world is going to shift in the direction of a new and more globally democratic system, other nations will need to meaningfully step forward to assume new responsibilities.
It is in America’s and the world’s interest that they do so.  The evidence of this will be seen not only in global institutions but also in places like Darfur, Zimbabwe, and Burma.
Until this happens, let us all hope that America can get back on track as the global champion of collaborative action to address the world’s greatest challenges and work with as many other countries  as possible to move collectively in the right direction.
After the Guns of August
The Middle East is a place where the dust hardly ever settles.
When it occasionally does, even for a short interval – as UN Resolution 1701 for cessation of hostilities in Lebanon seems to be holding – it is time to take stock of events in the hopes that a responsible debate may influence those in power.
Let’s start with the United States.
President George W. Bush has been short on neither initiatives nor catchy slogans and acronyms.
Recent years are littered with them: “Global War on Terror” (GWOT), “Road Map,” “Middle East Partnership Initiative “ (MEPI), “Broader Middle East and North Africa” (BMENA) – originally “Greater Middle East Initiative (GMEI) – Democracy Assisted Dialogue (DAD), and so on.
His latest reverie, envisioned in the thick of the recent fighting between Israel and Hezbollah, was the New Middle East (NME), with US clients Israel, Egypt, Jordan, and Saudi Arabia serving as the pillars of regional order.
But like all his previous initiatives since the terrorist attacks on New York and Washington almost five years ago now, the NME ran into trouble from the outset.
Secretary of State Condoleezza Rice announced its birth while rejecting an immediate ceasefire in Lebanon.
Her poor timing made the initiative appear heartless, as thousands of civilians were being uprooted, killed, or maimed by Israel’s efficient but ruthless artillery and air force.
This so embarrassed the three Arab NME partners that each raced to distance itself from the US-sponsored initiative.
Saudi Arabia, which had remained silent for nearly two weeks, did so with a $500 million contribution to rebuilding devastated areas of Lebanon and another billion to support Lebanon’s threatened currency.
Egypt’s heir apparent Gamal Mubarak followed suit in the fourth week of the fighting by heading a 70-member delegation on a solidarity visit to Beirut.
But, rather than earning him the respect of an outraged Egyptian public, revelations in the opposition press that his plane had to obtain a safe passage and authority to land from the Israelis garnered only howls of derision.
As for America, anything it touches in the Middle East has become radioactive, even for longstanding clients and friends.
In the course of maneuvering to delay the UN ceasefire, Bush and Rice continually reiterated the need for a Security Council resolution that deals forcefully with “the roots of the problem.”
Of course, for them and for Israel, this was Hezbollah and the need to eradicate or at a minimum disarm it and force its fighters to a safe distance from settlements and towns in northern Israel.
While this is a reasonable demand, the rest of the Middle East – and, indeed, much of the world, including Europe – regard the root cause of the conflict as Israeli intransigence and arrogance, together with America’s blind support for it.
Both America and Israel have cited foot-dragging in implementing UN Resolution 1559, which calls for disarming all non-state actors in Lebanon and the deployment of government forces all the way to the southern border.
But for years the US and Israel have not uttered a word about the dozens of UN resolutions, going back as far as Resolution 49 on partition in 1947, which called for the establishment of distinct Arab and Jewish states on roughly half of Mandated Palestine.
This and numerous other resolutions seeking redress for injustices toward Palestinians have been ignored by the US.
Thus, for 300 million Arabs and more than one billion Muslims the “root cause” of the Middle East conflict is not Hezbollah.
As its leader, Hassan Nasrallah aptly put it, “We are just a reaction to chronic injustice.”
It may well be that there is more than one root cause – every party to the conflict has a favorite one.
There is no point in belaboring whose pain is greater or whose root cause is deeper.
In fact, arguing over grievances merely drives the sides further apart.
The long overdue UN Resolution 1701 may, with its adoption, indicate that all parties are fatigued, or could no longer withstand international pressure.
This is good news for all concerned and provides an opportunity to tackle each party’s “root cause.”
Seizing the opportunity requires that humility rather than moral supremacy prevails.
Empathy, not ethnocentrism, should be the order of the day now that the guns are falling silent and we have rediscovered the limits of military force.
But if we have learned anything at all from the tragic assassinations of the region’s greatest peacemakers, Anwar Sadat and Yitzhak Rabin, it is that the guns do not remain silent for long.
During any lull, a fanatic from either side could jump to center stage and, through an act of utter madness, kick up the settling dust and dash the hopes of the many on both sides who still long for a lasting peace.
After the Millennium Development Goals
CAMBRIDGE – In 2000, 189 countries collectively adopted the United Nations Millennium Declaration, which evolved into a set of concrete targets called the Millennium Development Goals (MDGs).
These ambitious targets – ranging from halving extreme poverty and reducing maternal mortality by three-quarters to achieving universal primary schooling and halting (and beginning to reverse) the spread of HIV/AIDS – are supposed to be met by the end of 2015.
As the deadline approaches, development experts are debating a new question: What comes next?
It is virtually certain that many of the MDGs will not have been met by the end of 2015, but there have been striking successes in some areas.
For example, the goal of halving extreme poverty (measured by the number of people living on less than $1.25 a day) will likely be achieved ahead of time, largely thanks to China’s phenomenal growth.
At the same time, there is little evidence to suggest that those successes were the result of the MDGs themselves.
China implemented the policies that engineered history’s greatest poverty eradication program prior to, and independently from, the Millennium Declaration and the MDGs.
Clearly, however, the MDGs were a public-relations triumph, which is not to belittle their contribution.
Like all worthwhile PR efforts, the MDGs served to raise awareness, galvanize attention, and mobilize action – all for a good cause.
They amplified the global conversation about development and defined its terms.
And there is evidence that they got advanced countries to pay more attention to poor nations.
Indeed, the MDGs possibly had their clearest impact on aid flows from rich to poor countries.
A study by Charles Kenny and Andy Sumner for the Center for Global Development in Washington, DC, suggests that the MDGs not only boosted aid flows, but also redirected them toward smaller, poorer countries, and toward targeted areas like education and public health.
However, aid was not directly linked to performance and results, and it is much more difficult to know whether it had the desired impact overall.
The MDGs encompass eight goals, 21 targets, and 60 indicators.
Much criticism has focused on the use of these numerical targets and indicators, which, skeptics argue, are misspecified, mismeasured, and divert attention from equally important areas.
But these complaints miss the point.
Any effort that is concrete and implementable needs to monitor the results, and setting clear numerical targets is the best way to do so.
Still, a central paradox plagues the MDGs.
The Millennium Declaration was meant to be a compact between the world’s rich and poor countries.
Poor countries promised to refocus their development efforts while rich countries pledged to support them with finance, technology, and access to their markets.
But, oddly, of the eight goals, only the last one deals with “global partnership,” or what rich countries can and should do.
Even here, the MDGs contain no numerical target for financial aid or any other aspect of rich countries’ assistance, in contrast to the highly specific poverty-related targets set for developing countries.
It is perhaps telling that the “progress charts” prepared by the United Nations Development Program, the agency charged with reporting on progress toward achieving the MDGs, track only Internet usage under that goal.
Why we need a global effort to convince developing countries to do what is good for them is not clear.
Poverty reduction and human development should be the first order of business for governments in these countries, with or without the MDGs.
It is true, of course, that these governments often pursue different goals, for political, military, and other reasons.
But it is wishful thinking to believe that they can be persuaded to act otherwise by international declarations that lack enforcement mechanisms.
If we have learned one thing in the development business, it is that real reform cannot be bought with donors’ money, let alone with vague promises of money.
Equally problematic, the MDGs implicitly assume that we know how to achieve development targets, and that only resources and political will are missing.
But it is doubtful that even well-intentioned policymakers have a good handle on, say, how to raise secondary-school completion rates sustainably or reduce maternal mortality.
Many development economists would argue that significant improvements in governance and political institutions are required before such goals can be achieved.
The most that rich countries can do is to provide an enabling environment for the benefit of developing countries that are willing and able to take advantage of it.
These considerations suggest an obvious direction for the next iteration of the MDGs.
First, a new global compact should focus more directly on rich countries’ responsibilities.
Second, it should emphasize policies beyond aid and trade that have an equal, if not greater, impact on poor countries’ development prospects.
A short list of such policies would include: carbon taxes and other measures to ameliorate climate change; more work visas to allow larger temporary migration flows from poor countries; strict controls on arms sales to developing nations; reduced support for repressive regimes; and improved sharing of financial information to reduce money laundering and tax avoidance.
Notice that most of these measures are actually aimed at reducing damage – for example, climate change, military conflict, and financial crime – that otherwise results from rich countries’ conduct.
“Do no harm” is as good a principle here as it is in medicine.
This kind of reorientation will not be easy.
Advanced countries are certain to resist any new commitments.
But most of these measures do not cost money, and, as the MDGs have shown, setting targets can be used to mobilize action from rich-country governments.
If the international community is going to invest in a bold new public-relations initiative, it might as well focus on areas where the potential payoffs are the greatest.
After the Promised Land
LONDON – At the height of the Arab uprisings last spring, many Europeans were gripped by nightmare visions of a tsunami of migrants crashing against the continent’s shores.
The wave never hit, but its specter fed a tenacious anti-immigrant populism that has concealed an important new trend: migration to Europe – and to the United States – has largely stalled.
In many countries, more immigrants are leaving than are arriving, owing mainly to the economic crisis that has drained jobs in the West.
That reversal is one of the great under-reported stories of 2011 (and of the preceding two years), and the numbers are startling.
Consider Spain, which is on track to lose more than a half-million residents by 2020.
By contrast, between 2002 and 2008, Spain’s population grew by 700,000 a year, driven largely by immigration.
The trends are similar elsewhere in Europe.
While this fact alone will not quiet opponents of immigration, it does give countries more breathing room to repair and strengthen badly broken systems for receiving and integrating newcomers.
Although rapidly aging Western countries are unable to attract the immigrants they need, they allow millions who are already there to suffer discrimination and abuse.
Detentions and deportations take place under sometimes terrible conditions.
Meanwhile, the international community collectively fails to protect vast populations of vulnerable migrants, such as the millions stranded by the recent conflicts in North Africa.
Undoubtedly, rising anti-immigrant populism must be confronted.
While polling suggests that attitudes are influenced more by ethnicity than religion, both help to define identities and mindsets.
Political parties in France, Switzerland, and the Netherlands (to name a few) have run successful campaigns that scapegoat immigrants.
Moreover, governments from Alabama to Hungary are passing laws that undermine what should be migrants’ rights.
Italy recently adopted harsh “emergency” decrees that target migrants by making undocumented entry and residence a criminal offense.
Anti-immigrant rhetoric from the political extremes has fed into mainstream political discourse.
European leaders trip over themselves to declare, one more forcefully than the next, that multiculturalism is dead.
Dutch politician Geert Wilders, whose Freedom Party is informally part of the governing coalition, did them one better by being charged with incitement to anti-Muslim hatred.
In the US, alligator-filled moats and electrified border fences have featured in the current presidential campaign.
Such attacks on immigration might offer some instant political gratification, but their net result is to cleave societies whose cohesion is already seriously challenged by the economic crisis.
Growing discrimination in employment, housing, and education affects not just immigrants and their children; it harms our societies as a whole.
With the lull in net immigration, we now have a window of opportunity to address these shortcomings.
Debunking the myths about migration – that most immigrants enter unlawfully, for example, or that immigration displaces existing workers – would be a good place to start.
It would also be useful to explain that immigration is necessary for prosperity and growth in almost all OECD countries.
If aging societies in the West and elsewhere (like Japan) fail to get immigration right, they will be woefully unprepared when they confront the real tidal wave: the retirement of baby boomers in the coming two decades.
The gaps in these countries’ labor markets – from software specialists to physicians to home health aides – will be immense.
The European Union’s labor force will decline by almost 70 million workers in the next 40 years; in the absence of significant net immigration (combined with a much higher retirement age), European economies and social safety nets will shrivel.
The priorities are clear.
We need to understand better how our economies will evolve in the coming decades, and to redesign our educational systems to produce workers with usable skills.
And, where it is clear that immigrants will be needed, we must be able to identify, welcome, integrate, and protect them.
Meanwhile, our most fundamental institutions – schools, police, and the courts – must be re-engineered to reflect and respond to the diversity of our communities, which is now a fact of life.
Countries must learn to work together to achieve these goals, few of which can be reached by going it alone.
If our toolbox were empty, our inaction might be understandable.
But examples of smart migration practices abound.
Canada and the Philippines, for instance, have a well-functioning accord that protects the rights of temporary workers.
Sweden has developed legislation that minimizes bureaucracy for companies that need foreign workers.
And important advances have been made in ensuring that immigrant children receive the education that they need to become full members of society.
Progress is being made on the global level as well, despite the economic crisis and populist headwinds.
In June, the International Labor Organization’s member states overwhelmingly approved the Domestic Workers Convention, which will significantly increase protections for a vulnerable group of workers –&nbsp;the majority of whom are migrants.
Meanwhile, the Global Forum on Migration and Development, established in 2007, has quickly become an important means of fostering knowledge and partnerships.
The reason for growing international cooperation is simple: countries everywhere are affected by migration, and, increasingly, they are experiencing immigration and emigration simultaneously.
Indeed, roughly one-third of migrants nowadays move between developed countries; one-third move between developing countries; and only one-third move from the developing to the developed world.
Highly skilled workers, such as bankers and engineers, are flocking to China.
Mexico, known primarily as a country of emigration, is home to millions of migrants from Central America.
Millions of people in Southeast Asia venture to the Middle East to work, but millions more cross borders within the region.
The list goes on.
When it comes to migration, we are all in the same boat – and that boat is leaking.
Starting in 2012, countries should redouble their efforts to fix it.
A Future without Precedent
JERUSALEM – In my nearly nine decades of life, I cannot recall a time in which the past was so irrelevant to policymaking.
All of today’s significant developments went unpredicted by anyone.
Experts studied the past, but, constrained by old paradigms, they could not discern the future.
Today’s dynamic complexity, in which a science-based, fast-changing global economy makes so many more phenomena interdependent, prevents us from foreseeing the future through linear extrapolations of the past.
The only certainty is that the future will be defined by scientific progress and innovation, which cannot be known ahead of time.
As a result, the traditional power of states and leaders is declining; in today’s global economy, innovators, not politicians, wield the most influence.
The globalized economy affects every state, yet no single state can determine the outcomes, because science and technology are borderless.
Global companies wish to do business worldwide, eroding not just sovereignty, but also racism and prejudice, as well as significantly weakening nationalism.
This transformation has placed the world in the hands of a younger generation, more technologically savvy than their parents and connected to one another through social networks that are not confined by territory, language, or government.
The young leaders who created Facebook and Google have had a greater global impact than many statesmen and generals.
These young people are also the leaders of erupting political protest movements.
The “Arab Spring,” the tent demonstrations in Israel, Occupy Wall Street, and the protests in Russia reveal not a clash of civilizations, but a battle of generations.
The young generation understands that the way states and economies are currently run is unfit for the new era.
Yet there are political “hitchhikers” who want to exploit the recent awakening, not by promoting an agenda of freedom, but by imposing a different type of coercion.
In the Arab world, it is mainly extreme Islamists who are hijacking the young generation’s wave, stealing their revolution.
Israel has reacted positively to the will of the young generation, but it cannot and should not intervene in events in the Arab world.
Our hearts are with the rebelling youngsters and their legitimate yearning for freedom and basic rights to express themselves, choose their leaders, and earn their own living.
Israelis wait for the day when our country will no longer be the region’s only democracy, because being an island of prosperity in a sea of poverty is unnatural.
Yet there is a real concern that the extremists, who are politically well organized, are seeking to gain control by the ballot over less-organized liberals, thus preventing peace and stability.
Fundamentalist radicals cannot provide real solutions to the region’s basic problems.
The social changes now underway threaten their way of life, which includes discrimination against women and a ban on modern education.
But only profound reforms of traditional authority can pave the way towards freedom and growth.
Israel can serve as an example to others striving to reach economic prosperity and social freedom, because its success is due to the fact that the country had absolutely nothing at the start.
We returned to our homeland, rich with history, but devoid of natural resources.
Israel was left with only one resource: its human capital.
So we invested in education and science, and today we have the world’s highest percentage of scientists and patents per capita.
Roughly 95% of our agriculture is hi-tech.
We use less water and yield more crops per acre than any other country in the world.
What Israel can do, others can do as well.
We will gladly offer a helping hand to whoever is willing to reach for it.
Together, in peace with our neighbors, we can create a region of hope, development, and success.
In particular, we must do everything in our power to end the conflict with the Palestinians.
Israel was not born, and it is not Israel’s destiny, to govern another people.
We are sincerely interested in the establishment of a Palestinian state living peacefully side-by-side with Israel, the democratic state of the Jewish people.
For us, peace is both a moral imperative and a national-security strategy, because resolving the conflict would help to stabilize the region by neutralizing the extremists who seek to manipulate today’s popular movements to advance their radical agenda.
The international community can support these efforts by providing incentives to countries that choose freedom and progress.
At the same time, determined and decisive policies must be taken against extremists.
In particular, Iran is a fount of moral corruption that spearheads extremism and halts reform, crushing the legitimate protest of its own citizens and acting against the brave Syrians now fighting for their freedom.
Iran also uses proxies to instigate terror against moderate forces in the Palestinian Authority, Lebanon, and Iraq.
If Iran is successful in its plan to acquire nuclear weapons, its leaders could shake the Middle East and encourage more extremism and violence.
Israel will defend itself if Iran continues to call for its destruction.
However, the threat is not to Israel alone; Iran is a danger to the peace and stability of the entire world.
The world’s democracies have declared that they will not allow Iran to possess nuclear arms; it is their duty to follow through on that commitment, before doing so becomes impossible.
Beyond the short-term challenges ahead, we all have a duty to profoundly change the way we prepare our children to cope with today’s new world.
In an era where yesterday has become almost irrelevant and we can hardly predict tomorrow, the role of education must allow all children to reach their highest potential.
Today’s educators should inspire our children towards creativity and innovation.
Self-expression is as important as free expression.
I write this in the 88th year of my life, but not because I have learned from experience.
On the contrary, experience is overrated, often constraining the courage needed to face tomorrow and build an unprecedented new world.
The future is already here; there is no point in looking back.
Against Simplification
NEW YORK – It is said that Americans have a genius for simplification.
Gradually, however, the quest for it has become a global trend, one that continues to conquer new territories, just as blue jeans once did.
The speed of our daily life is visibly increased – and not for the better – by this unstoppable evolution.
The tyranny of pragmatism seems to mark all of the complex dilemmas of our time.
Too many valid choices are ignored or skirted through the routine of short-cuts.
Nowhere is this trend more damaging than in today’s mercantile approach to art.
Even the much-praised notion of competition seems fake and cynically manipulated by the “corporate” mentality that now pervades the world of culture – by the financial pre-selection that determines what publishers, producers, and other impresarios will support.
Just imagine what might have happened with the works of, say, Proust, Kafka, Musil, Faulkner, or Borges had they been subjected to mass-market competition like shoes or cosmetics.
Culture is a necessary pause from the daily rat race, from our chaotic and often vulgar political surroundings, and it is a chance to recover our spiritual energy.
Great books, music, and paintings are not only an extraordinary school of beauty, truth, and good, but also a way of discovering our own beauty, truth, and good – the potential for change, of bettering ourselves and even some of our interlocutors.
If this respite and refuge is gradually narrowed and invaded by the same kind of “products” as those that dominate the mass market, we are condemned to be perpetual captives of the same stunted universe of “practicalities,” the ordinary agglomeration of clichés packaged in advertisements.
I was thinking again about these old and seemingly unsolvable questions during my re-reading of a quite challenging novel by a close friend and a great writer, not very present in the vivid landscape of American letters of today.
The theme, style, and echo of his work says a lot, I think, about our simplified world.
The novel is Blinding, by Claudio Magris.
Hailed in Europe as one of the great novels of the twentieth century, Blinding arrived in America only after a great delay, and never received the attention that it deserved.
Unfortunately, that is no surprise.
The number of literary translations done nowadays in the United States is, according to a United Nations report, equal to that of Greece, a country one-tenth the size.
Imported books are thought to be too “complicated,” which is another way of saying that literature should deal with simple issues in a simple way, obeying the rules of the mass market, with its tricks of packaging, accessibility, advertisement, and comfort.
At the core of Magris’ book is the destiny of a group of Italian communists who travel to Yugoslavia after the Second World War to contribute to the construction of a socialist society, only to be caught in the conflict between Stalin and Tito.
They are imprisoned for their Stalinist allegiance; when they are finally allowed to return to Italy, their old comrades refuse to accept them.
The book’s plot spans two centuries of revolution.
Then, suddenly,
“the party vanished, overnight, as if all of a sudden a giant sponge had drained the entire sea, Adriatic and Austral, leaving litter and clots of mud, and all the boats stranded.
How can you go home again if the sea has been sucked down a vast drain that opened up beneath it, emptying it who knows where, into a void?
The earth is arid and dead, but there won’t be another one, nor another heaven.”
The solitude of the individual facing his faith alone, without collective illusions, and forced to do something with himself in the arid, noisy world tells us something important about the exiled world of modernity and its complex and contradictory problems.
Magris’s novel is not only an important literary achievement; it also has a deep connection to the dangers that we face now, particularly the wave of fanaticism, from Mumbai to Oslo, in the name of a holy war against the “other.”
Are all the extremists searching for a new coherence, for a lost illusion of togetherness and a new hope of resurrection?
Can we ever forget September 11, 2001, the start of a bloody century in which the mystical force of hatred and destruction has recovered its strength?
Are Osama Bin Laden’s minions, the bloody Hamas-Hezbollah battalions, or troubled loners like Timothy McVeigh, Theodore Kaczynski, and now Norway’s Anders Behring Breivik, the “heroes” of our contemporary nightmare?
Is this the “rebel” response to an overly globalized, incoherent, and ultimately disturbing reality?
If so, their barbarism demands scrutiny – in relation to both historical precedent and to our modernity – rather than merely being labeled “monstrous” (though it certainly is that).
The new religious militants, fighting in the name of their particular and peculiar God, seem as fanaticized as the Fascists, Nazis, and Communists of earlier decades.
Magris’s main character is a rebel in more than one embodiment: as Salvatore Cipico, one of the inmates in the communist concentration camp in Yugoslavia; as Jurgen Jurgensen,  ephemeral king of Iceland and a convict forced to build his own jail; and as Jason, the mythic adventurer searching for the volatile truth.
A multilayered and complex chronicle of the devastating tragedies of the twentieth century, Blinding is an insistent, informed, and irreplaceable incursion into the moving landscape of the human soul, its wounds and voids, its vitality and versatility, its deep distortions and its unpredictable dynamics.
It is a fascinating story about the conflict between ideals and reality, or Utopia and humanness; about being faithful to a cause and betraying it; and about sacrifice and solidarity.
It is also a rich and original literary achievement that challenges today’s consumerist ethic.
By renouncing simplicity, it also repudiates today’s prevailing confusion of information with literature, of facts with creativity, and best-selling products with true works of art.
The Age of Hyper-Uncertainty
BERLIN – The year 2017 will mark the 40th anniversary of the publication of John Kenneth Galbraith’s The Age of Uncertainty.
Forty years is a long time, but it is worth looking back and reminding ourselves of how much Galbraith and his readers had to be uncertain about.
In 1977, as Galbraith was writing, the world was still reeling from the effects of the first OPEC oil-price shock and wondering whether another one was in the pipeline (as it were).
The United States was confronting slowing growth and accelerating inflation, or stagflation, a novel problem that raised questions about policymakers’ competence and the adequacy of their economic models.
Meanwhile, efforts to rebuild the Bretton Woods international monetary system had collapsed, casting a shadow over prospects for international trade and global economic growth.
For all these reasons, the golden age of stability and predictability that was the third quarter of the twentieth century seemed to have abruptly drawn to a close, to be succeeded by a period of greatly heightened uncertainty.
That’s how things looked in 1977, anyway.
Viewed from the perspective of 2017, however, the uncertainty of 1977 seems almost enviable.
In 1977, there was no President Donald Trump.
Jimmy Carter may not go down in history as one of the best US presidents, but he did not threaten actions that placed the entire global system at risk.
He did not turn his back on America’s international commitments such as NATO and the World Trade Organization.
Nor did Carter go to war with the Federal Reserve or pack its board with sympathetic appointees willing to sacrifice sound money to his reelection prospects.
On the contrary, he appointed Paul Volcker, a towering pillar of monetary stability, as chairman of the Board of Governors.
And although Carter did not succeed in balancing the federal budget, he didn’t blow it up, either.
Whether Trump slaps a tariff on Chinese goods, repudiates the North American Free Trade Agreement, packs the Federal Reserve Board, or undermines fiscal sustainability remains to be seen.
Conceivable outcomes range from mildly reassuring to utterly catastrophic.
Who knows what will happen?
By today’s standards, Carter was the embodiment of predictability.
In 1977, moreover, the prospects for European integration were rosy.
Denmark, Ireland, and, most notably, the United Kingdom had recently joined a rapidly growing European Community.
The EC was attracting members, not losing them.
It was a club that countries sought to join precisely in order to achieve faster economic growth.
Moreover, to buttress its common market, the EC had just established a regional monetary system, the suggestively named “snake in the tunnel.”
While this was far from a perfect monetary system, it had one very positive attribute: countries could leave in hard economic times, and rejoin if and when the outlook brightened.
In 2017, in contrast, negotiations over Brexit will continue to cast a dark cloud of uncertainty over the European Union.
How those negotiations will proceed and how long they will take are anyone’s guess.
Moreover, the main questions raised by Britain’s decision to leave – whether other countries will follow and, indeed, whether the EU itself has a future – remain far from resolved.
Meanwhile Europe’s monetary house remains half built.
The eurozone is neither appealing enough to attract additional members nor flexible enough to grant troubled incumbents a temporary holiday, in the manner of the currency snake. The euro will likely survive the year, inertia being what it is.
In 1977, uncertainties emanating from emerging markets were not on commentators’ radar screens.
Developing countries in Latin America and East Asia were growing, although they depended increasingly on a drip feed of foreign loans from money-center banks.
China, still largely cut off from the world, did not figure in this discussion.
And even if something went wrong in the Third World, developing countries were simply too small to drag down the global economy.
The situation today couldn’t be more different.
What happens in China, Brazil, or Turkey doesn’t stay in China, Brazil, or Turkey.
On the contrary, developments in these countries have first-order implications for the world economy, given how emerging markets have accounted for the majority of global growth in recent years.
China has an unmanageable corporate-debt problem and a government whose commitment to restructuring the economy is uncertain.
Turkey has a massive current-account deficit, an erratic president, and an unstable geopolitical neighborhood.
And if political scandals were export goods, Brazil would have a clear comparative advantage.
Although The Age of Uncertainty was about much more than the year 1977, it captured the tenor of the times.
But if Galbraith were writing the same book in 2017, he probably would call the 1970s The Age of Assurance.
A German Europe?
LISBON/RIGA – Is the Europe that is emerging from the euro crisis a German one?
During the euro crisis, power in the European Union seems to have shifted towards national capitals in general, and towards one national capital in particular: Berlin.
But, with Germany introverted, France downgraded, and Britain semi-detached, the big story in European foreign policy is that the time has come for the little guy who thinks big.
In this Europe, the important moves are now sometimes made in Stockholm or Warsaw, not only in Berlin, Paris, or London.
And, with major foreign-policy issues on Europe’s doorstep – whether in Egypt, Belarus, or now Syria – useful European initiatives are to be welcomed, regardless of where they originate.
Germany, in foreign policy as well as in economics, can exert decisive leadership in the EU – when it wants to.
For example, together with Poland, it led the EU’s attempt to develop a coordinated approach to Russia, and it flexed its muscles on Serbia.
But, on other issues – for example, Libya – Germany did not so much lead as use its newfound room for maneuver to follow its own preferences in the face of other EU members.
So the answer today to Henry Kissinger’s famous question about whom he should call when he wants to speak to Europe, is not necessarily “the German chancellor.”
While Berlin is increasingly imposing its economic preferences on others in the eurozone, it is not prepared to use military force as a foreign-policy tool, as it demonstrated in the case of Libya.
Moreover, Germany, it seems, is becoming a “geo-economic power” driven by the needs of its export sector.
By using economic means to pursue its foreign-policy ends, Germany is gradually turning its back on its European partners.
Meanwhile, as France experiences a loss of power relative to Germany on economic issues, it continues to play a decisive role in foreign policy.
France led the Libya operation, and is doing much the same with attempts to impose stronger sanctions against Iran and provide support for the United Nations in Côte d’Ivoire.
But France’s unilateral approach often antagonizes its European partners.
For example, French President Nicolas Sarkozy preempted a common European position on the Palestinian statehood bid at the UN in September.
In other words, even when France leads, it does not always do so in a constructive way.
Apart from the decisive role that it played in Libya alongside France, Britain is becoming increasingly marginal in European foreign policymaking.
Even before it vetoed a plan by eurozone countries to create a “fiscal union” at the European summit in December 2011, it was playing less of a leadership role than it traditionally has on key European foreign-policy issues.
Britain has continued to support EU enlargement, closer links with Turkey, and development in Africa, but it has not launched any creative initiatives to bring other member states along or change the terms of the EU debate.
On other issues, such as engaging “strategic partners” – China and Russia in particular – the United Kingdom is often a follower as well.
As the “big three” increasingly pursue their own narrowly defined national interests, however, other EU member states are emerging as leaders in key foreign-policy fields.
For example, Sweden – the 14th largest member state in terms of population, and eighth in terms of GDP – under the leadership of Prime Minister Fredrik Reinfeldt and Foreign Minister Carl Bildt punches considerably above its weight.
Last year, it increased annual aid to North Africa by SEK100 million (€11.1 million), proposed an EU mission to Tunisia just a week after the revolution to support democratic aspirations there, and was an early and strong backer of UN resolutions in support of the uprising in Libya.
Poland, too, is emerging as a foreign-policy leader.
Prime Minister Donald Tusk and Foreign Minister Radek Sikorski have particularly taken the initiative on the EU’s strategy towards Russia, where Poland has largely overcome its differences with Germany and is now at the forefront of efforts to develop a genuinely comprehensive approach.
Poland has also led on European defense (though it declined to take part in the military intervention in Libya).
This reflects the strength of the Polish economy, which is expected to grow by more than 3% in 2012 – faster than almost anywhere else in the EU.
Germany might be getting all of the attention in this time of crisis, but the last year has been a reminder that Europe is most effective and influential when the small countries get involved and join forces with – and even lead – the big ones.
For example, on Iran (with exceptions like Greece), Europeans have united around a clear policy and collective positions, such as an oil embargo.
So, Poland and Sweden:&nbsp; Europe needs your leadership.
But that might not be enough in an EU with more than 500 million citizens.
Other EU states need to follow their example in order to make European foreign policy truly effective and influential.
A German Glimmer in a Global Boom
In 2004, the world economy grew at a rate of 5.1%, the fastest pace in the last 28 years.
While Ifo`s World Economic Climate indicator, generated from quarterly surveys of 1,200 experts in 90 countries, worsened slightly during the first three quarters of 2005, it rose again in the last quarter, indicating a continuation of the boom.
In 2005, growth is estimated to have been about 4.3%, and a similar rate can be expected in 2006, marking a period of sustained rapid global growth unseen since the 1970’s.
But the boom is not uniform.
In the United States, the number of experts giving a favorable assessment of the current situation declined; indeed, a majority believes that the economic situation will worsen during the next six months.
However, in the Asian countries, including China, the optimism is unbroken.
The same is true for Eastern Europe, the ex-Soviet states, and Latin America.
The big surprise is Europe, which, unlike in 2004 and the first half of 2005, now seems to be catching up with the rest of the world.
Whereas growth was a miserable 1.5% in 2005 in the 15 “old” members of the European Union, Ifo expects EU-15 growth to accelerate to 2.1% in 2006.
To be sure, economic performance will vary widely among EU countries.
While Italy will be the laggard, with only 1.1% growth, the Irish rocket will not lose its force, pushing real GDP up by about 4.8%.
In general, the big EU countries are still performing badly, in contrast to the smaller members – hardly surprising, given that the EU is basically an institution to help the smaller countries overcome the drawback of their size by extending the agglomeration advantages that formerly were reserved to the bigger countries.
But even Germany, Europe’s biggest economy, is experiencing an upswing.
The Ifo climate indicator for Germany, based on monthly surveys of 7,000 firms, jumped upwards in the second half of 2005, reaching its highest value since the boom year 2000, with businesses’ assessment of the current situation and expectations improving.
After five years of stagnation, the economy is finally on the move.
The driving force is external demand, as Germany, the world’s second-largest exporter, profits from the global boom.
Exports increased by 6.2% in 2005 and are expected to increase by 7.4% in 2006.
However, as we saw in 2004 and 2005, exports are not enough to create substantial growth if domestic demand does not follow.
The good news for Germany is that investment demand is now growing, too.
While the second half of 2005 was already quite good, Ifo expects investment in equipment to grow by a healthy 6% in 2006.
After many years of contraction, investment in construction also will rise slightly.
Total investment growth is expected to reach 2.9% – weak by past standards, but nonetheless a promising salve for the wounded German mood.
Moreover, any investment growth is vital for Germany, which, according to the latest OECD statistics, currently suffers from the world’s lowest share of net investment in national income.
Even if Germany remains the world’s laggard, rising investment demand as such will contribute to GDP growth, which Ifo estimates at 1.7% in 2006.
That number looks small compared to most other countries.
In fact, all EU countries except Italy and the Netherlands will grow faster.
But everything is relative: Germany’s trend growth rate is just 1.1%, and the country has been the slowest growing EU country since 1995.
Measured against a disappointing past, even Germany is currently experiencing an economic boom.
Indeed, even German unemployment, which has been rising in cycles since 1970, will decline slightly in 2006, from 4.8 to 4.7 million.
The good economic data will reinforce initial favorable impressions of Angela Merkel’s new government, which got off to an excellent start at the EU Summit, where Merkel helped to broker a compromise between Britain and France on the Union’s 2007-2013 budget (by adding another €2 billion to Germany’s annual contribution).
In fact, the government may even have contributed a bit to the good economic data by announcing a serious effort to consolidate Germany’s own public finances – a prerequisite for investor confidence.
According to the government, substantial tax increases will bring the fiscal deficit below the 3%-of-GDP limit set by the Stability and Growth Pact – a target missed for five consecutive years – by 2007.
The real test for the German government is the labor market.
Most observers now agree that Germany needs something like the American earned-income tax credit.
In Germany, it’s called “activating social aid” or “combi wages,” but the principle is the same: the state should reduce the money it pays for doing nothing and pay more for participating in the work force.
That would widen the wage distribution, create jobs, and maintain the living standard of the poor.
Merkel announced in her inaugural speech in the Bundestag that her government will introduce such a system in 2006.
If this is more than lip service, and if she really carries out a serious reform of the German welfare state’s incentive structure, the result could be higher employment and structural economic growth.
In the long term, that would be more promising for the EU – and for the global economy – than the demand-driven performance that Germany is currently enjoying.
A Global Agenda for Seven Billion
NEW YORK – Late next month, a child will be born – the 7th billion citizen of planet Earth. We will never know the circumstances into which he or she was born.
We do know that the baby will enter a world of vast and unpredictable change – environmental, economic, geopolitical, technological, and demographic.
The world’s population has tripled since the United Nations was created in 1945.
And our numbers keep growing, with corresponding pressures on land, energy, food, and water. The global economy is generating pressures as well: rising joblessness, widening social inequalities, and the emergence of new economic powers.
These trends link the fate and future of today’s seven billion people as never before. No nation alone can solve the great global challenges of the twenty-first century. International cooperation is a universal need.
The 66th session of the UN General Assembly is a renewed opportunity for the countries of the world to set aside narrow, short-term interests and commit to cooperative efforts to address humanity’s long-term imperatives.
At a time when all nations are experiencing individual challenges, we need to forge a worldwide common agenda that can help to ensure that the seven billionth baby and future generations grow up in a world characterized by sustainable peace, prosperity, freedom, and justice.
To help create this future, I am focusing my second term as Secretary-General on five global imperatives – five generational opportunities to shape the world of tomorrow by the decisions we make today.
The first and greatest of these imperatives is sustainable development. We all must understand that saving our planet, lifting people out of poverty, and advancing economic growth are one and the same fight. We must connect the dots between climate change, water scarcity, energy shortages, global health, food security, and women’s empowerment. Solutions to one problem must be solutions for all.
In the next five years, we need to create a new economic vision for sustainable development and forge global consensus on a binding climate change agreement.
Fostering economic growth, realizing the Millennium Development Goals, and combating climate change will all depend on creating a new energy system for the twenty-first century and extending it to every person on the planet.
Prevention as a framework for international cooperation is a second opportunity.
This year, the UN peacekeeping budget will total $8 billion. Think of what we could save by avoiding conflicts – by deploying political mediation missions, for example, rather than troops.
We know how to do this.
Our record proves it – in Guinea, Kenya, and Kyrgyzstan.
A third imperative is building a safer and more secure world. In this effort, we must be courageous in standing up for democracy, human rights, and peace.
This year was one of signature achievements in restoring and securing peace – in Côte d’Ivoire, Darfur, Egypt, and elsewhere. But hatred and bloodshed still stand in the way of our vision for peace.  
In the Middle East, we must break the stalemate.
Palestinians deserve a state.
Israel needs security.
Both want peace. A negotiated settlement can produce these outcomes, and the UN is a platform for forging such a peace.
So, too, will we continue our efforts to foster democratic governance in Iraq, Afghanistan, the Democratic Republic of Congo, and Sierra Leone. And, in the name of all of humanity, we will continue to push forward on nuclear disarmament and non-proliferation, in service of realizing a world free of nuclear weapons.
The fourth big opportunity is supporting countries in transition.
This year’s dramatic events in North Africa and the Middle East inspired people around the globe.
Let us help make the Arab Spring a true season of hope for all.
In Libya, we are deploying a new UN support mission to assist the country’s transitional authorities in establishing a new government and legal order, consistent with the aspirations of the Libyan people.
Syria is a special concern.
For six months we have seen escalating violence and repression.
The government has repeatedly pledged to undertake reforms and listen to its people. It has not done so.
The moment to act is now.
The violence must stop.
Last but not least is the imperative of working with and for women and young people.  
Women hold up more than half the sky and represent much of the world’s unrealized potential.
We need their full engagement – in government, business, and civil society.
The UN has placed a high priority on promoting women at all levels of the Organization and this year, for the first time, UN Women is operating to promote the interests and rights of women all over the world.
Seven billion people now look toward the United Nations for solutions to the world’s great global challenges.
They hold different religions and backgrounds but common dreams and aspirations.
Our global future depends on bringing these individual talents and universal rights together in common cause.
Let our common agenda begin.
A Global Consensus Against Terrorism
Mention the United Nations and the first reaction is likely to be the ongoing oil-for-food scandal and what it will mean for Secretary-General Kofi Annan’s ability to lead the organization for the remaining year and a half of his tenure.
But there is much more going on at the UN than investigations.
Reform is in the air – in part because of the scandal, but also because of the UN’s inability to deal effectively with challenges ranging from Rwanda and Kosovo to Iraq and, most recently, Sudan.
Even the UN’s most ardent supporters now recognize that change is called for if the organization is to make a significant contribution to international peace and security.
Some of the reform talk concerns the UN Security Council’s composition.
The Security Council represents what the World War II Allies believed the post-war world would look like and how it should be run.
This helps to explain why a much-weakened France was made a permanent member of the Council – and why Germany and Japan (and a not-yet independent India) were not.
Defending the Security Council’s current make-up is impossible; the need for change is beyond debate.
But coming up with an approach that gains broad international support will prove extremely difficult.
Great Britain and France will resist being replaced by a single EU seat, while making Germany a permanent member would only exacerbate the problem of Europe’s relative over-representation.
Pakistan would object to adding India to the Security Council; Argentina, Chile, and Mexico to adding Brazil; Nigeria to South Africa (and vice-versa); and several countries, including China, Indonesia, and South Korea, might resist creating a permanent seat for Japan.
Clearly, fixing the Security Council will require considerable time and political effort.
In the meantime, there is important work to be done. One productive avenue would be to follow up on one of the recommendations of the High Level Panel that was endorsed by Annan; namely, that all UN members go on record declaring that terrorism has no place in today’s world.
This will prove more difficult than it first sounds.
For too long, the international community has tolerated terrorism – the intentional killing of civilians and noncombatants by non-state actors for political purposes – on the grounds that, on occasion, “one man’s terrorist is another man’s freedom fighter.”
Historians have the luxury of debating whether terrorism may have been justified in certain situations in the past.
We do not.
Modern terrorism is too destructive to be tolerated, much less supported.
Weapons of mass destruction – nuclear, biological, and chemical weapons – are just that, and no cause can excuse their use.
Moreover, as the terrorist attacks on America of 2001 showed, weapons as basic as box-cutters can become weapons of mass destruction if they are used to exploit the vulnerabilities of modern, global life.
Terrorism is even less justified given that political avenues exist nowadays for pursuing political aims.
Palestinians can negotiate their future relationship with Israel and can count on American, Russian, European, and UN assistance.
Iraqis have elected their own representatives and are poised to write their constitution.
No one pursuing reasonable goals and who is prepared to compromise can argue that terrorism is his or his group’s only option.
The world has already taken some important steps against terrorism.
A dozen international conventions and numerous UN resolutions commit governments to oppose hostage taking, the hijacking of civilian aircraft, and terrorism more broadly.
Similarly, the mandate of the Financial Action Task Force, created in 1989 to curb money laundering, has grown and become focused mainly on curbing terrorist financing.
UN Security Council Resolution 1373, passed after the September 11 attacks, calls on states to deny safe haven to terrorists, bring to justice anyone associated with terrorism, suppress recruitment by terrorist groups, block terrorists’ efforts to acquire weapons, and cooperate with other governments and international organizations in tracking suspects and boosting security.
What is missing is a new, 13th convention that closes the loophole that seems to permit governments to decide what constitutes terrorism and what does not.
Broad agreement is needed that any intentional killing of civilians and noncombatants is unacceptable, and that its perpetrators and supporters must be punished.
Of course, such a convention will not prevent all future acts of terrorism.
But ideas matter.
Terrorism needs to be de-legitimized in the way that slavery has been.
Doing so will make governments and individuals think twice before becoming a party to terrorism; it should also make it less difficult to garner support for international action against those who nevertheless carry it out.
We are taught early on in our lives that the end cannot justify the means.
It is time to put this principle into effect before many more innocent lives are lost.
A Global Green New Deal
NAIROBI – With unemployment soaring, bankruptcies climbing, and stock markets in free-fall, it may at first glance seem sensible to ditch the fight against climate change and put environmental investments on hold.
But this would be a devastating mistake of immediate, as well as inter-generational, proportions.
Far from burdening an already over-stressed, over-stretched global economy, environmental investments are exactly what is needed to get people back to work, get order books flowing, and assist in powering economies back to health.
In the past, concern for the environment was viewed as a luxury; today, it is a necessity – a point grasped by some, but by no means all, economic architects yet.
A big slice of President Barack Obama’s $825 billion stimulus package for the United States includes a boost to renewable energy, “weatherizing” a million homes, and upgrading the country’s inefficient electricity grid.
Such investments could generate an estimated five million “green-collar” jobs, provide a shot in the arm for the construction and engineering industries, and get America back into the equally serious business of combating climate change and achieving energy security.
The Republic of Korea, which is losing jobs for the first time in more than five years, has also spotted the green lining to grim economic times.
President Lee Myung-Bak’s government plans to invest $38 billion employing people to clean up four major rivers and reduce disaster risks by building embankments and water-treatment facilities.
Other elements of Lee’s plan include construction of eco-friendly transportation networks, such as high-speed railways and hundreds of kilometers of bicycle tracks, and generating energy using waste methane from landfills.
The package also counts on investments in hybrid vehicle technologies.
Similar pro-employment “Green New Deal” packages have been lined up in China, Japan, and the United Kingdom.
They are equally relevant to developing economies in terms of jobs, fighting poverty, and creating new opportunities at a time of increasingly uncertain commodity prices and exports.
In South Africa, the government-backed
This work is set to expand as more than 40 million tons of invasive alien plants are harvested for power-station fuel.
As a result, an estimated 500 megawatts of electricity, equal to 2% of the country’s electricity needs, will be generated, along with more than 5,000 jobs.
So it is clear that some countries now view environmental investments in infrastructure, energy systems, and ecosystems as among the best bets for recovery.
Others may be unsure about the potential returns from investing in ecosystem services such as forest carbon storage or in renewable energy for the 80% of Africans who have no access to electricity.
Still others may simply be unaware of how to precisely follow suit.
In early February, the United Nations Environment Program will convene some of the world’s leading economists at the UN’s headquarters in New York.
A strategy for a Global Green New Deal, tailored to different national challenges, will be fleshed out in order to assist world leaders and ministers craft stimulus packages that work on multiple fronts.
The Global Green New Deal, which UNEP launched as a concept in October 2008, responds to the current economic malaise.
Spent wisely, however, these stimulus packages could trigger far-reaching and transformational trends, setting the stage for a more sustainable, urgently needed Green Economy for the twenty-first century.
The trillions of dollars that have been mobilized to address current woes, together with the trillions of investors’ dollars waiting in the wings, represent an opportunity that was unthinkable only 12 months ago: the chance to steer a more resource-efficient and intelligent course that can address problems ranging from climate change and natural-resource scarcity to water shortages and biodiversity loss.
Blindly pumping the current bail-out billions into old industries and exhausted economic models will be throwing good money after bad while mortgaging our children’s future.
Instead, political leaders must use these windfalls to invest in innovation, promote sustainable businesses, and encourage new patterns of decent, long-lasting employment.
A Global Growth Bargain
LONDON – US President Barack Obama caught the imagination of the world when he talked recently of a new “Sputnik moment.”
He outlined a bold plan for improving education, infrastructure, and technology, and vividly compared the resolve required to put a man on the moon to the determination needed to restore growth to the US economy.
Obama is right to say that the West faces not only great challenges, but also great opportunities.&nbsp;In the last decade, the global economy was transformed by one billion Asian workers entering the ranks of industrial producers.&nbsp;In 2011, for the first time in two centuries, Europe and America face being out-produced, out-exported, and out-invested by China and the rest of the world.
Yet Asia’s growth also gives the West unprecedented economic hope.
In this decade, the world will be transformed&nbsp;yet again by the rise of the Asian consumer.&nbsp;By 2020, Asia’s domestic markets will be twice the size of America’s.
The world’s middle class will have swelled from one billion consumers to three billion.
The opportunities for growth in Europe and the US from this additional global demand are enormous.
The countries and companies that will flourish in Asia’s new markets will be those that can provide the technology-driven, custom-built, high value-added goods and services needed to serve Asia’s two billion consumers.
But neither Europe nor the US is in a strong enough position to take best advantage of these new markets.
The West must again begin to out-invent, out-innovate, and out-skill the rest of the world if it is to seize the opportunities that Asia presents.&nbsp;Indeed, unless the West significantly expands its capital investment in engineering, science, and new technologies, it will be marginalized by countries whose governments back their innovators with hard cash.
Obama’s investment plan could be the foundation stone for a formal global agreement that delivers higher levels of growth to all corners of the world and creates millions of new jobs.
Under such an agreement, Europe would join the US in raising levels of investment – complementing America’s “moonshot”&nbsp;initiative with a program of structural reform aimed at building a digital, green, energy-efficient, and competitive economy – while China would play its part by increasing its consumption.
I believe that such an agreement could boost the world economy by around 3% by 2014 – and lift 100 million people out of poverty.
I presented this plan when I chaired the G-20 in London in 2009.
I wanted East and West to commit to a formal strategy to deliver more enduring results than those promised by the rescue packages that we were putting together at the time.
Our attention was focused on preventing recession from turning into depression.
I argued that this was also the moment to pioneer a more lasting framework of growth.
In the end, no agreement was possible on a shared growth objective, and there has not yet&nbsp;been enough political will for the coordinated action to achieve it.
Since then, Europe and America have grown well below their capacity (despite huge unmet demand throughout the world) and unemployment has climbed to around 10% on both continents (with youth unemployment reaching an alarming 20%).
The global growth agreement that evaded us in 2009 remains the unfinished work of the G-20.
Front-loaded public investment could be funded through an enhanced European Investment Bank.
China has already laid the foundation for playing its part: its policy of xiaokang (reducing poverty and expanding the middle class) should create a market for billions of dollars of&nbsp;Western goods and services.
The West should propose that if China’s consumption increases by 2-4 percentage points of its GDP over the next three years (entirely possible as it improves its social safety net, cuts taxes, and puts homeownership within reach of ordinary citizens), America and Europe will expand their public investment by similar amounts.
If other Asian countries do likewise, and agree to create a level playing field for exporters, we could create around 50 million additional jobs.
Of course, in the West, an investment plan invites criticism from those who prefer that we do nothing but talk about growth strategies.
Indeed, critics argue that raising public investment conflicts with the drive to reduce deficits, and warn of higher interest rates on the back of further spending.
But critics are wrong about the impact on the deficit&nbsp;of focused investment.
A recent study by the International Monetary Fund produced unequivocal evidence that we can actually maintain deficit-reduction plans while benefiting from the additional capital investment that the US and European economies need.
My extrapolation of the IMF model shows that Western countries can boost their long-term GDP growth significantly by increasing their levels of capital investment over a three-year period.
An annual stimulus equivalent to just 0.3% of GDP yields a return in the US of 0.8% in economic growth at its peak in 2013, and 0.4% in Europe.
This approach, which secures growth and cuts unemployment without raising the deficit, is needed to energize the private sector and mobilize some of the capital that has accumulated on corporate balance sheets in recent years.
It also underscores the importance of the G-20 and the IMF in seeking global consensus now.
The West is well placed to play its part in global renewal.
Its extraordinary workforces produce world-class goods and services.
But the West’s workforce must not be condemned to policies that willfully produce a decade of slow growth and low employment.
That would be a human tragedy, not just an economic disaster.
A Global Perfect Storm
NEW YORK – Dark, lowering financial and economic clouds are, it seems, rolling in from every direction: the eurozone, the United States, China, and elsewhere.
Indeed, the global economy in 2013 could be a very difficult environment in which to find shelter.
For starters, the eurozone crisis is worsening, as the euro remains too strong, front-loaded fiscal austerity deepens recession in many member countries, and a credit crunch in the periphery and high oil prices undermine prospects of recovery.
The eurozone banking system is becoming balkanized, as cross-border and interbank credit lines are cut off, and capital flight could turn into a full run on periphery banks if, as is likely, Greece stages a disorderly euro exit in the next few months.
Moreover, fiscal and sovereign-debt strains are becoming worse as interest-rate spreads for Spain and Italy have returned to their unsustainable peak levels.
Indeed, the eurozone may require not just an international bailout of banks (as recently in Spain), but also a full sovereign bailout at a time when eurozone and international firewalls are insufficient to the task of backstopping both Spain and Italy. As a result, disorderly breakup of the eurozone remains possible.
Farther to the west, US economic performance is weakening, with first-quarter growth a miserly 1.9% – well below potential.
And job creation faltered in April and May, so the US may reach stall speed by year end.
Worse, the risk of a double-dip recession next year is rising: even if what looks like a looming US fiscal cliff turns out to be only a smaller source of drag, the likely increase in some taxes and reduction of some transfer payments will reduce growth in disposable income and consumption.
Moreover, political gridlock over fiscal adjustment is likely to persist, regardless of whether Barack Obama or Mitt Romney wins November’s presidential election.
Thus, new fights on the debt ceiling, risks of a government shutdown, and rating downgrades could further depress consumer and business confidence, reducing spending and accelerating a flight to safety that would exacerbate the fall in stock markets.
In the east, China, its growth model unsustainable, could be underwater by 2013, as its investment bust continues and reforms intended to boost consumption are too little too late.
A new Chinese leadership must accelerate structural reforms to reduce national savings and increase consumption’s share of GDP; but divisions within the leadership about the pace of reform, together with the likelihood of a bumpy political transition, suggest that reform will occur at a pace that simply is not fast enough.
The economic slowdown in the US, the eurozone, and China already implies a massive drag on growth in other emerging markets, owing to their trade and financial links with the US and the European Union (that is, no “decoupling” has occurred).
At the same time, the lack of structural reforms in emerging markets, together with their move towards greater state capitalism, is hampering growth and will reduce their resiliency.
Finally, long-simmering tensions in the Middle East between Israel and the US on one side and Iran on the other on the issue of nuclear proliferation could reach a boil by 2013.
The current negotiations are likely to fail, and even tightened sanctions may not stop Iran from trying to build nuclear weapons.
With the US and Israel unwilling to accept containment of a nuclear Iran by deterrence, a military confrontation in 2013 would lead to a massive oil price spike and global recession.
These risks are already exacerbating the economic slowdown: equity markets are falling everywhere, leading to negative wealth effects on consumption and capital spending.
Borrowing costs are rising for highly indebted sovereigns, credit rationing is undermining small and medium-size companies, and falling commodity prices are reducing exporting countries’ income.
Increasing risk aversion is leading economic agents to adopt a wait-and-see stance that makes the slowdown partly self-fulfilling.
Compared to 2008-2009, when policymakers had ample space to act, monetary and fiscal authorities are running out of policy bullets (or, more cynically, policy rabbits to pull out of their hats).
Monetary policy is constrained by the proximity to zero interest rates and repeated rounds of quantitative easing.
Indeed, economies and markets no longer face liquidity problems, but rather credit and insolvency crises.
Meanwhile, unsustainable budget deficits and public debt in most advanced economies have severely limited the scope for further fiscal stimulus.
Using exchange rates to boost net exports is a zero-sum game at a time when private and public deleveraging is suppressing domestic demand in countries that are running current-account deficits and structural issues are having the same effect in surplus countries.
After all, a weaker currency and better trade balance in some countries necessarily implies a stronger currency and a weaker trade balance in others.
Meanwhile, the ability to backstop, ring-fence, and bail out banks and other financial institutions is constrained by politics and near-insolvent sovereigns’ inability to absorb additional losses from their banking systems.
As a result, sovereign risk is now becoming banking risk.
Indeed, sovereigns are dumping a larger fraction of their public debt onto banks’ balance sheet, especially in the eurozone.
To prevent a disorderly outcome in the eurozone, today’s fiscal austerity should be much more gradual, a growth compact should complement the EU’s new fiscal compact, and a fiscal union with debt mutualization (Eurobonds) should be implemented.&nbsp; In addition, a full banking union, starting with eurozone-wide deposit insurance, should be initiated, and moves toward greater political integration must be considered, even as Greece leaves the eurozone.
Unfortunately, Germany resists all of these key policy measures, as it is fixated on the credit risk to which its taxpayers would be exposed with greater economic, fiscal, and banking integration.
As a result, the probability of a eurozone disaster is rising.
And, while the cloud over the eurozone may be the largest to burst, it is not the only one threatening the global economy.
Batten down the hatches.
A Global Solutions Network
NEW YORK – Great social change occurs in several ways.
A technological breakthrough – the steam engine, computers, the Internet – may play a leading role.
Visionaries, such as Mahatma Gandhi, Martin Luther King Jr., and Nelson Mandela, may inspire a demand for justice.
Political leaders may lead a broad reform movement, as with Franklin Roosevelt and the New Deal.
Our own generation urgently needs to spur another era of great social change.
This time, we must act to save the planet from a human-induced environmental catastrophe.
Each of us senses this challenge almost daily.
Heat waves, droughts, floods, forest fires, retreating glaciers, polluted rivers, and extreme storms buffet the planet at a dramatically rising rate, owing to human activities.
Our $70-trillion-per-year global economy is putting unprecedented pressures on the natural environment.
We will need new technologies, behaviors, and ethics, supported by solid evidence, to reconcile further economic development with environmental sustainability.
United Nations Secretary-General Ban Ki-moon is taking on this unprecedented challenge from his unique position at the crossroads of global politics and society.
At the political level, the UN is the meeting place for 193 member states to negotiate and create international law, as in the important treaty on climate change adopted at the Rio Earth Summit in 1992.
At the level of global society, the UN represents the world’s citizenry, “we the peoples,” as it says in the UN Charter.&nbsp; At the societal level, the UN is about the rights and responsibilities of all of us, including future generations.
In the past two decades, governments have come up short on solutions to environmental threats.
Politicians have failed to implement properly the treaties adopted at the 1992 Earth Summit.
Ban knows that strong government action remains vital, but he also recognizes that civil society must also play a larger role, especially because too many governments and politicians are beholden to vested interests, and too few politicians think in time horizons that extend past the next election.
To empower global society to act, Ban has launched a bold new global initiative, for which I am grateful to volunteer.
The UN Sustainable Development Solutions Network is a powerful effort to mobilize global knowledge to save the planet.
The idea is to use global networks of knowledge and action to identify and demonstrate new, cutting-edge approaches to sustainable development around the world.
The network will work alongside and support governments, UN agencies, civil-society organizations, and the private sector.
Humanity needs to learn new ways to produce and use low-carbon energy, grow food sustainably, build livable cities, and manage the global commons of oceans, biodiversity, and the atmosphere.
But time is running very short.
Today’s mega-cities, for example, already have to confront dangerous heat waves, rising sea levels, more extreme storms, dire congestion, and air and water pollution.
Agricultural regions already need to become more resilient in the face of increased climate volatility.
And as one region in one part of the world designs a better way to manage its transport, energy needs, water supplies, or food supplies, those successes should quickly become part of the global knowledge base, enabling other regions to benefit rapidly as well.
Universities have a special role to play in the new UN knowledge network.
Exactly 150 years ago, in 1862, Abraham Lincoln created America’s “land-grant” universities to help local communities to improve farming and the quality of life through science.
Today, we need universities in all parts of the world to help their societies face the challenges of poverty reduction, clean energy, sustainable food supplies, and the rest.
By linking together, and putting their curricula online, the world’s universities can become even more effective in discovering and promoting science-based solutions to complex problems.
The world’s corporate sector also has a significant role to play in sustainable development.
Now the corporate sector has two faces.
It is the repository of cutting-edge sustainable technologies, pioneering research and development, world-class management, and leadership in environmental sustainability.
Yet at the same time, the corporate sector lobbies aggressively to gut environmental regulations, slash corporate-tax rates, and avoid their own responsibility for ecological destruction.
Sometimes the same company operates on both sides of the divide.
We urgently need far-sighted companies to join the Sustainable Development Solutions Network.
These companies are uniquely placed to move new ideas and technologies into early-stage demonstration projects, thereby accelerating global learning cycles.
Equally important, we need a critical mass of respected corporate leaders to press their peers to cease the anti-environmental lobbying and campaign-finance practices that account for the inaction of governments.&nbsp;
Sustainable development is a generational challenge, not a short-term task.
The reinvention of energy, food, transport, and other systems will take decades, not years.
But the long-term nature of this challenge must not lull us into inaction.
We must start reinventing our productive systems now, precisely because the path of change will be so long and the environmental dangers are already so pressing.&nbsp;
At the Rio+20 Summit this past June, the world’s governments agreed to adopt a new set of goals on sustainable development for the period after 2015, to build upon the Millennium Development Goals’ success in reducing poverty, hunger, and disease.
In the post-2015 era, the fight against poverty and the fight to protect the environment will go hand in hand, reinforcing each other.
Secretary-General Ban Ki-moon has already initiated several global processes to help establish the new post-2015 goals in an open, participatory, and knowledge-based way.&nbsp;
The Secretary General’s launch of the Sustainable Development Solutions Network is therefore especially timely.
Not only will the world adopt a new set of goals to achieve sustainable development, but it will also have a new global network of expertise to help achieve those vital objectives.&nbsp;
A Good Rate Hike for Europe
Two wrongs don’t make a right.
Just because European governments have failed to put bread on their constituents’ tables doesn’t mean that the European Central Bank should likewise fail in its job of promoting price stability in the euro zone.
That may sound obvious, but abandoning price stability is exactly what some European politicians are advocating.
For example, Italian politicians, who, given Italy’s recent dismal economic performance, would seem the least qualified to offer the ECB advice on monetary policy, are nonetheless advocating interest-rate cuts.
Echoing comments by Italian Prime Minister Silvio Berlusconi, Deputy Economics Minister Mario Baldassarri said in Il Sole 24 Ore last week that all efforts to boost growth are in vain “if someone is pushing on the brake pedal.”
Who’s he kidding?
If anyone is “pushing down on the Italian growth brake” it is Berlusconi himself.
He has made no efforts at economic reform during his term and now seeks to blame the ECB for Italy’s lame economic performance.
But it is precisely the lack of economic reform at home that has made Italy one of the least competitive states in the euro-zone economy.
More than the usual “blame game” is at work here.
Pressures are mounting on the ECB to raise interest rates – and Berlusconi and Co.’s attacks are as much as an attempt to forestall future rate hikes as to get the ECB to loosen its monetary policy.
Soaring energy prices, for example, have become a leading inflation risk.
But higher energy prices, by themselves, will not cause the ECB to pull the interest-rate trigger.
The key will be so-called “second-round effects” – whether growing crude prices lead to higher wage demands from trade unions.
So far, the “social partners,” as ECB president Jean-Claude Trichet likes to call the unions, have been quiet.
Should this change, the ECB will have to raise rates even if Europe’s economic growth remains slack.
The good news is that economic growth in the euro-zone economy appears to be picking up (even in Italy).
Though second-quarter GDP growth was weak — the euro-zone average was only 0.3% year on year – third-quarter data are indicating a sustained economic pick-up in the second half of the year.
How will the ECB react to better economic news?
Some on the Governing Council have grown uncomfortable that euro-zone interest rates have stayed so low, at 2%, for so long (more than two years).
True, there is no inflation problem in the short run, but the ECB’s monetary policy focuses on the medium term.
One particular worry is that euro-zone money supply is well above the ECB’s benchmark level, indicating an excess supply of liquidity.
It is doubtful that the ECB would raise interest rates to curb excess liquidity so long as economic recovery remains in question.
Slow growth has silenced the monetarists on the ECB’s Governing Council. This will change, however, once the economic pick-up is confirmed.
Interest-rate hikes may be coming sooner rather than later, which is why Berlusconi and French President Jacques Chirac are talking up interest-rate cuts now.
Meanwhile, in Germany, the elections this September may have surprising consequences for ECB monetary policy.
Angela Merkel, the Christian Democrats’ candidate, is a reformer, holding out hope for Germany’s future – and that of Europe.
Unfortunately, Merkel’s campaign is off to a rocky start, and the recent entry of Oskar Lafontaine’s extreme left-wing party into the fray may necessitate the formation of a grand coalition between the Christian Democrats and the Social Democrats.
This would be bad news for the German economy, which could delay possible ECB interest rate hikes.
Because the expected gridlock in parliament would make reforms less likely, companies might hold off on investment, while consumers would be more likely to keep their wallets closed, because official policy would be even less clear than it is now.
On the other hand, a center-right coalition between the Christian Democrats and the Free Democrats could spark the ECB into action.
This raises an interesting point.
The public should be relieved if the ECB raises rates, because this would most likely signal that the long-awaited economic recovery is well under way, and that inflationary repercussions are being addressed.
A hike, in other words, would indicate that good things are happening.
But the public often views interest-rate increases as negative events that increase unemployment and stifle growth.
Blame-game politicians like Berlusconi, who have failed to put bread on the table, their minions in the media, and Keynesian economic professors who don’t understand and misrepresent Keynes sustain this distorted view.
Europe would be a lot better off if someone told the public the truth.
A Good Year for God
LONDON – It’s been a better year for God.
After withering literary assaults on the Almighty from the Oxford academic Richard Dawkins, the essayist Christopher Hitchens, and others, believers have hit back.
Best of all has been The Case for God by the brilliant religion writer Karen Armstrong.
More important still is the news that more people (certainly in Britain) are going to Christian churches of all denominations.
Moreover, the Pope made a very successful visit to Britain in September.
We know already about heavy attendance at the country’s mosques.
At this time of year, of course, many Christians who are not regular churchgoers attend the Nativity services.
Carols, church bells, and mangers are still at the heart of mid-winter festivities, alongside the consumer binge.
This year, however, the “big spend” in Europe may have been inhibited by the big winter freeze and the big austerity programs across most of the continent.
Even in the most Godless households, most children in Western societies probably know the details of the Christmas story.
The travelers who can find no room at the inn.
The birth of a baby in the stables.
The arrival of the wise men bearing gifts of gold, frankincense, and myrrh.
We learn about all this at the same time as we are told about Father Christmas, his Lapland reindeers, and his sacks full of presents.
We rapidly lose our belief in that winter myth.
But we tend to retain into adulthood the same views of God that we formed in childhood.
An old man with a long beard watches over us, and most of us retain a pretty literal opinion of the stories about his Son told in the Bible’s New Testament.
It is this God that atheists like Dawkins and Hitchens attack.
And, with such a target, it is not very difficult to poke holes and pile on the ridicule.
Leave aside the fact that you can make an even stronger case against Godlessness – remember the atrocities of atheist totalitarians in the twentieth century – and consider the assault on those whose commitment to literal interpretations of religious texts means that they deny science and reason.
To them the world was made in six days; evolution is a fanciful tale.
Those of us who think that science and religion dwell in different domains, and who recall that Socrates argued that science did not teach you about morality or meaning, find that our case is undermined by the literalists and fundamentalists in every religion.
There are Christians who know all about the fire and brimstone of the Book of Revelation, but seem not to have heard the instructions about generosity in the Sermon on the Mount.
Likewise, there are hard-line Jews, such as the settler groups who drive Palestinians from their homes in East Jerusalem and Hebron, who have forgotten the early teachings of Jewish scholars who argued that strangers should be treated like your own people.
And there are Muslims who ignore the Koran’s commands of pluralism, tolerance, and peace.
Where the atheist assault is often correct is in pinpointing the amount of harm frequently done in our world by such fundamentalists.
Right-wing American attitudes about their country’s place in the world are invigorated by fundamentalist dogma.
The United Nations is the devil’s own creation.
President Barack Obama is an un-American Muslim.
Palestine from the Jordan River to the coast should be handed to Israel so that the world can end with a cataclysmic Christian triumph.
Jewish fundamentalists obstruct any peace process that is left in the Middle East and build more illegal settlements.
Islamic fundamentalists define jihad as a war of terror against the West and call for an Islamic caliphate from the Atlantic to the Pacific.
The strident and damaging dogmatism of fundamentalists of every stripe has a common feature: a truculent sense of grievance, rooted in fear and resentment of modernity.
Christian fundamentalism in America harks back to nineteenth-century populism and anti-intellectualism.
Members of evangelical churches associate their beliefs with the rugged individualism of the early pioneers.
They are contemptuous of the establishment.
Jewish fundamentalists believe that Israel’s critics are anti-Semitic or, in the case of Jewish opponents of Israel’s harder-line policies, “self-hating Jews.”
Islamic fundamentalists reckon that what the rest of us regard as the liberalizing influence of technological progress and globalization is a brash re-run of Western colonialism.
For a happier New Year, we should listen to the core messages of all these great religions, above all the Confucian golden rule that we should never do to others what we would not like to be done to us.
What religion should teach us is not how to hate, but – to borrow again from Confucius – how to develop societies that look after and welcome the poor, the stranger, and the oppressed.
That is the most important message for everyone, atheists included, to take from the Christian story of Christmas.
A Gravity Test for the Euro
CAMBRIDGE – Although I appreciate that exchange rates are never easy to explain or understand, I find today’s relatively robust value for the euro somewhat mysterious.
Do the gnomes of currency markets seriously believe that the eurozone governments’ latest “comprehensive package” to save the euro will hold up for more than a few months?
The new plan relies on a questionable mix of dubious financial-engineering gimmicks and vague promises of modest Asian funding.
Even the best part of the plan, the proposed (but not really agreed) 50% haircut for private-sector holders of Greek sovereign debt, is not sufficient to stabilize that country’s profound debt and growth problems.
So how is it that the euro is trading at a 40% premium to the US dollar, even as investors continue to view southern European government debt with great skepticism?
I can think of one very good reason why the euro needs to fall, and six not-so-convincing reasons why it should remain stable or appreciate.
Let’s begin with why the euro needs to fall.
Absent a clear path to a much tighter fiscal and political union, which can lead only through constitutional change, the current halfway house of the euro system appears increasingly untenable.
It seems clear that the European Central Bank will be forced to buy far greater quantities of eurozone sovereign (junk) bonds.
That may work in the short term, but if sovereign default risks materialize – as my research with Carmen Reinhart suggests is likely – the ECB will in turn have to be recapitalized.
And, if the stronger northern eurozone countries are unwilling to digest this transfer – and political resistance runs high – the ECB may be forced to recapitalize itself through money creation.
Either way, the threat of a profound financial crisis is high.
Given this, what arguments support the current value of the euro, or its further rise?
First, investors might be telling themselves that in the worst-case scenario, the northern European countries will effectively push out the weaker countries, creating a super-euro.
But, while this scenario has a certain ring of truth, surely any breakup would be highly traumatic, with the euro diving before its rump form recovered.
Second, investors may be remembering that even though the dollar was at the epicenter of the 2008 financial panic, the consequences radiated so widely that, paradoxically, the dollar actually rose in value.
Although it may be difficult to connect the dots, it is perfectly possible that a huge euro crisis could have a snowball effect in the US and elsewhere.
Perhaps the transmission mechanism would be through US banks, many of which remain vulnerable, owing to thin capitalization and huge portfolios of mortgages booked far above their market value.
Third, foreign central banks and sovereign wealth funds may be keen to keep buying up euros to hedge against risks to the US and their own economies.
Government investors are not necessarily driven by the return-maximizing calculus that motivates private investors.
If foreign official demand is the real reason behind the euro’s strength, the risk is that foreign sovereign euro buyers will eventually flee, just as private investors would, only in a faster and more concentrated way.
Fourth, investors may believe that, ultimately, US risks are just as large as Europe’s.
True, the US political system seems stymied in coming up with a plan to stabilize medium-term budget deficits.
Whereas the US Congress’s “supercommittee,” charged with formulating a fiscal-consolidation package, will likely come up with a proposal, it is far from clear that either Republicans or Democrats will be willing to accept compromise in an election year.
Moreover, investors might be worried that the US Federal Reserve will weigh in with a third round of “quantitative easing,” which would further drive down the dollar.
Fifth, the current value of the euro does not seem wildly out of line on a purchasing-power basis.&#160; An exchange rate of $1.4:€1 is cheap for Germany’s export powerhouse, which could probably operate well even with a far stronger euro.
For the eurozone’s southern periphery, however, today’s euro rate is very difficult to manage.
Whereas some German companies persuaded workers to accept wage cuts to help weather the financial crisis, wages across the southern periphery have been marching steadily upwards, even as productivity has remained stagnant.
But, because the overall value of the euro has to be a balance of the eurozone’s north and south, one can argue that 1.4 is within a reasonable range.
Finally, investors might just believe that the eurozone leaders’ latest plan will work, even though the last dozen plans have failed.
Abraham Lincoln is credited with saying “You can fool some of the people all of the time, and all of the people some of the time, but you cannot fool all of the people all of the time.”
A comprehensive euro fix will surely arrive for some of the countries at some time, but not for all of the countries anytime soon.
So, yes, there are plenty of vaguely plausible reasons why the euro, despite its drawn-out crisis, has remained so firm against the dollar so far.
But don’t count on a stable euro-dollar exchange rate – much less an even stronger euro – in the year ahead.
A Green Alternative to Austerity?
OXFORD – While austerity in Europe faces increasing social resistance, in principle it has the merit of simplicity.
As the debate on fiscal consolidation versus growth intensifies, it is clear that there is little agreement on how to kick-start the economy, beyond fielding broad stimulus packages.
One idea is that environmental technology might feed a virtuous cycle of innovation and employment.
To some, green growth evokes a countryside covered with windmills and urban roofs lined with solar panels.
But it is broader than that.
For example, when Airbus moved from injection molding to 3D printing to produce the metal hinges for its airplanes’ doors, it reduced their weight by half, yielding phenomenal savings in material and associated fuel consumption over a lifetime of flying those hinges around the world.
Still, it is easier to find exciting anecdotes than it is to show how they scale up to revitalizing an entire economy.
Moreover, there is a great diversity of narratives on the green economy – and their proliferation is likely to grow.
This June, thousands of activists, policymakers, and business people will converge on Rio de Janeiro for the third giant United Nations Sustainable Development Conference (Rio+20), whose theme is the green economy.
The conference will unleash new arguments about green jobs, growth, cost increases, cost reductions, changes in values, consumer choice – green this and green that.
As a co-author of A New Growth Path for Europe, a report commissioned by the German government, I am guilty of contributing to this cacophony of complementary perspectives on green growth.
The European Climate Foundation had already published its Roadmap 2050, A Practical Guide to a Prosperous, Low-Carbon Europe.
Since then, the UN Environment Program has released its Green Economy Report; McKinsey has written about the Resource Revolution; and the International Trade Unions Council has published Growing Green and Decent Jobs – to name but a few.
All take somewhat different approaches and offer different recommendations, making it hard for policymakers to see the forest through the trees.
And, at the root of this multiplicity of perspectives lays the fact that economics struggles to explain how growth and innovation move an economy as a whole.
The macroeconomic models on which policymakers depend are solid tools in times of smooth and incremental evolution, but green growth is not about gradual change.
For example, the European Union’s goal of achieving an 80% reduction in greenhouse gas emissions by 2050 implies a complete overhaul of EU infrastructure in just a few decades.
Economists’ inability to model such rapid, radical change should not be taken as a condemnation of the discipline; it is simply a reflection of the state of our knowledge, and of the fact that the economy is really, really complicated.
We simply do not yet have sufficiently precise insights into how all of its elements interact during times of far-reaching change, whether it be a financial crisis or a growth spurt.
Yet, the studies of green growth mentioned above all appear to provide such explanations.
So, what do they really tell us?
In practice, each is limited to just one or two aspects of the economy, and describes how these interact.
Growing Green and Decent Jobs looks at the relationship between investment and jobs.
A New Growth Path for Europe examines the impact of expectations and learning-by-doing.
Roadmap 2050 focuses on greening the power system.
The authors then make a leap of faith to derive conclusions about the economy as a whole.
But, while the value of these studies is in the light that they shed on the parts, the ensuing headlines invariably are about the whole, articulated in terms of GDP and jobs.
Each of the studies describes a part of a green economy, but none can capture the whole – not because they are deficient, but because it is simply beyond our capability.
That said, the fact that one cannot prove conclusively how green growth would work does not mean that we should give up on the idea.
We know from history that waves of innovation, from the steam engine to the information and communications revolution, have led to dramatic increases in economic growth.
We cannot prove that a wave of environmental innovation will have a similar effect, but the studies of the parts make such an outcome highly plausible.
As humans, we are uniquely equipped to make decisions on the basis of ambiguous information – in fact, we do it all the time.
When we choose a career or a spouse in our private lives, or when a politician seizes an opportunity from a plethora of possibilities, the task at hand is always about making highly consequential decisions based on imperfect information.
A big pile of green-growth reports demonstrates the plausibility of this path to recovery from an historic economic crisis.
It is now up to us to realize its potential.
Green growth offers a realistic alternative to the faltering austerity approach to overcoming the current economic crisis.
Policymakers should incorporate this thinking into the “beyond austerity” narrative that is taking shape in a growing number of key EU member states.
Supporters of free markets will argue that if local landowners wish to sell their land, that is their choice to make.&#160;
How to Feed the World
PRAGUE – Hunger has wracked humanity since time immemorial.
Nearly every major society has been shaped by famine; one estimate suggests that China suffered drought or flood-induced starvation in at least one province almost every year from 108 BC to 1911.
Yet the struggle against hunger is a battle that humanity could finally win.
More cereals were produced annually in the last quarter of the twentieth century than in any preceding period, and more grain will be harvested this year than at any time in history.
Since 1992, the number of hungry people worldwide has plummeted by more than 200 million, even as the human population grew by nearly two billion.
But enormous challenges remain.
Affordable, nutritious food is one of people’s top priorities everywhere, and one in nine people still do not get enough food to be healthy.
With today’s population of 7.3 billion expected to reach 8.5 billion by 2030 and 9.7 billion in 2050, food demand will increase accordingly.
Along with more mouths to feed, stresses on food supplies will include conflicts, economic volatility, extreme weather events, and climate change.
Increases in agricultural productivity, owing to improvements in seeds, new fertilizers and pesticides, improved credit access, and technological breakthroughs, have been a key driver in reducing hunger.
Between 1930 and 2000, agricultural output in the United States quadrupled, with productivity growth outstripping that of manufacturing.
Developing countries have begun sharing in these gains: responsible for next-to-none of the world’s fertilizer consumption in 1960, by 2000 they used more than industrialized countries.
The World Bank has found that productivity growth in agriculture can be up to four times more effective in reducing poverty than growth from other sectors.
So how do we keep up this progress?
Investment in research and development is vital.
According to research conducted for Copenhagen Consensus, which I direct, investing an extra $88 billion in agricultural R&D over the next 15 years would increase yields by an additional 0.4 percentage points each year, which could save 79 million people from hunger and prevent five million cases of child malnourishment.
Achieving these targets would be worth nearly $3 trillion in social good, implying an enormous return of $34 for every dollar spent.
Scientific breakthroughs also play a key role in fighting specific nutritional challenges such as vitamin A deficiency, the leading cause of preventable childhood blindness.
Robert Mwanga was awarded this year’s World Food Prize for inspiring work that resulted in the large-scale replacement of white sweet potato (with scant Vitamin A content) by a vitamin A-rich alternative in the diets of Uganda’s rural poor.
Another way to increase agricultural productivity is through labor.
When Copenhagen Consensus researchers examined responses to global warming in Bangladesh, they found that increasing agricultural labor productivity “is the only way to increase the resilience of Bangladesh to climate change and to meet long-term development goals.”
Investing around $9,000 per worker over two decades could boost agricultural productivity by 10%.
Bangladesh is an instructive case, because it is susceptible to flooding and the effects of climate change, and its agricultural productivity lags behind other developing and middle-income countries.
Unsurprisingly, the Bangladeshi prime minister’s office is striving to lead in global innovation, sustaining an agriculture innovation lab that shares best practices and ideas.
Copenhagen Consensus has worked with the world’s largest NGO, BRAC, to find out the policy wishes of people living in rural Bangladesh, including the “ultra-poor” with whom BRAC works closely.
These laborers, housewives, and others, some of whom live on the equivalent of $0.60-0.70 or less a day, are seldom given a place at the table to discuss policy.
Across nine rural forums in far-flung parts of the country, the participants overwhelmingly spoke with one voice, calling for the same policy priority: increased agricultural productivity.
“Everyone knows Rangpur has a Monga problem,” said a local from Chandpara in the Rangpur division, using the Bengali term for the annual cyclical phenomenon of seasonal hunger.
“We cannot feed our people two times a day – we need to increase our agricultural productivity.”
A Mukimabad villager had the same vision for Bangladesh: “We need crops and seeds which are not vulnerable to salinity and flood so that we do not have to die from food shortages.”
Humanity’s fight against hunger can be won.
Great progress has been made, but the world needs more agricultural R&D and higher productivity.
As a rural villager from Deukhola, near the Brahmaputra River in remote northern Bangladesh, starkly put it: “Our survival depends on it.”
We would do well to listen.
An Arab Marshall Plan
OXFORD – The wave of revolts that swept across the Arab world two years ago were fueled by demands for freedom, bread, and social justice.
But, although the revolutions toppled dictators and transformed societies, these core objectives remain as distant as ever.
In fact, the economic challenges facing the Arab Spring countries have become even more pressing, weighing heavily on these countries’ political prospects.
Unemployment has nearly doubled in Tunisia and Egypt, and foreign direct investment has dried up across the Arab world.
Tourism revenues, while resilient, are declining, and fiscal challenges remain considerable.
But the economic urgency is not reflected in the policy response, which has been painfully slow or non-existent.
For example, Egypt’s fiscal deficit will exceed 11% of GDP this year.
But the country’s leaders have been stalling on the terms of a much-needed International Monetary Fund loan.
The government’s reduction of fuel subsidies last year was not followed by additional reforms, and the required tax increase was delayed soon after President Mohamed Morsi announced it.
Almost all political stakeholders in Egypt, as in the other Arab countries in transition, recognize the need for economic reform.
But neither citizens nor policymakers appear willing to bear its social and political costs.
In a charged and uncertain political climate, in which new crises erupt on a daily basis, it is unsurprising that economic reform has been postponed repeatedly.
Politicians know that macroeconomic stabilization and social cohesion can be irreconcilable in the short run.
Slashing food and energy subsidies in order to reduce fiscal strain is unlikely to win favor in a country like Egypt, where 40% of per capita income is allocated to food.
Politics is thus constraining efforts to strengthen public finances.
At the same time, narrow IMF prescriptions threaten to exacerbate political instability, with citizens no longer afraid to take to the streets to demonstrate their dissatisfaction.
The current impasse on economic reform highlights a larger point: subsidy and tax regimes cannot be reformed without first redefining the underlying social contract, which has long exchanged welfare distribution for political acquiescence.
But such a move is far too risky for an individual politician, or even a single country, at a time of economic uncertainty and high unemployment.
In order to create the political space needed for economic reform, Arab leaders must underwrite a regional growth pact – a Marshall Plan of sorts – that would facilitate major new investments aimed at reviving economic activity.
It is much easier to reform subsidy programs when the economy is expanding.
Moreover, building competitive markets is essential to ensuring sustainable GDP growth.
To this end, regional trade barriers, which are more pervasive in the Arab world than even in Sub-Saharan Africa, must be dismantled.
By agreeing to the pact, Arab countries would commit to reforming their subsidy systems and to reducing restrictions on cross-border economic exchange.
The regional dimension of prosperity has long been ignored in the Arab world.
But weak regional linkages limit small firms’ growth potential, forcing them to depend on state patronage.
Although Arab leaders often cite Turkey as a beacon of hope, they rarely acknowledge that the country’s recent transformation from the “sick man of Europe” to one of the world’s fastest-growing emerging markets would not have been possible had it not pursued regional synergies.
Such linkages are particularly important for Egypt and Tunisia, which will struggle to reduce unemployment unless Libya’s labor market – which has historically absorbed migrants from its North African neighbors – is reopened.
And, while Tunisia’s situation seems to be the most promising, a crippling investment shortfall is threatening to derail reform efforts there.
With Europe mired in crisis, capital flows from Tunisia’s resource-rich Arab neighbors are its best hope.
Furthermore, Arab countries must ratchet up development spending.
Given that existing development banks in the region have largely failed to act as vehicles of coordination and commitment, a new institution – resembling the European Bank for Reconstruction and Development – would have to be established to oversee a regional aid push and underwrite the costs of economic transition.
New investment vehicles, such as sovereign wealth funds and Islamic finance, can contribute financing to credit-starved firms.
At the same time, Arab countries must streamline current aid efforts.
For too long, Arab governments have simply thrown money at problems, with the rich Gulf countries effectively subsidizing their troubled neighbors’ public services.
Over the last two years, Saudi Arabia has provided more than $3 billion to Yemen.
Qatar has provided &#160;$5 billion to Egypt since 2011, with a promise of $3 billion more.
And the United Arab Emirates recently pledged $2.5 billion to Bahrain.
But unconditional aid only delays reforms, because it weakens budget constraints, which reduces pressure on policymakers and creates moral hazard.
The Arab Spring has exposed fault lines that run not just through individual countries, but also through the entire region.
This calls for redefining relationships not only between citizens and states, but also among Arab countries.
Above all, it is no longer prudent to divide Arab countries between donors and recipients, or between resource-rich and resource-poor countries.
It is in the interest of the entire region – including those countries that do not seem to face an imminent threat of revolt – to contribute to their neighbors’ economic revival and facilitate their political transitions.
A History Lesson for Koizumi
Once again, protests against Japanese Prime Minister Junichiro Koizumi’s annual visit to the Yasukuni shrine are breaking out in China as well as South Korea.
Koizumi’s insistence on paying homage to the war dead interred at Yasukuni, where convicted war criminals from World War II are among the buried, has been damaging relations with Japan’s neighbors for years.
Indeed, Chinese President Hu Jintao continually affirms that he will not hold a summit with a Japanese prime minister who goes to Yasukuni, which most Chinese regard as a glorification of past Japanese aggression and colonialism.
Even some in Japan are becoming critical of Koizumi.
While the public remains negative about Chinese outbursts against Japan, a recent survey indicates that more than 70% of Japanese view the current state of Japan-China relations as unacceptable.
More people are not supporting Koizumi’s annual pilgrimage to Yasukuni, with seven former prime ministers jointly demanding that he refrain from the visits.
Yet Koizumi remains defiant.
Moreover, Chief Cabinet Secretary Shinzu Abe, the front-runner to succeed him, has openly declared that he will continue to visit the shrine as prime minister.
Foreign Minister Taro Aso, another possible successor to Koizumi, has called for the Japanese Emperor to pray at Yasukuni.
So pessimism appears to be settling in, and the deadlock over Yasukuni appears to be deepening.
But the past can bring us more than just troubles of this kind.
Even on the issue of Yasukuni, there are positive lessons to be learned.
Consider Yasuhiro Nakasone, Koizumi’s predecessor in the 1980’s.
Both are master politicians who remained popular and served long terms in office.
Both are conservative and nationalistic, advocating the revision of the constitution and an assertive political and military role for Japan abroad.
Finally, both are pro-American, with Nakasone declaring Japan to be America’s “unsinkable aircraft carrier” in East Asia and Koizumi sending troops to Iraq in support of the United States-led war effort.
But a crucial difference between Nakasone and Koizumi is often overlooked: their handling of the Yasukuni controversy and relations with China.
Nakasone broke the taboo by being the first prime minister to worship at the Yasukuni shrine in his official capacity on August 15, 1985, the fortieth anniversary of the end of World War II.
The decision triggered a severe response from China, where students held demonstrations against his visit.
Bilateral relations were frozen.
But, instead of capitalizing on domestic resentment over China’s criticisms, Nakasone decided not to visit Yasukuni again.
He chose to mend relations with China by focusing on the positive aspects of bilateral ties.
In 1986, Nakasone went to Beijing at the personal invitation of Chinese Communist Party General Secretary Hu Yaobang and laid the cornerstone for a Sino-Japanese Youth Exchange Center, promising to forge future friendships with China.
This genuine embrace of reconciliation provided much-needed support to Chinese leaders, who were eager to control anti-Japanese sentiments.
Hu praised Nakasone’s courage and warned Chinese youth publicly that if they “think merely of the well-being of their own country… they are not sober-minded patriots.”
Nakasone emerged from the crisis and was recognized as a capable statesman in managing Japan’s diplomacy with China.
There was no accusation that Nakasone was “selling out” to Beijing.
Nor were his conservative, nationalist, and pro-American credentials damaged.
This episode suggests that Koizumi’s hardline position isn’t the only option.
A Japanese prime minister can be strong without exploiting domestic resentment against the country’s neighbors, and conservative, patriotic, and pro-American while forging a healthy working relationship with China.
Indeed, the cessation of Yasukuni visits would likely open the door to the long-overdue Sino-Japanese summit, which in turn might strengthen moderate voices in China seeking a future-oriented relationship with Japan.
Unfortunately, Koizumi and his allies are not prepared to move forward on the Yasukuni issue.
As Foreign Minister Aso recently put it: “The more China voices [opposition], the more one feels like going there.
It’s just like when you’re told ‘Don't smoke cigarettes,’ it actually makes you want to smoke.”
No one expects the current Japanese and Chinese leaders to embrace, as Nakasone and Hu did two decades ago, but it is a sad state of affairs when the leaders of neighboring giants pretend not to see each other at international forums.
If Nakasone, who now urges Koizumi to stop the Yasukuni pilgrimage, were to respond to Aso, he might simply extend the analogy: it is not in Japan’s national interest to continue to inhale Koizumi’s second-hand smoke.
Israel versus America versus Iran
TEL AVIV – Israel’s concern about the specter of a nuclear Iran has now degenerated into a crisis of confidence concerning the United States.
Prime Minister Binyamin Netanyahu has embarked on a campaign to force President Barack Obama to set a red line that Iran must not cross, lest it risk unleashing an American military response.
Implicit threats of a unilateral Israeli attack, together with conspicuous meddling in the US presidential election campaign, have compounded Netanyahu’s effort to twist Obama’s arm.
The controversy between the two allies partly reflects their divergent timelines: for Israel, the red line is Iran’s imminent burial deep underground of its uranium-enrichment facilities; for the US, it is the start of a dedicated weapons program.
But, equally important, the dispute underscores their different objectives.
For Israel, war with Iran is not about neutralizing an existential threat; it is about reasserting its regional status.
Israel’s leaders see their country’s standing in the region being seriously threatened by the emergence of a hostile Islamist regime in Egypt; the possibility that a similarly hostile regime will eventually emerge in Syria; the fragility of traditionally friendly Jordan; and the dangerous boost that the regional Islamist awakening has given to Israel’s sworn enemies, Hamas and Hezbollah.
Both Netanyahu and Defense Minister Ehud Barak thus regard an attack on Iran as a major strategic move aimed at the broader Middle East, which implies that they would not discount a military campaign that goes well beyond surgical air strikes.
Indeed, they probably contemplate land incursions into Iran, and possibly a decisive –&#160;and, from their perspective, long overdue – showdown with Hamas in Gaza and Hezbollah in Lebanon.
Though determined to prevent Iran from acquiring nuclear weapons, even if doing so requires military action, the US weighs the consequences of a military showdown in very different terms.
A superpower that has earned only frustration in its abortive efforts – whether war or regional diplomacy – in the dysfunctional Middle East, the US faces the Iran crisis in the midst of its epochal strategic shift to Asia and the Pacific.
The fallout from a war in Iran would pin down the US in the Middle East for years to come, undermining its new strategic priorities.
As a result, the US, though certainly better equipped than Israel for a war to ensure that Iran forever abandons its nuclear ambitions, could nonetheless conclude that that objective is simply too costly.
The recent report by The Iran Project, whose signatories include the former US national security advisers Brent Scowcroft and Zbigniew Brzezinski, concluded that an American military attack on Iran could only delay its nuclear program for up to four years.
To guarantee that Iran never acquires a nuclear bomb, the US would need to maintain military pressure on Iran for several years.
And, if forced to impose regime change as the ultimate solution to the dilemma, the report assumes that this would require military occupation, which would entail a commitment of resources and personnel greater than what the US invested in the Iraq and Afghanistan wars combined.
Moreover, the conventional assumption that the region’s Sunni Arab regimes would give tacit approval to a military attack on Iran’s nuclear installations must be revisited in the wake of the Arab Spring – particularly in the aftermath of the recent, sudden upsurge in anti-American violence throughout the Muslim world.
The pre-Arab Spring paradigm that framed the Middle East as being divided between “moderates” and “extremists” has become obsolete.
The Islamist governments that have emerged from the downfall of America’s puppet regimes are no friends of an Iranian nuclear empire.
But, in their struggle to survive, they must channel popular anti-Americanism.
For Egyptian President Mohamed Morsi, that imperative meant placating the angry mob that recently attacked the US embassy rather than merely condemning the violence.
An attack on Iran, especially if it develops into a longer war involving regional proxies, is bound to become the trigger for mass anti-Israel and anti-US hysteria, which might draw the Islamist regimes in the region into a dynamic of escalation.
It would be impossible to rule out a regional war.
The main problem facing a military operation in Iran is the need to ensure its legitimacy.
China and Russia would never allow the US to secure a United Nations mandate for an attack.
Moreover, while Iranian provocations that clearly reveal the regime’s intentions to develop a nuclear-weapons capability might help build support for American military action, it is far from certain that Europeans, or others, would rush to join another US-led “coalition of the willing.”
The dire legacy of Iraq and Afghanistan weighs heavily on the Western democracies.
The saddest part of the story is Israel’s utter indifference to the need to build international legitimacy for its drive to stop Iran’s nuclear program.
Netanyahu thinks in bold military terms, not in terms of geopolitical strategy.
His careless Palestine policy has left Israel with few friends in the international community, let alone in the Arab Middle East.
Indeed, many regard Netanyahu’s Iran obsession as nothing more than a successful ploy to divert attention from the Palestinian issue.
Only a generous, bold peace initiative that would genuinely revive the two-state solution, accompanied by a freeze on construction and enlargement of West Bank settlements, would help to recover the good will of the Palestinians and their brethren throughout the Arab world.
And only that outcome can secure the international goodwill that both Israel and the US will need for a showdown with Iran.
A Human Rights Crime In Gaza
Atlanta &#45;&#45; The world is witnessing a terrible human rights crime in Gaza, where a million and a half human beings are being imprisoned with almost no access to the outside world by sea, air, or land. An entire population is being brutally punished.
This gross mistreatment of the Palestinians in Gaza was escalated dramatically by Israel, with United States backing, after political candidates representing Hamas won a majority of seats in the Palestinian Authority parliament in 2006. The election was unanimously judged to be honest and fair by all international observers.
Israel and the US refused to accept the right of Palestinians to form a unity government with Hamas and Fatah and now, after internal strife, Hamas alone controls Gaza.  Forty-one of the 43 victorious Hamas candidates who lived in the West Bank are now imprisoned by Israel, plus an additional ten who assumed positions in the short-lived coalition cabinet.
Regardless of one’s choice in the partisan struggle between Fatah and Hamas within occupied Palestine, we must remember that economic sanctions and restrictions in delivering water, food, electricity, and fuel are causing extreme hardship among the innocent people in Gaza, about one million of whom are refugees.
Israeli bombs and missiles periodically strike the encapsulated area, causing high casualties among both militants and innocent women and children.
Prior to the highly publicized killing of a woman and her four little children last week, this pattern was illustrated by a previous report from B’Tselem, the leading Israeli human rights organization: 106 Palestinians were killed between February 27 and March 3. Fifty-four of them were civilians who didn't take part in the fighting, and 25 were under 18 years of age.
On a recent trip through the Middle East, I attempted to gain a better understanding of the crisis.
One of my visits was to Sderot, a community of about 20,000 in southern Israel that is frequently struck by rudimentary rockets fired from nearby Gaza.
I condemned these attacks as abominable and an act of terrorism, since most of the thirteen victims during the past seven years have been non-combatants.
Subsequently, I met with leaders of Hamas, both a delegation from Gaza and the top officials in Damascus, Syria.
I made the same condemnation to them, and urged that they declare a unilateral ceasefire or orchestrate with Israel a mutual agreement to terminate all military action in and around Gaza for an extended period.
They responded that such previous action by them had not been reciprocated, and they reminded me that Hamas had previously insisted on a ceasefire throughout Palestine including both Gaza and the West Bank, which Israel had refused.
Hamas then made a public proposal of a mutual ceasefire restricted to Gaza, which the Israelis considered and also rejected.
There are fervent arguments heard on both sides concerning blame for a lack of peace in the Holy Land.
Israel has occupied and colonized the Palestinian West Bank, which is approximately one-fourth (28.5%) the size of the nation of Israel as recognized by the international community.
Some Israeli religious factions claim a right to the land on both sides of the Jordan River, and others aver that their 205 settlements with some 500,000 people are necessary for “security.”
All Arab nations have agreed to full recognition of Israel if it will comply with key United Nations resolutions.
Hamas has agreed to accept any negotiated peace settlement between Palestinian Authority President Mahmoud Abbas and Israeli Prime Minister Ehud Olmert, provided it is approved in a referendum among the Palestinian people.
This holds promise of progress, but despite the brief fanfare and positive statements at the peace conference last November in Annapolis, Maryland, a retrogression has occurred in the process.
Nine thousand new Israeli settlement housing units have been announced in Palestine, the number of roadblocks within the West bank has increased, and the stranglehold on Gaza has been tightened.
It is one thing for other leaders to defer to the US on the crucial peace negotiations, but the world must not stand idle while innocent people are treated cruelly.
It is time for strong voices in Europe, the US, Israel, and elsewhere to speak out and condemn this human rights tragedy among the Palestinian people. 
A Hundred Years of Superconductivity
CHICAGO – The world’s first “quantum” computer – a machine that harnesses the magic of quantum phenomena to perform memory and processing tasks incredibly faster than today’s silicon-based computer chips – was recently sold by D-Wave Systems of Canada to Lockheed-Martin.
And, while some question whether the machine is truly a quantum computer, its designers have published articles in peer-reviewed journals demonstrating that the basic elements of this novel computer are indeed superconducting quantum bits.
This spring marked the 100th anniversary of the discovery of superconductivity – the ability of materials to carry electrical current with no loss.
Currents set up in superconducting wires can exist for years without any measurable decay.
Because of this property, superconductors have unique features that can be exploited in many ways.
They can carry enormous amounts of current, making them ideal for urban power grids. And, when wound into coils, they can produce extremely strong magnetic fields.
Such superconducting magnets have been applied in a variety of technologies.
The best-known examples are the magnets that drive the magnetic resonance imaging (MRI) machines found in most hospitals.
Perhaps the most exotic are the huge magnets used to accelerate particles in the Large Hadron Collider, which seeks to discover the fundamental principles of matter.
Despite their great promise, however, superconductors have limits, the primary one being that most superconduct at very low temperatures – indeed, near absolute zero (-273 ºC).
Such temperatures can be achieved only through liquid-helium cooling.
Thus, Swiss researchers caused excitement in 1986 by announcing the discovery of superconductivity in an oxide of copper at twice the temperature of the previous record holder.
Shortly thereafter, researchers in the United States found a related material that superconducts above the temperature at which air liquefies.
As Time magazine proclaimed in May 1987, with the discovery of these so-called “cuprates,” the superconducting revolution had begun.
Alas, the revolution soon bogged down.
Cuprates are notoriously difficult materials to work with, because they are very brittle.
This is exacerbated by their strong anisotropy – the materials have a quasi-two-dimensional structure consisting of a weakly coupled stack of conducting sheets. As such, they are a challenge for industry, though applications are beginning to appear.
Since the cuprates first appeared, a variety of other “high temperature” superconductors have been discovered – one is a simple compound of magnesium and boron, and another involves a mixture of iron and arsenic.
Although none of them superconduct at temperatures as high as liquid air, they may ultimately be better materials with which to work.
Given the vast number of combinations of elements that can form compounds, there is a good chance that better superconductors await our discovery.
In the coming years, superconductors are expected to play a growing role in technology.
Already, “second generation” cuprate wires are being used to make high-capacity cables for electric-power transmission, and lighter-weight generators for wind turbines.
Stronger superconducting magnets are leading to the development of MRIs with more sophisticated diagnostic capabilities.
Superconductors are being used for levitated trains in high-speed rail transport, and as microwave filters for improved signal bandwidth in cellular base stations.
The discovery of a new superconductor with enhanced properties could lead to even greater technological innovation.
This brings us to the intellectual challenge of superconductors.
It took 46 years from the discovery of superconductivity to the 1957 Bardeen, Cooper, and Schrieffer (BCS) theory of how the phenomenon occurs.
Along the way, a number of famous physicists tried and failed to get the answer – Albert Einstein, Werner Heisenberg, and Richard Feynman being notable examples.
Discovering the solution required the development of advanced theoretical techniques.
What had been difficult to figure out was how to get electrons to superconduct.
The basic discovery of BCS was that if the electrons pair up, those couples could indeed superconduct.
Fortunately, the mechanism for such coupling was known.
Although electrons are negatively charged, and therefore repel one another, the positive ions that they leave behind when they flow through a metal can mediate an effective attraction between two electrons under restrictive conditions (for example, the metal must be very cold).
The suspicion, though, is that this is not the case in the new superconductors.
Cuprates superconduct at much higher temperatures, but, more importantly, they possess some exotic properties: they are formed by doping electrical carriers into a host material that is a magnetic insulator – the last place one would look for a conventional superconductor.
And, unlike BCS theory, in which the pairs are isotropic – with identical properties in all directions in space – the pairs in cuprates are strongly anisotropic, resembling a cloverleaf.
How can one pair electrons without ions holding them together, thereby enabling higher-temperature superconductors?
While ideas about this abound, new theoretical breakthroughs most likely will be needed to develop the machinery required to solve such electron-electron theories, perhaps even involving black holes.
Whatever the theory turns out to be, it is certain to revolutionize physics.
A Better Global Framework to End AIDS
STOCKHOLM, GENEVA – This week, we celebrate the tremendous progress that has been made in the struggle against HIV and AIDS.
In many countries with strong health systems, HIV is no longer a death sentence, but a chronic condition.
And Africa has reached a critical milestone: each year, there are now more Africans starting HIV treatment than being infected.
Still, even as we celebrate, we must also mourn the 1.1 million people who lost their lives to the disease this year.
HIV still infects 6,000 people every day, and AIDS remains a leading cause of death among children, adolescents, and women in Africa.
The movement against AIDS has inspired all of us to help the people who continue to be left behind, and to commit to ending AIDS once and for all.
Fortunately, we already have the know-how, resources, and, crucially, the political momentum to do this; and at the High-Level Meeting on Ending AIDS this year, United Nations member states made ambitious commitments that will put us on the fast track toward our goal.
What’s more, in September, Canada hosted a successful financing conference for the Global Fund to Fight AIDS, Tuberculosis, and Malaria, which brought in almost $13 billion, replenishing the Global Fund for 2017-2019.
Meanwhile, individual countries have increased their domestic investments, and international partners – big and small – have maintained their support, which is how we will reach the $26 billion needed for the global AIDS response in 2020.
But funding parts of the global health system is not enough.
The international community must take a more holistic view and reinforce a global-response architecture that features a clear division of labor and seamless cooperation among various stakeholders.
Ultimately, the goal of such a framework must be to support countries’ own health systems, by marshaling public and private actors at all levels in a given country, so that every facility – from the public hospital in the capital to the village clinic – is properly provisioned.
Sweden is proud to continue its support for the Global Fund; at the replenishment conference in September, it pledged 2.5 billion krona ($271 million).
The Global Fund is by far the largest multilateral source of financing for efforts to fight AIDS, tuberculosis, and malaria; but just like the Global Alliance for Vaccines and Immunization (now known as Gavi, the Vaccine Alliance), it is part of a global architecture, and relies on a range of partners to deliver aid effectively.
So, if country-level support for other global-health organizations – such as UNAIDS, the World Health Organization, and the UN Development Programme – dries up, continued progress in the fight against HIV and AIDS will be at risk.
Providing the necessary support will require donors to coordinate with one another, so that all parts of the existing architecture for managing global health issues are adequately funded.
This will then ensure that all countries – and, more importantly, all people – receive the support they need.
UNAIDS is setting a powerful example for international collaboration, by organizing partners around a common 2016-2021 Strategy to end AIDS.
This unique and innovative partnership brings together 11 co-sponsoring UN agencies, each with diverse sector-specific expertise, and mobilizes various government stakeholders.
Partners include business, community, and faith leaders, as well as teachers, judges, members of law enforcement, parliamentarians, and many others outside the health sector whose actions nonetheless affect health outcomes.
One of UNAIDS’ tasks is to encourage national governments to keep AIDS high on their public-health agendas, and to invest in joint efforts to end the disease.
It is also the only organization with a mandate to set norms and standards for the global response to AIDS, which means that it plays a key role in the current international framework.
UNAIDS maintains a close partnership with the Global Fund.
It has a presence in more than 80 countries, and its regional teams provide technical support and strategic information, which helps the Global Fund direct its grants to the right programs, locations, and populations at sufficient scale.
Moreover, it helps to create the social, legal, and political conditions for people to use health services, not least by promoting gender equality and ensuring that populations at higher risk of contracting HIV do not face adverse discrimination.
UNAIDS engages with civil society at all levels, by leveraging the international AIDS response to promote equality, dignity, and human rights around the world.
As such, UNAIDS works to expand the political space for – and investment in – civil society.
Yet, despite its broad mandate and many functions, UNAIDS lacks adequate resources, which threatens past achievements and future programs alike, and poses a danger to people and communities that depend on the lifesaving support the organization helps facilitate.
Sweden and UNAIDS will work together to ensure that the international AIDS response continues to transform – and save – lives.
We will safeguard and empower women and girls, and make sure that vulnerable populations’ voices are heard.
But, at the same time, the international community must strengthen the existing framework for managing global-health issues.
As Swedish Prime Minister Stefan Löfven said in Montreal in September: “Today we are focusing on the Global Fund, but tomorrow let’s not forget to provide sufficient funding for the entire global health architecture.”
It is time for the international community to meet that challenge, by pledging to support our global health infrastructure, so that no agency – and no country or person – is left out.
Aid Works
NEW YORK – The critics of foreign aid are wrong.
A growing flood of data shows that death rates in many poor countries are falling sharply, and that aid-supported programs for health-care delivery have played a key role.
Aid works; it saves lives.
One of the newest studies, by Gabriel Demombynes and Sofia Trommlerova, shows that Kenya’s infant mortality (deaths under the age of one year) has plummeted in recent years, and attributes a significant part of the gain to the massive uptake of anti-malaria bed nets.
These findings are consistent with an important study of malaria death rates by Chris Murray and others, which similarly found a significant and rapid decline in malaria-caused deaths after 2004 in sub-Saharan Africa resulting from aid-supported malaria-control measures.
Let’s turn back the clock a dozen years.
In 2000, Africa was struggling with three major epidemics.
AIDS was killing more than two million people each year, and spreading rapidly.
Malaria was surging, owing to the parasite’s growing resistance to the standard medicine at the time.
Tuberculosis was also soaring, partly as a result of the AIDS epidemic and partly because of the emergence of drug-resistant TB.
In addition, hundreds of thousands of women were dying in childbirth each year, because they had no access to safe deliveries in a clinic or hospital, or to emergency help when needed.
These interconnected crises prompted action.
The United Nations’ member states adopted the Millennium Development Goals in September 2000.
Three of the eight MDGs – reductions in children’s deaths, maternal deaths, and epidemic diseases – focus directly on health.
Likewise, the World Health Organization issued a major call to scale up development assistance for health.
And African leaders, led by Nigeria’s president at the time, Olusegun Obasanjo, took on the challenge of battling the continent’s epidemics.
Nigeria hosted two landmark summits, on malaria in 2000 and on AIDS in 2001, which were a crucial spur to action.
At the second of these summits, then-UN Secretary-General Kofi Annan called for the creation of the Global Fund to Fight AIDS, TB, and Malaria.
The Global Fund began operations in 2002, financing prevention, treatment, and care programs for the three diseases.
High-income countries also finally agreed to reduce the debt owed by heavily indebted poor countries, allowing them to spend more on health care and less on crippling payments to creditors.
The United States also took action, adopting two major programs, one to fight AIDS and the other to fight malaria.
In 2005, the UN Millennium Project recommended specific ways to scale up primary health care in the poorest countries, with the high-income countries helping to cover the costs that the poorest could not pay by themselves.
The UN General Assembly backed many of the project’s recommendations, which were then implemented in numerous low-income countries.
Donor aid did start to rise sharply as a result of all of these efforts.
In 1995, total aid for health care was around $7.9 billion.
This inadequate level then crept up slowly, to $10.5 billion by 2000.
By 2005, however, annual aid for health had jumped another $5.9 billion, and by 2010, the total had grown by another $10.5 billion, to reach $26.9 billion for the year.
The expanded funding allowed major campaigns against AIDS, TB, and malaria; a major scaling up of safe childbirth; and increased vaccine coverage, including the near-eradication of polio.
Many innovative public-health techniques were developed and adopted.
With one billion people living in high-income countries, total aid in 2010 amounted to around $27 per person in the donor countries – a modest sum for them, but a life-saving one for the world’s poorest people.
The public-health successes can now be seen on many fronts.
Around 12 million children under five years old died in 1990.
By 2010, this number had declined to around 7.6 million – still far too high, but definitely an historic improvement.
Malaria deaths in children in Africa were cut from a peak of around one million in 2004 to around 700,000 by 2010, and, worldwide, deaths of pregnant women declined by almost half between 1990 and 2010, from an estimated 543,000 to 287,000.
Another $10-15 billion in annual aid (that is, roughly $10-15 more per person in the high-income world), bringing total aid to around $40 billion per year, would enable still greater progress to be made in the coming years.
The MDGs for health could be achieved even in many of the world’s poorest countries.
Unfortunately, at every step during the past decade – and still today – a chorus of aid skeptics has argued against the needed help.
They have repeatedly claimed that aid does not work; that the funds will simply be wasted; that anti-malaria bed nets cannot be given to the poor, since the poor won’t use them; that the poor will not take anti-AIDS medicines properly; and so on and so forth.
Their attacks have been relentless (I’ve faced my share).
The opponents of aid are not merely wrong.
Their vocal antagonism still threatens the funding that is needed to get the job done, to cut child and maternal deaths by enough to meet the MDGs by 2015 in the poorest countries, and to continue after that to ensure that all people everywhere finally have access to basic health services.
A decade of significant progress in health outcomes has proved the skeptics wrong.
Aid for health care works – and works magnificently – to save and improve lives.
Let us continue to support these life-saving programs, which uphold the dignity and well-being of all people on the planet.
The AIIB and Global Governance
HONG KONG – Despite official American and Japanese opposition, 57 countries have opted to be among the founding members of the China-led Asian Infrastructure Investment Bank (AIIB).
Regardless of what naysayers believe, this remarkable turn of events can only benefit global economic governance.
According to former US Treasury Secretary Larry Summers, the AIIB’s establishment “may be remembered as the moment the United States lost its role as the underwriter of the global economic system.”
Asia Development Bank (ADB) President Takehiko Nakao, by contrast, does not believe that there will be a “major change to the world of development finance,” though he conceded that “there can be interpretations as to the symbolic meaning of this.”
Who is right will depend largely on the decisions that the AIIB’s top shareholders make regarding its operating structure.
So far, the AIIB has not sought to amend the principle that the largest contributor to a multilateral organization gets the largest say in running it.
Just as the US dominates the World Bank and Europe leads the International Monetary Fund, China will head the AIIB.
This implies a larger global leadership role for China – which the world, including its traditional powers, should welcome.
After all, global leadership is not just a matter of might; it also reflects the provision of global public goods.
When World War II ended, the US, aside from being the world’s leading military and economic power, was the largest provider of such goods, through the Marshall Plan, support for the United Nations, and contributions to the Bretton Woods institutions (the International Monetary Fund and the World Bank).
But massive debts have lately undermined the ability of the US – not to mention Europe and Japan – to continue making such large contributions.
Fortunately, China is willing and able to fill the gap.
In fact, China might have done so within the Bretton Woods institutions, were the distribution of voting rights within them not skewed so heavily toward the incumbents, who still enjoy veto power.
For example, China has a 3.8% voting share in the IMF and World Bank, even though it accounts for more than 12% of world GDP.
The United Kingdom and France – which are one-third the size of China – each have a 4.3% share.
With the incumbents unwilling to bring China’s voting share in line with its economic might, China had little choice but to launch its own institution.
But the AIIB has its own objectives, which do not align precisely with those of, say, the World Bank.
Specifically, the bank is a critical element of China’s “one belt, one road” strategy, which encompasses two initiatives: the overland Silk Road Economic Belt, connecting China to Europe, and the 21st Century Maritime Silk Road, linking China to Southeast Asia, the Middle East, and Europe.
While the US “pivots” to the east, China is pirouetting west, applying the lessons of its development to its trading partners across Eurasia and beyond.
Perhaps the most important of these lessons is that connectivity is vital to economic growth.
Over the last three decades, the construction of roads, railways, ports, airports, and telecommunications systems in China has fostered trade, attracted investment, and, by linking the country’s land-locked western and southern provinces to its more prosperous coastal areas, helped to reduce regional disparities.
China’s Silk Road initiative, which aims to boost prosperity among China’s trading partners largely through infrastructure investment, is a logical next step – one on which China is spending significantly.
In addition to its initial contribution of up to $50 billion to the AIIB, China has committed $40 billion to its Silk Road Fund, $32 billion to the China Development Bank, and $30 billion to the Export-Import Bank of China.
According to estimates by HSBC, the “one belt, one road” initiative could end up costing as much as $232 billion – just under two-thirds of the World Bank’s balance sheet in 2014.
The $100 billion AIIB will play a central role in this effort.
Given massive global demand for infrastructure finance – which, according to ADB estimates, will amount to $8 trillion in Asia alone over the next decade – the AIIB should not be considered a threat to the World Bank, the ADB, or other multilateral lenders.
Nonetheless, it will compete with them, owing to its distinctive – and probably more efficient – approach to lending.
In fact, the AIIB’s operations will most likely resemble those of the World Bank in the 1960s, when engineers with hands-on development experience dominated the staff and could design lending conditions that worked for borrowers.
In the late 1980s, the World Bank began to implement the Washington Consensus, pushing for economic and political liberalization, without sufficient regard for local political or economic realities.
The result was conditional lending, with terms – created mostly by policy wonks – that many developing-country borrowers could not meet (at least not without hiring consultants to adjust their official reporting).
The acid test of the AIIB’s effectiveness will be its governance model.
One failing of the Bretton Wood institutions is their full-time shareholder boards of directors, which tend to undermine effectiveness by micro-managing and often requesting conflicting lending conditions.
The World Bank has wasted far too much time re-organizing itself under various presidents, without recognizing the fundamental problem with its own governance structure.
Even if the AIIB does not deliver as promised, its establishment is an important reminder that in a fast-changing world, economic governance cannot remain stagnant.
If Western leaders really do believe in innovation, competition, and meritocracy, they should welcome the AIIB.
AIPAC in Decline
MADRID – The American Israel Public Affairs Committee’s lobbying power in the United States is undeniable.
But AIPAC’s supposed ability to control US policy decisions is a Potemkin village myth, cultivated by friends and rivals alike.
In fact, thanks to Israeli Prime Minister Binyamin Netanyahu, AIPAC’s influence is under threat – though Netanyahu himself will be just fine.
Claims about AIPAC’s clout have long shaped analysis of US foreign policy.
For example, Steve Walt and John Mearsheimer, in their notorious essay “The Israel Lobby,” asserted that AIPAC manufactured the Iraq War.
But the reality is far less sinister: in that case, AIPAC merely surfed on the pro-invasion wave unleashed by President George W. Bush, with his Messianic urges, and Vice President Dick Cheney, a one-man war lobby.
The truth about AIPAC – that it is influential, but far from invulnerable – has recently been revealed, both to the public and to the group itself.
Having been pushed by Netanyahu into an unwinnable fight against US President Barack Obama’s administration over its nuclear deal with Iran, AIPAC is now crumbling under the weight of its own hubris.
In fact, AIPAC has never overcome resolute opposition from an American president, particularly in a matter of US national security.
It failed to stop Jimmy Carter from selling F-15 Eagle fighters to Saudi Arabia in 1978, or to prevent Ronald Reagan from supplying AWACS reconnaissance planes to the Saudis three years later.
And its 1991 battle with President George H.W. Bush over the linkage of US loan guarantees for Israel with Prime Minister Yitzak Shamir’s support of the 1991 Madrid peace conference – one of Bush’s key legacies – ended in defeat.
Against this background, AIPAC should have known that its attempt, in close cooperation with Obama’s Republican opponents, to block the Iran nuclear deal (one of Obama’s most important achievements) would fail.
Indeed, Obama even used a tactic similar to that of George H.W. Bush to win the day.
Just as Bush openly denounced the “thousand lobbyists” working the halls of the US Congress against a vital national interest, Obama said in a conference call that his critics “would be opposed to any deal with Iran,” and called out AIPAC’s $20 million advertising campaign against the agreement.
He also put AIPAC in the same category as the Republicans who “were responsible” for leading the US into the Iraq war.
For AIPAC – which has traditionally relied on a broad coalition of social and political forces in the US that view Israel’s security as both a moral cause and a vital national interest – this is not any old defeat.
The Republican-backed crusade against a key agreement negotiated by a Democratic president, with his party’s overwhelming support, has threatened the bipartisan foundations of Israel’s cause in America.
Of course, the nuclear deal involved more than just the US and Iran.
AIPAC was opposing an international agreement that six major world powers – China, France, Germany, Russia, the United Kingdom, and the US – had already signed and that the United Nations had approved.
Even some of Israel’s staunchest supporters in Congress were unlikely to deal a potentially devastating blow to America’s international credibility, and the idea that the negotiating countries would all agree to reopen the talks to produce a “better deal” was sheer fantasy.
Yet that is the objective that Netanyahu set for AIPAC.
The row over the Iran deal is bound to be a watershed moment for American Jews, among whom sharp divisions have formed.
Indeed, the American Jewish Committee 2015 Survey of American Jewish Opinion reports the emergence of “two diverging Jewish sub-communities,” with a growing number of Jews feeling alienated by the organizations that claim to represent them.
AIPAC represents a striking anomaly in the life of American Jews.
It is increasingly identified with the Republican agenda and Israel’s evangelical Christian supporters, even though polls have repeatedly shown that Jews are America’s most liberal ethnic group.
The truth is that American Jews largely opposed the Iraq war.
They overwhelmingly vote for the Democratic Party.
They define their religion as moderate and liberal, with many upholding gay rights and abortion, both anathema to evangelical Christians.
The majority of American Jews even support the creation of a Palestinian state.
And, although they are far from united on the Iran deal, the agreement’s supporters outnumber its opponents.
Much of the blame for the damage that has been done – to AIPAC, American Jewish communities, and even the US political process – falls on Netanyahu.
But he is unlikely to face retribution for any of it.
On the contrary, the Obama administration has already begun the discussions it promised on upgrading Israel’s strategic capabilities.
As Arab countries throughout the Middle East melt down – with increasingly significant spillover effects in the West – Israel continues to represent a stable regional partner for the US.
More dangerous, Netanyahu could achieve his next goal: preventing a strategic détente between the US and Iran that would enable cooperation in resolving major regional conflicts, from Yemen to Syria.
After all, Obama’s victory on the nuclear deal may have been inevitable, but it was far from easy.
An odd coalition of Iranian radicals, AIPAC, the Saudi-led Sunni alliance, the Israeli government, and US politicians from both parties have already compelled Obama to promise additional sanctions on Iran for its sponsorship of terrorism.
As a result, America’s cold war with Iran is likely to persist.
The Dawn of Climate-Friendly Air Travel
MONTREAL – As the world becomes increasingly interconnected, demand for air travel is growing, with more than 30,000 new large aircraft expected to take to the skies in the next few years.
But if we are to sustain growth in air travel without aggravating global warming, we must quickly reduce aviation-related CO2 emissions, which are substantial and not covered by the Paris climate agreement that more than 190 countries agreed to last December.
Fortunately, now is the perfect time to decouple aviation emissions from air-travel growth.
Representatives from 191 countries convened in Montreal this week for the 39th Session of the United Nations’ International Civil Aviation Organization; after decades of wrangling, they have agreed to an aviation-specific climate agreement.
The new ICAO framework aims for “carbon-neutral growth” in international aviation from 2020 onward, and has as its centerpiece a global market-based measure (GMBM) to help airlines affordably cap their net emissions at 2020 levels.
When implemented, it will be the first carbon-emissions cap on a global industry that does not noticeably increase costs for consumers.
And airlines will purchase emissions reductions from other economic sectors, thus funneling billions of dollars into low-carbon development around the world.
For the first six years, the new framework will apply only to flights between countries that have voluntarily adopted it, which means that the ICAO will have to encourage adequate participation for the program to be effective.
This opt-in approach has some critics, but whether a program is categorized as “voluntary” or “mandatory” is beside the point, because international accords generally apply only to the sovereign countries that have decided to join them.
Some 64 countries have already signaled their willingness to sign on to the ICAO agreement, and together they account for nearly 80% of expected growth in CO2 emissions above 2020 levels.
That isn’t 100%, but it’s a great start, and we can expect more countries to join when they see others reaping the benefits of low-carbon development.
The airlines themselves will welcome a coherent global framework that establishes clear and predictable compliance metrics, rather than a regulatory patchwork that differs from country to country and complicates international operations.
To minimize compliance costs – and because environmental sustainability is now a key competitive marker for customers and investors alike – airlines will likely encourage the countries where they do business to participate in the ICAO program.
The new agreement provides an enormous opportunity to prevent the emission of 2.5 billion tons of CO2 in the first 15 years – the equivalent of taking roughly 35 million cars off the road every year the program is in force.
The agreement will also spur major manufacturers such as Boeing, Airbus, Bombardier, and Embraer – which are already investing in quieter, more fuel-efficient aircraft and efficiency improvements for existing models – to develop cleaner technologies that will allow them to purchase fewer emissions offsets.
However, the framework decided in Montreal is not complete, and crucial details need to be worked out quickly so that airlines can begin to plan how they will meet the new environmental targets.
Developed countries have already offered to help implement the GMBM, which, it is hoped, will pave the way for investments in emerging economies that are becoming new aviation powerhouses.
If the countries can leapfrog over old technologies, they can become new leaders in carbon-smart flying.
They should seize the opportunity before them and join the ICAO framework so that their manufacturers have a clear and predictable path forward.
At the Paris climate talks last year, we witnessed the power of global collective action to address climate change.
No fewer than 187 countries – large and small, developed and developing – announced emissions-reduction targets in the months before the conference, which created the momentum to reach a landmark accord.
With the Paris climate agreement on track to enter into force in the coming months – more rapidly than anyone ever thought possible – we still have that momentum.
The ICAO agreement is the next wave in the international battle against climate change.
Together, the two agreements will boost our chances of delivering environmentally sustainable economic growth.
By cleaning up our carbon footprint now, future generations of air travelers from all countries will be able to look out their window onto a healthy planet.
Europe’s Airpocalypse
SINGAPORE – European policymakers like to lecture the rest of the world on air pollution.
Asia, and China in particular, is a favorite target for criticism.
Indeed, it sometimes seems as if no major environmental conference is complete without a presentation by European policymakers on their continent’s supposed “best practices,” which the rest of the world should emulate.
When it comes to air pollution, however, Europe might consider doing less talking and more listening.
Air pollution is a growing concern across Europe.
The World Health Organization has called it the continent’s “single largest environmental health risk,” estimating that 90% of Europe’s citizens are exposed to outdoor pollution that exceeds WHO air-quality guidelines.
In 2010, some 600,000 European citizens died prematurely because of outdoor and indoor air pollution, and the economic costs have been put at $1.6 trillion, roughly 9% of the European Union’s GDP.
London and Paris suffer from particularly severe air-quality problems.
Nitrogen dioxide levels in some parts of London regularly reach 2-3 times the recommended limit.
In the United Kingdom, air pollution kills some 29,000 people a year, putting it second only to smoking as a cause of premature death.
Paris may be even worse off; in March, after air-pollution levels surpassed Shanghai’s, the city imposed a partial driving ban and introduced free public transportation.
Sadly, Europe’s policymakers do not seem up to the challenge.
George Osborne, the UK’s chancellor of the exchequer, has argued against British leadership in the fight against climate change.
“We are not going to save the planet by shutting down our steel mills, aluminum smelters, and paper manufacturers,” he declared in 2011.
Osborne is not alone.
With European politicians arguing that introducing environmental safeguards will hurt the EU’s already-weakened economy, it comes as little surprise that measures to limit air pollution fall far short of the mark.
The EU’s proposed standards regulating toxic emissions from coal plants are even less strict than China’s, Greenpeace reports.
Yet various European politicians have called for watering them down even further, with Hungary suggesting that they be scrapped altogether.
To be sure, air pollution levels in Asia are truly worrisome.
The continent is home to nine of the world’s ten most polluted countries, according to Yale University’s 2014 Air Quality Ranking.
New Delhi is ranked as the most polluted city on earth, with air pollution exceeding safe levels by a factor of 60.
Owing to Beijing’s unhealthy air, foreign companies pay a “hardship bonus” of up to 30% to employees working there.
But at least policymakers in Asia have recognized the problem and are taking steps to address it.
China, for example, has declared a “war on pollution.”
By 2017, Beijing – once dubbed “Greyjing” by the international media – will spend some CN¥760 billion ($121 billion) to combat air pollution.
At the heart of China’s measures are improved public transportation, green trade, and a revision of the energy mix.
The government has decided to install bus stops every 500 meters in city centers, reduce tariffs to 5% or less for a list of 54 environmental goods, and decommission many outdated and inefficient coal plants.
The share of non-fossil fuels in primary energy consumption is expected to increase to 20% by 2030.
These targets are likely to be rigorously implemented, given strong political support from the very top.
Meanwhile, in India, the state governments in Gujarat, Maharashtra, and Tamil Nadu are about to launch the world’s first cap-and-trade schemes for particulates.
India’s Supreme Court even suggested an extra charge on privately owned diesel vehicles in New Delhi.
Other parts of Asia are also taking steps to improve air quality.
Vietnam aims to construct eight urban rail lines in the coming years.
Bangkok, which has been tackling air pollution since the 1990s, has planted 400,000 trees.
And Japan is offering subsidies for hydrogen cars and creating new pedestrian-only areas.
Europe, as one of the world’s wealthiest regions, ought to be at the forefront of the effort to promote environmental sustainability.
When it comes to air pollution, however, Europe’s policymakers should stop preaching to others and focus on fixing their own problems.
A Japanese Metamorphosis?
OSAKA – Yesterday’s landslide general-election victory by the Democratic Party of Japan (DPJ) terminated the one-party-dominated system that the catch-all Liberal Democratic Party (LDP) has controlled almost without interruption since 1955.
For most of the last decade, the DPJ was not seen as a viable alternative to the LDP, although they appeared to form a pseudo-two-party system.
Twenty years after the Cold War’s end, Japan will at last have a post-Cold War system of government.
The Japanese public, even now, remains uncertain about the DPJ’s ability to govern and is skeptical of its rosy programs of wealth redistribution, which lack solid funding.
The public is also fully aware that the ideologically fragmented DPJ lacks a pragmatic, coherent foreign and security policy
Yet the DPJ will form the next government because of public disgust with the LDP.
For the last four years, the LDP had shown itself to be utterly unresponsive to the key issues of popular concern: pensions, unemployment, and the fraying social safety net.
Moreover, the LDP was plagued by a string of minor scandals and consistent bungling.
The LDP’s need for three different prime ministers in the space of little more than a year made plain that the party’s power nucleus had melted down.
Once in power, the DPJ will immediately confront the massive bureaucracy and entrenched mandarins, which usually sabotage any efforts at administrative reform that threatens their power and vested interests.
Indeed, immediately after the election, the budget estimates for the next fiscal year are due.
The figures that will be presented are the result of a lengthy process, in which the bureaucracy closely consulted with LDP.
So, without breaking the regular budget cycle, the DPJ will be forced to implement not only the supplementary budget drawn up by the LDP, but will also be stuck with next year’s budget, which embodies LDP policies that the DPJ has denounced.
As a result, the DPJ has announced plans to revoke the LDP’s guidelines for a ceiling on budget requests so as to formulate its own budget from scratch.  It will also revise the supplementary budget as well.
But time is short, and few of new DPJ lawmakers possess the legislative experience and budgetary expertise to make that happen.
To gain control of the mandarins, the DPJ plans to place 100 lawmakers in the ministries’ top leadership, as well as three dozen political appointees to policy staffs in the office of the prime minister.
Unfortunately, the DPJ scrapped an LDP-sponsored civil-service reform bill, which would have allowed the DPJ to replace mandarins with an army of political appointees.
The DPJ, despite its manifesto, seems unprepared to tame the mandarins, and so may be forced to rely on them.
The ascendency of the mandarins is a legacy of Japan’s unique historical development dating back to its early modern period.
Unlike in Europe, Japan developed its state before building a strong civil society.
Indeed, full-fledged “society”-building started only after the 1868 Meiji Restoration, which tipped the balance of power definitively in favor of the state.
As a result, the mandarins survived WWII and the postwar American occupation relatively undamaged, and they will strive to survive the DPJ government as well.
They will most likely succeed.
LDP lawmakers and mandarins developed a routine in which mandarins drafted cabinet-sponsored bills, LDP lawmakers checked the bills, and the two together finalized legislative drafts before they were introduced to the Diet (parliament).
Since the LDP, recently with a coalition partner, controlled the Diet, the legislative process was simply the interaction between LDP lawmakers and mandarins, centered in the LDP’s headquarters.
The Diet’s role was merely pro forma.
Indeed, under the LDP-led one-party-dominant system, this extra-constitutional mechanism became an integral part of Japan’s government polity.
The DPJ government will collide head-on with the mandarins, partly because the party will find it hard to recruit sufficiently qualified policymakers.
The mandarins have maintained their privileged position in this regard, owing partly to the tax system, which prevents the emergence of non-profit institutions, especially think tanks, where independent policy expertise can be forged.
Moreover, perhaps in anticipation of a change in power, the mandarins have moved forward the annual personnel changes in the major ministries’ top administrative positions.
And what of the LDP?
Having fallen from power, it will lose its control of the redistribution of government funds.
Unable to pay off its constituencies, disintegration looms, for the LDP has never been a party with entrenched grass-roots support, but instead operates as a machine of power and redistribution through a web of insiders across the country’s industrial sectors, occupational associations, and local communities.
Only by recruiting new blood and reorganizing itself with a solid ideological platform will an LDP comeback be possible.
The DPJ has even weaker grass-roots support, so the mandarins will most likely use their standard techniques of divide and rule to cajole the party by teaching it to mimic the LDP in using state money and contracts to underwrite its major constituencies, such as labor unions and other interest groups.
The birth of the DPJ government can yet be a turning point.
A major power shift in favor of “society” has taken place.
If the DPJ can break free of mandarin control by centralizing policy formation in the office of the prime minister, as it intends, Japan can emerge as a more resilient democracy with a full-fledged two-party system and greater willingness to assume an international leadership role.
A Jobless Recovery?
CAMBRIDGE – Who will suffer the longest and the most from the implosion in 2008-2009 of Wall Street and the ensuing world recession?
Not the bankers and financiers who created the disaster.
Some financiers, like Bernard Madoff, will go to prison for fraud.
But, although Madoff was only the tip of the iceberg of rampant financial malfeasance, most suspect financiers need not fear arrest, either because their behavior merely skirted the law, or because financial impropriety more subtle than outright fraud is often difficult to prove.
Some bank bosses will retire in shame, but with huge payments to ease their pain – such as the $55 million golden parachute handed to Bank of America’s Ken Lewis, with his, and the £25 million pension bestowed on Royal Bank of Scotland’s Fred Godwin.
But, buoyed by government bailout money, guarantees, and low interest rates, many banks have again begun to pay their top managers huge bonuses while fighting vigorously against reforms designed to restrain their risk-taking and compensation.
The big losers from this economic disaster are workers in the advanced countries that bought into the laissez-faire flexibility of American-style capitalism.
From 2007 to October 2009, the United States lost nearly eight million jobs, which reduced the employment-population ratio from 63% to 58.5%.
The unemployment rate at the end of 2009 was above 10%, duration of joblessness was the longest since the Great Depression, millions had had their working hours cut, and millions more were too discouraged by a lack of jobs to seek work.
Advanced Europe, Canada, and Japan also suffered major job losses that will last for a long time.
Spain, which allows for widespread temporary contracts, has had the biggest increase in unemployment, because Spanish workers can be fired as quickly as those in the US.
Some countries – for example, Germany, Sweden, and South Korea – have “hidden” their joblessness by paying firms to keep workers on the payroll.
This can work in the short term, but it cannot be sustained over time.
From the 1980’s through the mid-2000’s, employment has increasingly lagged GDP in economic recoveries.
In the US, there was a jobless recovery under President Bill Clinton until the dot.com boom in the latter part of the 1990’s, and there was a jobless recovery under George W. Bush in the wake of the 2001 slowdown.
In the early 1990’s, Sweden suffered a huge recession precipitated by a housing bubble and a banking crisis.
Its unemployment rate rose from 1.8% in 1990 to 9.6% in 1994, before bottoming out at 5% in 2001.
Sixteen years after the crisis, the unemployment rate was 6.2% – more than triple the rate in 1990.
In 1997, Korea suffered not only from the Asian financial crisis, but also from insistence by the US and the International Monetary Fund that it raise interest rates and undertake “Washington Consensus”-style reforms to receive aid.
Employment recovered, but primarily in “non-regular” jobs with limited benefits, low wages, and little job security.
Inequality in Korea rose from moderate levels to second highest (behind the US) among advanced OECD countries.
Weakness in the job market takes a huge toll on economic and personal well-being.
Young people seeking their first jobs and experienced workers who lose jobs in a weak job market suffer economic losses that will last their entire lives.
Studies of happiness show that unemployment reduces happiness by as much as the loss of a family member.
It is difficult to see the US re-attaining full employment anytime soon.
From 1993 to 1998, the US created millions of jobs, which raised the employment rate by 5.4 percentage points.
If employment began rising at this rate in 2010, it would take until 2015 before it reached its pre-recession level.
And slow recovery in the US will drag down recovery in other advanced countries, reducing their employment as well.
A long, painful period of high unemployment runs counter to what most experts believed the flexible US economic model would ever produce.
From the early 1990’s on, many analysts viewed America’s weak unionization, at-will employment, limited legal job protection, and high job turnover as major factors in achieving a lower unemployment rate than most EU countries.
Many OECD countries initiated various kinds of flexibility reforms in the hope of improving their economies along US lines.
The view that flexibility is the key factor in employment is no longer tenable.
In its 2009 Employment Outlook , the OECD took a hard look at its favored policy reforms and found them deficient in helping countries adjust to a finance-driven recession.
According to the OECD, “there does not appear to be any strong reason to expect that recent structural reforms mean that OECD labor markets are now substantially less sensitive to severe economic downturns.”
So the lesson from the recession is clear.
The weak reed in capitalism is not the labor market, but the financial market.
At worst, labor-market failures impose modest inefficiency costs on society, whereas capital-market failures harm society greatly, with workers, rather than the perpetrators of financial disaster, suffering the most.
Moreover, globalization means that the US capital market’s failure spreads misery around the world.
We owe it to workers victimized by this recession to reinvent finance so that it works to enrich the real economy, instead of enriching only the financiers.
This means changing the incentives and rules that govern the financial sector.
Since other countries’ economies and jobs are also at stake, they owe it to their citizens to press the US to deliver meaningful financial reforms.
France’s Midsummer Night’s Dream
PARIS – Bastille Day, the French national holiday, was glorious this year.
The military parade, dominated by the celebration of “victory” in Mali and the joint participation of African and United Nations troops, had the perfection of a gracious, albeit muscular, ballet.
The classical concert that preceded the magisterial fireworks that ended the day was the closest thing to a French version of the Proms in London, mixing light classical and popular songs.
The Eiffel Tower imbued the evening with its magic.
Paris, in case anyone had any lingering doubts, remains the capital of the world – or so it seemed for a night.
The melancholia that began to seize France many years ago was all but forgotten.
The celebration of the glory of the past, mixed with popular English songs of the present, seemed to indicate renewed national confidence.
What was the meaning of this moment of grace?
Was it purely the product of a collective delusion, an emotional Potemkin village of sorts, encouraged, if not conceived, by the authorities to restore some level of self-assurance among France’s depressed citizens?
Even if the positive emotions remain only fleeting (as seems most likely), they were real and palpable.
The French seemed to be in the mood to celebrate.
Of course, it could simply have been the weather; a gorgeous summer has finally settled in after a miserable spring.
But it might also have been one of those natural turning points, a collective and spontaneous decision to say: “Enough of depression, let’s move on.”
We French may not be what we used to be, the celebrants seemed to be saying, but we are still much more than people think we are.
We have a great revolutionary past that still conveys universal values – liberty, equality, fraternity – and an army that, as in Mali, continues to make a difference in the world.
One can draw two lessons from this collective form of escapism.
The first is that, beyond the many layers of depression and distrust in France, there is potential for a new and collective departure.
This would require, of course, less cynical political elites who can transcend their petty ambitions and divisions for the sake of the country.
The second lesson, even more obvious, is that reality cannot be changed with a simple public spectacle.
France is not Imperial Rome, where panem et circenses made a fundamental difference.
It is a weakened democracy mired in an economic and social crisis so deep that it verges on becoming an identity crisis.
The proof was provided by a third traditional event on Bastille Day, between the morning’s military parade and the evening’s music and fireworks: President François Hollande’s speech to the nation, which took the form of an interview with two prominent journalists.
He, too, was in a reassuring mood.
According to Hollande, the economic upturn – la reprise – had just started, and hope was around the corner.
His tone and message had changed.
He was no longer the “normal man” of his election campaign and tenure until now; instead, he tried to present himself, like his predecessor, Nicolas Sarkozy, as a superhero.
Of course, given his personality and low public-approval ratings, his address was the least convincing event of the day.
Who could have said with certainty that the economic upturn announced by Hollande was real rather than aspirational?
Beyond his message’s wishful thinking, the public’s reaction to the messenger was a mixture of disbelief and indifference.
Seeing the behavior of friends, all French, listening with me to Hollande, I was reminded of another moment.
It was December 31, 1989, and I was in the Soviet Union.
I had found myself in a restaurant in the old city of Suzdal, listening to President Mikhail Gorbachev’s “New Year wishes.”
I was moved: The man who symbolized glasnost and perestroika, who had allowed the peaceful emancipation of most of Eastern and Central Europe, was speaking.
But I was alone in paying attention to him.
The restaurant’s customers, like my French friends now, could not have cared less.
Their president had become background noise.
Has Hollande become, in this sense, a French Gorbachev?
For the left and the Greens, he is close to being a traitor.
These voters chose him a year ago not only because he was not Sarkozy, but because he incarnated the values of the true left, even if his centrist moderation seemed a bad omen.
Voters of the center or even the center-right are disappointed, too, by their president’s lack of charisma, if not sheer incompetence.
After a year of Hollande, France is witnessing a fundamental political revolution.
During the half-century of the Fifth Republic, a bipartisan system of left and right has traditionally prevailed.
But now France is becoming a country dominated by a “tripartite system” of more or less equal strength: the left, the right, and the extreme right.
If France wants to capitalize on the positive emotions of Bastille Day, it needs much more responsible elites, ready to unite in the fight against unemployment and its causes (lack of competitiveness and labor-market rigidity) and consequences (the rise of populist, non-republican forces).
What Bastille Day revealed, even briefly and superficially, is that the potential to unite France exists.
But doing so requires more than shallow promises.
A Kick-Off for Peace?
Yerevan – Armenian President Serzh Sargsyan’s recent invitation to Turkish President Abdullah Gul to visit Yerevan to watch a football match together was historic.
Given the two countries’ long-strained relations, this visit would have been remarkable at any time.
But coming as it does only one month after the alarming Russian-Georgian confrontation, it may offer real hope that tensions in the volatile Caucasus region can be eased.
Of course, ancient and difficult issues divide Armenia and Turkey.
But now is the moment for both countries to put the past aside in order to address their common security concerns.
In the new context set by the war in Georgia, the urgency of Turkey becoming a real bridge between the nations of the Caucasus is not lost on anyone.
This expectation is an inevitable consequence of Turkey’s geography and history.
Situated figuratively between modernity and tradition, secularism and Islam, and democracy and tyranny, Turkey also is an actual physical bridge between East and West.
For the peoples of the Caucasus, Turkey marks our path to Europe.
It is a NATO member, bordering the three Caucasus republics that have NATO Individual Partnership Action Programs.
It aspires to join the European Union, and would bring the EU to our three borders, even as we, too, aspire to join one day.
Indeed, Turkey has never missed an opportunity to present itself as a regional broker.
Immediately after the collapse of the Soviet Union, Turkey proposed the Black Sea Economic Cooperation.
This year, as the American-led effort to mediate a Middle East peace settlement began to falter, Turkey took up the job of mediator in both the Israeli-Palestinian conflict and the conflict between Syria and Israel.
Now, in the immediate wake of the Russia-Georgia crisis, Turkey’s leaders have stepped forward once again to take a leadership role in the Caucasus.
The world must fervently hope that the Turkish proposal for a Caucasus Stability and Cooperation Platform is more serious and sustained than previous similar efforts.
But, in order to succeed, Turkey must firmly pursue a pledge from all the region’s players to repudiate the use of force in settling their disputes.
If this pledge is adopted and respected, conflicts in the region will be viewed in a wholly different, more tolerant context, marking a historic breakthrough to peace.
In fact, why not take the idea of such a pact one step further?
We in this region can, and I believe should, call for a non-aligned Caucasus, free of security blocs and adversarial alliances.
After all, security alliances and guarantees only create dividing lines, with their attendant security challenges.
Our countries and peoples have, throughout history, lived under a common umbrella for far longer than we have been divided.
Today, we share a common vision of European integration, and it is in this broader context that our conflicts should be resolved.
French President Nicolas Sarkozy’s and German Chancellor Angela Merkel’s visits to Georgia and Russia proved that there is no substitute for Europe insofar as the Caucasus is concerned.
Only Europe can play the role of honest broker in the region’s atmosphere of suspicion and intolerance.
But, at the end of the day, we ourselves must be willing to work toward a region of peace and cooperation.
The Caucasus is too small a space for closed borders and explosive conflicts.
Although some of those tensions appear purely bilateral, the Georgian-Russian conflict demonstrates that there is no such thing anymore in this globalized world, and certainly not in this interconnected region.
In fact, real peace in the Caucasus requires two key strategic transformations.
One is a lesson from history: Russia’s strategic interests here cannot be ignored.
To believe and behave otherwise would lead to regional chaos.
The other lesson is that Turkey and Armenia cannot remain adversaries forever.
There must be normalization in our relations in order for the Caucasus to coalesce into a functional region.
Ironically, both Russia and the United States recognize that this is in their interest.
The Russians view normal relations between Turkey and Armenia as a way to minimize Georgia’s strategic role in the region.
The US views an opening to Turkey as a way to decrease Armenia’s real and imagined reliance on Russia.
Beyond the emotional impact of President Gul’s visit to Yerevan, real improvement in Turkish-Armenian relations requires opening the two countries’ closed border – the last in Europe.
Or, for a start, the existing railroad link between the two countries could be made operational.
If this does not happen within the coming weeks and months, then Turkey will have demonstrated that all this was just a show.
President Gul’s visit does mark a watershed – either as a failure to make history, or as the beginning of a new era.
Truth and Consequences
NEW YORK – The recent re-election of Colombia’s president, Juan Manuel Santos, brings hope to a country seeking to end a half-century of conflict.
But, as with so many peace processes, finding a balance between creating a stable accord and acknowledging the terrible injustices that occurred during the conflict can be difficult to achieve.
Many countries and communities, from Nepal to Northern Ireland, have grappled with legacies of ethnic, ideological, or religious division and violence, often with limited success.
This is frequently the case because the mechanisms established to cope with post-conflict reconciliation, truth, and justice, have proved inadequate.
In Bosnia and Herzegovina, the International Criminal Tribunal for the former Yugoslavia (ICTY) has made important contributions to truth seeking.
But victims complain that its procedures are slow and abstruse; and many Bosnian Serbs are convinced that the tribunal is selective and politically motivated.
An agreement between Nepal’s government and Maoist guerrillas to establish a truth commission and investigate the “disappeared” was delayed for seven years.
When legislators finally enacted the enabling legislation in May 2013, victims were dismayed to discover that the commission would be allowed to recommend amnesties for crimes against humanity, in contravention of international principles and United Nations guidelines.
In Northern Ireland, the Good Friday Agreement, justly acclaimed for staunching the bloodshed and starting reconciliation, has – to the great frustration of victims – run into political resistance over one integral element of the peace process: the establishment of mechanisms to clarify past crimes.
Peace negotiators understandably fear that criminal accountability for past crimes will threaten their side’s leaders and supporters.
Many have wrongly assumed – based on a misinterpretation of the South African experience – that truth commissions provide a “soft” alternative to justice.
As a result, they have willingly incorporated these mechanisms into peace agreements (conveniently ignoring the fact that the victims are forced to choose between seeking justice and learning the truth).
Predictably, as truth commissions have become established components of transitional justice, former fighters have become increasingly worried that their reputations and political credibility could be on the line should past crimes ever come to light.
Seeking the truth can be unsettling and painful for anyone, but it comes with serious consequences for those with reason to fear justice.
Indeed, conflict mediation and transitional justice rely on truth commissions as a fundamental building block of peace not because such commissions provide impunity for the worst crimes; on the contrary, they reinforce comprehensive rights-based policies and access to justice.
As a recent symposium, organized by the Kofi Annan Foundation and the International Center for Transitional Justice, concluded, truth commissions contribute most to peace by reasserting the rule of law, recognizing victims, and supporting institutional reform.
But, in order to succeed, these commissions must be effective, independent, and legitimate.
Half-measures will not do.
Truth commissions therefore should never be established as “box-ticking” exercises to assuage local public opinion or the international community, as witnessed in Nepal.
Even when broad mandates and functions are established with the best of intentions, truth commissions are often deprived of the necessary resources, leading to further frustration and disillusion.
Moreover, a commission should not be led or staffed by individuals of questionable integrity, thereby undermining the legitimacy of the process.
Above all, truth commissions must be adapted to a country’s particular circumstances.
As we have seen in Bosnia, Colombia, Nepal, Northern Ireland, and elsewhere, the nature of conflicts and how they are resolved differ widely; so should their respective commissions.
A “one-size-fits-all” solution ends up fitting no one.
It is vital that the details of each case of post-conflict transitional justice are understood and implemented.
It is all too easy for political leaders to ignore victims or suppress the truth in their quest for a peace deal.
But recognizing victims’ rights is an indispensable condition for lasting peace.
Human suffering and victims’ dignity are too powerful to be erased by others’ political pacts.
Eventually, the past demands its due: justice is not just an ideal; it is an investment in a better future.
Alan Greenspan on Trial
The release of Alan Greenspan’s ghostwritten memoirs The Age of Turbulence has elicited charges that he was not such a great central banker after all.
Stan Collender of National Journal sees the fingerprints of the White House on these attacks: Greenspan is harshly critical of George W. Bush’s administration, after all, and to attack the credibility of Republican ex-policymakers who are critical of Bush is standard counterpunching for it.
But what is one to make of the criticisms of Greenspan’s tenure at the Federal Reserve?
The indictment contains four counts: that Greenspan wrongly cheered the growth of non-standard adjustable-rate mortgages, which fueled the housing bubble; that he wrongly endorsed Bush’s tax cuts; that he should have reined in the stock market bubble of the 1990’s; and that he should have done the same with the real estate bubble of the 2000’s.
To the first two counts, Greenspan now pleads guilty.
He says that he did not understand how the growth of non-standard mortgages had lured borrowers and investors into bearing dangerous risks.
He was, he now says, focusing on how fixed-rate mortgages are relatively bad deals for borrowers in times of low inflation, which was a mistake.
Greenspan also pleads guilty to a mistake in early 2001.
He thought that he was giving balanced testimony to Congress on government budget issues.
He testified that it is important to run surpluses to pay down the debt, but that surpluses must not be so large that the government winds up owning American industry.
He also testified that tax cuts are better than spending increases to keep surpluses from growing too large, but that uncertainty is enormous, so that any tax cuts should be canceled if they threatened to bring us back to an age of deficits.
Robert Rubin and Kent Conrad warned him that the press would not interpret his testimony as being balanced, and that Congress would interpret it as an excuse to abandon fiscal discipline.
They were right.
Greenspan also pleads guilty to misunderstanding the character of the Bush administration.
He thought that his old reality-based friends from the Ford administration were back in power.
He thought that he – and Treasury Secretary Paul O’Neill – could win the quiet “inside game” for sensible policy without resorting to an “outside game” that would make his reappointment in 2004 unlikely.
He was wrong.
But how serious are these policy-political crimes to which Greenspan now pleads guilty?
In my view, they are misdemeanors.
Against them you have to set what former Treasury Secretary Larry Summers calls Greenspan’s “golden glove” performance at avoiding and minimizing recessions during his years at the Fed.
The “felonies” of which Greenspan stands accused are the other two charges: that he should have done more to stop the stock market bubble of the late 1990’s, and that he should have done more to stop the housing bubble of the early 2000’s.
Here, Greenspan holds his ground, and pleads not guilty.
The only way, he says, for the Fed to have kept stock prices in reasonable equilibrium ranges in the late 1990’s would have been to raise interest rates so high that they hit the real economy on the head with a brick.
Interest rates high enough to curb stock market speculation would also have curbed construction and other forms of investment, raised unemployment, and sent the economy into recession.
To cause a significant current evil in order to avoid a possible future danger when our knowledge is limited and our judgments uncertain is, Greenspan believes, unwise.
In this, he is following a tradition of caution that extends from Edmund Burke to John Maynard Keynes.
Greenspan mounts a similar defense concerning the housing bubble.
High construction employment has been good for American workers in the past half-decade – a period that has not produced much good for them.
Higher interest rates to reduce the housing boom seem, even in retrospect, ill advised if the cost is mass unemployment.
And Greenspan eschews paternalism: he would not assume the role of a regulator telling people that they cannot buy a house even though a lender is willing to finance it.
But Greenspan would have served the country and the world better if he had been somewhat more paternalist in slowing the growth of non-standard adjustable-rate mortgages.
He would have served the country and the world better had he been less of a loyal Republican working the inside game of trying to convince Bush’s political advisors that good policy was important, and more of a nonpartisan steward of America’s long-term fiscal stability.
Of course, such a Greenspan would never have been re-appointed.
All in all, Greenspan served the United States and the world well through his stewardship of monetary policy, especially by what he did not do: trying to stop stock and housing speculation by halting the economy in its tracks.
A Lasting Poison
NEW YORK – Next year will mark the twentieth anniversary of the collapse of communism in Europe.
Liberated from the complexity of knowing too much about the cruel past, the young people of Eastern Europe’s post-communist generation seem uninterested in what their parents and grandparents endured.
Yet the recent revelation of the Czech writer Milan Kundera’s presumed complicity in the face of Stalinism is but the latest of the long half-life of a toxic past.
Other examples come to mind: the accusations of collaboration with the secret police raised against Lech Walesa, Romania’s public controversies surrounding Mircea Eliade’s fascist past, and the attacks on the alleged “Jewish monopoly of suffering” which equate the Holocaust with the Soviet Gulag.
Friedrich Nietzsche said that if you look in the eye of the Devil for too long, you risk becoming a devil yourself.
A Bolshevik anticommunism, similar in its dogmatism to communism itself, has from time to time run riot in parts of Eastern Europe.
In country after country, that Manichean mindset, with its oversimplifications and manipulations, was merely re-fashioned to serve the new people in power. 
Opportunism has had its share in this, of course.
In 1945, when the Red Army occupied Romania, the Communist Party had no more than 1,000 members; in 1989, it had almost four million.
One day after Nicolae Ceausescu’s execution, most of these people suddenly became fierce anticommunists and victims of the system they had served for decades.
Residual traces of totalitarian thinking can also be found in the hostility to former dissidents like Adam Michnik or Václav Havel, both of whom argued that the new democracies should not exploit resentments or seek revenge, as the totalitarian state did, but instead build a new national consensus to structure and empower a genuine civil society.
Former generals of the secret police and members of the Communist
But the case of Kundera appears different – though no less disturbing.
In 1950, Kundera, then a 20-year-old Communist, reportedly denounced to the criminal police as a Western spy a man he had never met – a friend of his friend’s girlfriend.
The man was later brutally interrogated in a former Gestapo torture facility and spent 14 years in prison.
Kundera’s name was contained in the investigating officer’s report, which was authenticated after a respected historian discovered it in a dusty Prague archive.
The reclusive Kundera, who immigrated to Paris in 1975, has declared that “it never happened.”
Moreover, Czechoslovakia’s fearsome secret police, who had every interest in silencing or compromising the famous dissident writer, never used the incident to blackmail or expose him.
Until more information is forthcoming, both from Kundera and from the authorities, the case will not be solved “beyond reasonable doubt.”
But
As far as we know, Kundera never was an informer before or after this incident, and we cannot ignore that he later freed himself from the compulsory totalitarian happiness that communism propagated.
Indeed, his case also serves as a reminder that the early 1950’s was the most brutal period of “proletarian dictatorship” in Eastern Europe – a period of great enthusiasm and terrible fear that poisoned the minds and souls of devoted believers, fierce opponents, and apathetic bystanders alike.
Moreover, Kundera’s case is hardly unique.
In 2006, the Nobel Prize-winning German author Günter Grass’s disclosed that, 60 years earlier, he was, as a teenager, a member of the Waffen-SS.
Similarly, a few years ago, the world was shocked to learn that famous Italian writer Ignazio Silone had, in his youth, collaborated with the fascist police.
Daily life under totalitarianism, be it communist or fascist, was routinely based on a deep duplicity whose effects are longstanding.
I don’t agree with those who say we should not be interested in the dark episodes in the life of a great writer.
Why not?
We should be interested not for prosecutorial purposes, but in order to gain a more profound understanding of a bloody, demagogical, and tyrannical Utopia – and of human weakness and vulnerability. We may even consider it a rewarding testament to an artist’s ability to overcome his past mistakes and still produce priceless work. 
But can we justifiably defend morally compromised artists and intellectuals on the basis of their work’s merit, yet condemn ordinary people for often less grave offenses?
An egregious example of this was the way followers of Romanian philosopher Constantin Noica defended his support for the fascist Iron Guard and his later collaboration with the Communists, while at the same time condemning even a generic cleaning woman for mopping the floors in the offices of the secret police.
Shouldn’t that cleaner’s drudgery to support her family, children, and her own survival be taken equally into account?
Life under totalitarianism was an extreme situation that requires us to apply special, nuanced rules to all the captives of that ordeal.
In order to understand that epoch, we have to know and carefully judge often ambiguous and overwhelming circumstances, never simplifying a multilayered daily reality for the sake of current political goals.
If nothing else, in order to forgive, we have to know what we are forgiving.
In Eastern Europe today, old and young alike stand to benefit from that lesson.
Moses wandered with his people in the desert for 40 years, until they had rid themselves of the poisonous slave mentality.
India’s Prohibition Hypocrisy
NEW DELHI – Last month, 18 people in the Gopalganj district of India’s Bihar state died after consuming illicit alcohol, highlighting – once again – the peculiar relationship between morality and tragedy in India.
The victims were poisoned because this April, in a fit of moralism, Bihar adopted a draconian law prohibiting the sale, possession, and consumption of alcohol.
It is far from the first such ban that has ended badly.
In a country where the national hero is the saintly Mahatma Gandhi, who considered alcohol an unmitigated evil, drinking has always carried a whiff of disrepute.
India’s constitution, in its non-enforceable Directive Principles, urges Indians to work toward prohibition, and the government does not serve alcohol even at state banquets and official receptions.
Four out of 29 Indian states (Bihar, Gujarat, Manipur, and Nagaland) and one union territory (Lakshadweep or the Laccadive Islands) are currently attempting to enforce total prohibition.
But maintaining a sweeping prohibition policy has long proved difficult in India.
In Manipur in 2002, the 1991 ban was lifted in five hill districts, where alcohol consumption is a centuries-old local tradition.
Lakshadweep makes an exception for an uninhabited island, where a tourist resort is allowed to operate a bar.
When I was a child, what was then Bombay excused anyone with a doctor’s note confirming alcoholism.
(Well-heeled executives tripped over themselves to be labeled alcoholics.)
The state that best illustrates the appeal and the pitfalls of such moralism is Kerala, which announced in 2014 that it was implementing a partial ban on the sale of alcohol, with the goal of achieving total prohibition in ten years.
It has been backsliding ever since.
A coastal state, Kerala has long been viewed as a tourist paradise – a reputation no doubt kept afloat on a sea of easily available libations.
Before the ban, Kerala held a somewhat dubious distinction: India’s highest per capita consumption of spirits.
But in India, where prohibition is popular among many segments of the electorate, politicians find it particularly difficult to resist the self-righteous urge to improve their fellow citizens.
So Kerala’s government introduced the ban.
And, at first, many approved.
The influential Christian churches applauded the move, as did the Christian-affiliated political parties.
Kerala’s Muslim leadership, including the then-ruling coalition’s ally, the Indian Union Muslim League, was equally vocal in its support.
Working-class women, tired of watching their laborer husbands blow their monthly wages on booze, also welcomed the decision, as did traditionalists, Gandhians, and other moralists, of which India has an abundance.
No public figure of any consequence in Kerala stood up to oppose the decision.
Any politician who might have been inclined to do so knew that they would be instantly tarred as a votary of evil alcohol, an agent of the “liquor mafia,” a bar-loving enemy of good, wholesome Gandhian values.
But there were good reasons to oppose the ban – reasons that had nothing to do with religion, morality, or alcoholism.
Excise duties on liquor account for 22% of the state revenues that sustain generous welfare programs in Kerala, which boasts the best social development indicators in India.
Another 26% of state revenues come from tourism, which would surely also take a hit.
Furthermore, much of Kerala’s economic viability depends on dynamic knowledge and services sectors.
Attracting talent and investment from abroad would become much more difficult if prohibition hampered the state’s quality of life.
(IT professionals in Bangalore, in the neighboring state Karnataka, flock to that city’s bars and pubs after long hours at work.)
Kerala’s leaders should have known that their state could not afford to do without widely available, heavily taxed liquor.
But they began to implement the policy anyway.
Almost immediately, 20,000 bar workers and distillery employees lost their jobs, in a state that already struggles with high unemployment.
Tourism operators were stung by cancelations, as would-be visitors decided to visit Sri Lanka or Goa instead; 50% of existing convention bookings were canceled.
And IT companies contemplating moving to clean, green, tech-friendly Kerala expressed concern about the prohibition policy.
It was not long before Kerala’s government decided that prohibition would apply only to hard alcohol, and closed bars could reopen as wine and beer parlors.
But that was not enough to save the government in June’s state election, which produced a new communist administration that, advocating education about the evils of alcohol instead of a ban, has promised to review the prohibition policy.
So Kerala is no longer hurtling toward disaster in the name of saving people from themselves.
But it never should have gone as far as it did, given experience with prohibition in other states, where falling revenues and rising crime (including smuggling, tax evasion, and illicit liquor production) forced its revocation.
Four states – Andhra Pradesh, Haryana, Mizoram, and Tamil Nadu – have repealed prohibition policies.
To be sure, not everyone loses out from a prohibition policy.
When Kerala first announced its plans, neighboring Tamil Nadu’s alcoholic beverages corporation, TASMAC, promptly declared its intention to open a string of new outlets along the states’ border, to cater to the demands of Keralite consumers.
In other words, excise duties from Kerala would now fill Tamil Nadu’s coffers.
Banning alcohol in India has been economically devastating.
Yet politicians continue to use the promise of prohibition to win votes.
When elections were called in Tamil Nadu early this year, its chief minister declared herself in favor of prohibition.
After the election was won, however, all such talk discreetly subsided.
My late father liked to say: “India is not only the world’s largest democracy; we are also the world’s largest hypocrisy.”
I suppose we can drink to that.
Leaders for a Leaderless World
PARIS – The newspaper commentaries that I write often have a dark perspective.
Sadly, this one will be no different.
But there are two pieces of good news that break through the gloom.
First, the global significance of US President Barack Obama’s reelection is clear: the world has escaped a disaster for international cooperation.
The US was on the verge of sinking into isolationist nationalism, reinforced, perhaps, by xenophobic sentiment.
Obama’s victory, despite America’s economic travails, clears the way for cooperation based on a sympathetic ear to others and on negotiations in which the US does not deny the legitimacy of a global public interest (as it has done, unfortunately, on the issue of climate change).
The other piece of good news concerns France, and thus is more “local,” but is crucially important nonetheless.
Like everywhere else in the developed world, the global crisis has hit the French economy hard, with output stagnating, unemployment rising, job insecurity mounting, government debt soaring, and the stock market at risk of crashing.
Manufacturing production has plummeted, the trade balance has deteriorated sharply, and corporate bankruptcies are increasingly frequent.
For six months, France has had new leadership – a new president, government, and parliament.
But President François Hollande and his government were strangely inactive after the elections, limiting themselves to reducing the impact of unfair budget cuts and taxation reforms implemented by the previous government of Nicolas Sarkozy.
Many began to wonder whether Hollande was aware of the scope of the crisis that the recent downturn might trigger.
In recent weeks, however, the government has introduced energetic and courageous measures to boost the competitiveness of French industries, including a huge €20 billion ($26 billion) tax break for businesses, to be financed by a hike in value-added tax, which means that the general public will pay for it.
The VAT increase will hurt, but there was no other way.
Awareness, boldness, and comprehensive policymaking have come as a relief to French investors, and have left them better positioned to face the crisis.
The French government’s new push to confront the country’s economic plight matters not only to France, but to Europe and the world as well.
After all, France is the eurozone’s second-largest economy, and the fifth-largest economy in the world.
And yet, despite these bright spots, international cooperation on issues ranging from regional conflicts to the protection of global public goods remains weak.
Antarctica, the only land in the world that is administered directly by the international community, is a recent case in point.
The Antarctic Treaty, negotiated in 1959, prohibits any and all military activities in Antarctica and forbids the establishment of any borders.
Three agreements – the Convention for the Conservation of Antarctic Seals (1972), the Convention on the Conservation of Antarctic Marine Living Resources (CCAMLR, 1980), and the Protocol on Environmental Protection to the Antarctic Treaty (PEP, 1991), which prohibits any activity relating to mineral resources – have since been added to the treaty.
The Antarctic Treaty System includes three annual meetings: one deals with the supervision and management of the Treaty itself, and the other two concern the CCAMLR and the PEP.
In recent years, proposals have been considered that would establish marine reserves around the continent and end the risk of growing scarcity, or the outright disappearance, of a variety of species of fish and cetaceans.
The principle that international cooperation is required to protect fishery resources, which are dwindling everywhere, was adopted at the 2011 CCAMLR meeting.
At the 2012 CCAMLR meeting, which concluded at the beginning of November in Hobart, Australia, three proposals (from the US, New Zealand, and France/Australia) to establish marine reserves in three different areas were discussed.
They were compatible and would reinforce one another.
Yet the discussion foundered, and no decision was taken.
Russia and Ukraine – and, to a lesser extent, China – blocked efforts to reach an agreement.
This failure reflects the same dynamic at work in the breakdown of global climate-change conferences in recent years: a few cynical countries, whose cooperation is needed to save the planet, fuel the madness of those bent on destroying it.
That will not change until a new consciousness emerges worldwide to persuade states to support binding international law.
The US has now reelected a president who understands this.
France has a president who understands the need for bold, far-reaching actions as well.
Their active leadership, and that of others, is needed now more than ever to turn the tide.
Assured Mutual Dependence
LONDON – During the Cold War, the certainty of “mutually assured destruction” steered the nuclear arms race away from catastrophe: a would-be attacker would face immediate retaliation, inevitably ending in both sides’ annihilation.
Today, a very different race is taking place – a race for the earth’s vital resources, and it threatens to undermine stability in key regions of the world.
The growing dependence of countries on one another’s food, water, and energy requires that the global response to sustainability is taken to the highest political level.
Unlike the nuclear arms race of the twentieth century, the resource-security agenda is not linear.
Mutually assured destruction was explicitly acknowledged during the Cold War in statements from both sides.
In the race for resources that defines the twenty-first century, no actor is directly or indirectly threatening other players to curtail food or energy exports, but all bear the systemic risks.
Countries have become unavoidably interdependent, and climate change, water stress, and the loss of ecological resilience all increase the volatility of this mutual dependence.
In a world of limited and scarce resources, countries and companies will be forced to make decisions that affect one another’s security.
In order to navigate this interdependence, the Earth Security Index 2014, produced by the Earth Security Initiative, shows countries’ combined vulnerabilities that might increase the risk exposure of governments and companies, unless more strategic approaches and sustainable investments are put in place.
The ESI identifies four areas of mutual dependence that will likely shape global security in the coming decades:
·         Choke points.
Countries’ growing demand for energy, water, food, and land cannot be satisfied without incurring tradeoffs among limited available resources.
Choke points are reached when the available resources are insufficient to satisfy demand.
In China and India, for example, this means that in certain regions there may not be enough water in the short term to run coal-fired thermal power stations and irrigate large fields to grow crops.
In China, 60% of planned coal-fired power plants will be built in water-stressed regions.
·         Food.
The growing dependence of many countries on food, water, and energy imports creates new opportunities for trade and investment, but it also exposes countries to critical vulnerabilities.
Australia, for example, is a large coal exporter but imports most of its refined fuels and holds just three days of fuel stockpiles.
The challenges of mutual dependence are particularly acute with respect to food.
As the ESI shows, some countries – including Egypt, Peru, and the United Arab Emirates – are heavily dependent on cereal imports from a small number of suppliers.
Moreover, grain suppliers’ exposure to extreme weather may compromise their ability to sustain supplies, with knock-on effects for import-dependent countries.
In 2010, for example, Russia imposed an export ban on wheat, following a severe drought.
The resulting food-price increases are believed to have played a role in Egypt’s revolution.
·         Teleconnections.
Anticipating systemic ecological risks will be increasingly important for sectors such as reinsurance and infrastructure investments.
“Teleconnections” refer to weather events that are related to one another over large geographic distances.
They are well known to science but not properly discussed by the industries, investors, and governments whose security depends on environmental stability.
For example, tropical rainforests play a crucial function in maintaining stable weather and rainfall, acting as a “pump” that helps moisture travel between different regions.
Deforestation can thus have a destabilizing effect on weather patterns, amplifying the frequency and severity of extreme events such as floods and droughts.
The resulting liabilities to key industries and the financial sector are clear.
In Brazil, for example, deforestation in Amazonia has slowed significantly over the last five years, but Brazil has already lost more than 11 million hectares of rainforest; its exposure to extreme weather has also steadily risen, with floods causing $4.7 billion in losses in 2011 alone.
·         Land productivity bottlenecks: Agriculture systems are reaching resource limits, and persistent governance gaps compromise their ability to ensure food security, dignified livelihoods, and ecological stewardship.
Companies, investors, governments, and communities confront a series of critical barriers to increasing the food availability that the world needs: Local populations’ insecure land ownership; receding water tables, owing to unsustainable extraction rates; inefficient use of pollution-causing inputs like fertilizers and pesticides; the loss of vital ecosystems, affecting the resilience of food production; and certain areas’ inability to cope with extreme weather.
In some regions of India, for example, these issues are playing out in tandem.
Insecure land tenure acts as a disincentive for smallholder farmers to commit to productivity-enhancing investments; water extraction rates are depleting aquifers as a result of permissive policies; and food security remains out of reach for millions of people, despite rapid economic growth in urban areas.
Countries and companies will increasingly need to invest in sustainable land in order to hedge their resource risks.
In 2015, global frameworks are due to be agreed to address climate change, coordinate responses to natural disasters, and guide the world’s development agenda.
Some of these multilateral processes – in particular, those seeking an ambitious global climate agreement – appear to be moving in slow motion and against the grain of geopolitical interests.
In the past, the case for high-level nuclear governance was urgent and clear, but required processes for creating a common understanding of risks and opportunities across national borders.
Successful multilateral responses, like the Nuclear Non-Proliferation Treaty, continue to be supported by more flexible global platforms, such as the Nuclear Threat Initiative, based on relationships and trust established outside the box of formal multilateralism.
This year, as world leaders discuss the next generation of sustainability, development, and climate frameworks, they will need to put their security and mutual dependence at the heart of the responses.
Here, too, the world will need to create informal platforms that supplement traditional multilateralism.
In particular, the outdated divisions between rich and poor countries and their responsibilities must be revised.
As new powers like China, Brazil, India, and other G-20 economies bid to reform global governance systems, their vulnerability to resource security must invigorate these processes.
Only then will the world be on track to improve the security of all.
After Aleppo
DENVER – The end of the fighting in Aleppo will not end the Syrian war, despite the countrywide ceasefire that has just been agreed.
Nor will it ease the suffering of the city’s population, much of which has been displaced.
What the Aleppo siege will do is clinch Syria’s place in history as, to borrow former US Secretary of State Warren Christopher’s phrase, another “problem from hell.”
And, like other hellish recent regional conflicts, such as those in Bosnia (to which Christopher was referring) and Rwanda, future historians will emphasize a crucial feature of the Syria conflict: the spectacular diplomatic failures that enabled it to escalate.
Good diplomacy begins with a keen analysis of interests, both of the country in question and of relevant external powers.
It demands a careful assessment of how the pursuit of those interests will affect the regional and international order.
And it seeks ways to strengthen the capacity of regional or world powers to help solve problems.
Throughout this process, universally shared and consistently reinforced values – both critical in getting disparate actors to work together to resolve problems and challenges – must provide a moral compass and common ground for action.
The key is to ensure that values do not become weapons, deployed by one actor against another in a way that exacerbates tensions and undermines solutions.
Consider the 1990s Bosnian War – the result of unfinished business from the breakup of the Austrian and Ottoman empires and the creation of nation-states earlier in the twentieth century.
The conflict erupted in the immediate aftermath of the Cold War, at a moment when one set of international organizing principles had collapsed and a new set had not yet been created.
Partly as a result of this, the conflict was characterized by large-scale civilian carnage and human-rights violations.
But, as a test for the new world order, the Bosnian War ended up catalyzing change in the international community’s institutional structure (including the establishment of war crimes tribunals).
Could the nascent post-Cold War system handle the inchoate problems of the former Soviet Union?
Could NATO take on new roles and missions?
Could the West work with the new Russian Federation?
Could the transatlantic relationship weather the storm?
The answer to all of these questions turned out to be yes.
As a result, though the region continues to be beset by serious problems, the gates of hell have remained closed – as they have in Rwanda.
And yet, just 20 years later, it seems that the world’s collective memory of how to cooperate has failed.
To be sure, there was never a clear path to peace in Syria.
President Bashar al-Assad, whose forces now control all of Aleppo for the first time since 2012, is a brutal dictator who has waged war on his own people, including civilians, and has even used chemical weapons.
The temptation to seek regime change – a goal embraced by the United States and some European countries – was understandable.
Yet, in a display of spectacularly incompetent diplomacy, the US set about pursuing that goal without any serious effort to marshal international support, or even to take stock of other opinions or interests.
And make no mistake: there are a lot of (often conflicting) opinions and interests.
After all, Syria is strategically perched on the Mediterranean; shares borders with Israel, Jordan, Turkey, and Iraq; and, like Iraq, has its own restive Kurdish minority.
It is not the kind of country to which international and regional powers would be indifferent.
In fact, when Western powers called for regime change, other actors – including Iran, Russia, and Shia interests in neighboring Lebanon – objected.
Nonetheless, the US soldiered on with its own poorly formulated agenda, supplying weapons to virtually unknown combatants on the ground before properly vetting them.
That gave the Assad regime’s allies all the justification they needed to supply weapons of their own.
Some argue that, if the US had just provided more weapons sooner, Assad would not have had time to galvanize support and hold onto power.
But that neglects the strategic importance of Syria to so many external powers, as well as the fragmentation and unpredictability of the US-based combatants.
America’s real mistake was failing to engage with all sides, including Assad and the Sunni opposition, which it deemed sectarian.
(During the Bosnian War, by contrast, the US talked to rump Yugoslavia’s ruler, Slobodan Milošević.)
With that narrow-minded approach – reflected in the lack of any articulated vision for a post-war Syria – the US effectively handed the diplomatic reins over to Russia.
Now, the US is essentially playing the role of agitator, offering little more than displays of moral outrage and stale references to a stillborn Geneva process.
Reacting to the carnage in Aleppo, Samantha Power, the US ambassador to the United Nations, was reduced to demanding of Assad’s Russian ally, “Are you truly incapable of shame?”
Meanwhile, the conflict rages on, with severe spillover effects on US allies like the European Union.
As for Russia, it, too, is pursuing a version of diplomacy that utterly lacks inclusiveness.
It is working with Turkey (a NATO member that seems increasingly lost at sea) to bring the Syrian opposition and representatives of the Assad government together in Kazakhstan for a new series of peace talks, facilitated by the ceasefire, of which Russia and Turkey are guarantors.
Iran will be there.
But where are the Sunni Arab states?
More important, where is the US?
It is often observed that, every four years, the US does without a foreign policy.
This time, it seems to have gotten an early start.
A Less-is-More Growth Strategy for Africa
REYKJAVIK – If African countries were to adopt only one policy to boost economic growth and improve macroeconomic stability, they should reduce the number of currencies in circulation across the continent as quickly as possible. Doing so would most likely encourage trade, as happened in Europe with the arrival of the euro, and could help contain inflation – which is always good for growth – by imposing international discipline on monetary policy.
The African Union is now aiming at pooling all the continent’s currencies into a single currency by 2028.
In the meantime, several regional monetary unions are on the drawing board, in addition to the two monetary unions that already exist, one
The premier and oldest of these unions is composed of the fourteen countries that belong to the Economic and Monetary Community of Central Africa and the West African Economic and Monetary Union, which both use the CFA franc.
The second of these unions is composed of Lesotho, Namibia, Swaziland, and now Zimbabwe, all of which use the South African rand. Disregarding Zimbabwe, a recent and incomplete convert, the 18 countries of the two existing monetary unions have, as intended, benefited from lower inflation than much of the rest of Africa.
To see why, consider Nigeria. Before independence, Nigeria’s legal tender was the British pound.
With the establishment of the Central Bank of Nigeria in 1959, the Nigerian pound was introduced. Back then, one Nigerian pound was equivalent to one British pound.
This arrangement remained intact until 1973, when Nigeria adopted a new currency, the naira. The exchange rate remained unchanged: one naira was equivalent to one British pound.
The naira was intended to bolster the country‘s independence by making it possible for the central bank to pursue its own monetary policy.
It was also a matter of national pride.
The thinking behind the new arrangement was that an independent and flexible monetary policy would serve the nation‘s interest better than a fixed exchange rate that tied the naira to the pound.
But the naira’s introduction quickly put an end to parity with the British pound. Government expenditure exceeded federal revenue, despite rapidly rising foreign-exchange earnings from oil exports after 1970.
The federal government’s budget deficits were financed through foreign and domestic borrowing, and by printing money, which led to inflation and depreciation of the new currency. Today, it costs 220 naira to buy one British pound, which implies 15% annual average depreciation since 1973.
This depreciation would perhaps be justifiable had Nigeria managed to use easy money to narrow the gap between ordinary Nigerians’ standard of living and that of people living in Britain.
But that did not happen.
The purchasing power of national income per person in Nigeria is now 50% lower relative to Britain than in 1980.
In view of this experience, Nigeria now plans to abolish the naira in favor of joining a monetary union with four or five other West African countries (The Gambia, Ghana, Guinea, Sierra Leone, and perhaps Liberia).
But that planned monetary union, until recently envisaged to be launched in 2009, has now been put on ice.
Why? The smallest countries show no signs of fear of being swamped by Nigeria, by far the most populous country in the group (accounting for 155 million of the six countries’ 200 million people), especially as the new West African Central Bank is to be located in Accra, the capital of Ghana (24 million).
Others, though, may fear the dilution of their sovereignty when the new Central Bank of the
takes over some of the policymaking responsibilities of national central banks.
But that, of course, is the chief purpose of a monetary union.
When the West African Monetary Zone finally is established, the number of currencies in Africa will equal about half the number of countries.
And when the East African Community with its five members (Burundi, Kenya, Rwanda, Tanzania, and Uganda) re-emerges as scheduled, the number of currencies will be reduced by another four.
The belief that sovereign national currencies, by enabling independent and flexible monetary policies, are the best way to foster economic and social development – the vision of Nigeria’s post-colonial leaders – is gradually falling by the wayside.
Efficiency dictates the use of fewer and larger currencies (and foreign investors, understandably wary of weak and volatile currencies, demand it).
Indeed, the success of the European Union and of the euro since its launch in 1999 has made a strong impression in Africa.
Alexander Hamilton’s Eurozone Tour
PRINCETON – Europe’s debt crisis has piqued Europeans’ interest in American precedents for federal finance.
For many, Alexander Hamilton has become a contemporary hero.
Perhaps one day his face should appear on the €10 banknote.
Specifically, for European states groaning under unbearable debt burdens, Hamilton’s negotiation in 1790 of the new federal government’s assumption of the states’ large debts looks like a tempting model.
Indeed, after Thomas Sargent won the Nobel Prize in Economics last year, he cited it as a precedent in his acceptance speech.
Hamilton argued – against James Madison and Thomas Jefferson – that the debts accumulated by the states during the War of Independence should be assumed by the federation.
There were two sides to his case, one practical, the other philosophical.
Initially, the most appealing argument for his plan was that it would provide greater security to creditors, and thus reduce interest rates, from the 6% at which the states financed their debt to 4%. Hamilton emphasized the importance of a commitment to sound finance as a prerequisite to public economy.
“When the credit of a country is in any degree questionable,” he argued, “it never fails to give an extravagant premium upon all the loans it has occasion to make.”
While that logic certainly appeals to Europeans today, Hamilton insisted on a stronger reason for pursuing sound finance than merely the pursuit of expediency.
There is, he maintained, “an intimate connection between public virtue and public happiness.”
That virtue consisted in honoring commitments, and it would build solidarity in the new political community of the United States.
Indeed, public virtue made federal finance what he called “the powerful cement of our union.”
The condition for success in the American case was that the US raised its own revenue, with federally administered customs houses initially providing the bulk of its receipts.
The logic of a need for specific revenue applies also in modern Europe, where a reformed fiscal system might include common administration of value-added tax (with the additional benefit of eliminating a considerable amount of cross-border fraud).
In the American case, however, unity carried a price: a ceiling was imposed on Virginia’s exposure to the common debt.
Only this inducement to the most powerful state in the union persuaded Madison to drop his opposition to the proposal.
That compromise (which also led to the US capital’s relocation to the District of Columbia, on the border of Virginia and Maryland) may serve as a precedent for limiting Germany’s liabilities if Eurobonds, or some other debt-mutualization scheme, are introduced.
The US experiment in federalized finance was not immediately successful.
Two important components of Hamilton’s financial architecture were not realized, or were realized imperfectly.
He proposed a model of joint-stock banking on a national scale, which ran into immediate opposition (curiously, his proposal was much more influential in Canada).
Second, opponents eventually blocked his proposal for a national central bank.
The charter of the First Bank of the United States was allowed to lapse in 1811; a generation later, in 1836, President Andrew Jackson successfully opposed the charter of the Second Bank of the United States.
Nor did the Hamiltonian scheme of federal finance guarantee a peaceful commonwealth.
In fact, the fiscal union proved to be explosive rather than adhesive.
As international capital markets developed in the early nineteenth century, state governments borrowed on a large scale, quickly turning them from creditors into debtors.
A wave of state defaults followed in the late 1830’s.
A generation later, in the 1860’s, the Civil War between northern and southern states resulted in large part from a dispute about the character of financial burdens –amp at least from the South’s perspective.
Abraham Lincoln’s original proposal to end the immoral practice of slavery by compensating slave owners for manumission was unacceptably expensive, so the Union, according to the slave-holding Confederacy, was determined to expropriate the South.
The federal assumption of states’ debts by itself could not guarantee political order.
The Civil War revealed the centrality of a common foundation of morality to Hamilton’s approach to debt and public finance.
As a result, his approach foundered on the differences between the different states’ conception of morality.
Europeans today have latched onto the practical side of Hamilton’s argument – that is, the idea that debt mutualization might be a means to cheaper credit; but they have worked out neither the political institutions, nor the shared public virtue, that Hamilton deemed crucial.
The extended and politicized debate about debt restructuring has made a Hamiltonian solution more difficult, because the credit of the countries that would be party to it has become questionable.
An obvious starting point for a Hamiltonian Europe would be to set some standard limit for federalized national debt – perhaps the tarnished threshold of 60% of GDP that was mandated (without adequate enforcement) by the Maastricht convergence criteria, or perhaps a lower limit.
Debt exceeding that amount would be left to the responsibility of the member states.
Collective burden-sharing is in the long run the only non-catastrophic way out of Europe’s current crisis, but that requires a substantially greater degree of political accountability and control on a European level.
The lesson to be learned from Hamilton and the US is that the necessary institutions will not function without a greater degree of moral consensus as well.
How We Lose Our Marbles
ATHENS – George Clooney has reignited a longstanding debate after suggesting, in response to a Greek journalist’s question, that removing the Parthenon Marbles, known in Britain as the Elgin Marbles, from London’s British Museum and returning them to their ancient home in Athens would be “the right thing to do.”
In the early nineteenth century, the friezes and sculptures were removed from the Parthenon by Lord Elgin, Britain’s ambassador to the Ottoman Empire from 1799 to 1803.
Elgin sold them to the British government, which put them in the British Museum.
Greece wants them back.
The occasion for this latest round of historical jousting is the release of Clooney’s new film The Monuments Men, which details Allied efforts to rescue art works from the Nazis during World War II.
His comments infuriated London’s provocative mayor, Boris Johnson, himself a classics scholar and author, who shot back that Clooney’s position on the issue was similar to that of the Nazis portrayed in his film.
But the film is of less interest in this dispute than the identity of the characters involved.
Perhaps the most important question is this: Whom is the public inclined to believe – Clooney or Johnson (or perhaps the Nazis)?
Of course, one might ask why the people involved should matter at all; surely the facts of the case should speak for themselves.
And yet, on questions such as this – as with so many important political, social, economic, and cultural issues – what we come to believe is not based on the facts alone, if at all.
Sometimes we may indeed think deeply about the pros and cons of each argument, actively seeking information and data that would support one view over another; in other cases, however, we rely on a “quick and dirty” evaluation of the arguments, focusing not on evidence, but rather on an advocate’s expertise or popularity.
Social and cognitive psychologists have long understood these two basic processes in their study of “dual-process” models, which explain how we process information and eventually form an opinion.
We take the peripheral route to information processing when buying, say, a toaster on a whim, whereas we take the so-called central route – thoroughly considering technical, safety, and aesthetic features – when buying a car.
The systematic study of persuasion began during World War II, when the US Army recognized that fighting a nation mesmerized by Hitler would require bolstering troop motivation and rallying popular support for the war.
They sought help from Yale University psychologist Carl Hovland and his associates, who produced what has become a well-known model of persuasion, comprising three groups of variables related to the communicator, the audience, and the message.
Hovland drew upon ideas dating back to Aristotle’s Rhetoric, which argued that persuasiveness is built on the communicator’s ethical character, the audience’s emotional state, and the logic of the argument, the latter being the most powerful.
Psychological research has shown that any one of these three can be persuasive, depending on the speaker’s attractiveness or the audience’s predisposition.
For example, star-struck female film fans may be especially prone to believe any utterance from Hollywood’s most famous silver fox. Or, in the case of the Nazis, fear may predispose the audience to be persuaded.
But in most cases, when people are confronted with matters of great importance, they are more likely to use the so-called central route to information processing, and rightly so.
Issues of world cultural heritage, for example, deserve conscious, thoughtful deliberation of the facts.
Indeed, it is our duty, and the very basis of any successful civilization, that important decisions are made only after scrutinizing all relevant information and weighing the relative merits of every position.
Once that duty has been fulfilled, a logical person will understand that the Parthenon Marbles, long held by a former imperial power’s flagship museum, were violently severed from the rest of the Parthenon sculptures – an outrage against art and an unhealed scar inflicted by the British on the long-suffering Greek people.
At that point, only one conclusion is possible: The plundered Marbles must be reunited in their historical home and exhibited to the world as the ancient artists intended.
Persuaded?
Perhaps not – I am Greek, after all.
But do not take Clooney’s word for it, either (or Johnson’s).
Deciding the disposition of the world’s cultural patrimony is not like buying a toaster.
Peril and Promise in Algeria
MADRID – Five years after the start of the so-called Arab Spring, the hope that initially characterized those revolutions has largely been dashed.
In many cases, the revolutions have evolved into brutal and protracted internal conflicts, with no solution in sight.
Amid all of this strife, the international community has paid little attention to countries like Algeria, where the revolutionary spirit was stifled while still incipient.
But Algeria’s fate is back on the world’s radar – and not a moment too soon.
On February 7, Algeria’s parliament approved a new package of constitutional reforms, which, among other things, limit presidents to two terms (President Abdelaziz Bouteflika, the last surviving leader of Algeria’s war of independence against France, has been in office since 1999) and recognize some fundamental freedoms.
These steps, in the making since 2011, aim to strengthen Algeria’s democratic standing; but they have been widely criticized as insufficient.
What is not in doubt is that the reforms come at a sensitive time, when Algeria is plagued by political and economic uncertainty.
The “consensus” that supposedly shapes Algerian politics has, in fact, paralyzed decision-making for many years now.
With the ailing Bouteflika not seen in public for more than a year, important questions have emerged about how the 2019 presidential election will play out.
Efforts over the last three years to curtail the power of the security and intelligence services – in September, Mohamed Mediene, who had been chief of the intelligence services since 1990, was forced to retire – are just one source and manifestation of domestic political tension.
Significant external challenges have exacerbated Algeria’s situation.
In particular, with the oil and gas industry accounting for fully 97% of Algeria’s export income, the sharp decline in oil prices since June 2014 has underscored the unsustainability of the country’s economic model.
Falling oil revenues mean that Algeria’s government cannot maintain the broad array of subsidies that traditionally served as a social balm, helping prevent protest.
The government has already had to increase some taxes, while raising prices for fuel, electricity, and gas.
If the price of oil does not rise soon, and Algeria’s leaders are forced to take more drastic measures, social stability could be jeopardized.
To be sure, some factors may help to stave off social unrest – namely, the population’s memories of the brutal civil war of the 1990s, in which more than 150,000 people were killed.
But, memories fade as time passes, and a new generation of young people lack the same fear of social strife that their parents and grandparents have.
In this social context, and if economic hardship persists, protests and even revolt may not be a distant prospect.
To avoid such an outcome, Algeria’s government must work fast to diversify the economy.
But such concerted action will be difficult in the current political environment, especially in view of the government’s increased focus on security challenges in Algeria’s neighborhood.
Given the revolution in Tunisia, the war in Libya, the rebellion of the Tuaregs in Mali, and, most important, the 2013 terrorist attack on Algeria’s large In Amenas gas plant, the country’s leaders are placing an increasingly high priority on regional security.
Although the constitution explicitly prohibits military intervention in other countries, Algeria has a clear interest – reflected in its foreign policy – in ensuring that its neighbors are stable and capable of dissuading extremist groups.
For example, in Libya, Algeria has defended a process of inclusive national reconciliation of all forces, in support of efforts by the United Nations to stabilize the country.
The United States and Europe have already recognized Algeria’s leadership and cooperation in anti-terror efforts in its neighborhood.
For the European Union, a further strengthening of ties with Algeria is particularly important, given both sides’ interest in the stability of nearby North Africa and the Sahel, as well as Algeria’s potential to help improve the EU’s energy security.
One key way Algeria can help improve security cooperation in its region would be to restore diplomatic relations with Morocco.
True, the countries have been at loggerheads for 40 years, owing to their sovereignty dispute over Western Sahara.
But the economic, commercial, and security-related dividends that renewed cooperation would provide should be enough to persuade them to reconsider this position.
If the two North African giants were to recognize their mutual interests and reestablish ties, they would disentangle relations in the Maghreb.
Algeria’s influence across Africa would also receive a boost.
Already, Algeria’s Africa-wide influence may be set to grow.
Some have suggested that an Algerian candidate could become Chair of the Commission of the African Union when the current term expires next July.
Here, Algeria’s consistent support for the AU and its commitment to regional security – exemplified in its role in the Mali peace agreement and its hosting of the Libya talks – would speak in its favor.
If successful, Algeria would become the first North African country to lead the AU.
The severe challenge posed by falling oil prices and a jittery regional context attest to the urgent need for change in Algeria.
But if the government acts to unblock the political system, diversify the economy, and ramp up diplomatic efforts, Algeria can emerge stronger and more influential than ever.
A Sunni-Shia Bridge Too Far
BAGHDAD – Iraq’s recent parliamentary election, the first since United States troops left the country in 2011, was held amid a rising tide of violence that is fast approaching the levels experienced during the 2005-2007 insurgency.
Can the new government restore order and address the many immense challenges that Iraq faces?
The challenges are indeed daunting.
The authorities must resolve fundamental constitutional questions (such as whether Iraq should be a federal state or a confederation), rebuild civil society, reform state institutions, reconstruct the economy, and end the waste and corruption in the oil sector.
But perhaps the most intractable challenge of all is bridging the sectarian rift between the country’s Shia and Sunni citizens.
These fissures are mirrored in other Arab countries (such as Syria, Lebanon, the Gulf countries, and Yemen) and, increasingly, in the wider Muslim world (including Pakistan, Malaysia, and Indonesia).
Is this a historical aberration, or are Islam’s two largest sects condemned to perpetual mutual hostility?
Certainly, there have been periods when the two communities have coexisted peacefully.
But what matters today is that Shia and Sunni relate to their past differently, and that this historical memory can be distorted – and even invented – to create mistrust and hate.
The overthrow of the first Muslim dynasty, the staunchly anti-Shia Umayyads, in the year 750, by the Abbasids, who traced their lineage to the Prophet Muhammad’s uncle, raised hopes, albeit short-lived, of a Sunni-Shia rapprochement.
The 500 years of Abbasid reign that followed provide many valuable illustrations of how these two communities subsequently related to each other.
In particular, there is much to be learned from the different legacies of the caliph al-Nasir (1180-1225) and the last Abbasid caliph, al-Musta’sim (1242-1258).
The rule of al-Nasir – who viewed the Shia as an intrinsic part of the Islamic community and sought to treat all of his subjects equally – was characterized by a marked decrease in sectarian tensions.
By contrast, Sunni-Shia clashes – including killings, arson, and other violence – were common during al-Musta’sim’s rule.
These examples demonstrate the importance of good leadership when communities that uphold different claims to the truth are subject to the same political authority – especially when these communities seek assurance that their survival is not threatened.
Iraq’s current political leaders need to learn from this past and ensure that none of the country’s communities face marginalization or discrimination – lessons that apply throughout the Muslim world.
In Pakistan, for example, there are sectarian killings almost daily; in Malaysia, the tiny Shia population is viewed as an existential threat; and incendiary language dominates discourse about rival sects in Wahhabi circles in Saudi Arabia and far beyond.
Politics and power struggles explain much of the violence and mistrust.
Fear of Iranian-led hegemony, for example, has focused Gulf leaders’ minds on their Shia population’s loyalty.
Malaysia’s political parties use anti-Shia animus to spread fear, helping to attract votes and consolidate power.
Syria and its regional allies are determined to protect a new regional balance of power that shifted in their favor following the US-led invasion of Iraq.
But political calculation cannot explain everything.
The fall of Saddam Hussein in 2003 provides a good example of how a political event, viewed through a sectarian lens, can be interpreted differently.
The US destruction of the Iraqi state brought about a precarious new order that sought to redress years of Sunni dominance by favoring the Shia.
However, the shock of sudden Sunni disempowerment generated a discourse, widely shared in the Muslim world, in which the Shia are guilty of collusion in the US occupation of the country – a view reinforced by events in Syria.
According to this thesis, the Shia simply reverted to their “historic” role as wreckers and fifth columnists.
Was it not the case, it is claimed, that the Shia also colluded with the Mongols in the fall of Baghdad in 1258, culminating in the death of the last Abbasid caliph and the destruction of the Abbasid Empire, the “universal state” of Muslims?
Several medieval Muslim historians pointed to the role of the Shia vizier Ibn al-‘Alqami, arguing that he plotted with the Mongols to bring down the caliphate.
Once the preserve of a handful of scholars, the Ibn al-‘Alqami story now plays a prominent part in today’s Sunni- Shia disputes.
Indeed, “‘Alaqima,” the plural form of the Arabic name “‘Alqami,” is now applied to the Shia as short-hand for treachery.
Social media forums are replete with polemics about the Shia role in assisting both Mongol and US invaders.
Many even claim that Iraq’s Shia are al-‘Alqami’s descendants, and that Nouri al-Maliki, Iraq’s Prime Minister, is his modern incarnation.
These diatribes reflect Iraqi’s polarized historical memory.
Despite ample historical evidence of peaceful inter-communal relations, many people – whether through simple ignorance of history or the need to assert the supremacy of one version of the truth – prefer to consecrate narratives of treachery and betrayal that perpetuate hatred.
More important, the current situation reflects a lack of wisdom, responsibility, and basic decency on the part of political and religious leaders, who prefer to fuel, rather than dampen, inter-communal strife.
Sadly, intolerance has now become a generalized condition.
There is too little knowledge about other communities’ beliefs and history, and what little exists has been overwhelmed by sectarian anger and its poisonous rhetoric.
As long as Sunnis and Shia refuse to think about their past together, it is difficult to foresee a tranquil future together.
And if political and religious leaders are unable or unwilling to seek accommodation, it will be up to like-minded individuals, groups, and civil-society institutions to rebuild mutual respect and find ways to cooperate.
Doing so will require knowledge, patience, and, above all, open minds and hearts.
All in the Family
MUNICH – Big economic crises often cause iconic companies to falter.
Rupert Murdoch’s media empire is a model of the modern global enterprise.
A particularly dynamic and innovative business model came from outside and took over central aspects of British and then American public life.
That model is now threatened by the fallout from the scandal that started with phone hacking in Murdoch’s British press operations.
The Murdoch experience is a microcosm of how modern globalization works.
Murdoch always looked like a foreign intrusion into British life. It was not just that he was Australian; he also brought new ideas.
In particular, the application of digital technology, introduced after a ferocious struggle with the powerful print unions, brought substantial cost savings and allowed a new era of journalism.
Even more importantly, Murdoch represented a concept of family business that is common in many parts of the world, but relatively rare in Britain and the United States.
Family capitalism in the continental European model uses relatively little capital to achieve maximum control.
It frequently depends on very complex corporate structures, with multiple layers of holding companies, as well as privileged shares that can guarantee the continuation of control.
This sort of firm is also very common in the most dynamic emerging-market economies in Asia and Latin America.
The Murdoch family holds only 12% of the shares of News Corporation, the top-level holding company, but it wields about two-fifths of the voting rights; other votes are held by a loyal Saudi prince.
For decades, academic analysts have been fighting over whether such large-scale family businesses should be considered beneficial.
Their defenders point out that such companies often have a much longer-term vision than is true of managerial capitalism, which enables them to establish strong and enduring relationships with their customers and suppliers.
At least in the case of the Murdoch empire, it now appears that they pursue long and binding relationships with politicians and the police as well.
Indeed, political entanglements are one of two sources of weakness in European-style family capitalism, as owners seek political advantages and preferred access as much as they strive for technical innovation.
Murdoch’s empire depended on its closeness to politicians.
In retrospect, three successive British prime ministers – Tony Blair, Gordon Brown, and David Cameron – were on overly familiar terms with a manipulative business leader.
Cameron now talks about the need for “a healthier relationship between politicians and media owners.”
And Murdoch apparently is now saying that he wishes that all these prime ministers would “leave me alone.”
The second notorious weakness of family businesses is the problem of succession.
When he appeared before the British parliament in July, Rupert Murdoch looked like an old man, remote and out of control.
In old-style family firms, there is a clear rule of succession that the oldest son takes over.
But that rule is rightly recognized as being potentially dysfunctional.
There is obviously no guarantee that the oldest son is the best businessman, and the result could be bitter and ferocious sibling rivalry.
Such succession disputes become even more acute when there are multiple marriages and multiple sets of competing children.
Until the eruption of the current scandal, the youngest of Murdoch’s three children from his second marriage, James, was generally believed to stand the greatest chance of succeeding his father.
The complexities of modern marriage patterns make family life much more fraught, especially when phenomenal power and huge sums of money are involved.
All three of Murdoch’s marriages have produced children, though those from his current relationship are too young to be considered potential corporate successors.
In addition, succession planning can become complicated by the emergence of “substitute children” from the company’s management.
Rebekah Brooks, the editor of The News of the World at the beginning of the phone-hacking scandal, and subsequently the chief executive of News International, Murdoch’s British subsidiary, played precisely such a role.
The disintegration of the business empire is then accompanied and amplified by bitter disputes between the children and the substitute children.
Indeed, the crisis of the Murdoch family’s business empire is neither unique nor unprecedented.
In the first half of the 1990’s, many observers of the alleged Asian economic miracle emphasized trust and families’ capacity to cooperate with political authorities in order to realize long-term growth plans.
After the 1997-1998 Asia crisis, and as authoritarian regimes in South Korea and Indonesia disintegrated, these relationships were suddenly interpreted as corrupt, and the counter-view – that “crony capitalism” had become entrenched in these countries – soon prevailed.
The Arab Spring has been in large part a movement against corrupt family capitalism, embodied not only in ruling families like the Ben Alis, the Mubaraks, and the Assads, but also in the large family business empires that depended on and supported them.
As a result of globalization, large family firms could increase their size and their geographic range.
But globalization also increases the chances of backlashes that focus on the vulnerabilities, weaknesses, and mistakes of big family firms.
They are vulnerable to an Arab Spring (and a British summer) – and maybe to a US autumn that will focus not just on the Murdochs’ business, but also on its interplay with politics.
All Man’s Land
NEW DELHI – Ernest Hemingway’s collection of stories, Men without Women, examines tense gender relationships.
In a particularly poignant story, a young man convinces his partner to have an abortion, viewing their unborn child as a hindrance to the status quo. Frustrated, the woman gives in.
That story, published more than 80 years ago, remains relevant today in India, where female fetuses face severe risks.
According to the 2011 census, the sex ratio of the country’s children has dipped from 927 females per 1000 males to 914, a 60-year low.
Ratios in the northern states are particularly alarming: only Himachal Pradesh now has a ratio of girls to boys above 900.
Despite being illegal, ultrasound sex-determination tests are being used across India to identify for abortion extraordinary numbers of healthy female fetuses.
But there are serious concerns about legal operations, too.
Genitoplasty – a sex-change operation on newborn girls – is a mushrooming, and deeply disturbing, business in India.
There’s only one word for it: gendercide.
Left unchecked, it will leave India’s next generation of men with a severe shortage of women.
Indian couples have a strong cultural preference, bordering on obsession, for sons over daughters – despite the strides in education and employment that women have made over the last few decades.
Education and wealth have nothing to do with it – in fact, some of the worst-affected areas are in India’s wealthiest cities.
However discomfiting a possibility, the real culprit might be Indian culture and tradition itself.
The expenses and pressure of the dowry system, and the fact that, in most joint families, only sons inherit property and wealth, contribute to this favoritism.
Perhaps just as important is that sons typically live with their parents even after they are married, and assume responsibility for parents in their old age.
Daughters, who live with their in-laws after they marry, are viewed as amanat – someone else’s property.
In short, sons represent income and daughters an expense.
In the old days, when families typically had 5-10 children, this didn’t matter so much.
The number of sons and daughters often evened out.
But, for today’s smaller families, whether the children are two boys or two girls influences everything from financial planning to preparations for old age.
Many have argued that Indian women should stand up to their families and refuse to abort their daughters.
But Indian women want male children just as much.
Unlike Hemingway’s character, they are often more than willing to abort a girl and try for a boy.
The novelist Salman Rushdie once put the question to supporters of abortion rights: “What should be done when a woman uses her power over her own body to discriminate against female fetuses?”
This raises other questions concerning the consequences of a large shortage of girls.
Will women be valued and treasured?
Or will the oversupply of men result in more bride trafficking, sexual violence, and female suicides?
Niall Ferguson, the British historian, cites scholars who attribute Japan’s imperial expansion after 1914 to a male youth bulge, and who link the rise of Islamist extremism to an Islamic youth bulge.
“Maybe the coming generation of Asian men without women will find harmless outlets for their inevitable frustrations, like team sports or video games.
But I doubt it,” he writes.
He warns us not to be surprised if, in the coming generation, “shrill nationalism is replaced by macho militarism or even imperialism.”
Unfortunately, there is no instant solution.
Saving our girls will require radically altering some of Indian society’s family arrangements, traditions, and attitudes.
And there is no easy way to accomplish this.
Legislation alone won’t help, for tradition is a law unto itself.
Hindu religious law, for example, allows a woman to claim an equal share in her parents’ wealth, but few exercise this right.
Culturally, she feels that she does not have an equal claim on her father’s property.
Nonetheless, India does need new laws – direct and enforceable – that clamp down on the cultural practices that underpin destructive traditions.
For example, India could enforce a ceiling on wedding expenditure – typically a father’s biggest expense associated with his daughter.
Constrained from spending on the wedding, he would compensate her differently – perhaps with a larger inheritance.
Gradually, this would become the norm, and tradition would adjust accordingly.
(Interestingly, the state of Kerala, whose people adhere to matrilineal inheritance, has among the most equal sex ratios and literacy rates in India.)
A more radical measure, which some have advocated, would be direction intervene, with the state providing benefits for families with more girls.
Perhaps the authorities could also penalize families with boys, at least temporarily.
India imagines herself as a woman – Bharat Mata, or Mother India.
The irony is that, unless far-reaching changes are made soon, Mother India could eventually be the only woman left in the country.
All Stimulus Roads Lead to China
BEIJING – Now that the “green shoots” of recovery have withered, the debate over fiscal stimulus is back with a vengeance.
In the United States, those who argue for another stimulus package observe that it was always wishful thinking to believe that a $787 billion package could offset a $3 trillion fall in private spending.
But unemployment has risen even faster and further than expected.
Combine this with the continued fall in housing prices, and it is understandable that consumer spending remains depressed.
The banks, having been recapitalized only to the extent necessary to keep them afloat, still have weak balance sheets.
Their consequent reluctance to lend constrains investment.
Meanwhile, state governments, seeing revenues fall as a result of lower taxable incomes last year, are cutting back like mad.
If there was a case for additional stimulus back in February, that case is even stronger now.
But the case against additional stimulus is also strong.
The US federal deficit is an alarming 12% of GDP, and public debt as a share of national income is already projected to double, to 80% of GDP.
The idea that the US can grow out of its debt burden, as did Finland and Sweden following their financial crises in the 1990’s, seems unrealistic.
Given all this, more deficit spending will only stoke fears of higher future taxes and inflation.
It will encourage the reemergence of global imbalances.
And it will not reassure consumers or investors.
It is possible to argue the economics both ways, but the politics all point in one direction.
The US Congress lacks the stomach for another stimulus package.
It has already faced intense criticism for its failure to get the country’s fiscal house in order.
The slowness with which the first stimulus has been rolled out, and the fact that it will take even more time for its full effects to be felt, provides more fodder for the chattering classes.
Disappointment over the effects of the TARP has already destroyed popular – and Congressional – support for more public money to recapitalize the banks.
So, even those who find the economic logic of arguments for fiscal activism compelling must acknowledge that the politics are not supportive.
A second stimulus simply is not in the cards.
If there is going to be more aggregate demand, it can come from only one place.
That place is not Europe or Japan, where debts are even higher than in the US – and the demographic preconditions for servicing them less favorable.
Rather, it is emerging markets like China.
The problem is that China has already done a lot to stimulate domestic demand, both through government spending and by directing its banks to lend.
As a result, its stock market is frothy, and it is experiencing an alarming property boom.
Through May, property prices were up 18% year on year.
Understandably, Chinese officials worry about bubble trouble.
The obvious way to square this circle is to spend more on imports.
China can purchase more industrial machinery, transport equipment, and steelmaking material, which are among its leading imports from the US.
Directing spending toward imports of capital equipment would avoid overheating China’s own markets, boost the economy’s productive capacity (and thus its ability to grow in the future), and support demand for US, European, and Japanese products just when such support is needed most.
This strategy is not without risks.
Allowing the renminbi to appreciate as a way of encouraging imports may also discourage exports, the traditional motor of Chinese growth.
And lowering administrative barriers to imports might redirect more spending toward foreign goods than the authorities intend.
But these are risks worth taking if China is serious about assuming a global leadership role.
The question is what China will get in return.
And the answer brings us back, full circle, to where we started, namely to US fiscal policy.
China is worried that its more than $1 trillion investment in US Treasury securities will not hold its value.
It wants reassurance that the US will stand behind its debts. It therefore wants to see a credible program for balancing the US budget once the recession ends.
And, tough talk notwithstanding, the Obama administration has yet to offer a credible roadmap for fiscal consolidation.
Doing so would reassure American taxpayers worried about current deficits. Just as importantly, it would reassure Chinese policymakers.
We live in a multipolar world where neither the US nor China is large enough to exercise global economic leadership on its own.
For China, leadership means assuming additional risks.
But for this to be tolerable, the US needs to relieve China of existing risks.
Only by working together can the two countries lead the world economy out of its current doldrums.
A Long March with China
BEIJING – US Vice President Joe Biden’s recent four-day visit to China ended on a high note.
He assured Chinese leaders that the United States is committed to honoring all its debts, despite its recent credit downgrade; he talked enthusiastically about US-China interdependence; and he showcased his granddaughter, who has studied Chinese for several years, as a future bridge between the two countries.
But, behind all the smiles and banquet toasts, serious issues and perception gaps continue to divide the world’s two great powers.
For starters, there is always an attitude problem.
To those who view China’s rise in a negative light, the country is simply becoming ever more arrogant.
It is getting tough in its territorial disputes with Japan in the East China Sea; it is becoming assertive in the South China Sea with its neighbors, also over disputed islands; it put its own stealth fighter on display during the US defense secretary’s visit to China; it is sending its first aircraft carrier out to sea for trials, indicating the possibility of establishing naval bases in the Indian Ocean.
Even a brawl between the Chinese and a visiting American basketball team is viewed as evidence of China’s aggressive behavior.
Many Chinese, on the other hand, tend to think that the US is suffering from severe case of conceited superpower syndrome.
As these Chinese see it, the US has a rather dysfunctional government, but nevertheless insists that its political and economic system is the best in the world, and that everyone should emulate it.
It is heavily in debt, but cannot stop spending and borrowing.
It is no longer competitive in manufacturing, but blames others for its huge trade deficit.
And the world’s only military superpower is often seen within China as trigger-happy when intervening in other countries’ internal affairs.
Then, there is the issue of trust.
China’s critics argue that its claims to a peaceful rise are not credible, given the country’s non-democratic, one-party system.
Coupled with this is a zero-sum view of the world, in which any Chinese gain in the share of the global economy, or any increased presence in many parts of the world, must be at the expense of the US or other powers.
Any Chinese military move is portrayed as an expansionary and aggressive act that must be contained.
Any attempts at engagement by Western politicians, such as Biden’s recent trip, are automatically met with doubt and criticism for cozying up to dictators.
Likewise, for those Chinese who are suspicious of US intentions, conspiracy is always in play.
They see a declining superpower using economic, military, and diplomatic means in an unrelenting effort to prevent China’s rise.
Talk of human rights and democracy is nothing but a smoke screen for demonizing China.
Arms sales to Taiwan, Tibetan activism, and “color revolutions” of various kinds are all sponsored by the US and other Western powers, and are aimed at weakening China.
Despite decades of close interaction, with millions of Americans, Europeans, and Japanese visiting China every year and similar numbers of Chinese now visiting the US and other advanced countries, both sides see each other through a glass darkly.
Increased interdependence has not led to better understandings on even some of the most basic issues.
China’s Vice Minister of Foreign Affairs Fu Ying expressed her country’s anxiety about this state of affairs in a recent interview. “The most important thing is the question of whether China and the US are enemies.
Are we going to be in a war?
Are we preparing for a war against each other?”
Biden, while reaffirming that the US does not view China as an enemy, implied that Fu’s worries are not fanciful, saying that the worst scenario is a misunderstanding that leads to an unintended conflict.
So the key issue for China, its neighbors, the US, and rest of the world is not how many aircraft carriers, missiles, submarines, and next-generation fighters China may produce and deploy in the coming years and decades. Rather, it is how China intends to use its newly acquired economic and military strength in pursuing its domestic and foreign-policy goals – and how the world’s leading powers can ensure that they do not end up harming each other by accident or misunderstanding.
To meet these challenges successfully, there is no viable alternative to a positive, continuous, and frank engagement between China and the rest of the world.
The Chinese economy will continue to grow; the Chinese military will continue to modernize; and the Chinese people will remain united in their Great Power aspirations.
A Cold War-style confrontation and containment policy from the West will be met with strong resistance from the Chinese, whose global leverage, particularly in finance, cannot be ignored.
Only a patient, creative, and consistent engagement strategy will mitigate fears on both sides.
China’s rise is a fact; the enduring peacefulness of that rise must be a priority for China, its neighbors, the West, and, most importantly, the US.
Alpine Schadenfreude
Not surprisingly, the atmosphere at this year’s World Economic Forum was grim.
Those who think that globalization, technology, and the market economy will solve the world’s problems seemed subdued.
Most chastened of all were the bankers.
Against the backdrop of the sub-prime crisis, the disasters at many financial institutions, and the weakening of the stock market, these “masters of the universe” seemed less omniscient than they did a short while ago.
And it was not just the bankers who were in the Davos doghouse this year, but also their regulators – the central bankers.
Anyone who goes to international conferences is used to hearing Americans lecture everyone else about transparency.
There was still some of that at Davos.
I heard the usual suspects – including a former treasury secretary who had been particularly vociferous in such admonishments during the East Asia crisis – bang on about the need for transparency at sovereign wealth funds (though not at American or European hedge funds).
But this time, developing countries could not resist commenting on the hypocrisy of it all.  There was even a touch of schadenfreude in the air about the problems the United States is having right now – though it was moderated, of course, by worries about the downturn’s impact on their own economies.
Had America really told others to bring in American banks to teach them about how to run their business?
Had America really boasted about its superior risk management systems, going so far as to develop a new regulatory system (called Basle II)?
Basle II is dead – at least until memories of the current disaster fade.
Bankers – and the rating agencies – believed in financial alchemy.
They thought that financial innovations could somehow turn bad mortgages into good securities, meriting AAA ratings.
But one lesson of modern finance theory is that, in well functioning financial markets, repackaging risks should not make much difference.
If we know the price of cream and the price of skim milk, we can figure out the price of milk with 1% cream, 2% cream, or 4% cream.
There might be some money in repackaging, but not the billions that banks made by slicing and dicing sub-prime mortgages into packages whose value was much greater than their contents.
It seemed too good to be true – and it was.
Worse, banks failed to understand the first principle of risk management: diversification only works when risks are not correlated, and macro-shocks (such as those that affect housing prices or borrowers’ ability to repay) affect the probability of default for all mortgages. 
I argued at Davos that central bankers also got it wrong by misjudging the threat of a downturn and failing to provide sufficient regulation.
They waited too long to take action.
Because it normally takes a year or more for the full effects of monetary policy to be felt, central banks need to act preemptively, not reactively.
Worse, the US Federal Reserve and its previous chairman, Alan Greenspan, may have helped create the problem, encouraging households to take on risky variable-rate mortgages by reassuring those who worried about a housing bubble that there was at most a little “froth” in the market.
Normally, a Davos audience would rally to the support of the central bankers.
This time, a vote at the end of the session supported my view by a margin of three to one. 
Even the plea of one of central banker that “no one could have predicted the problems” moved few in the audience – perhaps because several people sitting there had, like me, explicitly warned about the impending problem in previous years.
The only thing we got wrong was how bad banks’ lending practices were, how non-transparent banks really were, and how inadequate their risk management systems were.
It was interesting to see the different cultural attitudes to the crisis on display.
In Japan, the CEO of a major bank would have apologized to his employees and his country, and would have refused his pension and bonus so that those who suffered as a result of corporate failures could share the money.
He would have resigned.
In America, the only questions are whether a board will force a CEO to leave and, if so, how big his severance package will be.
When I asked one CEO whether there was any discussion of returning their bonuses, the response was not just no, but an aggressive defense of the bonus system. 
This is the third US crisis in the past 20 years, after the Savings &amp; Loan crisis of 1989 and the Enron/WorldCom crisis in 2002.
Deregulation has not worked.
Unfettered markets may produce big bonuses for CEO’s, but they do not lead, as if by an invisible hand, to societal well-being.
Until we achieve a better balance between markets and government, the world will continue to pay a high price.
Effective Altruism
PRINCETON – Can humans really be motivated by altruism?
My new book, The Most Good You Can Do, discusses the emerging new movement called Effective Altruism, and, in doing interviews about the book, I am surprised by how often that question is asked.
Why should we doubt that some people act altruistically, at least some of the time?
In evolutionary terms, we can easily understand altruism toward kin and others who can reciprocate our help.
It seems plausible that once our ability to reason and reflect has developed sufficiently enough to enable us to understand that strangers can suffer and enjoy life just as we can, then at least some of us would act altruistically toward strangers, too.
The polling organization Gallup asked people in 135 countries whether they had, in the last month, donated money to a charity, volunteered their time to an organization, or helped a stranger.
Gallup’s results, which form the basis of the World Giving Index 2014, indicate that approximately 2.3 billion people, a third of the world’s population, perform at least one altruistic act per month.
More objective evidence of altruism buttresses these findings.
In many countries, the supply of blood for medical purposes relies on voluntary, anonymous donations.
Worldwide, more than 11 million people have put their names on donor registries for bone marrow, signifying their willingness to donate their marrow to a stranger.
A small but growing number of people have gone further still, donating a kidney to a stranger.
There were 177 altruistic donations by living donors in the United States in 2013 and 118 in the United Kingdom in the year to April 2014.
Then there are those who donate to charity.
In the US alone, individuals gave $240 billion to charity in 2013.
Foundations and corporations topped this up to a total of $335 billion, or about 2% of gross national income.
The US is often said to be more charitable than other countries; but, in terms of the proportion of the population donating money, Myanmar, Malta, Ireland, the UK, Canada, the Netherlands, and Iceland all do better.
In Myanmar, 91% of the people surveyed had given money in the past month (the corresponding figure for the US is 68%), indicating the strong hold of the Theravada Buddhist tradition of donating to support monks and nuns.
Myanmar also had the highest percentage of people volunteering time (51%).
The US did, however, have the highest ranking for “helping a stranger.”
That, together with a high ranking for volunteering time, led it to tie with Myanmar as the most generous nation in the world.
Admittedly, not all of this giving is altruistic.
New York’s Lincoln Center announced last month that the billionaire entertainment industry mogul David Geffen has donated $100 million toward the renovation of its concert facility, Avery Fisher Hall, on the condition that it is renamed David Geffen Hall.
That gift seems motivated more by a desire for fame than a desire to do good.
After all, as Geffen presumably knew, the family of Avery Fisher had to be compensated with a payment of $15 million in order to agree to the renaming.
In any case, in a world with a billion people living in extreme poverty, it would not be difficult for an altruist to appreciate that there are many ways of doing more good than renovating a concert hall for well-off music lovers.
At the opposite end of the giving spectrum, psychologists who study giving behavior have suggested that people who give small sums of money to a large number of charities may be motivated less by the desire to help others than by the warm glow they get from making a donation.
By contrast, other donors give larger sums, usually to only a handful of charities chosen on the basis of some knowledge about what the charity is doing.
They want to have a positive impact on the world.
Their gifts may also make their lives better, but this is not what motivates them.
The Effective Altruism movement consists of people who give in the latter way, combining the head and the heart.
Their aim is to do the most good they can with the resources that they are willing to set aside for that purpose.
Those resources may include a tenth, a quarter, or even half of their income.
Their altruism may include their time and talents, and influence their choice of career.
To achieve their aims, they use reason and evidence to ensure that whatever resources they devote to doing good will be as effective as possible.
Several studies show that people who are generous are typically happier and more satisfied with their lives than those who do not give.
And other studies show that giving leads to activity in the reward centers of the brain (the areas of the brain that are also stimulated by tasty food and sex).
But this does not mean that these donors are not altruistic.
Their direct motive is to help others, and their giving makes them happier only as a consequence of the fact that it does help others.
If we had more such people, we would have more giving, and that is what we want.
To define “altruism” so narrowly that the term can be applied only when giving is contrary to a person’s overall interest would miss the point that the best situation to bring about is one in which promoting the interests of others harmonizes with promoting one’s own.
Testing Times for Alzheimer’s
LONDON – Alzheimer’s disease is by far the most common cause of dementia and one of the world’s most feared disorders.
By 2050, there will be 135 million Alzheimer’s sufferers worldwide, a threefold increase from today, with three-quarters of cases occurring in low- and middle-income countries.
Predicting the onset of Alzheimer’s, let alone preventing or curing it, remains an immense challenge.
Alzheimer’s disease was identified more than a century ago from autopsy results that showed characteristic brain lesions called “amyloid plaques.”
The disease is more difficult to diagnose in the living.
Doctors rely on observation of memory loss and other thinking deficits (such as reasoning or language comprehension) – signs that plaques are already present in the brain.
But any cure&nbsp;would have to be administered before the plaques form, and years before symptoms of dementia appear.
Alzheimer’s might be more predictable if scientists had the time and resources to conduct far-reaching longitudinal studies over many years.
Such studies ideally would involve blood, imaging, memory, and medical tests, as well as detailed lifestyle questionnaires filled out by thousands of young and middle-aged people.
Study participants would be followed over decades to see who developed the disease, and which tests proved positive before Alzheimer’s was diagnosed.
In fact, two famous longitudinal studies – the Framingham Heart Study in Massachusetts and the Kungsholmen Project in Sweden – have led to important progress in predicting the disease.
These studies found that short-term memory may be impaired for up to ten years before an Alzheimer’s diagnosis.
Major advances have since been made in brain imaging, biochemical analysis, and, perhaps most important, genetic testing.
Indeed, the risk of Alzheimer’s doubles if a parent or sibling has it, probably due in large part to the presence of the ApoE gene.
The risk triples for Europeans who inherit a particular type of ApoE, called ε4; inheriting two copies of ε4 increases the risk roughly tenfold.
But genetic testing alone is unlikely to be an accurate predictor, because around half of Alzheimer’s sufferers do not carry ε4, and probably half of those with ε4 do not develop the disease.
Moreover, though international studies of more than 70,000 people have found over 20 other genes linked to Alzheimer’s, their impact is minimal.
That said, a&nbsp;groundbreaking 2012 study&nbsp;published in the&nbsp;New England Journal of Medicine, analyzed a rare genetic mutation found in just 500 families around the world, which would lead to Alzheimer’s before the age of 50.
The study showed which tests were able to predict the outcome most accurately decades ahead of onset.
The research found that amyloid-beta – the substance that clumps together and forms amyloid plaques – becomes depleted in the cerebrospinal fluid around the brain as long as 25 years before the onset of dementia.
Fifteen years prior to onset, a positron emission tomography (PET) scan showed amyloid-beta being deposited in plaques in the brain itself.
And detailed short-term memory tests were abnormal ten years before onset, as suggested in the Framingham and Kungsholmen studies.
These tests are now becoming part of clinical practice, and are available commercially.
Memory and other cognitive tests can reveal whether one has minor problems with some aspects of thinking – a condition known as “mild cognitive impairment” that precedes Alzheimer’s disease.
The problem is that the tests must be administered by a trained neuropsychologist and take more than an hour to complete; moreover, many people with mild cognitive impairment do not progress to dementia.
Sampling cerebrospinal fluid via a lumbar puncture (or “spinal tap”) can predict which people with mild cognitive impairment will progress to dementia with over 80% accuracy, but this still means a misdiagnosis for one in five patients.
PET scans are slightly less accurate, while routine MRI brain scans can reveal with perhaps only 70% accuracy subtle abnormalities in people with mild cognitive impairment.
Scientists are therefore still searching for an accurate predictive test that is cheaper, quicker, and less invasive than PET scans or lumbar punctures.
This year, two small studies of blood tests seemed to predict Alzheimer’s 1-3 years before it occurred, but the tests are complicated and require the measurement of ten or more substances.
Whichever predictive methods doctors use over the next few years will probably enable them to inform those patients with mild cognitive impairment about their chances of developing Alzheimer’s in the short term.
The trickier question is whether we will be able to predict Alzheimer’s disease accurately in those with normal cognition and memory, or to predict it more than five years in advance.
Even if accurate early prediction of Alzheimer’s eventually is achieved, there are currently no drugs available to prevent or cure it before the amyloid plaques start destroying the mind.
That will be our next great challenge.
A Mania for Diagnosing Bipolar Disorder
PROVIDENCE, RI – During the past few years, many experts have suggested that bipolar disorder – a serious illness resulting in significant psychosocial morbidity and excess mortality – is under-recognized, particularly in patients with major depression.
Even patients who are diagnosed with bipolar disorder often wait more than 10 years after initially seeking treatment for the correct diagnosis to be made.
The clinical implications of the failure to recognize bipolar disorder in depressed patients include the under-prescription of mood-stabilizing medications, and an increased risk of rapid “cycling” – swings between manic and depressive phases.
But, perhaps as a consequence of concerted efforts to improve the recognition of bipolar disorder, during the past few years we have observed the emergence of an opposite phenomenon – over-diagnosis.
In my own practice, my colleagues and I have encountered patients who reported that they were previously diagnosed with bipolar disorder, despite lacking a history of manic or hypomanic episodes.
To be sure, we have also seen patients seeking treatment for depression who really did have bipolar disorder.
However, there seemed to be more over-diagnosis than under-diagnosis.
We therefore conducted a study to examine empirically how often bipolar disorder might be over- and under-diagnosed.
Seven hundred psychiatric outpatients were interviewed with the Structured Clinical Interview for DSM-IV (SCID) and completed a self-administered questionnaire that asked whether they had been previously diagnosed by a health-care professional with bipolar or manic-depressive disorder.
Family history information was obtained from the patient regarding their immediate relatives.
Slightly more than 20% (145 patients) in our sample reported that they had been previously diagnosed as having bipolar disorder, significantly higher than the 12.9% rate based on the SCID.
Less than half of those who reported that they had been previously diagnosed with bipolar disorder were diagnosed with bipolar disorder based on the SCID.
Patients with SCID-diagnosed bipolar disorder had a significantly higher risk of bipolar disorder in their immediate family members than patients who self-reported a previous diagnosis of bipolar disorder that was not confirmed by the SCID.
Patients who self-reported a previous diagnosis of bipolar disorder that was not confirmed by the SCID did not have a significantly higher risk for bipolar disorder than the patients who were negative for bipolar disorder by self-report and the SCID.
Our findings, validated by family history, thus suggest that bipolar disorder was over-diagnosed.
Any study seeking to determine whether a psychiatric disorder is over-diagnosed will find that some patients with the condition do not have it upon re-interview.
Such is the nature of the imperfect reliability of psychiatric diagnosis.
The question, then, is not whether
Over-diagnosis of bipolar disorder has costs.
Mood stabilizers are the treatment of choice, and, depending on the medication, they can produce potentially significant health complications affecting renal, endocrine, hepatic, immunologic, or metabolic function.
Thus, over-diagnosing bipolar disorder can unnecessarily expose patients to serious side-effects of medication.
The impact of marketing efforts by pharmaceutical companies and publicity probably plays a role in the emerging tendency to over-diagnose bipolar disorder.
Direct-to-consumer advertisements that refer individuals to screening questionnaires can result in patients suggesting to their doctors that they have bipolar disorder.
We have seen evidence of this in our practice.
This does not necessarily reflect a problem with the performance of a screening questionnaire, but rather how these scales are used.
Screening questionnaires maximize sensitivity, at a cost of false positives, because it is presumed that they are followed by expert clinical evaluation.
But insufficient diagnostic rigor can result in over-diagnosis.
Clinicians are inclined to diagnose disorders that they feel more comfortable treating.
We believe that the increased availability of medications that have been approved for the treatment of bipolar disorder might be influencing clinicians who are unsure whether or not a patient has bipolar disorder or borderline personality disorder to err on the side of diagnosing the disorder that is responsive to medication.
This bias is reinforced by the marketing message of pharmaceutical companies to physicians, which has emphasized research on delayed diagnosis and under-recognition of bipolar disorder, possibly sensitizing clinicians accordingly.
The campaign against under-recognition has probably resulted in some anxious, agitated, and/or irritable depressed patients who complain of insomnia and “racing thoughts” being misdiagnosed with bipolar disorder.
The results of our study are consistent with prior studies suggesting possible problems with the diagnosis of bipolar disorder.
With the greater number of medications approved for the treatment of bipolar disorder, along with multiple reports cautioning clinicians against under-diagnosis, it appears that over-diagnosis has become a greater problem than under-diagnosis.
Both can have negative consequences.
While there is still some uncertainty as to the best assessment approach, we recommend that clinicians use a standardized, validated method.
When Tweets Trump Diplomacy
NEW DELHI – Diplomacy often witnesses unusual spats.
There was the Pig and Potato War of 1859, the Affair of the Dancing Lamas in 1924, and the Bogotá Bracelet incident of 1970, to name just a few.
But few were more surprising than the just-concluded Episode of the Offensive Doormats.
The e-commerce giant Amazon – which has lately been cultivating India as the next frontier of its global expansion, reflected in plans to invest $5 billion in the country – was recently startled by a series of intemperate tweets from Indian External Affairs Minister Sushma Swaraj.
In just a few 140-character messages, Swaraj denounced the company and threatened to cancel its employees’ visas and refuse visas to its executives in the future.
What provoked Swaraj’s outburst was a Twitter user’s complaint to her that the Amazon Canada website offered for sale doormats depicting the Indian flag.
The notion that dirty shoes would be wiped on a representation of the Indian flag had outraged the tweeter, Atul Bhobe, who contacted – and found an advocate in – Swaraj.
Amazon was swift to respond.
After clarifying that the offending doormats were technically being offered by a third-party supplier, not Amazon itself, the company removed them from the Amazon Canada website and “implemented measures to ensure that these products could not be sold on any of our other marketplaces or websites.”
Amazon’s India country manager offered an apology to Swaraj for “hurting Indian sensibilities” and, recalling the company’s $5 billion investment commitment, reiterated Amazon’s dedication to the country.
Less than 24 hours after the doormat crisis erupted, the matter was defused.
But the episode raises a number of broader issues that won’t disappear so quickly.
The first issue is Swaraj’s use of Twitter.
Swaraj stands out among her peers in India for her trigger-happy approach to tweeting (though her use of the platform is still dwarfed by that of US President-elect Donald Trump, who often uses Twitter as a bully pulpit).
I certainly do not oppose the use of Twitter by public officials.
On the contrary, I view the growing comfort of government ministers with social media as a matter for celebration.
It is a welcome change from my time as Minister of State for External Affairs, under the previous government, when official computers were barred from accessing social media, and the tweets I issued from my own devices would often become the stuff of needless controversy.
But Swaraj may well be going too far, responding to every individual case of a lost passport or delayed visa tweeted to her – an approach that has earned her the not-entirely-flattering sobriquet of “India’s Minister for Consular Affairs.”
That a foreign minister would respond to a Twitter complaint on such trivial matters, some would argue, seems to indicate that she lacks more important things to do.
(The suggestion undoubtedly reflects the fact that, under Prime Minister Narendra Modi, substantive foreign policy is conducted largely by him and his office, rather than by the External Affairs Ministry that Swaraj leads.)
But the problem extends beyond Swaraj’s communication with ordinary citizens.
In the recent doormat drama, she also used Twitter to issue instructions to her own diplomats, tweeting at the Indian High Commission in Canada to deal with the “unacceptable” matter, by taking it up with Amazon “at the highest level.”
Such a move is unprecedented, and not particularly welcome.
Social media is no substitute for a diplomatic cable.
Also less than diplomatic was the language Swaraj used in her warning to the company.
“Amazon must tender unconditional apology,” she tweeted.
“They must withdraw all products insulting our national flag immediately.
If this is not done forthwith, we will not grant Indian Visa to any Amazon official. We will also rescind the Visas issued earlier.”
A profession famed for summoning ambassadors for a discreet dressing-down has been reduced to upbraiding companies on Twitter.
The final issue that the doormat incident brought to the fore is Indians’ tendency to take offense at the slightest affront – a tendency that is now being elevated, by the thumbs of a top minister, to the level of official policy.
Of course, disrespect for the national flag is derided in most countries, and has been a criminal offense in India since 1971, with the adoption of the Prevention of Insults to National Honor Act, which threatens whoever “mutilates, defaces, disfigures, destroys, tramples upon, or otherwise shows disrespect to” the Indian flag with imprisonment.
But Indians have a particularly low threshold for what qualifies as disrespect.
Whereas in other democracies, flags are used freely and harmlessly on t-shirts, boots, bikinis, and even underwear, in India, the majesty of the flag can, it seems, be tarnished by any tawdry manufacturer of gewgaws.
And it’s not just the flag.
Last year, Amazon enraged many Indians by offering doormats with pictures of Indian gods and goddesses, prompting the furious hashtag #BoycottAmazon.
Two years earlier, the company’s website had caused similar outrage by selling women’s leggings with images of Hindu gods.
So Amazon is no stranger to the anger of offended Indians.
But the company’s swift capitulation in the latest incident – which will surely not be the last – shows that the value of a gigantic market like India far outweighs that of any single product.
China has already proved that it can dictate terms to multinationals that covet its vast market.
India, it seems, will follow suit.
But whoever has emerged as the winner of the doormat debacle – outraged Twitter users, perhaps – diplomacy has been the loser.
Ambivalent Arabia
A democratic tide seems to be sweeping across the Arab world.
Even the traditional Arab monarchies and Emirates are changing in its wake.
Kuwait now allows women to vote, Qatar has embraced an ambitious reform program, Bahrain has shown great tolerance of mass demonstrations, and the U.A.E. is allowing something like a free press.
But Saudi Arabia continues to be deeply wary of any sort of change, and thus remains a huge and seemingly immovable obstacle to region-wide reform.
Although the Saudi ruling family, the al-Saud, is under enormous pressure to follow the example of its neighbors, internal resistance to doing so remains very strong.
So the al-Saud have become Janus-faced: looking in one direction, the royal family encourages democratic reformers to speak out; looking in the opposite direction, it jails them when they do.
On May 15, in a closed trial without legal representation for the accused, three leading reformers – Ali Al Dumaini, a well-known journalist and poet, and university professors Abdullah Al Hamid and Matruk al Falih – were condemned and sentenced to prison terms ranging from six to nine years.
Their crime was to call for a constitutional monarchy.
The official verdict states that they threatened national unity, challenged those in authority, and incited public opinion against the state while using “foreign,” that is, Western, terminology.
Not long after the September 2001 terrorist attacks in the United States, these liberal reformers joined with 160 other professionals to write and sign a petition to Crown Prince Abdullah asking for reforms.
The petition called for the monarchy to work within constitutionally prescribed limits, and for an independent judiciary.
The reformers believe that such reforms are the only way for Saudi Arabia to survive the threat of violence, instability, and national fragmentation that is looming on its horizon.
Only a constitution, they argue, can restore much needed legitimacy to a political system that is widely perceived as deeply corrupt and inept.
Crown Prince Abdullah, Saudi Arabia’s de facto ruler in place of his incapacitated half-brother King Fahd, is keen to be seen as a champion of reform.
He received these proposals with a warm welcome in January 2003.
But his half-brother and more powerful rival, Prince Naif, the Minister of Interior, ordered the arrests, trial, and imprisonment of 13 reformers in March 2004.
Crown Prince Abdullah offered not a peep of opposition, leaving the reform agenda that he initiated in a political netherworld.
In order to maintain absolutist power and to minimize public anger, the Saudi princes, led by Prince Naif, asked the reformers to sign an agreement that they would never again ask for reform.
Prince Naif bans the very word “reform” from public discourse, because it suggests that there is something wrong with the system; his preferred term is “development.”
Of the thirteen reformers who were arrested, ten submitted to this demand, but the other three refused and have paid the price.
They remained in jail in Riyadh without legal representation until the final verdict.
Those who submitted had their passports withdrawn, lost their jobs, and were forbidden to speak to the press.
Under regional and international pressure, the Saudi ruling family has constructed a Potemkin village of reform while retaining absolute control over all political developments.
Earlier this year, they staged partial, and tightly regulated municipal elections, with no independent opinion permitted to influence when and how the ballots were held.
These entire female population was excluded, and only one-quarter of the male population was eligible to vote.
Inevitably, Wahhabi Islamists did best.
The al-Saud face two threats: one from violent Islamists, and the other from liberal reformers.
There is every indication that they fear the reformers far more.
Perhaps the princes believe that it is easier to kill “terrorist” criminals than to crush demands for social justice.
Indeed, killing violent Islamists and al-Qaeda affiliates is applauded by the international community, especially the United States, as success in the “war on terrorism.”
But as they hunt down and kill violent domestic extremists, they are quietly tightening the noose around all those who want moderate reform.
This repression of liberal reformers passes unnoticed in the wider world, with America’s silence particularly noticeable.
This silence is vital to the princes, for what the al-Saud care about most is US support.
As things stand in Saudi Arabia, the US administration has no credible ally for change outside of the existing regime.
So, unlike in Ukraine, Georgia, Kyrgizstan, and Lebanon, it does nothing to encourage popular opposition.
As long as the Saudi regime meets America’s oil needs and fights Islamist radicals, it will continue to receive US support and silence – and hence its tacit consent.
But turning a blind eye is shortsighted, for America and for the Saudis.
Those who make peaceful revolutions impossible make violent revolutions inevitable.
The liberal reformers who have been jailed could have paved the way for a peaceful transition to a reformed Saudi Arabia.
By jailing them, the regime has made it clear that violence is the only avenue open to those seeking change.
Algeria’s Dying Dictatorship
ALGIERS – Despite his failing health, Algerian President Abdelaziz Bouteflika won a fourth term last month, with 81% of the vote – or so the regime claimed.
In fact, far from signaling growing political stability, the 77-year-old incumbent’s sham victory underscores just how few options Algerians have to effect change from within the system.
Under Bouteflika’s leadership, Algeria’s government has failed to address the country’s most pressing economic and social challenges.
And there is no reason to expect this to change.
Since suffering a stroke last year, Bouteflika has barely appeared in public, whether to campaign ahead of the vote or to acknowledge his victory after it.
As a result, the regime is finding it increasingly difficult to claim, as it has for the last 15 years, that Bouteflika’s leadership represents civilian control over the military.
So it has devised a new strategy, aimed at creating a sense of transition: the constitution will be revised to designate a vice president as the president’s legitimate successor.
Of course, the move’s true purpose will be to allow the army to rally around the next compliant “civilian leader.”
The regime will also propose a “national contract,” supposedly to initiate a dialogue with the opposition.
But, in the wake of Bouteflika’s bogus victory, the opposition can no longer accept a sham role in the regime’s reform plans.
In fact, the announcement that Bouteflika planned to run was enough to unite Islamists and leftists – even parties that had previously been co-opted by the regime – and spur them to stage a boycott of the vote.
When the election results were announced, they swiftly rejected the new government as illegitimate.
But, to gain credibility, the opposition parties will have to extend their criticism beyond Bouteflika to the system as a whole.
This has become crucial to their survival, as younger opponents are seeking new ways to bring about political change outside state-controlled politics.
One important development is the growing influence of non-partisan voices of dissent.
Non-violent movements have formed to protest not only Bouteflika’s continued leadership, but also the pervasive role of the army and intelligence services in civil society.
Such movements, like the much-publicized “Barakat” (“Enough”), have encouraged a shift among Algerians from resentful abstention to active boycott.
Underground unions – which mount demonstrations and strikes to protect workers’ rights, while refusing to cooperate with the regime’s official unions – have also criticized the election.
Moreover, young people have assumed a prominent role in opposition efforts, such as by disrupting Bouteflika’s campaign rallies.
Demonstrations by unemployed young people in southern Algeria, the center of the oil industry, drew a direct link between high unemployment and the military’s control of the country’s natural resources.
By organizing peaceful protests to demand accountability for public spending, these movements are raising issues that were not addressed during the election campaign.
More immediately, they are also challenging the government’s ban on street demonstrations – a vestige of the state of emergency that lasted from 1992 until 2011.
With the civil war of the 1990’s long over, security officials cannot explain why Algerians are being arrested for demanding jobs.
Of course, repression continues to intimidate many Algerians.
But it is becoming increasingly easy to rouse their sympathy for their fellow citizens through Twitter, YouTube, and Facebook.
By stimulating daily public debate about local human-rights violations, they spread the message of discontent more efficiently than traditional parties ever have.
By demanding better state services, rather than an “Arab Spring,” Algerians have walked a fine line, highlighting the regime’s inability to deliver security and economic prosperity, despite its efforts to stifle all debate.
Thus, even without explicitly talking about politics, ordinary Algerians are mobilizing in growing numbers against the government.
The majority of street protests have occurred in the most deprived and neglected areas, and the primary demands have been economic: better jobs, housing, health-care services, and infrastructure.
For some, the right to make a living through the informal market would be sufficient.
And demonstrators have gone to great – sometimes destructive – lengths to be heard, blocking roads, occupying factories and government buildings, and sabotaging water and electricity infrastructure.
More than 150 Algerians have even set themselves on fire since 2011, usually in front of public services buildings.
In this context, the failure of the government’s half-baked attempts to buy off protesters is unsurprising.
In 2011, the government, fearing contagion from Tunisia and Egypt, where long-established dictatorships had just been toppled, responded to the spread of protests by public-sector workers by raising their salaries by 100% – retroactively to 2008.
But the plan backfired; protests intensified, with other workers demonstrating for similar benefits and railing against the inflation that the move engendered.
To be sure, street protests have already had a profound impact on Algeria’s authoritarian politics, with official fears of massive uprisings affecting public budgets and political appointments.
But the decision to prolong Bouteflika’s presidency will not provide the kind of strong, transformational leadership that Algeria needs to materialize the regime’s stability promises. 
The Algerian authorities face a major challenge, because rejection of pluralist institutions makes it more difficult to find negotiating partners.
The more the regime tries to buy off the protesters, the more overweening it appears – and the angrier citizens become.
And the enraged younger generation, in particular, is not especially fearful of losing the limited benefits offered by the status quo.
America After the Election
NEW YORK – The ongoing presidential campaign in the United States stands out for its lack of civility and the vast differences between the candidates: the anti-establishment businessman Donald Trump on the Republican side and the polished politician Hillary Clinton representing the Democrats.
The contest has exposed deep fault lines within American society and damaged the country’s global reputation.
No surprise, then, that one of the few things Americans seem to agree on is that the campaign has gone on for too long.
But soon it will be over.
The question is: what comes next?
Polls suggest that Clinton, a former senator and secretary of state, will defeat the controversial Trump.
But polls are not to be confused with reality.
After all, going into June’s Brexit referendum, most observers believed that a victory for “Remain” was a sure thing.
More recently, Colombian voters rejected a peace accord that was widely expected to receive popular approval.
All of this is to say that, while a Clinton victory may be likely, it is no certainty.
The only poll that counts is the one on November 8.
Until then, all we can do is speculate.
Yet some predictions can be made with greater confidence.
There is little doubt that the US will emerge from this election a divided country with a divided government, regardless of who is president or which party has a majority in either chamber of Congress.
Neither Democrats nor Republicans will be able to realize their objectives without at least some support from the other.
But no one should think that the only divide in American politics is between Republicans and Democrats.
In fact, splits within the two major parties are just as deep, with large and highly motivated factions pulling each to their respective extremes – Democrats to the left and Republicans to the right.
This makes compromise on centrist positions all the more difficult to achieve.
The rapid resumption of presidential politics will undermine compromise further.
If Clinton wins, many Republicans will assume that it was only because of Trump’s flaws, and they will judge her likely to be a one-term president.
A country favoring change, they will conclude, is unlikely to keep a Democrat in the Oval Office for a fourth term.
Many Republicans (especially those who deny the legitimacy of a Clinton victory) will thus seek to frustrate her administration, lest she be able to run again in 2020 as a successful incumbent.
Similarly, if Trump manages to win, most Democrats (and even some Republicans) will – after recovering from their surprise and dismay – make it their highest priority to ensure that he does not have an opportunity for a second term.
Given how much of Trump’s agenda his fellow policymakers would likely find objectionable, governing would be very difficult during his administration.
In either scenario, it may still be possible to make progress in a few key areas.
The next US government might manage to enact legislation to fund the modernization of America’s aging infrastructure, a policy that both candidates and many in Congress favor.
It might also be able to cobble together a majority to reform the US tax code – in particular, lowering the high rate for corporations and raising taxes on the wealthy.
There could even be some reform of health care, President Barack Obama’s signature achievement, owing to serious implementation problems with the current system.
But other issues requiring cooperation between Congress and the president are unlikely to be addressed any time soon.
One is immigration reform, which is as controversial in the US as it is in Europe.
Another is trade: because the domestic political environment makes policymakers wary of supporting positions with dedicated opponents, both Trump and Clinton oppose the Trans-Pacific Partnership, even though its ratification would benefit America’s economy and strategic standing.
Meanwhile, America’s deficit and debt are certain to rise, as there seems to be little or no will to reduce entitlement spending.
The foreign-policy implications of the election are somewhat different, because, under the US Constitution, the president enjoys considerable latitude.
While only Congress can officially declare war or ratify treaties, presidents may use (or refuse to use) military force without explicit congressional approval.
They can also enter into international agreements other than treaties, appoint powerful White House staff, and change US foreign policy by executive action, as Obama recently did regarding Cuba.
Under Clinton, this discretion could translate into establishing one or more safe areas in Syria, providing more defensive arms to Ukraine, and taking a tougher line toward North Korea as it continues its nuclear and missile buildup.
It is more difficult to guess what Trump would do.
He is, after all, a political outsider, so no one knows how much of his campaign rhetoric would be translated into policy.
Still, one could anticipate a Trump administration distancing itself from some traditional allies in Europe and Asia and standing mostly aloof from the Middle East.
What exactly will happen to America after the presidential election remains an open question.
Though some outcomes can reasonably be expected, the only genuine certainty is that the 96% of the world’s population that does not vote in US elections will feel the effects no less than Americans will.
America and Europe
Deeply frustrated by the Bush administration’s policies, many people and governments in Europe hope for a fundamental change in American foreign policy after the upcoming presidential election.
But it would take a medium-sized political miracle for these hopes not to be disappointed, and such a miracle will not happen – whoever is elected.
The Bush administration made numerous foreign-policy blunders with far-reaching consequences.
But Bush neither invented American unilateralism nor triggered the transatlantic rift between the United States and Europe.
To be sure, Bush reinforced both trends, but their real causes lie in objective historical factors, namely America’s being the sole world power since 1989 and Europe’s self-inflicted weakness.
As long as America remains the sole world power, the next US President will be neither able nor willing to change the basic framework of America’s foreign policy.
It will, of course, be important who wins the presidency: a candidate expected to continue Bush’s foreign policy or someone ready for a new beginning.
In the former case, the transatlantic rift will deepen dramatically.
Four, or even eight, more years of US policy à la Bush would inflict such damage on the substance of the transatlantic alliance as to threaten its very existence.
But if America’s next president is committed to a new direction, US foreign policy might again become more multilateral, more focused on international institutions and alliances, and willing to bring the relationship between military force and diplomacy back to within its historical proportions.
That is the good news.
The bad news is that, even under such auspicious conditions, the US, as a world power, will not relinquish its “free-hand” policy or forget its strength and its claim to preeminence among nations.
Another piece of bad (or good?) news is that a more multilateral American policy will increase the pressure on Europeans to take on more responsibility for international crisis management and conflict resolution – in Afghanistan, Iran, Iraq, the Middle East, Transcaucasia, and Russia, and with respect to Turkey’s future.
To this common agenda, the Europeans should add Africa, climate change, and reform of the United Nations and the world trading system.
For a long time, Europe has underestimated its weight and importance.
Europe’s geopolitical, economic, and social weight is quite obvious.
But Europe’s integration of sovereign states’ interests by means of common institutions could also be an example for much of the world.
In particular, the way Europe, in the process of its enlargement, has projected its power to achieve lasting peace across the whole continent, and fostered development by integrating entire economies, states, and societies within its institutional framework, could become a model for shaping a cooperative world order in the twenty-first century.
This modern, progressive, and peaceful model is unique and superior to all other currently available approaches to the fundamental questions of political order.
But could doesn’t mean will.
Europe’s global influence is feeble because of its internal quarrels and lack of unity, which render the European Union weak and limit its ability to act.
Objectively strong, subjectively infirm – that is how the EU’s present condition can be described.
The current moment of American weakness coincides with a substantially changed international political environment, defined largely by the limits of US power, Europe’s ineffectiveness, and the emergence of new global giants like China and India.
In light of these developments, does it still make sense to speak of “the West”?
I believe it does, more than ever, because the rift between Europe and America leaves both sides substantially weaker in global terms.
The unilateral overstretching of American power offers a chance for a new beginning in US-European relations.
America, more than in the past, will depend on strong partners and will seek such partnerships.
So what are the Europeans waiting for?
Why not start now to overcome the traditional tension between NATO and the EU – especially as French policy toward NATO under President Nicolas Sarkozy has been moving in the right direction?
A regular mutual presence of the Secretary General of NATO and of the head of EU foreign policy in the councils of both organizations doesn’t require much time and effort.
Why not initiate EU-US consultations at a high political level (with the Secretary-General of NATO participating in security matters) – for instance, by inviting the US Secretary of State and other members of the administration, such as the Treasury Secretary or the Administrator of the Environmental Protection Agency, to sit several times a year on the appropriate EU Council meetings?
Why not have routine annual meetings between the European Council and the US President?
Periodic meetings between the appropriate committees of the US Congress and the European Parliament would also be of great importance, as ultimately both bodies will have to ratify any international treaties.
The fate of the Kyoto Protocol should be a lesson to all parties involved.
No such US-EU consultations would require any new agreements, so they could start without any further preliminaries.
There is one certainty that Europeans can take home from the US election campaign even today: with a more multilaterally oriented US foreign policy, Europe won’t be riding comfortably in the US world-political slipstream much longer.
And that is a good thing.
The new transatlantic formula must be greater say in decision-making in exchange for a greater share of responsibility.
America at Stall Speed?
NEWPORT BEACH – Judging from the skittishness of both markets and “consensus expectations,” the United States’ economic prospects are confusing.
One day, the country is on the brink of a double-dip recession; the next, it is on the verge of a turbo-charged recovery, powered by resilient consumers and US multinationals starting to deploy, at long last, their massive cash reserves.
In the process, markets take investors on a wild rollercoaster ride, with the European crisis (riddled with even more confusion and volatility) serving to aggravate their queasiness.
This situation is both understandable and increasingly unsettling for America’s well-being and that of the global economy.
It reflects the impact of fundamental (and historic) economic and financial re-alignments, insufficient policy responses, and system-wide rigidities that frustrate structural change.
As a result, there are now legitimate questions about the underlying functioning of the US economy and, therefore, its evolution in the months and years ahead.
One way to understand current conditions – and what is needed to improve them – is to consider two events that recently attracted considerable worldwide attention: the launch of Boeing’s Dreamliner passenger jet and the tragic death of Apple’s Steve Jobs.
Let us start with some simple aeronautic dynamics, using an analogy that my PIMCO colleague, Bill Gross, came up with to describe the economic risks facing the American economy.
For the Dreamliner to take off, ascend, and maintain a steady altitude, it must do more than move forward.
It has to move forward fast enough to exceed critical physical thresholds, which are significantly higher than those for most of Boeing’s other (smaller) planes.
Failure would mean succumbing to a mid-air stall, with tepid forward motion giving way to a sudden loss of altitude.
Unless we are convinced of the Dreamliner’s ability to avoid stall speed, it makes no sense to talk about all the ways in which it will enhance the travel experience for millions of people around the world.
America’s economy today risks stall speed.
Specifically, the question is not whether it can grow, but whether it can grow fast enough to propel a large economy that, according to the US Federal Reserve, faces “balance-sheet deleveraging, credit constraints, and household and business uncertainty about the economic outlook.”
And, remember, it is just over a year since certain US officials were proclaiming the economy’s “summer of recovery” – a view underpinned by the erroneous belief that America was reaching “escape velocity.”
Stall speed is a terrifying risk for an economy like that of the US, which desperately needs to grow robustly.
Without rapid growth, there is no way to reverse persistently high and increasingly structural (and therefore protracted) unemployment; safely de-leverage over-indebted balance sheets; and prevent already-disturbing income and wealth inequalities from growing worse.
The private sector alone cannot and will not counter the risk of stall speed.
What is desperately needed is better policymaking.
Specifically, policymakers must be open and willing to understand the unusual challenges facing the US economy, react accordingly, and possess sufficiently potent policy instruments.
Unfortunately, this has been far from the case in America (and in Europe, where the situation is worse).
Moreover, US policymakers in the last few weeks have been more interested in pointing fingers at Europe and China than in recognizing and responding to the paradigm shifts that are at the root of the country’s economic problems and mounting social challenges.
This is where the insights of Steve Jobs, one of the world’s best innovators and entrepreneurs, come in.
Jobs did more than navigate paradigm shifts; he essentially created them.
He was a master at converting the complicated into the simple; and, rather than being paralyzed by complexity, he found new ways to deconstruct and overcome it.
Teamwork was an obligation, not a choice.
And he eschewed the search for the single “big bang” in favor of aiming for multiple breakthroughs.
Underlying it all was a willingness to evolve – a drive for perfection through experimentation.
Moreover, he excelled at selling to audiences worldwide both his vision and his strategy for realizing it.
So far, America’s economic policymakers have fallen short on all of these fronts.
Rather than committing to a comprehensive set of urgently-needed reinforcing measures, they seem obsessed with the futile search for the one “killer app” that will solve all of the country's economic problems.
No surprise that they have yet to find it.
Teamwork has repeatedly fallen hostage to turf wars and political bickering.
Little has been done to deconstruct structural complexity, let alone win sufficient public support for a medium-term vision, a credible implementation strategy, and a set of measures that is adequate to the task at hand.
The longer the policymaking impasse persists, the greater the stall-speed risk for an economy that already has an unemployment crisis, a large budget deficit, many underwater mortgages, and policy interest rates floored at zero.
This is an atmosphere in which unhealthy balance sheets come under even greater pressure, and healthy investors refuse to engage.
In the process, the risk of recession remains uncomfortably high, the unemployment crisis deepens, and inequities rise as already-stretched social safety nets prove even more porous.
America, China, and the Productivity Paradox
NEW HAVEN – In the late 1980s, there was intense debate about the so-called productivity paradox – when massive investments in information technology (IT) were not delivering measureable productivity improvements.
That paradox is now back, posing a problem for both the United States and China – one that may well come up in their annual Strategic and Economic Dialogue.
Back in 1987, Nobel laureate Robert Solow famously quipped, “You can see the computer age everywhere except in the productivity statistics.”
The productivity paradox seemed to be resolved in the 1990s, when America experienced a spectacular productivity renaissance.
Average annual productivity growth in the country’s nonfarm business sector accelerated to 2.5% from 1991 to 2007, from the 1.5% trend in the preceding 15 years.
The benefits of the Internet Age had finally materialized.
Concern about the paradox all but vanished.
But the celebration appears to have been premature.
Despite another technological revolution, productivity growth is slumping again.
And this time the downturn is global in scope, affecting the world’s two largest economies, the US and China, most of all.
Over the past five years, from 2010 to 2014, annual US productivity growth has fallen to an average of 0.9%.
It actually fell at a 2.6% annual rate in the two most recent quarters (in late 2014 and early 2015).
Barring a major data revision, America’s productivity renaissance seems to have run into serious trouble.
China is witnessing a similar pattern.
Although the government does not publish regular productivity statistics, there is no mistaking the problem: Overall urban employment growth has been steady, at around 13.2 million workers per year since 2013 – well in excess of the government’s targeted growth rate of ten million.
Moreover, hiring seems to be holding at that brisk pace in early 2015.
At the same time, output growth has slowed from the 10% trend of the 33 years ending in 2011 to around 7% today.
That downshift, in the face of sustained rapid job creation, implies an unmistakable deceleration of productivity.
Therein lies the latest paradox.
With revolutionary technologies now driving the creation of new markets (digital media and computerized wearables), services (energy management and DNA sequencing), products (smartphones and robotics), and technology companies (Alibaba and Apple), surely productivity growth must be surging.
As a modern-day Solow might say, the ���Internet of Everything” is everywhere except in the productivity statistics.
But is there really a paradox?
Northwestern University’s Robert Gordon has argued that IT- and Internet-led innovations like automated high-speed data processing and e-commerce pale in comparison to the breakthroughs of the Industrial Revolution, including the steam engine, electricity, and indoor plumbing.
He maintains that, although these innovations led to dramatic transformations of the major advanced economies – such as higher female labor-force participation, increased transportation speed, urbanization, and normalized temperature control – these changes will be extremely hard to replicate.
Indeed, as taken with today’s revolutionary technologies as we are – I say this staring at my sleek new Apple Watch – I am sympathetic to Gordon’s argument.
If US productivity figures are to be taken at anything close to face value – a persistently sluggish trend interrupted by a 16-year spurt that now appears to have faded – it is possible that all America has accomplished are transitional efficiency improvements associated with the IT-enabled shift from one technology platform to another.
Optimists maintain that the official statistics fail to capture marked quality-of-life improvements, which may be true, especially in the light of promising advances in biotechnology and online education.
But this overlooks a much more important aspect of the productivity-measurement critique: the undercounting of work time associated with the widespread use of portable information appliances.
In the US, the Bureau of Labor Statistics estimates that the length of the average workweek has held steady at about 34 hours since the advent of the Internet two decades ago.
Yet nothing could be further from the truth: knowledge workers continually toil outside the traditional office, checking their email, updating spreadsheets, writing reports, and engaging in collective brainstorming.
Indeed, white-collar knowledge workers – that is, most workers in advanced economies – are now tethered to their workplaces essentially 24 hours a day, seven days a week, a reality that is not reflected in the official statistics.
Productivity growth is not about working longer; it is about generating more output per unit of labor input.
Any undercounting of output pales in comparison with the IT-assisted undercounting of working hours.
China’s productivity slowdown is probably more benign.
It is an outgrowth of the Chinese economy’s nascent structural transformation from capital-intensive manufacturing to labor-intensive services.
Indeed, it was only in 2013 that services supplanted manufacturing and construction as the economy’s largest sector.
Now the gap is widening, and that is likely to continue.
With Chinese services requiring about 30% more workers per unit of output than manufacturing and construction, combined, the economy’s structural rebalancing is now shifting growth to China’s lower-productivity services sector.
China has time before this becomes a problem.
As Gordon notes, there have been long-lasting productivity dividends associated with urbanization – a trend that could continue for at least another decade in China.
But there will come a time when this tailwind subsides and China begins to converge on the so-called frontier of the advanced economies.
At that point, China will face the same productivity challenges that confront America and others.
Chinese policymakers’ new focus on innovation-led growth seems to recognize this risk.
Without powerful innovations, sustaining productivity growth will be an uphill battle.
China’s recent shift to a slower-productivity trajectory is an early warning of what may well be one of its most daunting economic challenges.
There is no escaping the key role that productivity growth plays in any country’s economic performance.
Yet, for advanced economies, periods of sustained rapid productivity growth have been the exception, not the rule.
Recent signs of slowing productivity growth in both the US and China underscore this reality.
For a world flirting with secular stagnation, that is disturbing news, to say the least.
A New Blueprint for US-China Relations
NEW YORK – In the coming decades, nothing will matter more for global peace, prosperity, and governance than how the United States and China handle the ongoing shift in their relative power.
In the long term, today’s other pressing challenges – including Russia’s relationship with the West and events in the tumultuous Middle East – will amount almost to sideshows by comparison.
What makes the Sino-American relationship dangerous is that powerful forces in both countries seem intent on a collision course.
On the Chinese side, under Xi Jinping’s assertive leadership, the government is no longer heeding Deng Xiaoping’s injunction that the country should “hide its strength, bide its time, and never take the lead” in international affairs.
It has pursued manifestly expansionist territorial claims, most notably in the South China Sea, and shown a clear determination to resist the indefinite continuation of American dominance in the region.
The prevailing Chinese mindset is that the US is intent on isolating, containing, and undermining it.
Unhappily, there is plenty of evidence on the US side to feed that sentiment.
Whatever many American policymakers may be saying in private, their public discourse almost invariably reflects an intention to remain the world’s dominant power – and specifically in Asia – in perpetuity.
The most confrontational recent articulation of this position can be found in a report for the Council on Foreign Relations, by Robert Blackwill and Ashley Tellis, arguing that the central objective of American grand strategy must be “preserving US primacy in the global system,” and urging a series of aggressive economic, political, and military measures to “balance” China.
They say this is not a “containment” strategy, but it amounts to nothing less.
Is there another way to manage the relationship that, while reflecting the reality of these forces and mindsets on both sides, would not risk turning legitimate competition into dangerous confrontation?
In a new report for the Harvard Kennedy School’s Belfer Center for Science and International Affairs, Kevin Rudd, former Australian Prime Minister and now head of the Asia Society Policy Institute, outlines just such a strategy, which he calls “constructive realism”.
It’s a clunky label, but his analysis and policy prescriptions are compelling.
The “realist” dimension of Rudd’s argument recognizes that certain areas of disagreement – including Taiwan, territorial disputes in the South and East China Seas, US alliances in Asia, Chinese military modernization, and the legitimacy of China’s political system – will remain intractable for the foreseeable future.
They will defy easy solutions – and thus will require very careful management.
The “constructive” part of Rudd’s thesis argues for systematic collaboration – with the US treating China more as an equal – in tackling a series of other difficult issues at bilateral, regional, and global levels.
Bilaterally, such cooperation might involve an investment treaty, a joint intelligence task force on terrorism, a cyber-security protocol, agreed measures for managing unplanned military incidents, and mutual ratification of the Comprehensive Nuclear Test-Ban Treaty.
On a regional level, Rudd argues, the US and China could work on joint strategies to denuclearize and, ultimately, reunify the Korean Peninsula; tackle the lingering sore of Japan’s war history; harmonize regional trade agreements; and transform the East Asia Summit into a more complete Asia-Pacific Community.
Globally, Rudd believes that the joint agenda could focus on combating climate change, revitalizing the G-20, further internationalizing the renminbi; giving China a greater role in the International Monetary Fund and the World Bank; and reforming other key international institutions within the UN system.
Some in the West – including veteran China watcher David Shambaugh – remain convinced that this kind of collaborative accommodation will not be necessary, because failures of economic and political management will bring about China’s implosion.
Rudd argues that they are wrong, and that Xi will neither overplay his authoritarian hand nor under-deliver on growth.
China’s rise will continue, and the world – including the US – will have to find principled ways of peacefully accommodating it.
Rudd’s recommendations are undoubtedly ambitious.
But, given his credentials – he is a formidable Chinese linguist and creative policy thinker, with long and close personal relationships with key figures in both the US and China – his argument must be taken seriously.
Indeed, though Rudd’s tenure as Australia’s prime minister was anything but smooth, his sheer force of intellect is unmatched by that of any public figure with whom I have interacted over the last 30 years.
(Not that this will much help his evident willingness to be drafted as the next UN Secretary-General: in that role the major powers have always preferred bland secretaries to creative generals.)
No American presidential candidate is likely to be comfortable talking about the US as anything other than Number One.
But we must hope that in the years ahead we hear less talk of “primacy” and “dominance” and much more about cooperation and collaboration.
It is only with such US policies toward China that the world can begin to be confident that the twenty-first century will not, like the last, become a vale of tears.
America Confronts Old and New Europe
US Secretary of Defense Donald Rumsfeld's petulant remark of last year about "old and new Europe" was right for the wrong reasons.
He meant it to refer to Europe's divisions, but in May, ten additional states joined the European Union.
The expanded Europe truly forms a new Europe.
Should America be nervous?
Fifty-four years after the announcement of the Schuman Plan that began to knit together the economies of France and Germany, the EU now has 25 countries and a population larger than that of the United States.
Eight of the new members are former Communist countries that were locked behind the Iron Curtain for nearly half a century.
Their attraction to the Union is a sign of the appeal - the "soft power" - of the idea of European unification.
Of course, this new Europe faces many problems.
The per capita income of the new countries is less than half of that of the fifteen members they are joining. Concerns have been raised about the influx of cheap labor.
But average GDP growth rates in the new members are twice as high as in the original members, and this can provide a welcome stimulus to stagnant labor markets and sluggish economies.
Political arrangements are somewhat more problematic.
Negotiations are underway to revise a draft EU constitution.
Some Europeans worry that the constitution will enable courts to carry the integration process further and faster than public opinion in member states will tolerate.
Lack of grassroots support might lead to rejection of the constitution in countries like Britain, where referenda have been promised before the new arrangements come into force.
Across the Atlantic, most Americans (to the extent they pay attention) regard these changes with general approval.
But some express concern that the new Europe will be defined in opposition to the US.
Not only do the remarks of French leaders about recreating a multi-polar world arouse alarm, but recent public opinion polls show a decline in the popularity of the US among Europeans and a desire for more independent policies.
The Iraq War proved costly to American soft power, with the US losing about 30 percentage points of attractiveness on average in Europe, including in countries like Britain, Spain, and Italy, whose governments supported the war.
The recent photographs of detainees being abused and sexually degraded in Baghdad's Abu Ghraib prison added fuel to the fire.
Now some American neo-conservatives argue that the US should drop its longstanding support for European integration.
Such a policy change would be a serious mistake.
Not only would it add to anti-American attitudes and fail to accomplish its objectives, but it over-estimates the extent to which the new Europe is being formed in opposition to the US.
Whatever the rhetoric in France, for example, the policies and attitudes in countries such as Britain or Poland demonstrate that good trans-Atlantic relations can be maintained.
If anything, the risks of a US-Europe split will be reduced rather than increased by the EU's recent enlargement.
Moreover, there are several objective reasons why the current friction between Europe and the US is unlikely to lead to divorce.
For one thing, the divisive war in Iraq may turn out to be the last act of the twentieth century rather than a harbinger of the twenty-first.
American unilateralism is much less in evidence in the world's other hot spots, such as North Korea and Iran, both because of the costs of the war in Iraq and the realities of the situation in those other regions.
Moreover, while the common security threat from the Soviet Union has disappeared, both the US and Europe face a new common threat from radical
Europe and America also share a common structure of economic interests and values.
While trade produces frictions in democracies, it also enhances wealth.
If one looks at foreign direct investment, it is clear that the two sides of the Atlantic are closely integrated.
In terms of values, while some differences exist between Europe and America, at the fundamental level of democracy and human rights, no other two parts of the globe share more.
As the writer Robert Kagan concluded in the revision of his book in which he declared Europeans to be from Venus and Americans from Mars, it turns out that Americans seeking democratic legitimization of their policies and self-images cannot escape Europe.
In short, it is good for Americans - and for the world - that old and new Europe are becoming one.
We can all benefit from the soft power of an enlarged Europe.
What Makes America Great
CAMBRIDGE – Presidential inaugurations and commencement ceremonies are usually very emotional events.
They are rites of passage that mark both an end and a new beginning in the life of a country or an individual.
As a professor at Harvard’s Kennedy School of Government, I attend our commencement ceremony every year.
Despite this regularity, I still become emotional as I see my students complete a phase of their lives and contemplate their future.
One of the highlights of our ceremony is a video in which several professors and public personalities read, line by line, John F. Kennedy’s inaugural address.
It is a text written 56 years ago, in a different world, where the Cold War, the threat of nuclear Armageddon, and the challenges faced by so many newly independent poor states dominated policymakers’ concerns.
And yet, running at under 14 minutes, it never fails to move and inspire everyone in the audience, including that half of the graduates and their families who hail from other countries, near and far.
To understand why, it is useful to recall a few of the most famous passages.
For starters, there was Kennedy’s vow to defend freedom for its friends and from its enemies: “Let every nation know, whether it wishes us well or ill, that we shall pay any price, bear any burden, meet any hardship, support any friend, oppose any foe to assure the survival and the success of liberty.”
There was also his commitment to fight poverty: “To those people in the huts and villages of half the globe struggling to break the bonds of mass misery, we pledge our best efforts to help them help themselves, for whatever period is required – not because the communists may be doing it, not because we seek their votes, but because it is right.
If a free society cannot help the many who are poor, it cannot save the few who are rich.”
And this commitment was part and parcel of hemispheric solidarity: “To our sister republics south of our border, we offer a special pledge – to convert our good words into good deeds – in a new alliance for progress – to assist free men and free governments in casting off the chains of poverty.”
Finally, there was Kennedy’s ethic of service on behalf of the commonwealth: “And so, my fellow Americans: ask not what your country can do for you – ask what you can do for your country.
My fellow citizens of the world: ask not what America will do for you, but what together we can do for the freedom of man.”
These words’ enduring emotional appeal is rooted in their embrace of a potentially difficult course of action, motivated by a pledge to uphold values shared by citizens of America and the world alike.
It was this approach – one founded on a value-based system of rules, not on individual deals – that enabled the US to create and sustain a coalition of countries that could maintain peace and international cooperation.
Fast forward to today.
President-elect Donald Trump’s campaign narrative was based on the assumption that the US has fallen from its former greatness.
Jobs have moved to Mexico and China because weak leaders negotiated bad deals.
Immigrants, mostly illegal, have taken the few jobs that remain, killing and raping in their free time.
It follows that the US needs a president who will put America first and knows how to extract the best deals for it at every opportunity, using the country’s full might to advance its interests.
I doubt that an inaugural address based on these ideas will awe and inspire many audiences at commencement ceremonies, especially where many of those in attendance are citizens of other countries.
Such a speech will encourage no one to “bear any burden” for the sake of any universal principle or challenge, be it human rights or global warming.
It will not exhort us to focus on something bigger than ourselves.
Over the course of history, very few powerful states have developed a sense of themselves as being based not on ethnic heritage, but on a set of values that all citizens can live by.
For the US, it was “life, liberty, and the pursuit of happiness.”
For the Soviet Union, it was international proletarian solidarity – “workers of the world, unite.”
The European Union is based on universal values and principles that are so attractive that 28 countries have opted to join it; and, Brexit notwithstanding, some half-dozen more are trying to get in.
By contrast, a great and powerful Russia or China today – or the Third Reich in its time – may be able to garner the support of its citizens; but such states cannot constitute the basis of an international order that others find appealing, because they are based on a vision of themselves that does not encompass others.
The basis of America’s greatness and ability to lead the world stems from universal values that underpin a set of rules that uphold the others’ rights, not an America that tries to base its greatness on a set of deals aimed at getting the better of others.
Such an America will find its ability to lead the world compromised by a shortage of goodwill and an abundance of distrust.
Other countries will huddle together to protect themselves from the US bully.
If Trump really wants to make America great again, he should ponder how his inaugural address will sound to a global audience 56 years from now.
Will it inspire the Class of 2073 the way Kennedy’s address still inspires graduates today?
America Goes from Teacher to Student
Cambridge &#45;&#45; As the United States’ epic financial crisis continues to unfold, one can only wish that US policymakers were half as good at listening to advice from developing countries as they are at giving it.
Americans don’t seem to realize that their “sub-prime” mortgage meltdown has all too much in common with many previous post-1945 banking crises throughout the world.
The silver lining is that there are many highly distinguished current and former policymakers out there, particularly from emerging market countries, who have seen this movie before.
If US policymakers would only listen, they might get an idea or two about how to deal with financial crises from experts who have lived through them and come out safely on the other side.
Unfortunately, the parallel between today’s US crisis and previous financial crises is not mere hyperbole.
The qualitative parallels are obvious: banks using off-balance loans to finance highly risky ventures, exotic new financial instruments, and excessive exuberance over the promise of new markets.
But there are strong quantitative parallels as well.
Professor Carmen Reinhart of the University of Maryland and I systematically compared the run-up to the US sub-prime crisis with the run-up to the 19 worst financial crises in the industrialized world over the past 60 years.
These include epic crises in the Scandinavian countries, Spain, and Japan, along with lesser events such as the US savings and loan crises of the 1980’s.
Across virtually all the major indicators – including equity and housing price runs-ups, trade balance deficits, surges in government and household indebtedness, and pre-crisis growth trajectories – red lights are blinking for the US.
Simply put, surging capital flows into the US artificially held down interest rates and inflated asset prices, leading to laxity in banking and regulatory standards and, ultimately, to a meltdown.
When Asia and Latin America had their financial meltdowns in the 1990’s and early 2000’s, they took advice not only from the IMF, but also from a number of small panels composed of eminent people representing diverse backgrounds and experiences.
The US should do the same.
The head of the IMF, Frenchman Dominique Strauss-Kahn, could easily select a superb panel from any range of former crisis countries, including Mexico, Brazil, Korea, Turkey, Japan, and Sweden, not to mention Argentina, Russia, Chile, and many others.
Admittedly, the IMF’s panel would have to look past America’s current hypocrisy.
The US Treasury strongly encouraged Asia to tighten fiscal policy during its 1990’s crisis.
But today the US Congress and President are tripping over themselves to adopt an ill-advised giant fiscal stimulus package, whose main effects will be to tie the hands of the next president in simplifying the US tax code and closing the budget deficit.
Americans firmly told Japan that the only way to clean up its economy was to purge insolvent banks and regenerate the financial system through Schumpeterian “creative destruction.”
Today, US authorities appear willing to contemplate any measure, no matter how inflationary, to insure that none of its major banks and investment houses fails.
For years, foreign governments complained about American hedge funds, arguing that their non-transparent behavior posed unacceptable risks to stability.
Now, many US politicians are complaining about the transparency of sovereign wealth funds (big government investors mainly from Asia and the Middle East), which are taking shares in trophy American assets such as Citibank and Merrill Lynch.
In fact, having countries like Russia and China more vested in the well-being of the US economy would not be a bad thing.
Yes, the IMF ought to develop a voluntary code of conduct for SWF’s, but it should not be used as a weapon to enforce financial protectionism.
For years, I, along with many others, have complained that emerging markets need greater representation in global financial governance.
Today, the issue goes far beyond symbolism.
The US economy is in trouble, and the problems it spins off are unlikely to stop at the US border.
Experts from emerging markets and elsewhere have much to say about dealing with financial crises.
America should start to listen before it is too late.
America’s Second Chance with India
NEW YORK – Indian Prime Minister Narendra Modi’s visit to Washington, DC, in June garnered little public attention outside of India.
Yet diplomats and military professionals in Asia and beyond were certainly watching closely.
For good reason: the rapprochement between the world’s two most populous democracies could shape the world’s future.
It is worth noting that in his address to the US Congress, Modi invoked the word “partner” or “partnership” no fewer than 15 times.
The official joint statement released by the two governments described India as a “Major Defense Partner” of the United States, eligible for advanced technologies with military applications.
The relationship between India and the US has evolved from one of cool distance to strategic proximity in a generation – lightning fast for geopolitics.
The factors underlying this shift merit attention, for many of them are likely to bring the two countries even closer.
The Cold War’s end was a significant part of the bilateral rapprochement, because it eliminated the possibility of India’s continued association with the Soviet Union, as well as its rationale for embracing non-alignment.
A second factor is Pakistan.
For a long time, the US pursued an even-handed policy toward South Asia’s two most strategically important countries.
Nonetheless, during most of the Cold War, Pakistan was seen as a friendly country, whereas its great rival, India, was viewed as difficult.
This view was reinforced when Pakistan became the essential conduit of weapons to Afghans fighting the Soviet occupation of their country.
But the bond between the US and Pakistan weakened when Soviet forces withdrew from Afghanistan in 1989.
Relations suffered further from Pakistan’s development of nuclear weapons, its provision of sanctuary and support to the Taliban, and its willingness to extend hospitality to some of the world’s most dangerous terrorists, including Osama bin Laden.
As a result, US ties to India were no longer constrained by fear of complications in Pakistan.
China is also animating the improvement in India-US ties.
The motivation is far more fundamental than the fact that India and China still have an unresolved border.
China’s rise has created a strong incentive for countries with a stake in Asia to increase their cooperation with the US, as well as with one another, to ensure that they can stand up to China’s political, military, and economic might.
Domestic politics also loom large in the relationship’s development – on both sides.
The decline of India’s Congress party reduced the influence of the political force most associated with maintaining distance from the US.
Meanwhile, there are now more than three million Indian-Americans, and, as with many other immigrant populations, they have become ever more prominent and powerful.
Supporting closer ties with India has become a rare example of bipartisan US foreign policy, and it can be expected to continue regardless of which party controls the White House or Congress after this November’s elections.
The breakthrough in bilateral ties came a decade ago, when the US lifted sanctions introduced in response to India’s nuclear weapons program and then signed an accord paving the way for US involvement in India’s civil nuclear energy program.
India, unlike both Pakistan and North Korea, is seen as a responsible nuclear power, a country the US now supports for membership in various groups designed to stem the further spread of nuclear materials and weapons.
Economic ties are also growing, along with India’s economy.
Bilateral trade has increased to more than $100 billion a year.
High-level visits have become commonplace.
Closer economic ties and large-scale collaboration on clean energy are a high priority.
One can also predict increased cooperation between the two countries’ military and intelligence establishments.
Indeed, joint efforts to keep the Indian Ocean open and safe are already a reality.
The US and India need not be formal allies for their relationship to have the desired effect on Chinese strategic calculations.
Challenges remain, of course.
Bureaucracy, corruption, and poor infrastructure continue to hold back India’s economy.
Indian leaders must also be careful not to do or say things that could alienate the country’s large Muslim minority.
And they must still ensure that close ties with the US are not simply the policy of one prime minister or party.
This means getting the Congress party fully on board and overcoming the resistance of career officials to new ways of thinking and acting.
It is difficult to overlook the irony in much of this.
More than a half-century ago, in the early years of the Cold War, many in Washington saw India as a potential model of non-Communist political and economic development.
For many reasons, things did not work out that way, as India became economically statist, for a time politically authoritarian, and geopolitically closer to the USSR than US officials liked.
Now, however, India is emerging as a successful example of a market-oriented democracy with close ties to the US.
Second chances are rare in life, but both India and the US may be getting just that.
America Keeping Haiti Down
The IDB, the world's largest regional development bank, works in Latin America and the Caribbean purportedly to “contribute to the acceleration of economic and social development.”
Its actions in Haiti, however, have severely undermined those goals.
Roughly $54 million in IDB loans for water infrastructure in Haiti, home to literally the world’s worst water, offered a proven path to preventing deadly water-borne diseases. Designed to assist in fulfilling the right to water in the most impoverished nation in the Western Hemisphere, these loans and the lives they could have saved instead have become pawns in a deliberate political power play.
In 2001, US officials threatened to use their influence to stop previously approved IDB funding unless Haiti’s majority political party submitted to political demands to accept a particular apportionment of seats in a Haitian electoral oversight body.
Soon after, at the behest of the US, instead of disbursing the loans as planned, the IDB and its members took the unprecedented step of implicitly adding conditions to require political action by Haiti before the funds would be released.
These actions violated the IDB’s own charter, which strictly prohibits the Bank and its members from interfering in the internal political affairs of member states.
Internal emails reveal that a US legal counselor inside the IDB proposed to the US Treasury Department that, though the loans faced no legitimate technical obstacles, the US could effectively block them by “slowing” the process.
Indeed, by requesting further review of the loans, Haiti would have to make scheduled payments before the funds were even disbursed.
“While this is not a ‘bullet-proof’ way to stop IDB disbursements,” the counsellor wrote, “it certainly will put a few more large rocks in the road.”  
In 2001, then-US Ambassador to Haiti Dean Curran publicly and explicitly linked the withholding of IDB loans to the demand that Haiti’s political parties reach a compromise that America wanted.
These tactics worked.
Deprived of funds that had already been committed and expected, Haiti fell into arrears on money owed for loan repayment, triggering IDB policies that prevented the Bank from releasing loans.
In subsequent years, the US employed additional delaying tactics, working with the IDB to move the goal posts whenever Haiti appeared to be meeting their demands.
The results have been devastating.
The town of Port-de-Paix, slotted ten years ago by the IDB as the first project site due to its particularly deplorable water situation, has yet to see the implementation of any water projects.
A study conducted by Zanmi Lasante, Partners In Health, the Robert F. Kennedy Memorial Center for Human Rights, and New York University’s Center for Human Rights and Global Justice found no functioning public water sources in the city.
Researchers found three-quarters of water sources in the city contained high levels of coliform bacteria, a key indicator of contamination with fecal matter.
A frightening 15% of households reported symptoms likely related to typhoid.   
If the US and other member states join the IDB and take on the responsibility to improve conditions in the Americas, they cannot then use their membership to undermine the basic rights of the people they claim to serve simply to advance their own political agenda.
The IDB and the US government must take responsibility for their actions and implement the necessary transparency mechanisms to ensure that such abuses do not recur.  Congressional inquiries and annual reviews of the Treasury Department by the Government Accountability Office could provide the oversight necessary to prevent future political misuse of the IDB and its funds.
The people of Haiti, as well as US taxpayers, deserve a system that makes public the status of IDB loans and projects in Haiti in order to ensure that the US and IDB member states uphold their commitments to development and human rights.
Alliances for Peace
WASHINGTON, DC – I grew up in the shadow of World War II, and at the dawn of the Cold War.
My father’s work as a Foreign Service officer gave me an opportunity to see history up close in a searing way: I will never forget walking the beaches of Normandy with him and seeing the burned hulks of Higgins’ boats still on those shores, just a few years after so many young men went to their graves so the world could be free.
Likewise, I will never forget the eerie feeling of riding my bike through the Brandenburg Gate from West Berlin into the East, and seeing the contrast between people who were free and those who were trapped behind the Iron Curtain.
What strikes me now, all these years later, is that a generation of leaders won not only a war, but also the peace.
They did it together.
The United States and our partners worked to create alliances that brought prosperity and stability to Western Europe, Japan, and South Korea.
Old enemies became new allies, and together pioneered a new global economic system that made the world more prosperous.
And even as the Cold War raged, leaders found ways to cooperate on arms control and prevent a nuclear Armageddon.
In short, by building effective and indispensable international institutions and strategic partnerships, we did not just avoid another catastrophic world war; we ultimately ended the Cold War and lifted global living standards for hundreds of millions of people.
That is the remarkable story of the twentieth century.
The question now is what story will emerge from the twenty-first century.
Today, the world order faces new challenges.
Russian aggression is rattling allies.
Extremists who hijack religion threaten governments and people everywhere.
Technology is accelerating a shift in the balance of power between governments and governed that offers both opportunities for democratic accountability and obstacles to inclusive politics.
We have gone from a world where power resided in hierarchies to one where it inhabits networks.
Statecraft has yet to adapt.
The international institutions and partnerships that emerged in the postwar years demand both maintenance and modernization.
In the face of all of this turbulence, some suggest that America should turn inward.
That is nothing new.
Some argued the same after WWII.
They argued it again 25 years ago, after the fall of the Berlin Wall.
They were wrong then – and they are wrong now.
The need for leadership has never been greater, and the US has never been more engaged with the world.
Our role in Afghanistan’s first-ever peaceful, democratic transition reminds us all that, having invested so much blood and treasure in helping to give Afghans a chance to succeed in battle, the world has just as much responsibility to help its leaders succeed in governance.
We know that the destruction of 100% of Syria’s declared chemical weapons would not have happened without direct, hands-on diplomacy and perseverance, just as Syria’s immoral and horrifying civil war will not end without an equal commitment.
So, too, in Asia, where President Barack Obama and Chinese President Xi Jinping just announced ambitious commitments to tackle climate change, we are reminded of what countries can accomplish together with real leadership – and of how much additional leadership is required to conclude a successful climate agreement in Paris next year.
The world has changed, and we are changing with it.
Lines on the map no longer contain the gravest threats, and the players are no longer divided neatly into two camps.
In the twenty-first century, next door is everywhere.
That is why the world needs coalition diplomacy.
No country can defeat terrorism on its own.
No country can solve the existential threat of climate change alone.
No country can eradicate extreme poverty, combat potential pandemics, or improve nuclear security by itself.
None of us can live safer, richer lives by turning our back to the world.
We must build on our history of working with allies by forming new coalitions – with governments, with civil society, and, yes, with everyday people.
A good example is the international effort to confront the Islamic State’s malign brutality in Iraq and Syria.
Political, humanitarian, and intelligence tools from more than 60 countries are being used to support unified military action.
Success depends not on what one or even a handful of countries can do alone, but on what all of us are able to achieve by moving forward together against this common threat.
On an equally important front, the US is working with the United Nations to galvanize a global response to the danger posed by the Ebola virus.
I have personally talked with more than 50 foreign leaders, and we all agree that only by coordinating our actions can we stop the devastation in West Africa and halt Ebola’s spread.
We are making progress on both issues, but much work remains.
Bringing together countries with competing interests and varying resources is hard work.
It demands intense diplomatic engagement and calls upon relationships that have been built and maintained over decades, as well as alliances with new partners.
But by overcoming differences and coordinating efforts to defeat the Islamic State and conquer Ebola, we are reinforcing support for a world order grounded in collective solutions to common problems.
Cooperation is equally vital in reinforcing the bedrock economic principles on which America and other countries built their postwar prosperity.
Frustration cannot grow faster than opportunity in any country.
For example, the negotiations on the Trans-Pacific Partnership (TPP) reflect President Obama’s determination to strike an accord with countries that represent one-third of global trade and 40% of global GDP.
The benefits – for both the US and our partners – are enormous.
Estimates are that the TPP could provide $77 billion a year in real income and support 650,000 new jobs in the US alone.
The Transatlantic Trade and Investment Partnership being negotiated with the European Union offers another major step toward increasing trade.
Whether for mutual security or shared prosperity, genuine partnerships are not built overnight.
Patient diplomacy and a collective will are needed to advance common goals. America’s objectives remain the same as they have been for decades – peace, prosperity, and stability for the US and for our partners around the world.
Closing the Investment Gap
BERKELEY – The weakness of private investment in the United States and other advanced economies is a worrisome – and perplexing – feature of the recovery from the 2008 global financial crisis.
Indeed, according to the International Monetary Fund, through 2014, private investment declined by an average of 25% compared to pre-crisis trends.
The shortfall in investment has been deep and broad-based, affecting not only residential investment but also investment in equipment and structures.
Business investment remains significantly below pre-2008 expectations, and has been hit hard again in the US during the last year by the collapse of energy-sector investment in response to the steep drop in oil prices.
Interestingly, the investment shortfall in the US coincides with a strong rebound in returns to capital.
By one measure, returns to private capital are now at a higher point than any time in recent decades.
But extensive empirical research confirms that at the macro level, business investment depends primarily on expected future demand and output growth, not on current returns or retained earnings.
According to the IMF, this “accelerator” theory of investment explains most of the weakness of business investment in the developed economies since the 2008 crisis.
In accordance with this explanation, investment growth in the US has been in line with its usual historical relationship with output growth.
In short, private investment growth has been weak primarily because the pace of recovery has been anemic.
Businesses have marked down their pre-crisis investment plans to reflect a post-crisis “new normal” of slower and more uncertain growth in demand for their output.
Under conditions of weak aggregate demand, stronger public investment encourages more private business investment.
But public investment, too, has fallen below pre-crisis expectations, aggravating rather than ameliorating the slump in private investment.
The accelerator explanation of the shortfall in business investment in the US is consistent with evidence that, where projected demand growth has been relatively strong – for example, in cable, telecommunications, digital platforms, social networking, and, until recently, energy – investment growth has also been relatively strong.
Indeed, telecom and cable companies accounted for the largest share of business capital expenditures during the last three years, with energy production and mining second on the list.
Differences in innovation opportunities across industries are also consistent with the changing composition of business investment.
During the 2009-2015 period, while business investment in equipment slowed in the US, it accelerated in intellectual property products, including research and development, software, and so-called artistic originals (the output of artists, studios, and publishers).
R&D investment usually expands faster than GDP during cyclical expansions, and the current period is in line with historical trends.
Indeed, as a share of the economy, R&D investment is now at its highest level on record, which bodes well for future productivity growth.
As the accelerator theory of investment would predict, much R&D investment is occurring in technology-intensive sectors where current and future expected demand has been strong.
There is also evidence that the distribution of returns to capital is becoming increasingly skewed toward these sectors.
According to a recent McKinsey Global Institute report, the most digitized sectors – ranked by 18 metrics on digital assets, digital usage, and digital workforce – enjoy significantly higher profit margins than traditional sectors.
In a recent letter to the chief executives of the S&P 500 companies and large European corporations, Larry Fink, the CEO of BlackRock, the world’s largest investment management company, expressed concern that many global firms may be sacrificing value-creating investments by distributing dividends and buying back their own shares.
Among US nonfinancial corporations, the proportion of investable funds used for dividends and share buybacks has been trending upward, albeit with cyclical ups and downs, since the 1980s.
After a sharp downturn during the 2008-2009 recession, this proportion has now recovered to nearly 50%, a high point relative to historical averages.
The macro evidence indicates that the primary cause of disappointing business investment in the US and other developed countries in the years following the global financial crisis has been anemic demand, not a lack of investable funds resulting from excessive distributions to shareholders.
Over the longer term, however, the upward trend in dividends and share buybacks as a percentage of corporate investable funds is a symptom of mounting shareholder pressure on corporations to focus on short-term returns at the expense of long-term investments.
In a recent McKinsey survey of 1,000 top executives and corporate directors, 63% reported that shareholder pressure to realize short-term returns has increased over the last several years.
Indeed, some 79% reported pressure to demonstrate strong financial returns in two years or less.
Shareholder pressure tends to be greater in older firms, and in the US over the last few decades, the proportion of older firms has been growing as the startup rate for new businesses has fallen.
In addition, as Fink and others have warned, compensation practices that link top executives’ pay to measures of short-term success like quarterly earnings per share or annual equity performance also encourage “short-termism” in corporate investment decisions.
A sliding capital gains tax, with rates that decline as the holding period for investments increases, would reduce incentives for short-termism among investors.
Among others, Larry Fink, the Center for American Progress, and Hillary Clinton propose this approach.
In his recent CEO letter, Fink also calls on companies to issue annual “strategic frameworks” for long-term value creation, supported by quantifiable financial metrics and linking long-term executive compensation to performance on them.
These frameworks, Fink notes, should cover environmental, social, and governance (ESG) factors that are core determinants of long-term value.
Companies can use the new evidence-based standards developed by the Sustainability Accounting Standards Board to disclose material information about their ESG performance to their investors.
Strategic frameworks, along with ESG disclosure, should encourage both companies and their shareholders to focus more on long-term value and less on short-term financial performance.
But at the macro level, expected growth in demand and associated innovation opportunities will remain the primary drivers of business investment.
Inequality and the American Child
NEW YORK – Children, it has long been recognized, are a special group.
They do not choose their parents, let alone the broader conditions into which they are born.
They do not have the same abilities as adults to protect or care for themselves.
That is why the League of Nations approved the Geneva Declaration on the Rights of the Child in 1924, and why the international community adopted the Convention on the Rights of the Child in 1989.
Sadly, the United States is not living up to its obligations.
In fact, it has not even ratified the Convention on the Rights of the Child.
The US, with its cherished image as a land of opportunity, should be an inspiring example of just and enlightened treatment of children.
Instead, it is a beacon of failure – one that contributes to global sluggishness on children’s rights in the international arena.
Though an average American childhood may not be the worst in the world, the disparity between the country’s wealth and the condition of its children is unparalleled.
About 14.5% of the American population as a whole is poor, but 19.9% of children – some 15 million individuals – live in poverty.
Among developed countries, only Romania has a higher rate of child poverty.
The US rate is two-thirds higher than that in the United Kingdom, and up to four times the rate in the Nordic countries.
For some groups, the situation is much worse: more than 38% of black children, and 30% of Hispanic children, are poor.
None of this is because Americans do not care about their children.
It is because America has embraced a policy agenda in recent decades that has caused its economy to become wildly unequal, leaving the most vulnerable segments of society further and further behind.
The growing concentration of wealth – and a significant reduction in taxes on it – has meant less money to spend on investments for the public good, like education and the protection of children.
As a result, America’s children have become worse off.
Their fate is a painful example of how inequality not only undermines economic growth and stability – as economists and organizations like the International Monetary Fund are finally acknowledging – but also violates our most cherished notions of what a fair society should look like.
Income inequality is correlated with inequalities in health, access to education, and exposure to environmental hazards, all of which burden children more than other segments of the population.
Indeed, nearly one in five poor American children are diagnosed with asthma, a rate 60% higher than non-poor children.
Learning disabilities occur almost twice as frequently among children in households earning less than $35,000 a year than they do in households earning more than $100,000.
And some in the US Congress want to cut food stamps – on which some 23 million American households depend, threatening the poorest children with hunger.
These inequalities in outcomes are closely tied to inequalities in opportunities.
Inevitably, in countries where children have inadequate nutrition, insufficient access to health care and education, and higher exposure to environmental hazards, the children of the poor will have far different life prospects from those of the rich.
And, partly because an American child’s lifetime prospects are more dependent on his or her parents’ income and education than in other advanced countries, the US now has the least equality of opportunity of any advanced country.
At America’s most elite universities, for example, only around 9% of students come from the bottom half of the population, while 74% come from the top quarter.
Most societies recognize a moral obligation to help ensure that young people can live up to their potential.
Some countries even impose a constitutional mandate for equality of educational opportunities.
But in America, more is spent on the education of rich students than on the education of the poor.
As a result, the US is wasting some of its most valuable assets, with some young people – bereft of skills – turning to dysfunctional activities.
American states like California spend about as much on prisons as on higher education – and sometimes more.
Without compensatory measures – including pre-school education, ideally beginning at a very young age – unequal opportunities translate into unequal lifelong outcomes by the time children reach the age of five.
That should be a spur to policy action.
Indeed, while inequality’s harmful effects are wide-reaching, and impose huge costs on our economies and societies, they are largely avoidable.
The extremes of inequality observed in some countries are not the inexorable result of economic forces and laws.
The right policies – stronger social safety nets, progressive taxation, and better regulation (especially of the financial sector), to name a few – can reverse these devastating trends.
To generate the political will that such reforms require, we must confront policymakers’ inertia and inaction with the grim facts of inequality and its devastating effects on our children.
We can reduce childhood deprivation and increase equality of opportunity, thereby laying the groundwork for a more just and prosperous future – one that reflects our own avowed values.
So why don’t we?
Of the harm that inequality inflicts on our economies, politics, and societies, the damage done to children demands special concern.
Whatever responsibility poor adults may bear for their lot in life – they may not have worked hard enough, saved enough, or made good decisions – children’s circumstances are thrust upon them without any sort of choice.
Children, perhaps more than anyone, need the protection that rights afford – and the US should be providing the world with a shining example of what that means.
American Conservatism’s Crisis of Ideas
BERKELEY – On the back left corner of my desk right now are three recent books: Arthur Brooks’ The Battle, Charles Murray’s Coming Apart, and Nicholas Eberstadt’s A Nation of Takers.
Together, they constitute an important intellectual movement, which also happens to be a large part of the reason that American conservatism today has little that is constructive to say about managing the economy – and little purchase on the center of the American electorate.
But let’s back up historically, to the founding of what we might call modern conservatism in early nineteenth-century Britain and France.
There were some – Frédéric Bastiat and Jean-Baptiste Say come to mind – who believed that government should put the unemployed to work building infrastructure when markets or production were temporarily disrupted.
But they were balanced by those like Nassau Senior, who spoke out against even famine relief: Although a million people would die in the Irish Potato Famine, “that would scarcely be enough.”
The main thrust of early conservatism was root-and-branch opposition to every form of social insurance: make the poor richer, and they would become more fertile.
As a result, farm sizes would drop (as land was divided among ever more children), labor productivity would fall, and the poor would become even poorer.
Social insurance was not just pointless; it was counterproductive.
The proper economic policy was to teach people to venerate the throne (so that they would respect property), the paternal hearth (so that they would not marry imprudently young), and the religious altar (so that they would fear pre-marital sex).
Then, perhaps, with women chaste for half or more of their childbearing years, the surplus population would diminish and conditions for the poor would be as good as they could be.
Fast-forward 150 years to post-World War II America, and to the original Chicago School critique of the New Deal version of social insurance – that it created “notches” that perverted economic incentives.
The government, Milton Friedman and others argued, told the poor: make more money and we will take away your free housing, food stamps, and income support.
People are rational, Friedman said, so they will not work for long if they get nothing or next to nothing for it.
The big difference between the Malthusian conservative critics of social insurance in the early nineteenth century and the Chicago critics of the 1970’s is that the Chicago critics had a point: Providing public support to the “worthy” poor, and then removing it when they began to stand on their own feet, poisoned incentives and was unlikely to lead to good outcomes.
And so, from 1970 to 2000, a broad coalition of conservatives (who wanted to see the government stop encouraging immorality), centrists (who wanted government money spent effectively), and leftists (who wanted poverty alleviated) removed the “notches” from the social-insurance system.
Presidents Jimmy Carter, Ronald Reagan, George H. W. Bush, Bill Clinton, and even George W. Bush and their supporters created the current system, in which tax rates and eligibility thresholds are not punitive disincentives to enterprise.
So what is the problem that America’s new generation of conservative critics of social insurance sees?
It is not that raising poor people’s standard of living above bare subsistence produces Malthusian catastrophe, or that taxes and withdrawal of welfare benefits make people work, at the margin, for nothing.
For Eberstadt, the problem is that dependence on government is emasculating, and that too many people are dependent on government.
For Brooks, it is that knowing that public programs make one’s life easier causes one to vote for non-Republican candidates.
For Murray, it is that social insurance means that behaving badly does not lead to catastrophe – and we need bad behavior to lead to catastrophe in order to keep people from behaving badly.
The crucial point is that America’s conservative elites believe Brooks, Eberstadt, and Murray.
To this day, Mitt Romney is convinced that he lost the presidency in 2012 because Barack Obama unfairly gave Latino-Americans subsidized health insurance; gave women free reproductive health coverage (excluding abortion); and gave other groups similar “gifts.”
He could “never convince them that they should take personal responsibility and care for their lives.”
In fact, it would be a tough sell for any candidate to convince Americans who receive government benefits that they are dependent rather than empowered; that it is bad for people to vote for politicians who make their lives better; and that good public policy seeks to create human catastrophe rather than to avert it.
The problem for American conservatives is not their choice of candidates or the tone of their rhetoric. It is that their ideas are not politically sustainable.
Angry people swayed by the populist message are angrier at liberal professors, clever bankers, or skeptical journalists than they are at multi-billionaires.
The Indispensable American Partner
MADRID – The United States is gearing up for that most intoxicating (and exhausting) of political events: an open-seat race for the presidency.
With US President Barack Obama's eight years in office coming to an end, and Vice President Joe Biden unlikely to run, the race will be without an incumbent.
As a result, the election could be less a referendum on the last eight years than a contest of ideas, with foreign policy emerging as a key topic.
The potential candidates have already sought to stake out their positions on key foreign-policy issues, with early Republican frontrunner Jeb Bush, for example, delivering a speech devoted entirely to the topic.
As for the Democrats, former Secretary of State Hillary Clinton's likely nomination (despite recent revelations that she used her personal email account to conduct government business) reinforces foreign policy's centrality to the election.
Recognizing this trend, the World Economic Forum Global Agenda Council has brought together a group of experts and practitioners to help infuse substance into the foreign-policy discussions leading up to the US election, including by preparing a public discussion paper.
From my perspective as the group's only European member, the overarching message should be that the US must conceive of itself not as “the indispensable power," as it now does, but as “the indispensable partner."
This is not merely a matter of semantics; such a change will require the US to re-conceive its role in the world.
But the payoff, for both the US and the liberal world order that it created, would be substantial.
The key to success will be America's ability to retain the best – and abandon the worst – of that most American of notions: exceptionalism.
The sense in the US that the country is unique, with a special mission to promote prosperity, security, and freedom worldwide, has long shaped American foreign policy.
The idea extends as far back as 1630, when John Winthrop, the Massachusetts Bay Colony's first governor, declared that his community must act as a “city upon a hill," setting an example for the world.
In doing so, he planted the seed of the values-based approach that was adopted by the US as it spearheaded the development of the rules and structures that order today's world.
Those rules and structures have delivered unprecedented economic growth, benefiting all (though the US has reaped the greatest rewards).
But, ironically, the notion of American exceptionalism often has led the US to undermine the international system that it nurtured.
Indeed, US history reveals a persistent isolationist streak, in which the “city upon a hill" is not a beacon, but a fortress.
At times, including over the last six years, the belief that the US is better off going it alone has led to withdrawal from the world.
This tendency was not a serious issue before World War II (though the people of Abyssinia and Manchuria may beg to differ).
But today, US withdrawal from the international system that it built has serious ramifications – namely, the kind of chaos and lawlessness exemplified by Russia's invasion of Ukraine.
Yet isolationism is not America's most destructive impulse.
Worse is its “exemptionalism": its penchant for opting out of the rules that it promotes – and often actively enforces – elsewhere.
The lengthy – and growing – list of major international conventions left unratified by the US includes the Rome Statute of the International Criminal Court, the Convention on the Elimination of All Forms of Discrimination Against Women, the Mine Ban Convention, the Convention on the Rights of the Child, and the Convention on the Rights of Persons with Disabilities.
Beyond the resentment that such an attitude engenders, American exemptionalism directly undermines multilateral institutions' capacity to address challenges that the US is unwilling or unable to resolve on its own.
How can the US expect China to follow rules on maritime delimitation in the East and South China Seas when it refuses to ratify the United Nations Convention on the Law of the Sea?
US President Barack Obama's administration has tried to create the illusion of a change of course in this regard, pushing “soft" deals that allow the US to participate without submitting to binding rules.
Such was the case with the much-lauded “handshake agreement" between Obama and Chinese President Xi Jinping on carbon-dioxide emissions in November.
But, though such arrangements make for great headlines, they do not provide the stability and predictability necessary for long-term success.
For that, hard rules and strong institutions are essential.
If the US is to serve as the world's “indispensable partner," it must recommit to the rules-based order that has served it – and the world – so well for the last seven decades.
It should begin by strengthening the flagging institutions that have served as the backbone of the liberal international order.
Specifically, the US should finally approve the International Monetary Fund reform package that was agreed in 2010; promote real progress at the Non-Proliferation Treaty Review Conference in May; and ensure that this December's UN Framework Convention on Climate Change Conference in Paris yields formal commitments.
Indispensable partnership is about helping countries help themselves.
It requires vision, commitment, and, most important, leadership.
A frank discussion about America's foreign policy could prove vital to ensuring that this “city upon a hill" remains a beacon of hope – and a catalyst of progress.
American Foreign Policy after Iraq
What comes after Iraq?
If President George W. Bush’s current troop “surge” fails to produce an outcome that can be called “victory,” what lessons will the United States draw for its future foreign policy?
Will it turn inward, as it did after its defeat in Vietnam three decades ago?
Will it turn from promoting democracy to a narrow realist view of its interests?
Even while discussion in Washington is fixated on Iraq, a number of thoughtful foreign observers are asking these longer-term questions.
Analysts and pundits have often been mistaken about America’s position in the world.
For example, two decades ago, the conventional wisdom was that the US was in decline.
A decade later, with the Cold War’s end, the new conventional wisdom was that the world was a unipolar American hegemony.
Some neo-conservative pundits drew the conclusion that the US was so powerful that it could decide what it thought was right, and others would have to follow.
Charles Krauthammer celebrated this view as “the new unilateralism,” and it heavily influenced the Bush administration even before the attacks on September 11, 2001.
But the new unilateralism was based on a profound misunderstanding of the nature of power in world politics.
Power is the ability to get the outcomes one wants.
Whether the possession of resources will produce such outcomes depends upon the context.
For example, a large, modern tank army is a powerful resource if a war is fought in a desert, but not if it is fought in a swamp – as America discovered in Vietnam.
In the past, it was assumed that military power dominated most issues, but in today’s world, the contexts of power differ greatly.
I have likened the distribution of power in politics today as analogous to a three-dimensional chess game.
On the top board – military relations among states – the world is, indeed, unipolar, and likely to remain that way for decades.
But on the middle board of economic relations, the world is already multipolar, and the US cannot obtain the outcomes it wants without the cooperation of Europe, Japan, China, and others.
And, on the bottom board of transnational issues outside the control of governments – including everything from climate change to pandemics to transnational terrorism – power is chaotically distributed, and it makes no sense at all to claim American hegemony.
Yet it is on this bottom board that we find most of the greatest challenges we face today.
The only way to grapple with these problems is through cooperation with others, and that requires the “soft” power of attraction as well as the hard power of coercion. There is no simple military solution that will produce the outcomes we want.
The new unilateralists who dominated Bush’s first administration made the mistake of thinking that the unipolar distribution of power in the military context was sufficient to guide foreign policy.
They were like a young boy with a hammer who thinks that every problem resembles a nail.
The danger of their approach is now obvious.
Whoever plays a three-dimensional game by focusing on only one board is bound to lose in the long run.
Fortunately, the pendulum has begun to swing back toward cooperation.
In Bush’s second term, some of the most extreme unilateralists have departed from the government, and the president has approached difficult problems like North Korea or Iran with a more multilateral approach than during his first term.
Likewise, for all the complaints about the United Nations, the US and others turned to UN peacekeepers to sort out the mess after the Lebanon War last summer.
The Iraq War, in particular, increased public awareness of the mistakes in Bush’s first term, but other issues are changing as well.
Americans now view cooperative action on global climate change more favorably.
Similarly, the threat of pandemics means that Americans may come to recognize the importance of a stronger World Health Organization, just as the problem of nuclear proliferation is increasing awareness of the importance of the International Atomic Energy Agency.
The nature of these problems means that the US does not have the luxury of turning inward no matter what the outcome in Iraq.
These are not problems you can leave overseas.
They follow you home.
It also is unlikely that American foreign policy will return to a narrow realism and drop all emphasis on democracy and human rights.
While the Iraq War discredited the idea of coercive democratization, both Republicans and Democrats have a strong strand of idealism in their foreign policy orientations.
The problem for whoever is elected president in 2008 will be to find appropriate realistic means to advance democratic values and adjust official rhetoric accordingly.
When rhetoric greatly outstrips reality, others view it as hypocrisy.
Americans will need to find ways to assert their narrative of democracy, freedom, and rights in a manner that respects diversity and the views of others.
What Iraq has taught is the importance of developing civil society and the rule of law before trying to hold broad-based elections.
Democracy is more than voting, for it requires large investments in education, institutions, and promotion of non-governmental organizations.
It must be rooted in the indigenous society and bear its characteristics, not be imposed from abroad.
It is highly unlikely that the US will react after Iraq as it did after Vietnam.
The paradox of American power is that the world’s only military superpower cannot protect its citizens by acting alone.
American Foreign Policy After the Mid-Term Elections
NEW YORK – Few Americans cast their ballot in the recent mid-term elections on the basis of foreign policy.
While it may be difficult for people around the world to comprehend this, given the global reach of the United States, it is an undeniable fact.
Most Americans are, after all, preoccupied with the US economy’s sluggish growth and persistent high unemployment.
The world’s challenges seem far removed from their day-to-day lives.
The Cold War ended a generation ago; the terror attacks of September 11, 2001, are nearly a decade in the past.
Most Americans do not feel the sacrifices associated with the large troop presence and ongoing conflicts in Afghanistan and Iraq.
But the fact that foreign policy did not materially affect the November elections does not mean that the results will not affect US foreign policy.
They will, but in ways that are inconsistent and even surprising.
One relationship sure to be influenced by Republican gains will be that between the US and Russia.
Quick or easy Senate approval of the New START arms-control treaty is highly unlikely, given stated concerns about verification and the protection of US missile-defense programs; instead, we can expect delays and, possibly, attempts to amend what the two governments already agreed upon.
Congress may also prove less willing to remove hurdles to Russia’s admission to the World Trade Organization, given what is widely judged to be its leaders’ anti-democratic behavior.
China, too, will feel the results of the new balance in Congress.
Pressure was already growing to introduce trade sanctions in response to China’s refusal to allow its currency to rise to a natural level against the dollar.
Such pressure will likely grow, given concerns over Chinese behavior both at home and abroad.
Moreover, Congress will resist rolling back any of the long-standing economic sanctions against Cuba.
President Barack Obama has the authority to take some small steps on his own to normalize ties, but substantial change to US policy requires Congress to act – and Congress wants to see fundamental change in Cuba before it does so.
There will be other consequences stemming from the election.
What little chance there was of the US backing any global plan to limit or tax carbon emissions has disappeared.
Improvement in US performance on climate change will have to come from innovation and increased energy efficiency.
One can anticipate the Republicans, now in control of the House of Representatives, exploiting their ability to convene hearings to question and review foreign policy.
Depending on how this power is used (or abused), it can be beneficial (exercising needed oversight and increasing the transparency of policy and policy-making) or destructive (if, for example, hearings degenerate into politically motivated attacks on administration officials and policies).
In many other areas, continuity can be expected to trump change.
This comes as little surprise, as America’s Constitution and political system delegate most of the initiative on foreign policy and defense to the president.
Yes, Congress must declare war, approve spending, agree to most senior appointments, and (in the case of the Senate) ratify treaties, but the president has enormous latitude when it comes to carrying out diplomacy and using military force in situations other than war, which tend to be most situations.
One area of probable continuity is the Middle East, where Obama will continue to try to broker a deal between Israelis and Palestinians and press Iran not to develop nuclear weapons.
(Republicans, however will argue for putting less pressure on Israel to compromise and more pressure on Iran.)  But he can expect considerable backing from Republicans if he wants to maintain a sizeable US military presence in Afghanistan beyond this July, or a modest military presence in Iraq beyond the end of 2011.
Questions abound when it comes to foreign economic policy, however.
Three completed trade agreements (with South Korea, Panama, and Colombia) have been languishing for years, mostly because of deep opposition to free trade from labor unions and the Democratic Party.
Republicans have historically been more supportive of such bilateral free-trade agreements.
But will the new generation of Republicans continue this tradition?
There is a fair chance that one or more of these bilateral accords will be approved (in part because the Obama administration seems finally to have recognized that trade can generate good jobs), but it is far less certain that the president will gain the authority needed to negotiate a new global trade deal.
An even bigger question mark hovers over what might be the greatest national security concern of all: the federal budget deficit.
Failure to address the deficit (and the mounting debt) will create pressures to reduce what the US spends on foreign aid, intelligence, and defense – although Republicans are more likely than Democrats to protect such spending (except for foreign aid).
Mounting debt also leaves the US vulnerable to the decisions of those who lend it money – or to the vagaries of the market.
A dollar crisis could weaken the foundations of American power.
But averting such a crisis requires that the White House and Congress, Democrats and Republicans, agree on a plan for moving the US budget toward balance.
Alas, the election makes such agreement more distant than ever.
America’s Global Balancing Act
With Russia’s invasion of Ukraine and annexation of Crimea, the disintegration of Iraq’s and Syria’s borders, and increasing Chinese assertiveness in the South and East China Seas, the post-Cold War era appears to have ended in 2014.
Is that true?
The post-Cold War era was not really an “era,” but rather a gradual transition from a bilateral Cold War to a more complex international order that still involves, in the final analysis, two world powers.
In brief, the decisive axis of the new order increasingly involves the United States and the People’s Republic of China.
The Sino-American competition involves two significant realities that distinguish it from the Cold War: neither party is excessively ideological in its orientation; and both parties recognize that they really need mutual accommodation.
America’s supposed “pivot to Asia” took a back seat in 2014 to the crises in Ukraine and the Middle East.
To what extent has uncertainty about the US commitment in Asia stoked tension between China and America’s Asian allies?
I disagree with the premises of the question.
I do think America has made it quite clear that it is in the interest both of America and China to avoid situations in which they will be pushed toward a collision.
The recent indications of some initial dialogue between China and India, and between China and Japan, suggest that China also realizes that escalating old grievances is not in its interest.
The more serious problem with the “pivot to Asia” was its actual wording, which implied a military posture designed to “contain” or “isolate” China.
The Chinese have come to realize more clearly that we were not deliberately attempting to isolate them, but that we had a stake in the avoidance of collisions in the Far East that could produce a wider spillover.
Xi Jinping has used his war on corruption to concentrate more power in his hands than any Chinese leader since Deng Xiaoping, 30 years ago.
How do you see Xi’s presidency evolving?
Power in China is somewhat informally defined, and its limits are set more by political realities than by constitutional arrangements.
That makes it difficult to say whether Xi’s power is greater than any Chinese leader’s since Deng.
He certainly has an authoritative personality and without doubt is more active on the international scene than some of his predecessors.
He has also been very decisive in attacking the growing corruption that has become a major source of internal malaise, reaching even the highest levels of government.
In that respect, it may be argued that his power is more wide-ranging than that of his predecessors, but in fairness it must also be noted that the patterns of corruption that his predecessors faced were not as acute and widespread as they have become in recent years.
At the same time, the increasing emphasis in party journals on the proposition that China’s armed forces must be viewed as servants of the Communist Party, and not simply of the nation, seems to suggest concern that the military may be developing its own view of Chinese domestic affairs, in addition to proclaiming with increasing assertiveness its responsibility for national security.
The Party elite, quite understandably, does not find this reassuring.
Can Russian President Vladimir Putin’s regime withstand a prolonged period of low energy prices and Western sanctions?
What risks do you see emerging should Russia’s economy continue to decline, with Putin increasingly unable to reward his political base?
There is, of course, a danger that at some point Putin may choose to lash out and create a truly massive international crisis, and perhaps precipitate some new form of direct East-West warfare.
But to say that, one must also assume that to some extent he himself is unbalanced and has shifted from a kind of guerilla warfare against the West, always with some possibility of retreat, to all-out combat.
The outcome of that would be inherently unpredictable, but probably in any case very destructive for Russian wellbeing.
If Russia’s economy continues to decline, and if the West succeeds in deterring Putin from further use of force, it is still conceivable that some acceptable resolution (a form of which I recommended publicly by talking about the Finland model) may be contrived.
But that depends in turn on the West’s firmness in supporting Ukraine’s efforts to stabilize itself.
Following the withdrawal of US troops from Afghanistan and Iraq, much of the world now perceives the US as being in a period of “retreat,” similar to the post-Vietnam War era.
Is the US embracing a form of neo-isolationism?
Or will America’s apparent inward turn be as brief as it was following Vietnam?
I do not believe that the US is in a “period of retreat.”
The fact of the matter is that the redistribution of global power has produced a situation in which the US is no longer the sole hegemon.
The US has to acknowledge the fact that the world is now much more complex.
The spread of conflict throughout the Middle East is currently precipitated more by the rise of religious sectarianism than by American interventionism.
In these volatile circumstances, greater attention must be given to the national interests of countries such as Turkey, Iran, Saudi Arabia, Egypt, and Israel.
By the same token, the interests of any one of them must not be allowed to become the total interest of the US.
What may surprise the world most in 2015?
Perhaps the gradual reappearance in Russia of a more politically assertive liberal middle class.
That middle class was beginning to play a more significant role in shaping domestic and international Russian policy under Dmitri Medvedev.
With Putin’s return to power and his recent adventurism, it has been pushed aside by deliberately awakened and intensely stimulated national chauvinism.
Waving a chauvinist banner, however, may not be the best solution for dealing with international problems, especially if the West is intelligent and united. The Russian middle class, quite naturally, wishes to live in a society like that of Western Europe.
A Russia that gradually begins to gravitate toward the West will also be a Russia that ceases to disrupt the international system.
America’s Enemy Within
NEW YORK – Barring any unexpected new revelations, there is not much to be learned from the Tsarnaev brothers, better known as “the Boston bombers.”
We can dig into their family histories in strife-torn Dagestan, or examine, once again, the lethal appeal of Islamist radicalism.
But I doubt that this would be enlightening.
The elder brother, Tamerlan, who died in a gun battle with the police, appears to fit perfectly the profile of what the German writer Hans Magnus Enzensberger calls “the radical loser.”
And his younger brother, Dzhokhar, recovering from gunshot wounds in a Boston hospital while waiting to be put on trial for his life, seems to have been a pathetic follower who acted less out of deep conviction than out of fraternal love.
The radical loser is the kind of young man who feels victimized by an unfeeling, uncaring world.
That sour sense of rejection, felt by many confused youths, turns for some into a fierce desire for vengeance.
Like Samson in the temple of Gaza, he wishes to destroy himself in a public act of violence, taking as many people as possible with him.
Anything can trigger this final act: a lover’s rejection, a job application denied.
In the case of Tamerlan, a talented boxer, he was denied the chance to become a champion because he was not yet a United States citizen.
Radical Islamism offered him a ready-made cause to die for.
More interesting, and in a way far more disturbing, has been the reaction in the US to the Boston bombings, which killed three people and injured 264.
Even after Tamerlan had died, and Dzhokhar, already wounded, was the only known fugitive, the Boston authorities decided to close down the entire city.
Public transport was halted, trains to and from the city were stopped, shops and business closed, and citizens were told to stay home.
Until the surviving bomber was found, Boston was reduced to a ghost town.
If two troubled young men with homemade bombs cobbled together from fertilizer and pressure cookers can have this effect on a major American city, one can imagine how tempting their example must now be to other radical losers, not to mention radical groups.
It shows how vulnerable a modern city can be when its leaders lose their nerve.
The authorities’ overblown reaction – and that of much of the press – was all the odder for having occurred just as the US Senate was voting down a bill that would have made it harder for known killers and mentally disturbed people to buy guns, or for private individuals to acquire weapons normally used only in warfare.
It seems as though Americans can tolerate a society in which schoolchildren and other innocents are regularly murdered by deranged men with weapons bought on the open market, but erupt in collective hysteria when the killings are committed by people labeled as “terrorists.”
This may reflect what people are accustomed to.
The Spanish had grown so inured to acts of violence from Basque separatists that the murder of 191 people in Madrid by Islamist extremists in 2004 was met with remarkable sang-froid.
When 52 people were killed in a suicide bombing on the London Underground the following year, the British, too, reacted with relative calm, having lived through years of Irish terrorist violence in the 1970’s.
Like the Spanish, they were used to it.
Americans, despite the attacks of September 11, 2001, are not.
Worse than that, a number of Republican senators, including such luminaries as John McCain, called for stripping Dzhokhar Tsarnaev, who is a US citizen, of his legal rights and placing him before a military tribunal as an “enemy combatant,” as though the 19-year-old college student were a soldier in a war against America.
Exaggerated fear of outside enemies has always been part of the American political landscape.
The “nation of immigrants” was traditionally regarded as a refuge from danger.
The evil outside world should not be able to touch the Land of the Free.
When it does – Pearl Harbor, September 2001 – all hell breaks loose.
Another factor may be the need for a common enemy in a country whose citizens come from so many different cultures and traditions.
Besieged by Communists or Islamists, people feel a sense of belonging.
Defense of the nation against dangerous outsiders – and their domestic agents, whether real or imagined – provides a powerful bond.
Such bonds can be useful, even necessary, in times of war.
But the politics of fear poses a danger to the US itself.
The aim of political terrorist groups, such as Al Qaeda, is to provoke retaliation and maximize publicity for their cause.
As common criminals, such groups’ members would not achieve this goal.
But by claiming to be soldiers at war with the world’s biggest military power, they gain sympathy, as well as recruits, among the radical losers and the disaffected.
Former President George W. Bush once explained terrorism as the expression of hatred for American freedom.
But when terrorism results in torture of prisoners, ever more police surveillance, and official threats to US citizens’ legal rights – or, for that matter, when a crime committed by two young immigrants causes an entire city to be shut down – Americans’ government is harming their freedom more than any terrorist could ever hope to do.
American Hegemony or American Primacy?
CAMBRIDGE – No country in modern history has possessed as much global military power as the United States.
Yet some analysts now argue that the US is following in the footsteps of the United Kingdom, the last global hegemon to decline.
This historical analogy, though increasingly popular, is misleading.
Britain was never as dominant as the US is today.
To be sure, it maintained a navy equal in size to the next two fleets combined, and its empire, on which the sun never set, ruled over a quarter of humankind.
But there were major differences in the relative power resources of imperial Britain and contemporary America.
By the outbreak of World War I, Britain ranked only fourth among the great powers in terms of military personnel, fourth in terms of GDP, and third in military spending.
The British Empire was ruled in large part through reliance on local troops.
Of the 8.6 million British forces in WWI, nearly a third came from the overseas empire.
That made it increasingly difficult for the government in London to declare war on behalf of the empire when nationalist sentiments began to intensify.
By World War II, protecting the empire had become more of a burden than an asset.
The fact that the UK was situated so close to powers like Germany and Russia made matters even more challenging.
For all the loose talk of an “American empire,” the fact is that the US does not have colonies that it must administer, and thus has more freedom to maneuver than the UK did.
And, surrounded by unthreatening countries and two oceans, it finds it far easier to protect itself.
That brings us to another problem with the global hegemon analogy: the confusion over what “hegemony” actually means.
Some observers conflate the concept with imperialism; but the US is clear evidence that a hegemon does not have to have a formal empire.
Others define hegemony as the ability to set the rules of the international system; but precisely how much influence over this process a hegemon must have, relative to other powers, remains unclear.
Still others consider hegemony to be synonymous with control of the most power resources.
But, by this definition, nineteenth-century Britain – which at the height of its power in 1870 ranked third (behind the US and Russia) in GDP and third (behind Russia and France) in military expenditures – could not be considered hegemonic, despite its naval dominance.
Similarly, those who speak of American hegemony after 1945 fail to note that the Soviet Union balanced US military power for more than four decades.
Though the US had disproportionate economic clout, its room for political and military maneuver was constrained by Soviet power.
Some analysts describe the post-1945 period as a US-led hierarchical order with liberal characteristics, in which the US provided public goods while operating within a loose system of multilateral rules and institutions that gave weaker states a say.
They point out that it may be rational for many countries to preserve this institutional framework, even if American power resources decline.
In this sense, the US-led international order could outlive America’s primacy in power resources, though many others argue that the emergence of new powers portends this order’s demise.
But, when it comes to the era of supposed US hegemony, there has always been a lot of fiction mixed in with the facts.
It was less a global order than a group of like-minded countries, largely in the Americas and Western Europe, which comprised less than half of the world.
And its effects on non-members – including significant powers like China, India, Indonesia, and the Soviet bloc – were not always benign.
Given this, the US position in the world could more accurately be called a “half-hegemony.”
Of course, America did maintain economic dominance after 1945: the devastation of WWII in so many countries meant that the US produced nearly half of global GDP.
That position lasted until 1970, when the US share of global GDP fell to its pre-war level of one-quarter.
But, from a political or military standpoint, the world was bipolar, with the Soviet Union balancing America’s power.
Indeed, during this period, the US often could not defend its interests: the Soviet Union acquired nuclear weapons; communist takeovers occurred in China, Cuba, and half of Vietnam; the Korean War ended in a stalemate; and revolts in Hungary and Czechoslovakia were repressed.
Against this background, “primacy” seems like a more accurate description of a country’s disproportionate (and measurable) share of all three kinds of power resources: military, economic, and soft.
The question now is whether the era of US primacy is coming to an end.
Given the unpredictability of global developments, it is, of course, impossible to answer this question definitively.
The rise of transnational forces and non-state actors, not to mention emerging powers like China, suggests that there are big changes on the horizon.
But there is still reason to believe that, at least in the first half of this century, the US will retain its primacy in power resources and continue to play the central role in the global balance of power.
In short, while the era of US primacy is not over, it is set to change in important ways.
Whether or not these changes will bolster global security and prosperity remains to be seen.
Renewing American Leadership
MADRID – December always provides an opportunity to pause and reflect on what was and what will be.
This year, one of the conclusions that such reflection yields is that the United States remains firmly at the center of the liberal world order.
Another is that the US needs to do more to lead in the way that its international standing demands.
Doubts about America’s continued global leadership have been proliferating for years.
But, though the much-discussed multi-polar world order may well be in the cards, the reality is that, for now, efforts to address global challenges – from climate change to conflict in the Middle East – demand US engagement.
Unfortunately, the narrative of American decline has gained so much traction in recent years that even US officials seem to have started to believe it, pursuing weak and piecemeal policies (or, in some cases, doing nothing at all).
President Barack Obama’s restrained foreign-policy approach appears to be fueling, not reducing, global instability.
The reasons for this lack of strong action are disputed.
Some blame Obama’s own fears about repeating his predecessors’ mistakes; others blame a hostile Congress for tying his hands.
In fact, both factors may be at work.
It may well be true that Obama would rather exercise caution – even when bold action is called for – than act impulsively and potentially cause more damage.
But the negative impact of an obstructionist, highly partisan US Congress should not be underestimated.
For example, by blocking reforms to International Monetary Fund governance that were agreed in 2010, Congress has damaged, perhaps irreparably, the legitimacy and relevance of the Bretton Woods institutions.
Likewise, by refusing to ratify the United Nations Convention on the Law of the Sea, the US Congress has undermined America’s credibility as it attempts to reaffirm international law in the South China Sea, where China is acting with increasing audacity.
And, by opposing the inclusion of legally binding climate commitments, it weakened the global climate agreement that was reached this month in Paris, leaving compliance and implementation uncertain.
Stalemate has become the name of the game in US politics in recent years.
That is why next year’s presidential election is so crucial.
It offers an opportunity for a fresh start, a new approach that produces the type of policy actions that the world needs.
The key is engagement – among branches of the US government, between the US government and the public, and between the US and the rest of the world.
For starters, to avoid the kind of obstructionism that prevailed in the last eight years, the next president must engage Congress directly and actively.
And, in fact, two of the Obama administration’s recent wins – the passage of so-called trade promotion authority (fast-track negotiating authority to conclude the Trans-Pacific Partnership) and the reauthorization of the small but vital Export-Import Bank – were the result of dedicated outreach, education, and, yes, cajoling of lawmakers.
The Iran nuclear agreement, one of Obama’s hallmark achievements, involved similar efforts to engage Congress, from protracted trips to Capitol Hill by Obama administration officials to a creative approach that allowed legislators to display their displeasure for the deal, without blocking its progress.
Even in America’s highly divisive political atmosphere, it seems, where there is a will, there is a way.
America’s next president must also improve engagement with citizens, whose widespread disaffection constrains – or allows – US leaders to pursue a weak foreign policy.
Like many Europeans today, most Americans do not seem to understand – or care to understand – that the crumbling of the liberal world order would have dire consequences for all of them.
It was not always this way.
Immediately after World War II, the memory of war, together with the enduring threat posed by the Soviet Union, made plain the importance of building and maintaining a liberal world order.
Today, though the need for such an order is just as great, the argument is not nearly as comprehensible or emotionally powerful.
Discussion of rules and institutions comes across as bloodless.
It is up to political leaders – and especially the president – to figure out how to make a compelling case about what is at stake.
Only this approach can secure the mandate from the public that the next US president will need to engage effectively with other world leaders.
And make no mistake: Such engagement is indispensable.
While the US must play an integral role in addressing global challenges, from ending the Syrian civil war to following through on the promises of the Paris climate agreement, it cannot do it alone.
Real progress will demand real cooperation.
In the second half of the twentieth century, the US showed that committed leadership could help to ensure widespread stability and prosperity.
In the twenty-first century, it has showed how devastating a lack of such leadership can be.
Finger pointing will not fix anything.
Only by pursuing genuine, deep, and sustained engagement, both at home and abroad, can the next administration ensure that the coming years will be better than the last.
American Pie in the Sky
NEW YORK – While the risk of a disorderly crisis in the eurozone is well recognized, a more sanguine view of the United States has prevailed.
For the last three years, the consensus has been that the US economy was on the verge of a robust and self-sustaining recovery that would restore above-potential growth.
That turned out to be wrong, as a painful process of balance-sheet deleveraging – reflecting excessive private-sector debt, and then its carryover to the public sector – implies that the recovery will remain, at best, below-trend for many years to come.
Even this year, the consensus got it wrong, expecting a recovery to above-trend &nbsp;annual GDP growth – faster than 3%.
But the first-half growth rate looks set to come in closer to 1.5% at best, even below 2011’s dismal 1.7%.
And now, after getting the first half of 2012 wrong, many are repeating the fairy tale that a combination of lower oil prices, rising auto sales, recovering house prices, and a resurgence of US manufacturing will boost growth in the second half of the year and fuel above-potential growth by 2013.
The reality is the opposite: for several reasons, growth will slow further in the second half of 2012 and be even lower in 2013 – close to stall speed.
First, growth in the second quarter has decelerated from a mediocre 1.8% in January-March, as job creation – averaging 70,000 a month – fell sharply.
Second, expectations of the “fiscal cliff” – automatic tax increases and spending cuts set for the end of this year – will keep spending and growth lower through the second half of 2012.
So will uncertainty about who will be President in 2013; about tax rates and spending levels; about the threat of another government shutdown over the debt ceiling; and about the risk of another sovereign rating downgrade should political gridlock continue to block a plan for medium-term fiscal consolidation.
In such conditions, most firms and consumers will be cautious about spending – an option value of waiting – thus further weakening the economy.
Third, the fiscal cliff would amount to a 4.5%-of-GDP drag on growth in 2013 if all tax cuts and transfer payments were allowed to expire and draconian spending cuts were triggered.
Of course, the drag will be much smaller, as tax increases and spending cuts will be much milder.
But, even if the fiscal cliff turns out to be a mild growth bump – a mere 0.5% of GDP – and annual growth at the end of the year is just 1.5%, as seems likely, the fiscal drag will suffice to slow the economy to stall speed: a growth rate of barely 1%.
Fourth, private consumption growth in the last few quarters does not reflect growth in real wages (which are actually falling).
Rather, growth in disposable income (and thus in consumption) has been sustained since last year by another $1.4 trillion in tax cuts and extended transfer payments, implying another $1.4 trillion of public debt.
Unlike the eurozone and the United Kingdom, where a double-dip recession is already under way, owing to front-loaded fiscal austerity, the US has prevented some household deleveraging through even more public-sector releveraging –&nbsp;that is, by stealing some growth from the future.
In 2013, as transfer payments are phased out, however gradually, and as some tax cuts are allowed to expire, disposable income growth and consumption growth will slow.
The US will then face not only the direct effects of a fiscal drag, but also its indirect effect on private spending.
Fifth, four external forces will further impede US growth: a worsening eurozone crisis; an increasingly hard landing for China; a generalized slowdown of emerging-market economies, owing to cyclical factors (weak advanced-country growth) and structural causes (a state-capitalist model that reduces potential growth); and the risk of higher oil prices in 2013 as negotiations and sanctions fail to convince Iran to abandon its nuclear program.
Policy responses will have very limited effect in stemming the US economy’s deceleration toward stall speed: even with only a mild fiscal drag on growth, the US dollar is likely to strengthen as the eurozone crisis weakens the euro and as global risk aversion returns.
The US Federal Reserve will carry out more quantitative easing this year, but it will be ineffective: long-term interest rates are already very low, and lowering them further would not boost spending.
Indeed, the credit channel is frozen and velocity has collapsed, with banks hoarding increases in base money in the form of excess reserves.
Moreover, the dollar is unlikely to weaken as other countries also carry out quantitative easing.
Similarly, the gravity of weaker growth will most likely overcome the levitational effect on equity prices from more quantitative easing, particularly given that equity valuations today are not as depressed as they were in 2009 or 2010.
Indeed, growth in earnings and profits is now running out of steam, as the effect of weak demand on top-line revenues takes a toll on bottom-line margins and profitability.
A significant equity-price correction could, in fact, be the force that in 2013 tips the US economy into outright contraction.
And if the US (still the world’s largest economy) starts to sneeze again, the rest of the world – its immunity already weakened by Europe’s malaise and emerging countries’ slowdown – will catch pneumonia.
American Power in the Twenty-First Century
CAMBRIDGE – The United States government’s National Intelligence Council projects that American dominance will be “much diminished” by 2025, and that the one key area of continued American superiority – military power – will be less significant in the increasingly competitive world of the future.
Russian President Dmitri Medvedev has called the 2008 financial crisis a sign that America’s global leadership is coming to an end.
The leader of Canada’s opposition Liberal Party, Michael Ignatieff, suggests that US power has passed its mid-day.
How can we know if these predictions are correct?
One should beware of misleading metaphors of organic decline.
Countries are not like humans with predictable life spans.
For example, after Britain lost its American colonies at the end of the eighteenth century, Horace Walpole lamented Britain’s reduction to “as insignificant a country as Denmark or Sardinia.”
He failed to foresee that the industrial revolution would give Britain a second century of even greater ascendency.
Rome remained dominant for more than three centuries after the apogee of Roman power.
Even then, Rome did not succumb to another state, but suffered a death of a thousand cuts inflicted by various barbarian tribes.
Indeed, for all the fashionable predictions of China, India, or Brazil surpassing the US in the coming decades, the classical transition of power among great states may be less of a problem than the rise of modern barbarians – non-state actors.
In an information-based world of cyber-insecurity, power diffusion may be a greater threat than power transition.
So, what will it mean to wield power in the global information age of the twenty-first century?
What resources will produce power?
In the sixteenth century, control of colonies and gold bullion gave Spain the edge; seventeenth-century Holland profited from trade and finance; eighteenth-century France gained from its larger population and armies; and nineteenth-century British power rested on its industrial primacy and its navy.
Conventional wisdom has always held that the state with the largest military prevails, but in an information age it may be the state (or non-state) with the best story that wins.
Today, it is far from clear how the balance of power is measured, much less how to develop successful survival strategies.
In his inaugural address in 2009, President Barack Obama stated that “our power grows through its prudent use; our security emanates from the justness of our cause, the force of our example, the tempering qualities of humility and restraint.”
Shortly thereafter, Secretary of State Hillary Clinton said, “America cannot solve the most pressing problems on our own, and the world cannot solve them without America.
We must use what has been called ‘smart power,’ the full range of tools at our disposal.”
Smart power means the combination of the hard power of command and the soft power of attraction.
Power always depends on context.
The child who dominates on the playground may become a laggard when the context changes to a disciplined classroom.
In the middle of the twentieth century, Josef Stalin scornfully asked how many divisions the Pope had, but four decades later, the Papacy was still intact while Stalin’s empire had collapsed.
In today’s world, the distribution of power varies with the context.
It is distributed in a pattern that resembles a three-dimensional chess game.
On the top chessboard, military power is largely unipolar, and the US is likely to remain the only superpower for some time.
But on the middle chessboard, economic power has already been multi-polar for more than a decade, with the US, Europe, Japan, and China as the major players, and others gaining in importance.
The bottom chessboard is the realm of cross-border transactions that occur outside of government control.
It includes diverse non-state actors, such as bankers electronically transferring sums larger than most national budgets, and, at the other extreme, terrorists transferring weapons or hackers threatening cyber-security.
It also includes new challenges like pandemics and climate change.
On this bottom board, power is widely dispersed, and it makes no sense to speak of unipolarity, multipolarity, hegemony, or any other cliché.
Even in the aftermath of the financial crisis, the giddy pace of technological change is likely to continue to drive globalization and transnational challenges.
The problem for American power in the twenty-first century is that there are more and more things outside the control of even the most powerful state.
Although the US does well on military measures, there is much going on that those measures fail to capture.
Under the influence of the information revolution and globalization, world politics is changing in a way that prevents America from achieving all its international goals acting alone.
For example, international financial stability is vital to Americans’ prosperity, but the US needs the cooperation of others to ensure it.
Global climate change, too, will affect Americans’ quality of life, but the US cannot manage the problem alone.
In a world where borders are more porous than ever to everything from drugs to infectious diseases to terrorism, America must help build international coalitions and institutions to address shared threats and challenges.
In this sense, power becomes a positive sum game.
It is not enough to think in terms of power over others. One must also think in terms of power to accomplish goals.
On many transnational issues, empowering others can help to accomplish one’s own goals.
In this world, networks and connectedness become an important source of relevant power.
The problem of American power in the twenty-first century is not one of decline, but of recognizing that even the most powerful country cannot achieve its aims without the help of others.
Abusing Churchill
NEW YORK – A bronze bust of Winston Churchill, displayed in the White House since the 1960s, has been the object of a continuing right-wing canard in Washington.
The story goes that when President Barack Obama moved in, he returned the bust to the British Embassy, supposedly signifying his hatred of Britain.
In fact, Obama did no such thing.
The bust still stands in the White House Residence, where it always did, except for a short time under President George W. Bush when it was being repaired.
But Obama might have done well to remove the bust.
The cult of Churchill has not been an altogether beneficial one for the United States.
Too many US presidents fancy themselves Churchill’s true heirs.
Bush had a copy of Churchill’s bust, lent to him by Tony Blair, in the Oval Office.
He liked to portray himself as a “war president,” a “decider,” and a “great leader,” like Churchill.
He had a taste for battle dress.
And he got his country into a very foolish war.
Donald Trump’s British crony, Nigel Farage, the former leader of the UK Independence Party, suggested that Trump should put the bronze bust back in the Oval Office.
Trump thought this was a splendid idea.
Trump is the least appropriate figure to cast himself in Churchill’s mold.
Insofar as he has a coherent position on anything, he is hostile to most of the things that Churchill stood for.
His “America first” posture, standing aloof from Western allies, is exactly the kind of attitude against which Churchill and Franklin D. Roosevelt struggled in order to successfully resist Hitler’s Third Reich.
The summer before the Japanese attack on Pearl Harbor, 75 years ago this month, Churchill and Roosevelt met in Placentia Bay, Newfoundland, to set out their ideals for a postwar world.
The resulting Atlantic Charter included everything Trump seems to be against: lower trade barriers, economic cooperation, and the advancement of social welfare.
Once Hitler was defeated, Churchill was also a proponent of European unification, even if he remained ambivalent about Britain’s role in the future union.
Farage’s campaign for Brexit, often pilfering Churchill’s own wartime rhetoric about Britain’s finest hour in defending freedom against tyranny, was aimed at dismantling the very project Churchill favored.
The “special relationship” between the US and Britain, established during WWII, was never as substantial as Churchill and others liked to believe.
The US, as the dominant postwar power, pursued its own interests, whether the British liked it or not.
And British pride in standing alone against Nazi Germany, and the self-aggrandizing notion of being America’s special partner, has prevented the United Kingdom from playing to its full strength as a major power inside the EU.
American leaders sometimes pay lip service to the special relationship, to flatter visiting British prime ministers or get the UK onside in dubious military adventures.
There is talk of giving the relationship a new lease of life in the age of Trump and Brexit.
Whereas Obama warned that Britain outside the EU would be at the back of the queue for special trade deals, House Speaker Paul D. Ryan recently stated that the US should quickly make a new deal with Britain to show “solidarity” with an “indispensable ally.”
A special US tenderness for Brexit Britain – Trump oddly referred to himself as “Mr. Brexit” – rather suggests the solidarity of two countries embarking on their own forms of economic nationalism.
Again, this is precisely the route that Churchill and Roosevelt sought to avoid; after all, economic nationalism was one of the reasons why Europeans almost succeeded in destroying their continent.
Of course, Trump’s love of Brexit may be just a question of words, like so much else about the great showman.
It is hard to imagine the US jeopardizing its economic interests by favoring Britain at the expense of far bigger stakes in the rest of Europe.
But words do matter, as Churchill knew well.
Again, the rhetoric of Trump and his supporters, and of the Brexiteers, could not be further removed from the spirit of the Atlantic Charter.
Talk of sinister international bankers and other “citizens of nowhere” (British Prime Minister Theresa May’s phrase) undermining, in league with rootless liberal elites, “ordinary,” “real,” and “decent” people (Farage) smacks of the anti-Semitic propaganda that swirled around Europe in the 1930s.
And Churchill’s response to the flirtations of Trump and the European far right with Vladimir Putin’s Russia can easily be imagined.
None of this means that Churchill was always right, let alone a figure to emulate.
He was the right man in 1940 to raise British morale, when morale was about the only thing the British had going for them.
But he is not a good model for politicians in less perilous times.
His views of colonial rule were already out of date before the war, and became a racist anachronism after it.
His romantic ideas about the moral superiority of the English-speaking peoples were old-fashioned during his lifetime, and are an arrogant absurdity now.
But Churchill was neither petty nor provincial.
His vision, at least as far as the Western world is concerned, may have been romantic, but it had a certain nobility.
The same cannot be said of the next occupant of the White House.
The idea of Trump, advised by Farage, using Churchill’s bronze head as a totem would have filled the old man with horror.
American Retreats
Los Angeles – As Barack Obama’s incoming administration debates the pace and consequences of withdrawal from Iraq, it would do well to examine the strategic impact of other American exits in the final decades of the twentieth century.
Although American commitments to Lebanon, Somalia, Vietnam, and Cambodia differed mightily, history reveals that despite immediate costs to America’s reputation, disengagement ultimately redounded to America’s advantage. 
In all of these cases, regional stability of sorts emerged after an American military withdrawal, albeit at the cost of a significant loss of life.
America’s former adversaries either became preoccupied with consolidating or sharing power, suffered domestic defeat, or confronted neighboring states.
Ultimately, America’s vital interests prevailed.
The evidence today suggests that this pattern can be repeated when the United States departs Mesopotamia and leaves Iraqis to define their own fate.
Of the four withdrawals, arguably the 1982-1984 American intervention in Lebanon marks the closest parallel to Iraq today.
A country torn by sectarian violence beginning in 1975, Lebanon pitted an even more complex array of contestants against each other than Iraq does today.
Into this fray stepped the US and its Western allies. Their objective was to create a military buffer between the PLO and Israeli forces that were then fighting in Beirut in order to promote the departure of both.
The massacres in Palestinian refugee camps prompted a new commitment to “restore a strong and central government” to Lebanon, to quote President Ronald Reagan.
But the result of intervention was that US forces became just one more target, culminating in the 1983 bombing of a US Marine barracks that killed 241 American soldiers.
A similar suicide bombing two days later claimed the lives of 58 French soldiers.
In February 1984, facing a quagmire, Reagan acceded to Vice President George H.W. Bush’s recommendation to get out of Lebanon.
But the withdrawal of Western forces did not stop the fighting.
The civil war continued for another six years, followed by a bumpy political aftermath: Syrian intervention and expulsion (two decades later), as the Lebanese defined their own fate with the US exercising only background influence.
In 1992, the sirens of Somalia’s political collapse lured the US into another civil war to save a country from itself.
The US humanitarian mission to that benighted country sought to salvage a failed United Nations enterprise to secure and feed Somalia’s ravaged population.
The US committed 28,000 troops, which for a time imposed a modicum of security.
But ill-equipped and poorly led UN replacement forces for the American presence put the remaining US troops in the bull’s eye as they attempted to bring to justice the Somali warlord responsible for the death of Pakistani peacekeepers.
The ensuing bloodbath of US soldiers generated images that the American public could not stomach, prompting the exit of American and then UN forces.
As unrest mounted with these military retreats, offshore US forces monitored and intercepted jihadists who sought to enter Somalia, while Kenya and Ethiopia blocked the unrest from metastasizing across the region.
In 2006, the capture of Somalia’s capital, Mogadishu, by the Islamic Courts raised the specter of a jihadist state.
But Somalia soon demonstrated that quagmires can be a two-way street.
Following Ethiopia’s intervention, the Islamists found themselves out of power.
Today, Somalia remains a dysfunctional state, as rival clans, jihadists, and an interim government with Ethiopian support compete for power.
The US, now out of the quagmire, exercises limited influence from afar.
While Lebanon and Somalia remain damaged and failed states, respectively, regional and domestic factors have cauterized the consequences of America’s retreat from Vietnam and Southeast Asia. The result is the stable region that the world sees today.
But the US saw things very differently in the 1960’s, when the ghosts of Munich hovered over Vietnam’s jungles.
As President George W. Bush argued about the war in Iraq, US President Lyndon Johnson predicted that defeat in Vietnam “would be renewed in one country and then another.”
What Johnson failed to foresee were the domestic and regional constraints that would prevent the dominos from falling in the way he predicted.
Although the US bombed northeastern Cambodia intensely throughout the Vietnam War years, it had no stomach for a ground commitment there.
Still within congressional restraints, the Nixon administration attempted to bolster Cambodia’s military government.
But, despite modest material support, the US could not sustain a government that could not sustain itself.
Rather than the dominos falling following America’s retreat from Saigon in 1975, a Vietnam-Cambodian War ensued.
This in turn stimulated China’s unsuccessful intervention in North Vietnam.
The withdrawal by all of these invading armies to the recognized international boundaries demonstrated that nationalist forces were dominant in the region, not communist solidarity.
None of these American exits was without consequence.
But, while the US suffered costs to its reputation around the world, the supposed advantages from this for America’s opponents proved illusory.
America’s departure from Mesopotamia will likewise put the burden of problem solving onto Iraqis and other regional players, leaving the US offshore to assist when and where it deems appropriate.
History suggests that, in fits and starts, Iraq, like Vietnam and Lebanon, will find itself able to sort out its own affairs.
Trump’s Deplorables
NEW YORK – Hillary Clinton, the Democratic US presidential nominee, recently described supporters of her opponent, Donald Trump, as a “basket of deplorables.”
It was neither a tactful nor an elegant phrase, and she later apologized for her remark.
But she was more right than wrong.
Trump has attracted many supporters whose views on race, for example, are indeed deplorable.
The problem is that many of these deplorable voters are also relatively uneducated, which makes Clinton’s remark look snobbish.
Alas, the United States has too many relatively uneducated people.
Among developed countries, the US ranks low in terms of literacy, general knowledge, and science.
Japanese, South Koreans, Dutch, Canadians, and Russians score consistently higher.
This is at least partly the result of leaving education too much to the market: those with money are highly educated, and those with insufficient means are not educated enough.
So far, it seems clear that Clinton appeals to better-educated urban voters, while Trump attracts mainly less-educated white men, many of whom in earlier generations would have been Democrat-voting coal miners or industrial workers.
Does this mean that there is a link between education – or the lack of it – and the appeal of a dangerous demagogue?
One of the most remarkable things about Trump is the extent of his own ignorance, despite his high educational attainment, and the fact that he seems to benefit from flaunting it.
Perhaps it is easier for a loud-mouthed ignoramus to convince large numbers of people whose knowledge of the world is as slight as his own.
But this is to assume that factual truth matters in the rhetoric of a populist agitator.
Many of his supporters don’t seem to care much about reasoned argument – that is for the liberal snobs.
Emotions count more, and the prime emotions that demagogues manipulate, in the US and elsewhere, are fear, resentment, and distrust.
This was also true in Germany when Hitler came to power.
But the Nazi Party in its early days did not find the bulk of its support among the least educated.
Germany was more highly educated than other countries, on average, and the most enthusiastic Nazis included schoolteachers, engineers, and doctors, as well as provincial small businessmen, white-collar workers, and farmers.
Urban factory workers and conservative Catholics were, on the whole, less susceptible to Hitler’s blandishments than many more highly educated Protestants.
Low educational standards do not explain Hitler’s rise.
Fear, resentment, and distrust ran very high in Weimar Germany, after the humiliation of wartime defeat and amid a devastating economic depression.
But the racial prejudices whipped up by Nazi propagandists were not the same as the ones we see among many Trump supporters today.
The Jews were seen as a sinister force that was dominating the elite professions: bankers, professors, lawyers, news media, or entertainment.
They were the so-called back-stabbers who prevented Germany from being great again.
The Trump supporters are showing a similar animus against symbols of the elite, such as Wall Street bankers, “mainstream” media, and Washington insiders.
But their xenophobia is directed against poor Mexican immigrants, blacks, or Middle Eastern refugees, who are perceived as freeloaders depriving honest (read white) Americans of their rightful place in the social pecking order.
It is a question of relatively underprivileged people in a globalizing, increasingly multi-cultural world, resenting those who are even less privileged.
In the US today, as in the Weimar Republic, the resentful and the fearful have so little trust in prevailing political and economic institutions that they follow a leader who promises maximum disruption.
By cleaning out the stables, it is hoped, greatness will return.
In Hitler’s Germany, this hope existed among all classes, whether elite or plebeian.
In Trump’s America, it thrives mostly among the latter.
In the US and Europe, today’s world looks less scary to more affluent and better educated voters, who benefit from open borders, cheap migrant labor, information technology, and a rich mixture of cultural influences.
Likewise, immigrants and ethnic minorities who seek to improve their lot have no interest in joining a populist rebellion directed mainly against them, which is why they will vote for Clinton.
Trump must thus rely on disaffected white Americans who feel that they are being left behind.
The fact that enough people feel that way to sustain such an unsuitable presidential candidate is an indictment of US society.
This does have something to do with education – not because well-educated people are immune to demagogy, but because a broken education system leaves too many people at a disadvantage.
In the past, there were enough industrial jobs for less-educated voters to make a decent living.
Now that those jobs are vanishing in post-industrial societies, too many people feel that they have nothing more to lose.
This is true in many countries, but it matters more in the US, where putting a bigoted demagogue in charge would do great damage not only to that country, but also to all countries trying to hold onto their freedoms in an increasingly perilous world.
America’s Exploding Deficit
CAMBRIDGE – Two recent pieces of budget news are a grim reminder of the perilous state of fiscal policy in the United States.
President Barack Obama’s Office of Management and Budget announced that the federal government’s deficit this fiscal year will be about $600 billion, up by $162 billion from 2015, an increase of more than 35%.
And the annual Long-Term Budget Outlook produced by the Congressional Budget Office (CBO) predicts that, with no change in fiscal policy, federal government debt will rise from 75% of GDP to 86% a decade from now, and then to a record 141% in 2046, near levels in Italy, Portugal, and Greece.
Although the US debt-to-GDP ratio doubled in the past decade, the Obama administration and Congress ignored the problem, focusing instead on the annual deficit’s decline since 2012 and the relative stability of the deficit as a share of GDP.
That temporary progress reflected the economic recovery and congressional votes to limit spending on defense and nondefense discretionary programs.
But the longer-term rise in the annual deficits – owing to an aging population, changing medical technology, and rising interest rates – and the resulting increase in the debt-to-GDP ratio were inevitable (and were clearly predicted by the CBO and others).
The larger number of older Americans who are eligible for Social Security benefits will drive the program’s costs from 4.9% of GDP this year to 6.3% of GDP over the next 30 years.
Half of the rise in the cost of the major federal health-care programs, from 5.5% of GDP now to 8.9% in 2046, will result from the increased number of older beneficiaries, with the other half caused by the technologically-driven extra cost of treating them.
The Federal Reserve’s unconventional monetary policy has driven down the cost of the net interest on the federal debt to just 1.4% of GDP, despite the increase in the volume of the debt.
But as interest rates normalize and the volume of debt grows, the cost of servicing the interest on the national debt is projected to increase to 5.8% of GDP.
That projected interest cost may be much less than it would actually be if the rest of the deficit and debt forecast turns out to be correct.
With a federal debt of 141% of GDP, that 5.8%-of-GDP interest cost implies an average nominal interest rate of just 4% and, given the CBO’s inflation forecast, a real interest rate of about 2% – similar to historic rates when the debt ratio was less than 40% of GDP.
But investors in Treasury bonds might demand a much higher interest rate in exchange for loading up their portfolios with US debt.
In that case, the interest cost and the debt would be much greater.
The fact that more than half of the publicly held US government debt is now owned by foreign investors might make the interest rate even more sensitive to the debt’s relative size.
Foreign investors might fear that the government could adopt policies that reduced the real value of their holdings.
While the US government would never explicitly default, it could adopt policies such as deducting income tax on interest payments, which would disadvantage foreign holders and depress the value of the bonds.
Moreover, foreign investors might fear that very high debt levels could lead to inflationary monetary policy, which would depreciate the value of the dollar and lower the real value of their bonds.
Here is an amazing and disturbing implication of the CBO’s forecast.
By 2046, the projected outlays for the “mandatory” entitlement programs (Social Security and the major health programs), plus interest on the debt, would absorb more than all of the revenue that the government would collect with current tax rates.
A small deficit (1.6% of GDP) would emerge even before spending on defense and other annually appropriated “discretionary” programs.
There is no way to offset the growth of the mandatory programs by slowing the growth of defense and other discretionary outlays.
Total defense spending is now just 3.2% of GDP and is expected to decline to 2.6% over the next ten years and to remain at that level for the next 20 years.
That would be the lowest defense share of GDP since before World War II.
The same reduction is projected for all non-defense discretionary programs, also a record-low share of GDP.
The bright spot in this bleak picture is that it would not take much in terms of annual deficit reductions to prevent the rise in the debt ratio, or even to bring it back to where it was a decade ago.
Reducing the annual deficit by 1.7% of GDP by any combination of reduced spending and higher revenue would, if begun in 2017, prevent an increase from the current 75% debt-to-GDP ratio.
And reducing the deficit by 3% a year would reverse the debt trajectory and bring it back to where it was in the decades before the recession.
Neither of the presidential candidates has indicated either a plan or an inclination to reverse the projected rise in the national debt.
But it should be a top priority for whoever moves into the White House next year.
Given the need to act quickly to avoid the worst-case scenario, there is no excuse for waiting.
America’s Anti-Environmentalists
As an American, I am appalled, ashamed, and embarrassed by my country’s lack of leadership in dealing with global warming.
Scientific evidence on the risks mounts by the day, as most recently documented in England’s magisterial Stern Report .
Yet, despite the fact that the United States accounts for roughly 25% of all man-made global carbon emissions, Americans show little will or inclination to temper their manic consumption.
The first George W. Bush administration was probably right to refuse to sign the so-called “Kyoto Protocol,” albeit for the wrong reasons.
Among other problems, the Kyoto Protocol does not go far enough towards redistributing carbon emission rights towards developing countries.
But why can’t the US bring itself to raise taxes on gasoline and other sources of carbon emission like coal burning power plants?
It is not like the US government, running a huge deficit despite an economic boom, does not need the money.
Many people seem to think that the Bush administration is the problem.
Put a Texas oilman and his buddies in charge and what do you expect, conservation?
Unfortunately, that is a facile excuse.
American citizens’ resistance to moderating energy consumption for the sake of the global environment is much more deeply embedded.
Consider former US Vice President Al Gore, for example, whose documentary film on global warming, An Inconvenient Truth , is celebrated for its unflinching look at how fossil fuel consumption is leading mankind to the brink of catastrophe.
The evidence on global warming is considerably more muddled than Gore’s film suggests, but the basic problem is real.
Unfortunately, however, Gore was not successful in carrying the torch on global warming when he was a politician.
One cannot commend the 1990’s Clinton-Gore administration for taking any brave steps aimed at radically reducing carbon emissions.
Small wonder: the American public is fiercely resistant to anything that seriously forces them to compromise on their energy-burning, gas-guzzling lifestyle.
It is not just politicians who have failed to provide leadership here.
The venerable
The typical argument one hears is, “What about the poor guy with the gas-guzzling 1980 Chevy car, who has no other way to get to work?”
It is a legitimate point, but if ocean levels start rising, as the
The change of position by the
Until Americans suck it up and start fixing global environmental problems that they, more than anyone, have caused, it will be difficult to get the wholehearted support of the rest of the world.
Developing countries ask why they should pay attention to global warming if rich countries are not prepared to curtail their own emissions sharply?
Why should poor countries worry about how deforestation contributes to global warming when rich countries remain so profligate?
The scientific evidence suggests that carbon emissions from anywhere in the world have about the same impact on global warming.
For this reason, a wide range of economists favor a uniform (“harmonized”) global tax that would tax carbon emissions equally everywhere in the world, and from whatever source – whether coal, oil, or gas, and whether consumers or businesses.
Such a tax is the most flexible and market-friendly approach, and would have the least impact on economic growth.
Instead, the complex system of quotas favored by the Europeans and embodied in the Kyoto Protocol is likely to lead to much larger inefficiencies and costs.
For this reason, England’s Stern Report is probably far too optimistic when it calculates that an eclectic approach to reducing carbon emissions will cost the world only 1% per year of income.
But the Stern Report is still right to argue that the potential risks of continued inaction are far greater.
America’s unwillingness to take the lead on environmental issues may some day be regarded as one of the country’s most profound political failures.
One hopes that it changes course soon, before we all are forced to wear swimsuits to work.
A New Low for China Bashing
NEW HAVEN – As America’s election season nears its finish, the debate seems to have come unhinged.
Nowhere is that more evident than in the fixation on China – singled out by both President Barack Obama and his Republican challenger, Mitt Romney, as a major source of pressure bearing down on American workers and their families.
Get tough with China, both stressed in the presidential debates, and the pain will ease.
Nothing could be further from the truth. Consider the following charges:
Currency manipulation.
Since China reformed its exchange-rate regime in July 2005, the renminbi has risen 32% relative to the dollar and about 30% in inflation-adjusted terms against a broad basket of currencies.
These are hardly trivial amounts, and more renminbi appreciation can be expected in the years to come.
Unlike Japan, which was pressured by the West into a large yen revaluation in 1985 (the “Plaza Accord”), the Chinese have opted to move gradually and deliberately.
American officials call this “manipulation,” arguing that market forces would have resulted in a sharper renminbi appreciation than has occurred.
Fixated on stability – a concept alien to US politicians and policymakers – the Chinese prefer, instead, to play a more active role in managing the adjustment of their currency.
I call that prudence – perhaps even wisdom.
Two lost decades later, the guinea pig, Japan, might have a view on which approach works best.
Outsourcing and intellectual property.
Notwithstanding some recent modest improvements in the US labor market, America’s job situation remains terrible.
Private-sector employment is still down 4.1 million from its January 2008 peak.
Yet there is not a shred of evidence to support bipartisan claims that this ongoing carnage is the result of outsourcing US manufacturing jobs to China.
While the manufacturing sector’s share of private employment fell from 11.9% in January 2008 to 10.7% in September 2012, this is only a small portion of the enormous secular decline since the early 1970’s, when manufacturing accounted for more than 30% of private-sector employment.
Weak demand – especially the post-crisis collapse in consumer spending growth – is a far more likely culprit than China in explaining the recent hiring shortfall.
China, for its part, has become a major workhorse of globalization – an assembly hub for inputs produced by multi-country supply chains and an offshore efficiency solution for hard-pressed Western multinational corporations.
About 50% of all exports leaving China have been processed previously by other economies, and close to 60% are shipped by Chinese subsidiaries of “foreign-invested enterprises.”
While these trends benefit Chinese workers, they also support America and other countries by holding down inflation and making it possible for their companies to cope with tough competitive pressures. They allow beleaguered American families to stretch their paychecks (think Wal-Mart).
And they have not stopped innovative Western companies from putting their intellectual property and new technologies on the line in China in order to deliver spectacular new products to US customers (think Apple).
The trade deficit.
Yes, the US runs a massive trade deficit with China – around $295 billion in 2011, or fully 40% of America’s total merchandise trade gap of $738 billion.
Republicans and Democrats alike argue that this is the crux of America’s jobs problem.
After all, trade deficits mean job losses.
Because the biggest share of the US trade gap is with China, a country vilified as a currency-manipulating cheater, the bilateral trade deficit has become the lightening rod for China bashers.
It is what has driven Obama to go to the mat with China on recent disputes within the World Trade Organization and on restrictions on Chinese investment in Oregon wind farms, and what has led to saber-rattling by Romney on currency manipulation and trade sanctions.
But neither candidate acknowledges the much bigger elephant in the room.
In 2011, the US had trade deficits with 98 countries.
The other 97 deficits did not magically appear.
They are all part of an enormous multilateral trade deficit that stems from America’s unprecedented shortfall of saving – a depreciation-adjusted “net national saving rate” (combining businesses, households, and the government sector) that has been negative since 2008.
Lacking in savings and wanting to grow, the US runs massive current-account and multilateral trade deficits in order to import other countries’ surplus savings.
This goes to the heart of the folly of China bashing.
No leading country in world history has persistently maintained a negative saving rate.
Trade deficits – with China or any other country – are part of the price that America pays for its unbridled profligacy.
Unless and until the US faces up to its chronic aversion to saving – namely, by reducing massive federal budget deficits and encouraging the rebuilding of severely depleted household saving – multilateral trade deficits will persist.
Simple arithmetic and basic economics tell us that a multilateral problem cannot be addressed by a bilateral solution.
Politicians have a penchant for simple and powerful messages.
Yet those messages are often more spin than substance.
American families are hurting, and elected officials want to pin the blame on China, thereby deflecting attention from the difficult task of rebuilding saving, restoring competitiveness, and living within the country’s means.
Indeed, one could argue that it is the American public that is being manipulated by the erroneous charges leveled at China.
Fortunately, the campaign season is nearly over.
Left unanswered, however, is what comes next.
China bashers typically change their tune after a presidential election.
But there is nothing typical about the pressures that are likely to continue squeezing American families long after November 6.
Both Obama and Romney run the risk of painting themselves into a corner when it comes to China.
That could take all of us to the edge of a slippery slope.
America’s leaders need to come clean with the American people – before it is too late.
America’s Coming Social Democracy?
Almost all of the world’s developed countries consider themselves, and are, social democracies: mixed economies with very large governments performing a wide array of welfare and social insurance functions, and removing large chunks of wealth and commodity distribution from the market.
The United States is something different. Or is it?
Whatever it has been in the past, the US in the future will have to choose whether, and how much, it will be a social democracy.
Once upon a time, according to mythology at least, America had little downward mobility.
On the contrary, before the Civil War you could start out splitting rails, light out for the Western Territory, make a success of yourself on the frontier, and wind up as President – if you were named Abraham Lincoln.
In the generation after World War II, you could secure a blue-collar unionized manufacturing job or climb to the top of a white collar bureaucracy that offered job security, relatively high salaries, and long, stable career ladders.
This was always half myth.
Setting out for the Western Territory was expensive. Covered wagons were not cheap.
Even in the first post-WWII generation, only a minority of Americans – a largely white, male minority – found well-paying stable jobs at large, unionized, capital-intensive manufacturing companies like GM, GE, or AT&T.
But if this story was half myth, it was also half true, particularly in the years after WWII.
Largely independent of education or family, those Americans who did value stability and security could grasp it in the form of jobs with “a future.”
Even for those not so lucky, economic risks were usually fairly low: the unemployment rate for married men during the 1960’s averaged 2.7%, and finding a new job was a relatively simple matter.
It was during this era – roughly from 1948 to 1973 – that sociologists found that a majority of Americans had come to define themselves not as working class, but as middle class.
The post-WWII period stands as a reference point in America’s collective memory, but it was in all likelihood an aberration.
In the early postwar decades, foreign competition exerted virtually no pressure on the economy, owing to the isolation of America’s continental market from the devastation of WWII.
At the same time, the war left enormous pent-up demand for the products of mass production: cars, washing machines, refrigerators, lawn mowers, television sets, and more.
Government policy back then began with a permanent military program of spending and R&D and continued through massive public works program and suburbanization, underpinned by the Federal Highway Program and subsidized home ownership loans from the Federal Housing Administration.
The regulatory institutions and behavioral norms that originated in the New Deal and developed during WWII came into full force: social security, a system of unionized labor relations, market regulation.
Favorable macroeconomic circumstances, the absence of foreign competition, a system of government support and regulation, and large-scale private provision of what in Europe would have been public social insurance all combined to give post-WWII America many of social democracy’s benefits without the costs. The economy did not stagger under the weight of ample benefits or high taxes.
Americans – at least white, male Americans – did not have to worry about tradeoffs between security and opportunity, because the US offered the advantages of both.
Corporate welfare capitalism substituted for what in Europe would have been government provided social democracy.
America was thus a special place.
It had its cake and ate it, too: a combination of security with opportunity and entrepreneurship.
It seemed that this was the natural order of things.
Hence there was little pressure for government-sponsored social democracy: Why bother?
What would it add?
Now things are very different.
The typical American employer is no longer General Motors.
It is Wal-Mart.
Private businesses are providing their workers with less and less in the form of defined-benefit pensions, health insurance, and other forms of insurance against life’s economic risks.
Sharply rising income inequality has raised the stakes of the economic game.
A government that cannot balance its own finances cannot be relied on to provide macroeconomic stability.
Indeed, former Chairman of the US Federal Reserve Paul Volcker sees the US as so macroeconomically vulnerable as to be running a 75% chance of a full-fledged dollar crisis over the next several years.
The coming generation will be one of massive downward mobility for many Americans.
The political struggles that this generates will determine whether America will move more closely to the social democratic norm for developed countries, or find some way to accept and rationalize its existence as a country of high economic risk and deep divisions of income and wealth.
Syria and September 11
PARIS – By chance, it appears that the US Congress will decide on or around September 11 whether to endorse President Barack Obama’s proposal to respond militarily to the Syrian government’s use of poison gas against civilians.
The shadow of two previous events that took place on September 11 looms over the outcome – indeed, over the fact that the question is even being considered at all.
Long before September 11 became a day of infamy in the United States, it acquired similar significance in Chile, where 40 years ago, on September 11, 1973, the armed forces, led by General Augusto Pinochet, overthrew the country’s democratically elected government.
More than any other event of our era, that violent coup was responsible for launching both the contemporary global movement for human rights and the American movement to promote human rights internationally.
In part, this reflected the new regime’s cruelty.
More than three thousand people were murdered or “disappeared” during Pinochet’s rule, thousands more were tortured by his forces, and tens of thousands were forcibly exiled.
To an even greater extent, however, the motivation that spurred the human-rights movement was revulsion worldwide, including in the US, against American aid to Pinochet’s forces, a policy directed by President Richard Nixon and Secretary of State Henry Kissinger.
In the US, members of Congress turned the coup into a platform for efforts to promote human rights.
They condemned developments in Chile, held hearings about the importance of promoting human rights, and adopted legislation – over President Gerald Ford’s veto – requiring that human-rights standards guide US foreign policy.
A slightly revised version of that legislation remains in force.
Obama’s proclamation that the use of chemical weapons in Syria would cross a “red line” – and his implicit threat to use force if that line were crossed – reflects the commitment that the US has made during the past four decades to promote human rights worldwide.
The events of September 11, 2001, are also playing a crucial role in deciding the question of a punitive strike against Syrian President Bashar al-Assad’s regime.
One consequence of the terrorist attacks 12 years ago is that Americans and others in the West became aware that developments in the Middle East could affect their own safety and security.
Initially, the attacks unleashed a strong desire to retaliate, which later gave way to caution about intervention, owing to unforeseen consequences.
In Britain, continuing intense resentment over the deceptions that led to the country’s engagement in the Iraq war seems to be the main reason for Parliament’s refusal to back a strike against Syria.
Wariness of another Middle East war has also underpinned Obama’s unwillingness to go beyond a one-time punitive strike on Syria – with some in Congress opposed to even that.
Though Congress must guard against repeating its disastrous mistake in 2003, when it supported the war in Iraq, the commitment to promote human rights that the US made following September 11, 1973, seems a more appropriate standard for weighing Obama’s proposal for US military action in Syria.
Maintaining the international prohibition on the use of chemical weapons is an urgent concern.
The Assad regime’s culpability for using these weapons is not in doubt.
If the US Congress deals with Obama’s proposal responsibly, and does not yield to those motivated by a partisan desire to embarrass him at every turn, it will enhance its own claim to recapture the constitutional power to authorize military conflict – a power that has been disregarded more often than not in the past half-century.
A critical part of its role must be to consider with care the limits that should be placed on a punitive strike.
The war in Iraq was misconceived from the start, because it was an attempt to avenge the September 11, 2001, terrorist attacks by invading and occupying a country that had no part in them.
Obama’s proposal to strike Syria, by contrast, is an attempt to enforce an important human-rights norm by directly punishing – through means that do not involve invasion and occupation – those who committed a gross violation.
It restores human rights to the central place in American foreign policy set forth after September 11, 1973.
America’s Constrained Choice
NEWPORT BEACH – The conventional wisdom about the November presidential election in the United States is only partly correct.
Yes, economic issues will play a large role in determining the outcome.
But the next step in the argument – that the winner of an increasingly ugly contest will have the luxury of pursuing significantly different policies from his opponent – is much more uncertain.
By the time the next presidential term starts in January 2013, and contrary to the current narratives advanced by the Obama and Romney campaigns, the incumbent will find himself with limited room for maneuver on economic policy.
Indeed, the potential differences for America are elsewhere, and have yet to be adequately understood by voters.
They center on the social policies that would accompany a broadly similar set of economic measures; and, here, the differences between the candidates are consequential.
Whoever wins will face an economy growing at a sluggish 2% or less next year, with a nagging risk of stalling completely.
Unemployment will still be far too high, and almost half of it will be hard-to-solve, long-term joblessness – and even more if we count (as we should) the millions of Americans who have dropped out of the labor force.
The financial side of the economy will also be a source of concern.
The fiscal deficit will continue to flirt with the 10%-of-GDP level, adding to worries about the country’s medium-term debt dynamics.
The banking sector will still be “de-risking,” limiting the flow of credit to small and medium-size companies and undermining hiring and investment in plant and equipment.
And the household sector will be only partly through its painful de-leveraging phase.
The policy front will be equally unsettling.
Having dithered and bickered for too long, the US Congress will find it increasingly difficult to postpone action on these challenges.
Meanwhile, the Federal Reserve’s unusual activism, including an ever-expanding list of experimental measures, will yield fewer benefits and entail growing costs and risks.
The US economy will also be operating in a more difficult global environment.
In the next few months, Europe’s debt crisis will most likely worsen.
With emerging economies (including China) slowing, and with meaningful multilateral policy coordination remaining inadequate, protectionist pressures will mount as major trading powers compete for a stagnant pie.
So, whether President Barack Obama or Mitt Romney prevails in November, the next president will be constrained by the twin need for urgent economic stabilization and longer-term reforms.
And, with headwinds from Europe and a synchronized global slowdown, the candidates will have no choice but to pursue, at least initially, similar economic policies to restore dynamic job creation and financial stability.
In striking the right balance between immediate economic stimulus and medium-term fiscal sustainability, the most urgent step will be to counter properly the looming fiscal cliff, as temporary tax cuts expire and deep, across-the-board spending reductions kick in automatically.
Failure to do so would significantly increase the risk of an outright American recession.
Serious medium-term budget reforms are needed to deal with the legacy of repeated congressional failures.
And, if provided with realistic numbers, the next president will soon recognize that the right mix of tax and spending reforms falls into a much narrower range than today’s competing political narratives suggest.
It is certainly not an either/or proposition.
Fiscal reforms work best in a dynamic economy.
To this end, Obama and Romney will need to lift the impediments to growth and job creation.
Here again – in areas like housing, the labor market, credit intermediation, and infrastructure – there is less room for maneuver than most politicians would like us to believe.
But this does not mean that there is no scope for differences.
There is, and they reflect the fact that general economic tendencies will be accompanied by multi-speed dynamics at many levels.
From persistent differences in unemployment rates depending on skills and education to record-high income and wealth inequalities, each economic decision will be accompanied by the need for social judgment – whether explicit or, more likely, implicit – regarding its distributional impact.
After an “age” of excessive leverage, debt creation, and credit entitlement that culminated in the 2008 global financial crisis, America still faces the tricky challenge of allocating cumulative losses that continuously inhibit investment, jobs, and competitiveness.
Until now, Congress’s excessive political polarization has translated into an approach that has pushed more of the burden of adjustment onto those who are less able to bear it.
In an ideal world, America’s next president would rapidly embark on a two-step approach to restoring job dynamism and financial soundness.
First, he would devise a comprehensive set of economic-policy initiatives that are both feasible and desirable – and, again, the scope for major differences here is limited.
Second, he would accompany this with an explicit set of social policies – and here the potential differences are profound – that addresses the need for equitable burden-sharing.
This is not really an election about such hotly-debated issues as outsourcing, tax increases versus entitlement reforms, government control of production versus unfettered private sector activity, or job creators versus free riders.
It is much more about the accompanying concepts of social fairness, entitlement, equality and, yes, standards of behavior for a rich and civilized society.
This is an election about social responsibility – a society’s obligation to support those who are struggling, through no fault of their own, to find jobs and make ends meet.
It is about protecting the most vulnerable segments of society, including by providing them access to proper health coverage.
It is about reforming an education system that fails America’s young people (and about providing appropriate retraining to those who need it).
Among the numerous issues of fairness and equality, it is about the rich giving back to a system that has brought them unimaginable wealth.
It is here where the differences between Obama and Romney are important.
The sooner the campaign debate pivots to this, the greater the probability that Americans will make a more informed choice and, thus, buy into the collective effort needed to escape national malaise.
America’s Crony Capitalism
Buenos Aires – For 20 years, Americans have denounced the “crony capitalism” of Third World countries, especially in Asia.
But, just as those regions have been improving their public and corporate governance – Hong Kong just witnessed a breakthrough court decision against a telecom tycoon who is the son of the province’s richest and most powerful man – crony capitalism is taking root in the United States, a country that the world long considered the gold standard of a level playing field in business.
The recently completed “stress tests” of US banks are but the latest indication that crony capitalists have now captured Washington, DC.  
It is no surprise that stock markets liked the results of the stress tests that US Treasury Secretary Timothy Geithner administered to America’s big banks, for the general outcome had been leaked weeks before.
Indeed, most professional investors trashed the tests as dishonest even as their holdings benefited from a rising market.
Even The Wall Street Journal , usually financial markets’ loudest cheerleader, openly disparaged the tests’ integrity. The government had allowed bankers to “negotiate” the results, like a student taking a final examination and then negotiating her grade.
The tests were supposed to reveal the true conditions of banks saddled with unaudited toxic assets in housing loans and financial derivatives. The reasoning behind the tests seemed unimpeachable.
But was it?
As any seasoned banker knows, a well-managed bank should undertake internal “stress tests” regularly as a matter of good housekeeping.
The financial crisis should have mandated a running stress test to keep senior management up to date daily. Why, then, did the US need the government to conduct a financial exercise that bankers themselves could and should have done far better and faster?
The truth is that the tests were not designed to find answers.
Both Wall Street’s chieftains and the Obama administration already knew the truth.
They knew that if the true conditions at many big banks were publicly revealed, many would have been immediately declared bankrupt, necessitating government receivership to stop a tsunami of bank runs.
But the Obama administration did not want to be tagged as “socialist” for nationalizing banks, however temporarily, even though experts such as former US Federal Reserve Chairman Paul Volcker had recommended just that.
Moreover, nationalizing banks would have required dismissing Wall Street captains and their boards for grossly mismanaging their firms.
Wall Street’s titans, however, had convinced Obama and his team that their continued stewardship was essential to getting the world out of its crisis.
They successfully portrayed themselves as victims of a firestorm, rather than as accessories to arson.
Geithner and Larry Summers, Obama’s chief economic advisor, share Wall Street’s culture as protégés of Robert Rubin, the former treasury secretary who went on to serve as a director and senior counselor at Citigroup. Neither man found it difficult to accept the bankers’ absurd logic.
The stress tests were meant to signal to the public that there was no immediate threat of bank failures.
This message, it was hoped, would stabilize the market so that prices for “toxic” assets could rise to a level at which bankers might feel comfortable selling them.
After all, senior bankers had been claiming that these assets were “mispriced,” and that pricing them at market levels would penalize the banks unnecessarily.
So far, Geithner seems to have succeeded in his “tests,” as the stock market has indeed more than stabilized, with prices of bank shares such as Citigroup and Bank of America quadrupling from their lows.
The feared implosion of Wall Street seems to have been avoided.
But no one ever seriously thought that the US would allow Citigroup and Bank of America, to name just two, to fail.
In fact, the stock market bottomed out last winter.
Markets had factored into share prices the belief that the US government would not allow any more banks to collapse.
What the world wanted was an accurate picture of what the banks were worth and “mark-to-market” valuations to guide investors as to how much new capital they needed.
The world also wanted to see the US retaking the high road in reinforcing business ethics and integrity – so lacking under the last administration.
As taxpayers had already put huge sums into rescuing failing banks, with the prospect of more to come, a transparent process to reveal how the money was being used was imperative.
Substantial public rescue funds have reportedly been siphoned off to foreign banks, Goldman Sachs, and staff bonuses for purposes unrelated to protecting public interests.
None of this was either revealed or debunked by Geithner’s tests.
Instead, public servants now appear to be in cahoots with Wall Street to engineer an artificial aura of profitability.
Moreover, the value of toxic assets remains as murky as ever.
Once sacrosanct accounting principles have been amended at Wall Street’s behest in order to allow banks to report essentially whatever they want.
And now negotiated stress test results have been released to “prove” that the banks are a lot healthier.
Calling this a Ponzi scheme might be too harsh.
But few financial professionals have been fooled.
Meanwhile, Wall Street chieftains and their boards of directors have nothing to fear from government. On the contrary, they are now the government’s partners in a joint venture to manage this dishonest scheme.
Like swine flu, crony capitalism has migrated from corrupt Third World countries to America, once the citadel of sound public and private governance.
Is it any wonder that China is perceived as an increasingly credible model for much of the developing world, while the US is now viewed as a symbol of hypocrisy and double standards?
America’s Dangerous Debt Ceiling Debate
NEWPORT BEACH – It has been raised more than 70 times in the last 50 years, mostly without commotion.
It must be raised again this summer if the United States government is to continue paying its bills on time.
But now America’s debt ceiling has become the subject of intense political posturing and touch-and-go negotiations behind closed doors. And, obviously, the outcome has implications that go well beyond the US.
As part of America’s system of checks and balances, Congress gets to do more than just approve the annual federal budget. It also sets a limit on how much debt the US Treasury is allowed to issue.
Beyond this ceiling, the government can spend only from current revenues.
US Treasury Secretary Timothy Geithner recently informed members of Congress that the government will be in this situation on or around August 2.
Having already officially hit the ceiling, the Treasury is moving money around and tapping various pots of unused funds to pay its bills.
In a few weeks, this “flexibility” will be used up.
With the US government now borrowing around 40% of every dollar it spends, a truly binding debt ceiling would immediately force the government to reduce spending radically and in a disorderly fashion.
Politicians across the political spectrum know that such a situation would unsettle an already fragile US economy, severely weaken the dollar, and raise serious concerns about the country's ability to meet its debt-service obligations, including to the many foreign creditors that the US will need in the future.
Yet, in today’s polarized environment in Washington, Republicans and Democrats are unwilling to compromise – or at least to compromise “too early.”
By holding out, Republicans wish to force President Barack Obama’s administration into massive spending cuts.
Democrats respond that such a one-sided approach would be economically harmful and socially unjust.
In the meantime, both sides risk disrupting transfer payments (including to the elderly) and the provision of public services, as well as eroding further America’s global credit standing.
The overwhelming – and sensible – expectation is that the two parties will compromise and raise the debt ceiling before inflicting serious economic and financial dislocations.
The most recent precedent was the bipartisan agreement reached earlier this year on another fiscal issue that threatened to disrupt the normal functioning of government: the absence of a formally approved budget for this year.
A compromise would allow both parties to declare partial victory, for it would likely entail commitments to cut spending and some steps to make taxation more socially just.
But, like many last-minute agreements, it would have little durable impact.
In effect, the political system would again be kicking the can down the road, with real progress on necessary fiscal reforms expected only after the November 2012 presidential election.
Two scenarios for the timing of an interim compromise are possible, depending on whether it is a one- or two-step process. Most observers expect a one-step process for bipartisan agreement before August 2.
But politicians may need two steps: an initial failure to agree, and then a quick deal in response to the resulting financial-market convulsions.
In the meantime, the Treasury would temporarily re-prioritize and slow outgoing payments.
This two-step process would be similar to what happened in 2008, when Congress was confronted with another cliffhanger: the Bush administration’s request for $700 billion to prevent a financial-market collapse and an economic depression.
Congress initially rejected the measure, but a dramatic 770-point drop in the stock market focused politicians’ minds, bringing them back to the table – and to agreement.
But the two-step scenario involves incremental risks to the US economy, and to its standing in the global system. And the longer America’s politicians take to resolve the debt-ceiling issue, the greater the risk of an inadvertent accident.
This brings us to a third, and even more unsettling possibility: a longer and more protracted negotiation, resulting in greater disruptions to government entitlement payments, other contractual obligations, and public services.
Creditors would then ask many more questions before adding to their already-considerable holdings of US government debt, generating still more headwinds in a US economy that already faces an unemployment crisis and uneven growth.
The next few weeks will provide plenty of political drama.
The baseline expectation, albeit subject to risk, is that Democrats and Republicans will find a way to avoid disruptions that would damage the fragile US economy, but that the compromise will not meaningfully address the need for sensible medium-term fiscal reforms.
Such political paralysis on key economic issues is increasingly unsettling for the US private sector, and for other countries that rely on a strong US at the core of the global economy.
This helps to explain why so many companies continue to hoard cash, rather than investing domestically, and why a growing number of countries want to diversify gradually away from dependence on the dollar as the reserve currency and on US financial markets for intermediation of their hard-earned savings.
The world economy is hard-wired to the assumption of a strong America, and Americans benefit from this.
But the more their politicians argue over the debt ceiling, the greater the risk that the wiring will become irreparably frayed.
America’s Deepening Moral Crisis
NEW YORK – America’s political and economic crisis is set to worsen following the upcoming November elections.
President Barack Obama will lose any hope for passing progressive legislation aimed at helping the poor or the environment.
Indeed, all major legislation and reforms are likely to be stalemated until 2013, following a new presidential election.
An already bad situation marked by deadlock and vitriol is likely to worsen, and the world should not expect much leadership from a bitterly divided United States.
Much of America is in a nasty mood, and the language of compassion has more or less been abandoned.
Both political parties serve their rich campaign contributors, while proclaiming that they defend the middle class.
Neither party even mentions the poor, who now officially make up 15% of the population but in fact are even more numerous, when we count all those households struggling with health care, housing, jobs, and other needs.
The Republican Party recently issued a “Pledge to America” to explain its beliefs and campaign promises.
The document is filled with nonsense, such as the fatuous claim that high taxes and over-regulation explain America’s high unemployment.
It is also filled with propaganda. A quotation by President John F. Kennedy states that high tax rates can strangle the economy, but Kennedy’s was speaking a half-century ago, when the top marginal tax rates were twice what they are today.
Most of all, the Republican platform is devoid of compassion. 
America today presents the paradox of a rich country falling apart because of the collapse of its core values.
American productivity is among the highest in the world.
Average national income per person is about $46,000 – enough not only to live on, but to prosper.
Yet the country is in the throes of an ugly moral crisis.
Income inequality is at historic highs, but the rich claim that they have no responsibility to the rest of society.
They refuse to come to the aid of the destitute, and defend tax cuts at every opportunity.
Almost everybody complains, almost everybody aggressively defends their own narrow and short-term interests, and almost everybody abandons any pretense of looking ahead or addressing the needs of others.
What passes for American political debate is a contest between the parties to give bigger promises to the middle class, mainly in the form of budget-busting tax cuts at a time when the fiscal deficit is already more than 10% of GDP.
Americans seem to believe that they have a natural right to government services without paying taxes.
In the American political lexicon, taxes are defined as a denial of liberty.
There was a time, not long ago, when Americans talked of ending poverty at home and abroad.
Lyndon Johnson’s War on Poverty in the mid-1960’s reflected an era of national optimism and the belief that society should make collective efforts to solve common problems, such as poverty, pollution, and health care. America in the 1960’s enacted programs to rebuild poor communities, to fight air and water pollution, and to ensure health care for the elderly.
Then the deep divisions over Vietnam and civil rights, combined with a surge of consumerism and advertising, seemed to end an era of shared sacrifice for the common good.
For 40 years, compassion in politics receded.
Ronald Reagan gained popularity by cutting social benefits for the poor (claiming that the poor cheated to receive extra payments).
Bill Clinton continued those cuts in the 1990’s.
Today, no politician even dares to mention help for poor people.
The big campaign contributors to both parties pay to ensure that their vested interests dominate political debates.
That means that both parties increasingly defend the interests of the rich, though Republicans do so slightly more than Democrats.
Even a modest tax increase on the rich is unlikely to find support in American politics.
The result of all of this is likely to be a long-term decline of US power and prosperity, because Americans no longer invest collectively in their common future.
America will remain a rich society for a long time to come, but one that is increasingly divided and unstable.
Fear and propaganda may lead to more US-led international wars, as in the past decade.
And what is happening in America is likely to be repeated elsewhere.
America is vulnerable to social breakdown because it is a highly diverse society.
Racism and anti-immigrant sentiments are an important part of the attack on the poor, or at least the reason why so many are willing to heed the propaganda against helping the poor.
As other societies grapple with their own increasing diversity, they may follow the US into crisis.
Swedes recently gave enough votes to a right-wing, anti-immigrant party to give it representation in parliament, reflecting a growing backlash against the rising number of immigrants in Swedish society.
In France, Nicolas Sarkozy’s government has tried to regain popularity with the working class by deporting Roma migrants, a target of widespread hatred and ethnic attacks.
Both examples show that Europe, like the US, is vulnerable to the politics of division, as our societies become more ethnically diverse.
The lesson from America is that economic growth is no guarantee of wellbeing or political stability.
American society has become increasingly harsh, where the richest Americans buy their way to political power, and the poor are abandoned to their fate.
In their private lives, Americans have become addicted to consumerism, which drains their time, savings, attention, and inclination to engage in acts of collective compassion.
The world should beware.
Unless we break the ugly trends of big money in politics and rampant consumerism, we risk winning economic productivity at the price of our humanity.
America’s Economic Stalemate
CAMBRIDGE – The United States appears trapped in a dangerous economic stalemate.&#160; The refusal by both Republicans and Democrats to give ground on the budget is preventing the government from dealing with its massive fiscal deficit and rapidly rising national debt.
Indeed, the Congressional Budget Office projects that the national debt could increase to 82% of GDP over the next ten years – more than double the debt ratio as recently as 2008.
That forecast, moreover, is based on quite optimistic assumptions of strong economic growth and low interest rates.
With slower growth and more normal interest rates, the debt ratio could easily rise to more than 100% in 2021, and exceed 150% by 2030.
A major reason for the accelerating growth in government debt is America’s rapidly aging population and the resulting increase in the cost of the universal pension and health-care programs – Social Security and Medicare.
Most experts believe that limiting the rise in debt will require slowing the growth of these “entitlement” programs and increasing taxes as a share of GDP.
But President Barack Obama and the congressional Democrats oppose any reduction in future entitlement programs, while the Republican presidential candidates and their party’s congressional delegation oppose any increase in tax revenues.
The result is the current stalemate in reducing the fiscal deficit and reversing the growth of the national debt.
Republicans argue that the national debt’s growth should be limited only by cutting government spending.
Although some cuts in traditional outlays should be part of efforts to rein in spending, this approach should be supplemented by reducing “tax expenditures” – the special features of the tax code that subsidize health care, mortgage borrowing, local-government taxes, etc..
Limiting tax expenditures could reduce the annual deficit by as much as 2% of GDP, thereby reducing the debt-to-GDP ratio in 2021 by more than 25 percentage points.
Republicans generally reject this form of spending reduction, because it results in additional tax revenue.
While this method does indeed increase total revenue, the economic effect of limiting tax expenditures is the same as it is under any other method of cutting spending on those programs.
But the Republicans’ opposition to anything that raises revenue means that this key to breaking the budget stalemate won’t be implemented.
The budget cost of Social Security pensions could be gradually reduced by substituting annuities generated by investment-based personal retirement accounts for part of the current tax-financed benefits.
But even though such a reform could maintain income levels for retirees, Democrats oppose it, because it lowers traditional government benefits.
This reinforces the stalemate.
The two parties’ hardline stances anticipate the upcoming congressional and presidential elections in November 2012.
The Republicans, in effect, face the voters with a sign that says, “We won’t raise your taxes, but the Democrats will.”
The Democrats’ sign, by contrast, says, “We won’t reduce your pension or health benefits, but the Republicans will.”
Neither side wants any ambiguity in their message before the election, thus ruling out the possibility of any immediate changes in tax expenditures or future Social Security pensions.
But, for the same reason, I am optimistic that the stalemate will end after the election.
At that point, both Republicans and Democrats will be able to accept reforms that they must reject now.
Another post-election route to deficit reduction would be to lower marginal tax rates and balance that revenue loss with cuts in tax expenditures.
Official analyses downplay the effect of lower marginal tax rates on taxable income, but experience shows that taxable income rises substantially as taxpayers respond to lower marginal rates by working more, taking more of their compensation in taxable cash than in fringe benefits, and reducing their tax-deductible consumption.
Reducing tax expenditures while lowering marginal tax rates can produce substantial revenue by increasing the level of taxable income.&#160;
The current economic stalemate is troubling, because financial markets could react adversely, and because delays in addressing the fiscal deficit means a higher national debt.
I may be too optimistic, but I think there is good reason to believe that the current budget stalemate reflects election posturing, and that the US political system will prove more effective at making progress on fiscal consolidation once the election is past.
America’s Election and the Global Economy
STANFORD – As America’s elections approach, with President Barack Obama slightly in front of his Republican challenger, former Massachusetts Governor Mitt Romney, pollsters still rate the races for control of the presidency and the United States Senate too close to call, with the House of Representatives likely to remain in Republican hands.
The differences between the candidates are considerable, and highly consequential for American economic policy and the global economy, although enactment of their programs will depend on the makeup of Congress.
The most important differences between the two candidates can be summarized as follows:
Spending.
Obama has dramatically increased spending.
He would likely continue many of his temporary programs (as Milton Friedman once observed, “There is nothing so permanent as a temporary government program.”); double down on having government pick winners and losers in green energy; expand spending on education and infrastructure; and substantially reduce defense expenditures.
Romney, by contrast, favors limiting overall federal spending, currently 24% of GDP, to 20%, and keeping defense at 4%.
He wants private markets, not government, to choose winning firms and technologies.
Democrats oppose most nondefense spending cuts, arguing that reductions would cause the economy to contract.
That case is strongest if the spending reductions are large and abrupt in a weak economy.
If phased in over a multi-year period as the economy recovers, as Romney proposes, thrift would likely be expansionary.
For example, federal spending relative to GDP fell by five percentage points from the mid-1980’s to the late 1990’s in the US, and by an even larger margin in recent decades in Canada – that is, through periods of strong economic growth.
Taxes.
Obama would raise the top marginal tax rates on wages, capital gains, dividends, interest, and estates, especially on higher-income individuals and small businesses.
Yet he has never proposed comprehensive reform of either the personal or corporate income tax.
By contrast, Romney would reduce America’s corporate tax rate (the highest in the OECD) to 25% and tax American multinationals on a territorial, rather than a worldwide, basis in order to increase their tax competitiveness.
He would also lower personal tax rates by 20%, and make up lost revenue by limiting tax deductions and credits, particularly at the upper end, thereby raising about 18.5% of GDP, just above the historical average, at full employment. Romney’s fiscal plan thus reduces deficits sufficiently to decrease the debt-to-GDP ratio.
He favors a balanced-budget amendment to the Constitution, and hopes to balance the budget over eight years.
Obama, by contrast, would run larger deficits – his spending increase is much larger than his tax increase – which imply large tax hikes in the future.
Moreover, he would run far larger debt ratios than Romney, because the main driver of the debt is entitlement spending.
Entitlements.
Obama has remained silent about reform of Medicare and Social Security, whose long-run deficits are several times the national debt.
Vice President Joe Biden has even said that “no changes” to Social Security are to be made.
Romney supports gradually increasing retirement ages, a premium-support model for Medicare, and shifting Medicaid (health insurance for the poor) to the states via block grants.
The Obama campaign is pummeling Romney on Medicare, and the Romney campaign is hammering Obama for his refusal to negotiate or even propose a solution.
The Obama policy would thus lead to ever-higher deficits and debt ratios well over 100% of GDP, a level that numerous studies imply would reduce US economic growth by one-third or more and might induce a sovereign-debt crisis.
Some observers suggest that Obama’s unspoken plan is ever-growing entitlements eventually paid for by a European-style value-added tax.
Trade.
Obama is the first US president in a long time who has not played a leading role on global trade liberalization.
The Doha Round of global trade talks remains stalled, and Obama delayed the three bilateral free-trade agreements that awaited approval when he came into office.
Romney is a proponent of free trade, but has said that he would be tougher on China’s trade practices and currency policies.
Regulation.
Obama wants to expand federal command-and-control regulation further (though the courts have stopped his extension of some regulatory powers).
Romney vows an economically balanced approach that would reform Obama’s major health-care, environmental, and financial-services regulations.
Appointments.
Every US president appoints thousands of officials, many with considerable power.
Romney has said that he would not reappoint Ben Bernanke as Fed Chairman (likely candidates: economists Glenn Hubbard, Greg Mankiw, John Taylor, and Martin Feldstein).
Other presidential appointees exert considerable influence on firms, industries, or the entire economy.
For example, Obama’s appointees to the obscure National Labor Relations Board tried to prevent Boeing from expanding in South Carolina, despite the state’s anti-union “right to work” legislation.
These policies would affect US economic growth, the budget deficit, national saving, and hence global trade and capital flows.
With larger deficits under Obama than under Romney, America would need more capital from Europe, Latin America, and Asia, while higher taxes and debt would impede US growth and thus undermine these regions’ exports.
Obama would steer America in the direction of European social-welfare states; Romney’s agenda is designed to prevent that.
Whoever wins, a fiscal cliff looms at the end of 2012.
Previous legislation, if not reversed, will lead to large abrupt tax hikes and spending cuts, which the Congressional Budget Office forecasts would likely cause a recession in 2013.
While a post-election, lame-duck session of Congress will address the fiscal cliff, the deep differences between Republicans and Democrats on taxes and spending remain wide and difficult to bridge.
With uncertainty plaguing Europe’s finances and China slowing, the last thing the global economy needs is a stagnant or shrinking US economy.
But it will take strong leadership by the president-elect to avoid it.
America’s Exceptional Fiscal Conservatism
WASHINGTON, DC – In most countries, to be “fiscally conservative” means to worry a great deal about the budget deficit and debt levels – and to push these issues to the top of the policy agenda.
In many eurozone countries today, “fiscal conservatives” are a powerful group, insisting on the need to boost government revenue while bringing spending under control.
In Great Britain, too, leading Conservatives have recently proved willing to raise taxes and attempted to limit future spending.
The United States is very different in this respect.
There, leading politicians who choose to call themselves “fiscal conservatives” – such as Paul Ryan, now the Republican Party’s presumptive vice-presidential nominee to run alongside presidential candidate Mitt Romney in November’s election – care more about cutting taxes, regardless of the effect on the federal deficit and total outstanding debt.
Why do US fiscal conservatives care so little about government debt, relative to their counterparts in other countries?
It has not always been this way.
For example, in 1960, President Dwight D. Eisenhower’s advisers suggested that he should cut taxes in order to pave the way for his vice president, Richard Nixon, to be elected to the presidency.
Eisenhower declined, partly because he did not particularly like or trust Nixon, but mostly because he thought it was important to hand over a more nearly balanced budget to his successor.
The framework for US macroeconomic policy changed dramatically when the international monetary system broke down in 1971.
The US could no longer maintain a fixed exchange rate between the dollar and gold – the cornerstone of the postwar Bretton Woods system.
The arrangement collapsed because the US did not want to tighten monetary policy and run more restrictive fiscal policy: keeping US voters happy was understandably more important to President Nixon than maintaining a global system of fixed exchange rates.
Ironically, however, rather than undermining the predominant international role of the US dollar, the end of Bretton Woods actually boosted its use around the world.
Much has been written, and many hands wrung, about the dollar’s decline over the last four decades, but the fact remains that holdings of US dollar assets by foreigners today are vastly greater than they were in 1971.
This turns out to be a mixed blessing, because it has allowed the US to become less careful about its fiscal accounts.
Foreigners now hold roughly half of all US federal government debt, and they are willing to hold it when it yields a very low return in dollars (and even when the dollar depreciates).
In fact, whenever the world looks unstable, investors want to hold more dollar assets – even when the US is the cause of the instability.
When big US banks are in trouble or Americans are having another debilitating political fight over their public finances, global investors scramble into US Treasuries.
Last year’s congressional showdown over the federal debt ceiling may have cost the US its AAA sovereign rating with Standard &amp; Poor’s, but the federal government’s borrowing costs are actually lower now than they were then.
What has America done with this opportunity – arguably the lowest-cost funding in the history of humankind?
Not much, in terms of productive investment, strengthening education, or maintaining essential infrastructure.
But the US has done a great deal in terms of adopting tax cuts that boost consumption relative to income and lower government revenue relative to expenditure.
This is the lasting legacy of the “temporary” tax cuts adopted by George W. Bush’s administration in the early 2000’s.
And Americans have shifted greatly toward political philosophies – on the right and on the left – that regard public debt merely as a distraction. Or, as former vice president Dick Cheney put it, “Reagan taught us that deficits do not matter” – meaning that Ronald Reagan cut taxes, ran bigger deficits, and did not suffer any adverse political consequences.
Ryan and members of the Tea Party wing of the Republican Party undoubtedly want to cut the size of the federal government, and they have articulated plans to do this over several decades.
But, in the near term, what they promise is primarily tax cuts: their entire practical program is front-loaded in that direction.
The calculation is that this will prove politically popular (probably true) while making it easier to implement spending cuts down the road (less obvious).
The vulnerability caused by higher public debt over the next few decades is simply ignored.
For example, Ryan supported George W. Bush’s spending spree.
He also supports maintaining defense spending at or near its current level – resisting the cuts that were put in place under the Budget Control Act of 2011.
The assumption here – unstated and highly questionable – is that the US will be able to sell an unlimited amount of government debt at low interest rates for the foreseeable future.
There is no other country in the world where fiscal conservatives would want to be associated with such a high-stakes gamble.
America’s Failed Militarized Foreign Policy
Many of today’s war zones – including Afghanistan, Ethiopia, Iran, Iraq, Pakistan, Somalia, and Sudan – share basic problems that lie at the root of their conflicts.
They are all poor, buffeted by natural disasters – especially floods, droughts, and earthquakes – and have rapidly growing populations that are pressing on the capacity of the land to feed them.
And the proportion of youth is very high, with a bulging population of young men of military age (15-24 years).
All of these problems can be solved only through long-term sustainable economic development.
Yet the United States persists in responding to symptoms rather than to underlying conditions by trying to address every conflict by military means.
It backs the Ethiopian army in Somalia.
It occupies Iraq and Afghanistan.
It threatens to bomb Iran.
It supports the military dictatorship in Pakistan.
None of these military actions addresses the problems that led to conflict in the first place.
On the contrary, American policies typically inflame the situation rather than solve it.
Time and again, this military approach comes back to haunt the US.
The US embraced the Shah of Iran by sending massive armaments, which fell into the hands of Iran’s Revolutionary Government after 1979.
The US then backed Saddam Hussein in his attack on Iran, until the US ended up attacking Saddam himself.
The US backed Osama bin Laden in Afghanistan against the Soviets, until the US ended up fighting bin Laden.
Since 2001 the US has supported Pervez Musharraf in Pakistan with more than $10 billion in aid, and now faces an unstable regime that just barely survives.
US foreign policy is so ineffective because it has been taken over by the military.
Even postwar reconstruction in Iraq under the US-led occupation was run by the Pentagon rather than by civilian agencies.
The US military budget dominates everything about foreign policy.
Adding up the budgets of the Pentagon, the Iraq and Afghanistan wars, the Department of Homeland Security, nuclear weapons programs, and the State Department’s military assistance operations, the US will spend around $800 billion this year on security, compared with less than $20 billion for economic development.
In a stunning article on aid to Pakistan during the Bush administration, Craig Cohen and Derek Chollet demonstrated the disastrous nature of this militarized approach – even before the tottering Musharraf regime’s latest crackdown.
They show that even though Pakistan faces huge problems of poverty, population, and environment, 75% of the $10 billion in US aid has gone to the Pakistani military, ostensibly to reimburse Pakistan for its contribution to the “war on terror,” and to help it buy F-16s and other weapons systems.
Another 16% went straight to the Pakistani budget, no questions asked.
That left less than 10% for development and humanitarian assistance.
Annual US aid for education in Pakistan has amounted to just $64 million, or $1.16 per school-aged child.
The authors note that “the strategic direction for Pakistan was set early by a narrow circle at the top of the Bush administration and has been largely focused on the war effort rather than on Pakistan’s internal situation.”
They also emphasize that “US engagement with Pakistan is highly militarized and centralized, with very little reaching the vast majority of Pakistanis.”
They quote George Bush as saying, “When [Musharraf] looks me in the eye and says…there won’t be a Taliban and won’t be al-Qaeda, I believe him, you know?”
This militarized approach is leading the world into a downward spiral of violence and conflict.
Each new US weapons system “sold” or given to the region increases the chances of expanded war and further military coups, and to the chance that the arms will be turned on the US itself.
None of it helps to address the underlying problems of poverty, child mortality, water scarcity, and lack of livelihoods in places like Pakistan’s Northwest Frontier Province, Sudan’s Darfur region, or Somalia.
These places are bulging with people facing a tightening squeeze of insufficient rainfall and degraded pasturelands.
Naturally, many join radical causes.
The Bush administration fails to recognize these fundamental demographic and environmental challenges, that $800 billion of security spending won’t bring irrigation to Afghanistan, Pakistan, Sudan, and Somalia, and therefore won’t bring peace.
Instead of seeing real people in crisis, they see caricatures, a terrorist around every corner.
A more peaceful world will be possible only when Americans and others begin to see things through the eyes of their supposed enemies, and realize that today’s conflicts, having resulted from desperation and despair, can be solved through economic development rather than war.
We will have peace when we heed the words of President John F. Kennedy, who said, a few months before his death, “For, in the final analysis, our most basic common link is that we all inhabit this small planet.
We all breathe the same air.
We all cherish our children’s future.
And we are all mortal.”
America’s Financial Leviathan
BERKELEY – In 1950, finance and insurance in the United States accounted for 2.8% of GDP, according to US Department of Commerce estimates.
By 1960, that share had grown to 3.8% of GDP, and reached 6% of GDP in 1990.
Today, it is 8.4% of GDP, and it is not shrinking.
The Wall Street Journal’s Justin Lahart reports that the 2010 share was higher than the previous peak share in 2006.
Lahart goes on to say that growth in the finance-and-insurance share of the economy has “not, by and large, been a bad thing....Deploying capital to the places where it can be best used helps the economy grow...”
But if the US were getting good value from the extra 5.6% of GDP that it is now spending on finance and insurance – the extra $750 billion diverted annually from paying people who make directly useful goods and provide directly useful services – it would be obvious in the statistics.
At a typical 5% annual real interest rate for risky cash flows, diverting that large a share of resources away from goods and services directly useful this year is a good bargain only if it boosts overall annual economic growth by 0.3% – or 6% per 25-year generation.
There have been many shocks to the US economy over the past couple of generations, and many factors have added to or subtracted from economic growth.
But it is not obvious that the US economy today would be 6% less productive if it had had the finance-insurance system of 1950 rather than the one that prevailed during the past 20 years.
There are five ways that an economy gains from a well-functioning finance-insurance system.
First, people are no longer as vulnerable to the effects of fires, floods, medical disasters, unemployment, business collapses, sectoral shifts, and so forth, because a well-working finance-insurance system diversifies and thus dissipates some risks, and deals with others by matching those who fear risk with those who can comfortably bear it.
While it might be true that America’s current finance-insurance system better distributes risk in some sense, it is hard to see how that could be the case, given the experience of investors in equities and housing over the past two decades.
Second, well-functioning financial systems match large, illiquid investment projects with the relatively small pools of money contributed by individual savers who value liquidity highly.
There has been one important innovation over the past two generations: businesses can now issue high-yield bonds.
But, given the costs of the bankruptcy process, it has never been clear why a business would rather issue high-yield bonds (besides gaming the tax system), or why investors would rather buy them than take an equity stake.
Third, improved opportunities to borrow allow one to spend more now, when one is poor, and save more later, when one is rich.
Households are certainly much more able to borrow, thanks to home-equity loans, credit-card balances, and payday loans.
But what are they really buying?
Many are not buying the ability to spend when they are poor and save when they are rich, but instead appear to be buying postponement of the “unpleasant financial retrenchment” talk with the other members of their household.
And that is not something you want to buy.
Fourth, we have seen major improvements in the ease of transactions.
But, while electronic transactions have made a great deal of financial life much easier, this should have been accompanied by a decrease, not an increase, in the finance share of GDP, just as automated switching in telecommunications led to a decrease in the number of telephone switchboard operators per phone call.
Indeed, the operations of those parts of the financial system most closely related to technological improvements have slimmed down markedly: consider what has happened to the checking operations of the regional Federal Reserve Banks.
Finally, better finance should mean better corporate governance.
Since shareholder democracy does not provide effective control over entrenched, runaway, self-indulgent management, finance has a potentially powerful role to play in ensuring that corporate managers work in the interest of shareholders.
And a substantial change has indeed occurred over the past two generations: CEOs focus much more attention than they used to on pleasing the stock market, and this is likely to be a good thing.
Overall, however, it remains disturbing that we do not see the obvious large benefits, at either the micro or macro level, in the US economy’s efficiency that would justify spending an extra 5.6% of GDP every year on finance and insurance.
Lahart cites the conclusion of New York University’s Thomas Philippon that today’s US financial sector is outsized by two percentage points of GDP.
And it is very possible that Philippon’s estimate of the size of the US financial sector’s hypertrophy is too small.
Why has the devotion of a great deal of skill and enterprise to finance and insurance sector not paid obvious economic dividends?
There are two sustainable ways to make money in finance: find people with risks that need to be carried and match them with people with unused risk-bearing capacity, or find people with such risks and match them with people who are clueless but who have money.
Are we sure that most of the growth in finance stems from a rising share of financial professionals who undertake the former rather than the latter?
America’s Fiscal Isolationism
DENVER – Patience might be a virtue, but not necessarily when it comes to American foreign policy.
Consider “the long war,” a bold concept embraced a few years ago to describe the continuing struggle against terrorism, the grudging progress that could realistically be achieved, and the enormous financial burden that it would impose for years to come.
It was also a realpolitik acknowledgement of the setbacks to be expected along the way (the “slog,” as then Defense Secretary Donald Rumsfeld put it).
Above all, the term was an effort to communicate to Americans, accustomed to waging war with speed and decisiveness (and insistent on it since Vietnam), the long-term sacrifice and commitment needed to win a war of survival.
Its proponents also understood that the war would not be limited to weapons, but would need to be a sustained effort, involving, as they put it, the “whole of government,” with civilian agencies marshaled behind military – or paramilitary – objectives.
Daunting as the effort would be, its advocates assumed a sustainable political consensus to support it.
After all, the United States had been attacked.
Today, that consensus is unraveling as America’s politicians wrestle with a federal budget that is itself turning into a long war – one with its own casualties.
The battle lines in this struggle suggest that there is little accord among political elites for any spending, let alone for a long war with far-flung commitments.
As a result, basic assumptions are being questioned at every turn.
Indeed, the current budget war seems to be reopening old divisions about America’s view of itself and the world.
The outcome is far from certain, but even isolationism, a perennial American malady, seems to be making a comeback.
Isolationism is a familiar refrain in US foreign policy among those elements of the right that consider the US too good for the world, as well as among those on the left who consider America a destructive global force.
But this time, as perhaps never before, a bipartisan isolationist impulse is being driven by the budget.
America’s fiscal crisis is profound, and it is not just about numbers.
As the emotions in Washington today suggest, the aversion to tax increases runs far deeper than concern about their effect on current economic performance and job growth.
In part, it represents a fundamental – some would say fundamentalist – view that taxes are to government what a bottle of whisky is to an alcoholic.
Government, as Ronald Reagan told us, is the problem, not the solution.
That message is bad news for American diplomacy.
The linkage between politicians’ unwillingness to fund domestic programs and the imperiled commitment to “the long war” might elude those in US foreign-policy circles, but it is not lost on the rest of the country.
Opinion surveys suggest that Americans want to maintain many of the “discretionary” domestic programs – schools, hospitals, transportation infrastructure, recreational parks, etc. – that are now on the chopping block in budget negotiations.
In places like rural El Paso County, on the eastern plains of Colorado, far from the federal budget debate’s epicenter, spending cuts are the order of the day.
School districts are increasing class sizes as they shed teachers, as well as deferring maintenance projects and curtailing the school-bus service.
These cuts are having a very real and immediate impact on El Paso County’s residents.
Can they, and other Americans who are losing vital services, really be expected to rise above it all and support funding to build new schools in Afghanistan?
Not only are America’s public schools starting to look second-rate, but so is its infrastructure, which had long been a source of national pride.
How many travelers nowadays can fail to note the difference between Asia’s new, efficient airports and the aging, clogged antiques in some major US cities?
The budget war is not producing any consensus on fixing America’s infrastructure, but it is beginning to produce a view that Afghanistan and Pakistan are far from being core US national interests.
Why, people ask, are schools and roads in Afghanistan and Iraq more important than those in Colorado or California?
At one point in 2008, the US military picked up the cost of transporting a tiger for the Baghdad zoo.
When was the last time the US government did that for a US zoo (outside of Washington, of course)?
How this debate sorts itself out will have profound consequences for how America conducts itself in the world.
But it might also take a toll on how the world reacts to America’s fastest-growing export: unsolicited advice.
Countries take others’ advice for many reasons.
Sometimes they respect the adviser’s wisdom and insights (fairly rare in diplomacy).
Or they might fear the consequences of not taking the advice (an offer one cannot refuse, so to speak).
Or, as is true of many of America’s diplomatic transactions, accepting advice could open the way to a better relationship and to additional assistance.
In short, diplomacy – and US diplomacy, in particular – often involves money.
But what if there is no money to offer?
What if Americans, tired of the budget cuts in their neighborhoods, refuse to support funds even for “the long war”?
At that point, senior US officials might well arrive in a country, offer advice, and find that nobody is bothering to listen.
Obama’s Underachieving Foreign Policy
PARIS – To evaluate an American president’s foreign-policy performance after one term is challenging, given the complex diplomatic and strategic environment and significant domestic constraints that confront every US president.
Nevertheless, in advance of November’s presidential election, it is important to distinguish the forces that have shaped Barack Obama’s foreign policy, and to assess his handling of them.
Obama kept his promise to withdraw American forces from Iraq during his first term.
But the move proved to be a strategic defeat, given that it significantly diminished the United States’ political influence in Iraq.
Indeed, Prime Minister Nouri al-Maliki’s government is becoming increasingly allied with Iran.
Obama, who opposed the Iraq war, should not be blamed for current circumstances there.
But he was unable to improve the situation or help Iraq’s Shias and Sunnis reach a political compromise.
In contrast, Obama expanded the war in Afghanistan – which he considered to be a war of necessity – and put the Taliban on the defensive.
But the US will begin to withdraw troops after 2014, without having defined a political solution in line with its interests.
Meanwhile, America’s strategic partnership with Pakistan, where Obama won a significant symbolic victory by eliminating Osama bin Laden, is in tatters.
US-Pakistan relations have regressed to their level before September 11, 2001, with mutual distrust minimizing cooperation.
In fact, in all of the strategic challenges to US security that Obama inherited – Iran, North Korea, Iraq, Afghanistan, Pakistan, and the Israeli-Palestinian conflict – he has made virtually no significant political gains.
Notwithstanding Obama’s skillful response to the Arab Spring – the only strategic surprise that he has faced as president – his credibility in the Muslim world has steadily declined.
He has failed to deliver on the key promise of his Cairo speech in 2009: “to seek a new beginning between the United States and Muslims around the world.”
Moreover, Obama’s efforts to improve relations with Russia – embodied in the Strategic Arms Reduction Treaty (START) – did not lead to a genuine “reset” in bilateral ties, largely because an increasingly Soviet-style Russian leadership distrusts a US establishment that still regards Russia as a foe.
And the US-China relationship has deteriorated, with America seeking to manage China’s rise strategically – for example, through regional trade agreements and an enhanced military presence in Asia.
On multilateral issues, Obama’s performance is equally unimpressive.
After committing to a 17% reduction of greenhouse-gas emissions by 2020 – and despite his declaration that he would not tolerate inaction in this area – he simply stopped raising the issue after the Republicans’ sweeping victory in the November 2010 mid-term elections.
Likewise, domestic pressure has caused Obama to neglect trade issues.
The US is largely responsible for the failure of the Doha Round of global trade talks.
Obama’s one significant foreign-policy breakthrough has been to release the US from the grip of the “global war on terror.”
Jettisoning the Manichean rhetoric of that “war” allowed the US to regain the political legitimacy that former President George W. Bush had lost, without diminishing its strategic credibility.
After the Vietnam War, Jimmy Carter hoped to make a break with established US policy.
But his administration’s actions – including serious blunders in Iran and Afghanistan – made the US appear weak and indecisive.
While Obama’s policies have not weakened America’s international standing, they also have not led to achievements comparable to Richard Nixon’s rapprochement with China, largely owing to what might be described as the dogmatic pragmatism that underlies them – an emphasis on avoiding the worst, rather than on striving for the best.
Moreover, Obama has been confronted with significant constraints, including the global economic crisis, domestic political polarization, a hostile Congress, and the rise of emerging powers that need the US but are unwilling to accept its dominance.
As a result, he has failed to change strategic realities by, for example, reconciling America’s broader interests with those of Iran (a declared enemy), Pakistan (a “frenemy”), and Israel (a key ally).
To be sure, Obama faces a more complex diplomatic and strategic environment than Nixon faced in the 1970’s.
Unstable coalitions in Iran prevent any substantive negotiations between the two countries, while political fragmentation in Pakistan significantly hinders US policy there.
And the fragility of Israel’s ruling coalition, combined with strong congressional support for Prime Minister Binyamin Netanyahu, makes it difficult to influence the country’s policies, despite Israel’s significant impact on US strategy in the Arab world.
But Obama has also struggled to define the terms of a possible grand bargain.
Any agreement with Iran would require consent from Israel and the Gulf countries, which do not share the same objectives.
And the US cannot reach an accord with Pakistan without India’s consent, which America would be unable to force, especially given that it relies on India to counterbalance China’s growing clout in Asia.
With Israel, the terms are ostensibly simpler: in exchange for a stronger US security guarantee, Israel would accept the establishment of a Palestinian state based on the 1967 borders.
But Israel is also a crucial domestic political topic in the US; indeed, any distancing from Israel is unacceptable to most Americans.
While Obama’s first term could not be called a foreign-policy disappointment, his achievements – although not trivial – have been limited.
If he wins a second term, he is likely to find it increasingly difficult to win by playing not to lose.
America’s Groucho Marxists
LONDON – Groucho Marx has always been my favorite Marxist.
One of his jokes goes to the heart of the failure of the ideology – the dogmatic religion – inflicted on our poor world by his namesake, Karl.
“Who are you going to believe,” Groucho once asked, “me, or your own eyes?”
For hundreds of millions of citizens in Communist-run countries in the twentieth century, the “me” in the question was a dictator or oligarchy ruling with totalitarian or authoritarian powers.
It didn’t matter what you could see with your own eyes. You had to accept what you were told the world was like.
Reality was whatever the ruling party said it was.
The designated successor to Mao Zedong in China, Hua Guofeng, raised this attitude to an art form. He was known as a “whateverist.”
The Party and people should faithfully follow whatever Mao instructed them to do.
Groucho posed two insuperable problems for the “whateverists” of communism. First, your own eyes and your reason would surely tell you before long that the communist idyll – the withering away of the state and the triumph over need – would never come.
Communism, like the horizon, was always just beyond reach.
It would be interesting to know how many of those at Beijing’s Central Party School – the party’s main educational institute – believe that the Chinese state is about to wither away, or ever will.
The second application of Groucho’s question was that citizens of most Communist countries soon learned that the loss of freedom that they suffered was not compensated by greater prosperity or a higher quality of life.
The more that Russians, Poles, Czechs, and others saw of the life-style in the Western democracies, the more they questioned their own system. In his magisterial book
So, in the political sphere, reason has trumped both faith in an unattainable goal and self-delusion about the consequences of its pursuit.
Authoritarian party-states, such as China and Vietnam, survive, but not through commitment to communism. Their legitimacy depends on their ability to deliver economic growth through state-managed capitalism.
Democracies, of course, allow people to use their reason to make choices based on the evidence of their own eyes.
When you don’t like a government, you can turn the rascals out without overthrowing the whole system.
Change can be made in an evolutionary, rather than a revolutionary, way.
But no one should think that debate in democracies is always based on reason, or that democracy necessarily makes people more rational.
Sometimes reason does prevail.
This is what appeared to happen in the last Indian election, and the election in the United States of President Barack Obama was also plainly a supremely rational moment.
But reason does not seem to be getting much of a hearing during the current health-care debate in the US.
Outsiders, even admirers, have often wondered how the most globalized country in the world – a continent inhabited by people from every land – can be so irrationally insular on some issues.
We scratch our heads about America’s gun laws. We were astonished during President George W. Bush’s first term at the administration’s hostility to science, reflected in its stance on climate change and Charles Darwin’s theory of evolution.
The opposition to health-care reform is a similar cause of bemusement.
We know that despite its great wealth – and its groundbreaking medical research – America’s health-care system is awful. It is hugely expensive.
Its costs overwhelm workplace health-insurance schemes. The poor go unprotected.
Too many of the sick are untreated. Overall health statistics are worse than those in comparable countries.
Yet Obama’s attempts to reform health care have run into hysterical opposition.
His proposals would lead, it is said, to the state murdering the elderly.
They would introduce Soviet communism into the US – just like what apparently exists in Canada and Britain, with their state-sponsored health systems.
Communism in Toronto and London?
Or just better, cheaper, more reliable health care for all?
Reason seems to be having a hard time of it in the US just now.
Maybe it’s no coincidence that Groucho Marx was an American citizen.
But surely the way a society cares for its sick and needy and elderly is sufficiently important to deserve serious and thoughtful argument based on what we really can see with our own eyes rather than on uninformed partisan prejudice.
Gun Control After Newtown
NEW YORK – The brutal murder of 20 children and seven adults in Newtown, Connecticut, shakes us to the core as individuals and requires a response as citizens.
The United States seems to reel from one mass gun killing to another – roughly one a month this year alone.
Easy access to guns in the US leads to horrific murder rates relative to other highly educated and wealthy societies.
America needs to find a better way.
Other countries have done so.
Between the mid-1970’s and the mid-1990’s, Australia had several mass shootings.
After a particularly horrible massacre in 1996, a new prime minister, John Howard, declared that enough was enough.
He instituted a severe crackdown on gun ownership, and forced would-be gun owners to submit to a rigorous application process, and to document why they would need a gun.
Conditions for gun ownership in Australia are now very strict, and the registration and approval process can take a year or more.
Howard’s government also implemented a rigorous “buyback” policy, to enable the government to purchase guns already owned by the public.
The policy worked.
While violent crime has not ended in Australia, murders are down, and, even more dramatically, there has not been a single mass shooting since 1996 in which three or more people died (the definition used in many studies of mass shootings).
Before the crackdown, there had been 13 such massacres in 18 years.
Yet the US still refuses to act, even after this year’s string of shocking incidents: the massacre in a movie theatre in Colorado, an attack on a Sikh community in Milwaukee, another on a shopping mall in Oregon, and many more before the ruthless slaughter of first graders and school staff in Newtown.
The gun lobby in the US remains powerful, and politicians are afraid to counter it.
Given the shooting of then-Congresswoman Gabrielle Giffords in 2011, perhaps they even fear that they, too, might be targeted.
There can be little doubt that some societies are more steeped in violence than others, even controlling for obvious factors like income levels and education.
The US homicide rate is roughly four times that of comparable societies in Western Europe, and Latin America’s homicide rates are even higher than in the US (and dramatically higher than Asian countries at roughly the same income level).
What accounts for staggeringly high rates in the US and Latin America?
American violence is rooted in history.
The US and Latin American countries are all “conquest” societies, in which Europeans ruled over multi-racial societies.
In many of these countries, including the US, the European conquerors and their descendants nearly wiped out the indigenous populations, partly through disease, but also through war, starvation, death marches, and forced labor.
In the US and many Latin American countries, slaveholding fueled mass violence as well.
The slaves – and generations of their descendants – were routinely murdered.
The US also developed a particular populist belief that gun ownership constitutes a vital protection against government tyranny.
The US was born in a citizens’ revolt against British imperial power.
The right of citizens to organize militias to fight government tyranny was therefore a founding idea of the new country, enshrined in the Second Amendment to the US Constitution, which declares that, because a country needs a well-regulated militia, the people have the right to bear arms.
Since citizens’ militias are anachronistic, gun owners now use the second amendment merely to defend individual gun ownership, as if that somehow offers protection against tyranny.
A reckless, right-wing Supreme Court has agreed with them.
As a result, gun ownership has become perversely linked to freedom in the vast gun-owning American sub-culture.
But, instead of protection of freedom, Americans nowadays are getting massive bloodshed and fear.
The claim that gun ownership ensures freedom is especially absurd, given that most of the world’s vibrant democracies have long since cracked down on private gun ownership.
No tyrant has risen in Australia since Howard’s gun-control reforms.
Simply put, freedom in the twenty-first century does not depend on unregulated gun ownership.
Indeed, America’s gun culture is a threat to freedom, after the murder of a president, senator, and other public leaders, and countless assassination attempts against public officials over recent decades.
Yet US gun culture remains as pervasive as it is unrecorded.
America reels from one shooting disaster to the next, and on nearly every occasion, politicians dutifully declare their continued devotion to unregulated gun ownership.
Indeed, no one even knows how many guns Americans hold.
The number is estimated to be around 270 million, or almost one per person on average.
According to one recent poll, 47% of households have a gun at home.
The shooting in Newtown was not only especially horrific and heartbreaking, but is also part of an increasingly common pattern – a specific kind of murder-suicide that has been carefully studied by psychologists and psychiatrists.
Loners, often with paranoid tendencies, commit these heinous acts as part of their own suicide.
They use carefully planned and staged mass murders of innocents in order to take revenge on society and to glorify themselves as they take their own lives.
The perpetrators are not hardened criminals; many have no previous criminal record.
They are pathetic, deranged, and often have struggled with mental instability for much of their lives.
They need help – and society needs to keep guns out of their reach.
America has now suffered around 30 shooting massacres over the past 30 years, including this year’s deadly dozen; each is a gut-wrenching tragedy for many families.
And yet, each time, gun owners scream that freedom will be eliminated if they are unable to buy assault weapons and 100-round clips.
The bloodbath in Newtown is the time to stop feeding this gun frenzy.
Australia and other countries provide models of how to do it: regulate and limit gun ownership to approved uses.
America’s real freedoms depend on sane public policy.
America’s G-Zero Moment
NEW YORK – The 2008 financial crisis marked the end of the global order as we knew it.
In advance of the upcoming G-8 summit, it is impossible to overlook the fact that, for the first time in seven decades, the United States cannot drive the international agenda or provide global leadership on all of today’s most pressing problems.
Indeed, the US has trimmed its presence abroad by refusing to contribute to a eurozone bailout, intervene in Syria, or use force to contain Iran’s nuclear breakout (despite strong Israeli support).
President Barack Obama officially ended the war in Iraq, and is withdrawing US troops from Afghanistan at a pace constrained only by the need to save face.
America is handing off the leadership baton – even if no other country or group of countries is willing or able to grasp it.
In short, US foreign policy may be as active as ever, but it is downsizing and becoming more exacting about its priorities.
As a result, many global challenges – climate change, trade, resource scarcity, international security, cyber-warfare, and nuclear proliferation, to name a few – are bound to loom larger.
Welcome to the G-Zero world, a more turbulent, uncertain environment in which coordination on global policy issues falls by the wayside.
Paradoxically, this new environment, though daunting, is less troublesome for the US; in fact, it provides fresh opportunities for the US to capitalize on its unique position.
The G-Zero world is not all bad for the US – if it plays its cards right.
Many residual strengths take on greater importance in such a world, and America remains the world’s only true superpower and its largest economy – still more than twice the size of China’s.
Its defense expenditures represent nearly half the world total, and exceed those of the next 17 countries combined.
The dollar remains the world’s reserve currency, and investors’ scramble into US government debt at every peak in the crisis since 2008 has underscored America’s safe-haven status (even in crises that America caused).
Likewise, the US continues to lead in entrepreneurship, research and development, higher education, and technological innovation.
Moreover, it is now the world’s largest natural-gas producer and calorie exporter, which has reduced its vulnerability to price shocks or food shortages.
No country rivals America’s promotion of the rule of law, liberal democracy, transparency, and free enterprise.
While other countries certainly support these values, only the US has been willing, healthy, and big enough to ensure that they prevail.
So, as America curtails its global leadership, it will find itself in more demand.
Consider Asia, for example.&nbsp;As China’s economic importance and regional influence grows, its neighbors are seeking to deepen ties with the US.
Japan, Australia, Indonesia, and Taiwan have all recently closed trade and security-related deals with the US.
Even Burma has gotten on board, resuming diplomatic engagement with the US while trying to work its way out of China’s shadow.
In other words, in a G-Zero world, an increasingly aggressive global environment makes the US all the more appealing to countries seeking to hedge their bets.&nbsp;As a result, the US has an opportunity to act more precisely in its own interests.
Supplying less leadership allows the US to weigh opportunity costs before taking action, and to select the issues and circumstances that suit it the best.&nbsp;In this environment, military intervention in Libya does not necessitate the same in Syria.
The extent to which the US will capitalize on these opportunities remains to be seen.
In fact, America’s short-term advantages pose the biggest obstacle to its long-term outlook.
Call this the “safe-haven curse”:&nbsp;as long as the US remains the safest port in any storm, it faces no immediate pressure to address its weaknesses.
For example, for all of the hand-wringing about America’s national debt, investors will continue to loan the US money.
Over the long term, however, US policymakers must make steady progress in restoring confidence in the nation’s fiscal health by cutting politically sacred programs like social security, Medicare, and defense.
Officials will have to put aside short-term motives and party orthodoxy to bolster America’s aging infrastructure, reform its education and immigration systems, and pursue long-term fiscal consolidation.
America’s advantages in the G-Zero world afford it the chance to invest in the future.
But, by cushioning against sufficiently calamitous risks, the same advantages allow the US to procrastinate.
American politicians need to recognize the new G-Zero reality and rebuild America’s domestic sources of strength, even if only incrementally.&nbsp;If they do, the US will have the vigor and flexibility to shape the next world order.
America’s political system usually works well in crises.&nbsp;But, thanks to its residual advantages in a leaderless world, the US need not rely on a crisis to precipitate action.
It need only seize the G-Zero moment.
America’s Houses of Cards
There are times when being proven right brings no pleasure.
For several years, I argued that America’s economy was being supported by a housing bubble that had replaced the stock market bubble of the 1990’s.
But no bubble can expand forever.
With middle-class incomes in the United States stagnating, Americans could not afford ever more expensive homes.
As one of my predecessors as Chairman of the US President’s Council of Economic Advisers famously put it, “that which is not sustainable will not be sustained.”
Economists, as opposed to those who make their living gambling on stocks, make no claim to being able to predict when the day of reckoning will come, much less identifying the event that will bring down the house of cards.
But the patterns are systematic, with consequences that unfold gradually, and painfully, over time.
There is a macro-story and a micro-story here.
The macro-story is simple, but dramatic.
Some, observing the crash of the sub-prime mortgage market, say, “Don’t worry, it is only a problem in the real estate sector.”
But this overlooks the key role that the housing sector has played in the US economy recently, with direct investment in real estate and money taken out of houses through refinancing mortgages accounting for two-thirds to three-quarters of growth over the last six years.
Booming home prices gave Americans the confidence, and the financial wherewithal, to spend more than their income.
America’s household savings rate was at levels not seen since the Great Depression, either negative or zero.
With higher interest rates depressing housing prices, the game is over.
As America moves to, say, a 4% savings rate (still small by normal standards), aggregate demand will weaken, and with it, the economy.
The micro-story is more dramatic.
Record-low interest rates in 2001, 2002 and 2003 did not lead Americans to invest more – there was already excess capacity.
Instead, easy money stimulated the economy by inducing households to refinance their mortgages, and to spend some of their capital.
It is one thing to borrow to make an investment, which strengthens balance sheets; it is another thing to borrow to finance a vacation or a consumption binge.
But this is what Alan Greenspan encouraged Americans to do.
When normal mortgages did not prime the pump enough, he encouraged them to take out variable-rate mortgages – at a time when interest rates had nowhere to go but up.
Predatory lenders went further, offering negative amortization loans, so the amount owed went up year after year.
Sometime in the future, payments would rise, but borrowers were told, again, not to worry: house prices would rise faster, making it easy to refinance with another negative amortization loan.
The only way (in this view) not to win was to sit on the sidelines.
All of this amounted to a human and economic disaster in the making.
Now reality has hit: newspapers report cases of borrowers whose mortgage payments exceed their entire income.
Globalization implies that America’s mortgage problem has worldwide repercussions.
The first run on a bank occurred against the British mortgage lender Northern Rock.
America managed to pass off bad mortgages worth hundreds of billions of dollars to investors (including banks) around the world.
They buried the bad mortgages in complicated instruments, buried them so deep that no one knew exactly how badly they were impaired, and no one could calculate how to re-price them quickly.
In the face of such uncertainty, markets froze.
Those in financial markets who believe in free markets have temporarily abandoned their faith.
For the greater good of all (of course, it is never for their own selfish interests), they argued a bailout was necessary.
While the US Treasury and the IMF warned East Asian countries facing financial crises ten years ago against the risks of bail-outs and told them not to raise their interest rates, the US ignored its own lectures about moral hazard effects, bought up billions in mortgages, and lowered interest rates.
But lower short-term interest rates have led to higher medium-term interest rates, which are more relevant for the mortgage market, perhaps because of increasing worries about inflationary pressures.
It may make sense for central banks (or Fannie Mae, America’s major government-sponsored mortgage company) to buy mortgage-backed securities in order to help provide market liquidity.
But those from whom they buy them should provide a guarantee, so the public does not have to pay the price for their bad investment decisions.
Equity owners in banks should not get a free ride.
Securitization, with all of its advantages in sharing risk, has three problems that were not adequately anticipated.
While it meant that American banks were not hit as hard as they would otherwise, America’s bad lending practices have had global effects.
Moreover, securitization contributed to bad lending: in the old days, banks that originated bad loans bore the consequences; in the new world of securitization, the originators could pass the loans onto others.
(As economists would say, problems of asymmetric information have increased.)
In the old days, when borrowers found it impossible to make their payments, mortgages would be restructured; foreclosures were bad for both the borrower and the lender.
Securitization made debt restructuring difficult, if not impossible.
It is the victims of predatory lenders who need government help.
With mortgages amounting to 95% or more of the value of the house, debt restructuring will not be easy.
What is required is to give individuals with excessive indebtedness an expedited way to a fresh start – for example, a special bankruptcy provision allowing them to recover, say, 75% of the equity they originally put into the house, with the lenders bearing the cost.
There are many lessons for America, and the rest of the world; but among them is the need for greater financial sector regulation, especially better protection against predatory lending, and more transparency.
America’s Interest-Rate Puzzle
A great puzzle in today’s world economy is the continued low level of long-term real interest rates in the United States.
Conventional macroeconomists like me look at America’s current-account deficit, now running at 7% of GDP, and know that such vast deficits are inevitably followed by large currency depreciations.
So we expect a substantial depreciation premium on US interest rates.
If the dollar falls 20% more against the euro sometime in the next ten years, US long-term interest rates should be two percentage points higher than euro rates.
If it falls 40% against the yen sometime in the next ten years, US long-term interest rates should be four percentage points higher than Japanese rates.
If it falls 60% against China’s currency, the yuan, sometime in the next ten years, US long-term interest rates should be six percentage points higher than Chinese rates.
But we are not seeing signs of anything like this.
The puzzle is not only that long-term rates are too low when viewed in the international context, but also that they are too low when viewed in America’s domestic context.
The Bush administration continues to have no plans to sew up the veins it has opened with its medieval economic policy, which holds that bleeding revenue from the government cures all economic problems.
This means that unless America’s domestic savings rate rises mightily – which it shows no signs of doing – and unless investment expenditure remains abnormally low for the rest of this decade, the supply of loanable funds to finance investment will soon be much less than demand when the current-account deficit narrows to sustainable levels. But when supply is less than demand, prices rise sharply.
In this case, the price of loanable funds is the real interest rate.
An expectation that interest rates will be high sometime in the next decade should mean high interest rates on long-term bonds today.
Yet financial markets are not pricing dollar depreciation and a rise in long-term US interest rates accordingly.
When we macroeconomists talk to our friends on Wall Street, we find that they don’t view this as a puzzle at all.
On the contrary, they are puzzled about why we view the current low level of US long-term interest rates as worrisome.
From their perspective, today’s high demand for long-term dollar-denominated securities is easily explained: Asian central banks are buying in order to hold down their currencies, the US Treasury is borrowing short (and thus not issuing that many long-term securities), and US companies are not undertaking the kinds of investments that would lead them to issue many long-term bonds.
But for every market mispricing there is a profit opportunity: if long-term interest rates are, indeed, too low and long-term bond prices too high, investors will short long-term US bonds, park the money elsewhere, wait for bond prices to return to fundamentals, and then cover their short positions.
By doing so, they will push prices close to fundamentals today.
Wall Streeters, however, offer a counterargument: for any financial institution to, say, bet on the decline of the dollar against the yuan over the next five years in a serious, leveraged way is to put its survival at risk should the trades go wrong.
And trades do go wrong: remember the collapse of Long-Term Capital Management.
The existence of large financial-market actors that do not care about maximizing their profits magnifies the riskiness of the bets.
If, say, the Bank of China and the Federal Reserve decided to teach speculators a lesson by pushing the dollar’s value relative to the yuan up by 20% for a month, they could do so, bankrupting many financial institutions with short positions.
Similarly, any financial institution that bets on a sharp rise in long-term interest rates over the next five years in a serious, leveraged way also puts its survival at risk.
For where should they park their money?
Real estate rental yields and stock-market payouts are low, and real estate and stock prices may well fall as much as or more than bond prices if interest rates spike.
Only businesses that can borrow long-term now, lock in a low real interest rate, and invest in expanding their capacity can make the domestic bet that interest rates will rise.
But America’s businesses see enough risk in the future to be wary of getting stuck with unutilized capacity.
Economists believe that market forces drive prices to fundamentals.
But we are not careful enough to distinguish situations in which equilibrium-restoring forces are strong from those in which such forces are weak.
The dollar will fall and US long-term interest rates will rise, but only when traders on Wall Street and elsewhere decide that holding dollars and long-term US bonds is more risky in the short run.
When that happens, the long-run future will be now.
America’s Islamist Allies of Convenience
NEW DELHI – In just one decade, the United States has intervened militarily in three Muslim-majority countries and overthrown their governments.
Now the same coalition of American liberal interventionists and neoconservatives that promoted those wars is pushing for punitive airstrikes in Syria without reflecting on how US policy has ended up strengthening Islamists and fostering anti-Americanism.
Indeed, the last “humanitarian intervention” has clearly backfired, turning Libya into a breeding ground for transnational militants.
As the intense US debate about President Barack Obama’s proposed use of military force highlights, the attack-Syria push is not about upholding America’s national interest.
Rather, the desire to protect US “credibility” has become the last refuge of those seeking yet another war in the wider Middle East.
If “credibility” were purged from the debate and the focus placed squarely on advancing long-term US interests, it would become apparent that an attack on Syria might not yield even temporary geopolitical gains.
Beyond the short term, it would unleash major unintended consequences, potentially including an Iraq-style “soft” partition of Syria and the creation of a haven for extremists stretching across much of Islamist-controlled northern Syria and into the Sunni areas of Iraq.
Indeed, an attack would most likely increase America’s reliance on unsavory Islamist rulers in countries ranging from Saudi Arabia and Qatar to Turkey and the United Arab Emirates.
Some Arab monarchs have pledged to bankroll the US attack – an investment that they would easily recover, given that the war talk has already increased oil prices.
Al Qaeda-type groups already have gained ground in the Middle East and North Africa as an unintended byproduct of US policies, creating fertile conditions for stepped-up international terrorism in the coming years.
The US invasion and occupation of Iraq, for example, created a major opening for Al Qaeda, whose affiliates now represent the Sunni struggle against the Shia-dominated government.
Likewise, regime change in Libya aided the rise of Al Qaeda-linked militants, leading to the killing in Benghazi of the US ambassador.
A system based on sharia (Islamic law) has been imposed, human-rights abuses are legion, and cross-border movement of weapons and militants has undermined the security of Libya’s neighbors.
Meanwhile, America’s support for the regimes in Yemen and Saudi Arabia has contributed to the rise of Al Qaeda in the Arabian Peninsula.
In parts of southern Yemen, an Al Qaeda affiliate, Ansar al-Sharia, functions as a de facto government.
In Syria, where sizable chunks of territory are already under Islamist control and the pro-Al Qaeda Al Nusra Front overshadows the US-backed Free Syrian Army, the Obama administration is staring at the bitter harvest of its previous policy choices.
Airstrikes now would merely make matters worse by undercutting the FSA’s grassroots legitimacy and aiding Islamist forces.
Farther east, the US wants an “honorable” exit from Afghanistan – the longest war in its history – through a peace deal with the Taliban, its main battlefield opponent.
In seeking to co-opt the Taliban – an effort that has resulted in the Taliban establishing what amounts to a diplomatic mission in Doha, Qatar – the US is bestowing legitimacy on a thuggish militia that enforces medieval practices in the areas under its control.
America’s dalliances with Islamist-leaning political forces – and governments – have been guided by the notion that the cloak of Islam helps to protect the credibility of leaders who might otherwise be seen as foreign puppets.
That simply will not work, even in the short term.
On the contrary, until the Egyptian army removed him from the presidency, the Muslim Brotherhood’s Mohamed Morsi was coming to be seen by many as America’s man in Cairo.
In the long term, the US will gain nothing – and risk much – by continuing to back oil sheikhdoms that fund Muslim extremist groups and madrasas from the Philippines and India to South Africa and Venezuela.
By supporting Islamist rulers, the US is contributing to a trend evident from the Maghreb to the badlands of Afghanistan and Pakistan – Muslims killing Muslims.
American policy has also contributed to a growing conflict between Islamist and secular forces in Muslim countries.
This is best illustrated by Turkey, where Obama has ignored Prime Minister Recep Tayyip Erdoğan’s heavy-handed efforts to annul free speech and turn himself into a twenty-first-century Sultan.
There and elsewhere, the US, motivated by the larger geopolitical goal of containing Shia Iran and its regional allies, has embraced Sunni rulers steeped in religious and political bigotry, even though they pose a transnational threat to the values of freedom and secularism.
Moreover, the clash within Islam is likely to be destabilizing regionally and counterproductive to the interests of the free world.
Against this background, Obama should heed the doctrine proposed in 1991 by General Colin Powell.
The Powell doctrine stipulates that the US should use military force only when a vital national-security interest is at stake; the strategic objective is clear and attainable; the benefits are likely to outweigh the costs; adverse consequences can be limited; broad international and domestic support has been obtained; and a plausible exit strategy is in place.
Given the US record since the doctrine was formulated, another criterion should be added: the main beneficiaries of military intervention are not America’s mortal enemies.
Drone Wars
BRUSSELS – “Sometime they’ll give a war and nobody will come,” the American poet Carl Sandburg wrote hopefully in 1936.
His sentiment seems more apt than ever nowadays, but not because humanity has turned pacifistic.
Rather, wars are increasingly fought remotely, with drones – or unmanned aerial vehicles (UAVs) – doing the killing.
Under President Barack Obama, the number of drone strikes carried out by the United States has soared, with more than 300 UAV attacks reported in Pakistan alone.
In March 2011, the US Air Force for the first time trained more pilots for drones than for any other purpose.
This raises serious ethical questions.
With no military personnel risking their lives, UAVs make it easier to kill, and to justify war operations to the public at home.
Moreover, a human being’s reticence to kill is inversely related to the distance between attacker and target.
In the case of a pilot flying drones over Yemen by operating a joystick in Nevada, the threshold to pulling the trigger is dangerously low.
Killing is just a part of the job, to be followed by bowling, perhaps, or a quiet evening at home.
Meanwhile, the mere sound of drones terrorizes whole populations, indicating to enemies and civilians alike that they are being watched and might be attacked at any moment – which could well play into the hands of terrorist recruiters.
From a legal and human-rights point of view, the US drone program is even more alarming.
After all, countries such as Pakistan, Yemen, and Somalia do not belong to declared war zones.
Outside the context of war, in turn, state killings are legal only if they prove absolutely necessary to save lives.
They must be conducted either in self-defense after an attack, or in anticipatory self-defense against an immediate threat, when taking time to discuss non-lethal alternatives is not feasible.
More than a decade after September 11, America’s drone program does not fall into the first category of reactive self-defense.
Likewise, there is no evidence that any presumed terrorist who was killed outside of official war zones in the last few years represented a threat so immediate to US citizens’ lives that preventive and premeditated killing was the only option.
Unless US leaders prove otherwise in every case, American UAV attacks in countries like Pakistan or Yemen should be called what they are: extrajudicial killings.
US State Department legal adviser Harold Koh disagrees, arguing that America is involved in a worldwide “armed conflict with Al Qaeda, as well as the Taliban and associated forces.”
So, Koh claims, drone attacks are part of a global war, fought both in declared war zones and non-war countries; therefore, they are legal.
But, even under this adventurous assumption, human-rights issues arise.
The laws of war condone targeted killings only of “combatants” who “directly participate in hostilities.”
The killings must be proportionate, strategically necessary, and publicly justified.
Avoiding harm to civilians should be the top priority.
At the slightest sign of illegality, an investigation must be conducted, offenders prosecuted, and victims compensated.
The US drone program’s legal basis is entirely unclear, however.
Given that most information about UAV activity is classified, it is impossible to know whether all drone targets directly participated in hostilities.
And, while the Obama administration’s claim of zero or single-digit civilian fatalities may be true according to the official definition, it rests on the premise that any military-age male killed in a drone strike is a militant, unless intelligence posthumously proves otherwise.
A recent report by the law schools at Stanford University and New York University concludes that, in reality, civilian casualties in Pakistan may have accounted for up to 75% of all UAV victims between 2008 and 2011.
Others estimate a lower, but still alarming, rate of 30%.
The legal obligation of proportionality is clearly being violated.
Accountability is also being flouted.
Drone operations are carried out by the Central Intelligence Agency, an organization whose activities are shrouded in secrecy.
And, unlike military personnel, CIA agents enjoy extensive immunity, undermining international legal standards.
Without increased transparency, to declare America’s UAV campaign legal is impossible, both in the context of war and outside of armed conflict.
As long as the US keeps the rest of the world in the dark, illegal acts – including possible war crimes – may be committed with impunity.
Just as citizens worldwide are demanding increased economic and financial accountability, more pressure must be placed on the US to either prove that its drone activities are necessary and legal, or to stop them immediately.
Victims of UAV attacks, their families, and civil-society groups have begun to speak out against America’s questionable drone campaign, and to pursue legal action.
Others should feel encouraged to follow suit.
In the meantime, every drone strike will not only undermine human rights and international humanitarian law, but will also further widen a legal loophole that other governments and armed groups will not hesitate to exploit.
The US drone program does not make the world a safer place; it creates an environment in which unlawful killings can happen virtually anywhere, at any time, violating the fundamental human right not to be arbitrarily deprived of one’s life.
America’s Locust Years
BERKELEY – It is hard right now to write about American political economy.
Nobody knows whether the debt-ceiling tripwire will be evaded; if so, how; or what will happen if it is not.
If no deal to raise the debt ceiling is reached by August 3, interest rates on United States Treasury bonds could spike, or they could remain stable, as investors decide they have other problems to worry about.
Or the US Federal Reserve, the Peoples Bank of China (PBC), or both – or even some other body – could support the market.
Or interest rates could rise if people expect a much weaker global economy – and, in a weaker global economy with no inflation, investors should be holding more US Treasuries, not fewer.
Frankly, no one knows what legislative deal will be struck to raise the debt ceiling.
All we know as of this writing is that a deal would probably involve cuts in near-term spending, meaning weaker growth and higher unemployment over the next 18 months.
And we can assume that it would be repealed and replaced by something else come January 2013, either by a re-elected President Barack Obama, or by a new, Republican president.
So, rather than talking about the US debt ceiling, let us think instead about all of the things that the debt-ceiling impasse has prevented the US government from doing during the past six months – all of the useful policies that might have been debated and enacted, but were not.
The risks imposed by global warming, for example, have not gone away.
The sooner the world starts preparing to deal with those threats, the better.
Another six months should not be lost.
The employment-to-population ratio in the US remains flat – mired at the very low levels to which it fell during the recession.
With households desperately trying to rebuild their balance sheets, and with capital investment remarkably healthy, the only places to boost spending to restore capacity utilization and unemployment to normal levels are exports, government purchases, and construction investment.
But opportunities to pursue the necessary policies have not been grasped.
Here, too, another six months should not be lost.
Likewise, the US could have fulfilled its normal role as the conductor of the international economic orchestra. It has not, even as the European Union continues to respond inadequately to its own slow-moving solvency crises.
The mandarins of northern Europe continue to measure out a drip-feed of support with coffee spoons.
Another six months have been lost.
America faces long-run and short-run problems: decaying infrastructure, weakening educational systems, and a dysfunctional health-care system that produces sub-standard outcomes at twice the cost of any other industrial country.
Solving any of these three problems would go a long way toward resolving the long-run financing imbalance between current tax rates and America’s long-run social-insurance promises that the debt-ceiling debate’s instigators supposedly want to address.
But the US government won’t address them. Six months that could have been spent boosting the long-run growth potential of the American economy through infrastructure investment, educational reform, or an overhaul of health-care financing – greatly easing America's long-run deficit and debt dilemmas in the process – have been lost.
During the run-up to World War II, Winston Churchill, speaking in Parliament, lamented “the years that the locusts hath eaten” – the period during which preparatory action to face the great crisis of his day (the rise of Continental fascism) could have been taken, but was not.
Over the past century – with the notable exception of the Great Depression – the US political system has been remarkably good at foreseeing crises long before they have happened, and at least setting the foundation for dealing with them when they have occurred.
But so far in the third millennium, this skill – or simply run of luck – has deserted the US.
My view is that the problem would fix itself easily if only the Republican Party of Dwight D. Eisenhower could stage a comeback (though without Richard Nixon and Joseph McCarthy).
It is becoming increasingly clear, however, that the problem is one not only for the US, but for the rest of the world as well.
Since December 7, 1941, the world has in large part been able to rely on global governance by a somewhat-competent hyperpower.
That America may be gone for good.
If it is, the world needs to develop other institutions for global management – and quickly.
America’s Misguided Immigration Debate
A debate on immigration is beginning in the United States Senate, which will take up several proposals.
These include a hateful bill – which the House of Representatives has already approved – that provides for the construction of a wall along the US-Mexican border and makes unauthorized entry into the US a felony.
The US Senate will also consider a bill co-authored by Senator Edward Kennedy and Senator John McCain, which proposes stronger border enforcement, a temporary workers program with a path to residency and citizenship, and legalization for people already in the US without papers.
Another idea is to require anyone in the US wanting to regularize their immigration status to go home and wait in line there.
This last component is largely rhetoric; it is hard to imagine any Mexican already in the US voluntarily returning to, say, Zacatecas to wait patiently in line for a new visa.
President George W. Bush has been skirting the question ever since he committed himself to an immigration agreement with Mexico when he visited President Vicente Fox in Guanajuato almost exactly five years ago.
Finally, and perhaps most importantly, there is Senate Judiciary Committee Chairman Arlen Specter’s compromise proposal.
Specter’s proposal also provides for reinforced security at the border, as well as a six-year non-renewable Temporary Workers Program without a path to residency, although it would allow unauthorized immigrants to remain in the US with a new, non-immigrant status.
The latter status may or may not include a path to residency and citizenship; fudging the issue may be a negotiating tactic to avoid debate over whether this is a form of disguised amnesty (which, fortunately, to a certain extent, it is).
What’s missing in the debate is the Latin American context.
There was a time when north-south migratory flows in the western hemisphere were limited to Mexico and the Caribbean.
That changed in the 1980’s, when Central America’s civil wars sent hundreds of thousands of migrants thru Mexico to the US, and then in the 1990’s, when people fleeing violence in Colombia, Venezuela, Peru, and Ecuador also began searching for opportunity.
Today, even Brazil, traditionally a country of immigration, has become one of emigration.
Moreover, these migrants are no longer exclusively of rural origin, nor do they travel only to traditional areas in the US; they are, literally, everywhere.
Their remittances contribute immensely to the economic welfare of their families, communities, and home countries’ economies.
Thus, whatever immigration policy emerges in the US will have an enormous impact south of the Rio Grande well beyond Mexico.
This will occur precisely at a time when Latin America is swerving left, with country after country drifting back to anti-American, populist stances: Venezuela in 1999, Bolivia last year, perhaps Mexico, Peru, and Nicaragua later this year.
If the perception of further US hostility toward Latin America persists, the tilt toward an irresponsible, demagogic left will harden.
The responsible left in Chile, Brazil, and Uruguay are an exception to the emerging rule set by Venezuela’s President Hugo Chávez.
The best way to accentuate the region’s growing anti-American sentiment is to try to close the US-Mexican border (which will be futile).
Instead, the US should establish humane, secure, and legal mechanisms of temporary or permanent entry for people the American economy needs and wants, and it should work with, not against, governments in Latin America.
Five years ago, Mexico’s President Vicente Fox tried to convince Bush that something had to be done before a nativist backlash in the US complicated its relations with Latin America and made goals such as a Free Trade Agreement of the Americas (FTAA) impossible.
But matters have gotten worse: border tensions between the US and Mexico have grown, the proposed wall has rightly provoked indignation, more unauthorized immigrants than ever are entering the US, and the FTAA has collapsed.
Bush must begin to use what political capital he has left to support enlightened immigration reform, along the lines of the Kennedy-McCain bill.
He will never get a guest-worker program without Democratic support, which in turn is unlikely unless the White House supports access to a program for unauthorized immigrants already in the US that includes some type of path to residence and citizenship.
Mexico and the US must be sensitive to domestic political concerns in both countries.
No immigration deal is feasible north of the border without addressing security matters; south of the border, there is no conceivable Mexican cooperation on border security or on a Temporary Workers Program if immigration reform ignores the nearly five million Mexican citizens without papers currently living in the US.
Mexico must act on what Fox has called “shared responsibility.”
The best imaginable deal between the US and Mexico, or the best imaginable US immigration reform, will not eliminate the flow of undocumented migrants from Mexico and South America overnight.
Mexico has to assume responsibility for regulating this traffic, which means more than sealing off its southern border.
The government could, for example, double welfare payments to households whose male heads stay home, threaten to revoke land reform rights after years of absence in rural communities, and establish choke points on highways at the Tehuantepec Isthmus.
Fox has said that he is willing to break with old Mexican taboos, but the Bush administration has never taken him up on it.
That is unfortunate, because Fox will not be around forever.
Immigration has always been an immensely complex and delicate issue inside the US, and now for Latin America as well.
A window of opportunity opened at the beginning of Bush’s first term, and closed shut after the terrorist attacks of September 2001.
It is opening again and should be taken advantage of before it is too late.
Why Iran Won’t Budge
TEL AVIV – No one really believed that the latest round of international negotiations with Iran over its nuclear program would produce a breakthrough.
So it was no surprise that itdid not, despite the concessions that were made at the meeting in Kazakhstan by the P5+1 (China, France, Russia, the United Kingdom, and the United States, plus Germany).
America’s belief that a harsh sanctions regime could coax Iran into a deal has proved – at least so far – to be unrealistic.
Despite being isolated and ostracized, Iran has managed to gain some strategic breathing room with the help of countries like China, Russia, India, Syria, and Venezuela, allowing it to resist Western pressure.
More important, even though the severe sanctions regime led by the United States is bound to be imperfect – it only hardens further Iran’s resistance to “America’s designs.”
To be sure, Iran’s alliances are vulnerable to erosion and, in the case of two staunch allies, Syria and Venezuela, to outright collapse.
The end of Chavismo would threaten Iran’s vast interests in Venezuela and its considerable presence in the Andes, while the fall of the Assad dynasty would be a devastating blow to Iran’s regional strategy.
Even so, Russia and China continue to take a much more lenient approach to Iran than Europe and the US have since the International Atomic Energy Agency’s report in November 2011 described in detail Iran’s activities in pursuing the capability to produce nuclear weapons.
While the Western powers have embraced ever-harsher sanctions, Russia and China view Iran as a tool in their global competition with the US.
China’s Iranian interests boil down to economics.
Bilateral trade stands at about $40 billion a year, and China is not only Iran’s largest customer for crude oil, but also a colossal investor – somewhere between $40 billion and $100 billion – in Iran’s energy and transport sectors.
True, China cannot entirely overlook US pressure and the staunch opposition of its top oil supplier, Saudi Arabia, to Iran’s nuclear program.
But, while China has supported the mandatory sanctions set by the United Nations Security Council, it has rejected the West’s unilateral measures.
With bilateral trade worth only about $5 billion annually, Russia’s economic interests in Iran are fairly modest.
But it fears Iran’s ability to cause trouble, particularly by stirring up unrest among Russia’s Muslim citizens.
Moreover, America has refused to pay the Kremlin’s high price – curtailment of congressional human-rights legislation, repeal of Cold-War-era restrictions on Russian-US trade, and abandonment of plans for ballistic missile defense in Europe – for Russian support on Iran (or, for that matter, on any other trouble spot, such as Syria).
The problem with the US drive to have key stakeholders join its anti-Iran crusade is that some of them live in neighborhoods where Iran is an important factor.
India is a case in point.
India is certainly alarmed at the possibility of Iran developing nuclear weapons, not to mention its concern at the possible effects of Iran’s Islamist fundamentalism on Kashmiri Muslims.
But its $14 billion in annual bilateral trade, and dependence on Iranian oil – many of India’s refineries have been built to run solely on Iranian crude – are key strategic considerations.
Moreover, India needs Iran as an alternative trade and energy conduit to Central Asia, bypassing rival Pakistan, and also as a hedge against an uncertain future in Afghanistan after America’s withdrawal in 2014.
As a result, India’s policy mirrors China’s: it has aligned itself with mandatory international sanctions, but has abjured voluntary Western financial restrictions.
The best one can expect is that India continues to act at the margin –&#160;for example, by reducing dependence on Iranian oil while increasing imports from Saudi Arabia, already its largest supplier of crude.
The equivocal nature of Iran’s alliances, however, can be a mixed blessing.
Yes, a harsh sanctions regime might still gain additional supporters, but an Iran with its back against the wall would probably be even more obstinate in its nuclear drive.
After all, Iraq was an easy target in the first Gulf War precisely because it had abandoned its nuclear program, and possessed no weapons of mass destruction.
Similarly, Libya’s Muammar el-Qaddafi exposed himself to a NATO onslaught by relinquishing his WMDs.
By contrast, North Korea shows that defiance, rather than accommodation, is a strategy that works.
That is why Syria, with North Korean assistance, tried to develop a nuclear program (presumably destroyed by Israel’s officially unacknowledged “Operation Orchard” in 2007).Iran will not consider abandoning its nuclear insurance policy unless a broad agenda is agreed upon that addresses Iran’s concerns as a regional power and secures the immunity of its Islamist regime from American actions.
Albert Einstein’s definition of insanity as “doing the same thing over and over again and expecting different results” could be applied to America’s Iran policy.
The diplomacy of sanctions, ostracism, and brinkmanship has failed resoundingly.
As Iran’s uranium-enrichment and other weapons-development activities continue unabated, the US needs to make a break with the old rules of engagement.
America’s Misplaced Deficit Complacency
CAMBRIDGE – The United States still faces a dangerous fiscal deficit, but one might not know it from the complacency that dominates budget discussions in Washington.
Regarded as an urgent problem until recently, the federal deficit is now being placed on the back burner of American politics.
The shift in thinking was triggered by the revised deficit forecasts recently published by the Congressional Budget Office, the independent technical agency responsible for advising Congress on budget issues.
According to the CBO’s report, the US fiscal deficit will decline from 7% of GDP in 2012 to 4% in 2013.
This reduction reflects the cuts in government spending on defense and non-defense programs mandated by the budget “sequester” that took effect in March, as well as the rise in revenue caused by higher rates for income and payroll taxes since the end of 2012.
More striking is the CBO’s projection that the deficit will continue to decline rapidly, reaching just 2.1% of GDP in 2015, before rising gradually to just 3.5% of GDP in 2023, the end of the CBO’s official forecast period.
That path of deficits implies that the government debt/GDP ratio will remain at about the current level of 75% for the next ten years.
Unfortunately, these headline-grabbing numbers are not likely to be borne out in reality; indeed, even the CBO does not believe that they represent what will occur.
Instead, these official forecasts represent a “baseline” scenario that the CBO is required to present.
The CBO’s “baseline budget” assumes that all of the deficit-reducing features in current law will remain unchanged.
These include, for example, an old legislative requirement that payments to physicians in the government’s Medicare program be reduced sharply in future years, a requirement that Congress has voted each year to “postpone.”
In order to provide better guidance, the CBO presents an “alternative fiscal scenario,” in which such very unlikely features are removed from the forecast.
The alternative forecast implies that the annual budget deficit at the end of ten years will be back up to 4.7% of GDP, with the debt/GDP ratio at 83% and rising.
And those estimates are based on the optimistic assumption that the economy will have returned gradually to full employment with low inflation and moderate interest rates.
Officials and others who favor stimulating growth through increased government spending ignore the CBO’s more realistic alternative scenario.
They buttress their argument that the deficit is not an immediate problem by pointing to very low interest rates on long-term government debt, with a 2% yield on the ten-year Treasury bond and a negative real interest rate on Treasury inflation-protected bonds (TIPS).
But such low rates do not reflect ordinary market sentiment; rather, they stem from the fact that the Federal Reserve is now buying more long-term securities than the government is issuing to finance the budget deficit.
Looking further ahead, the CBO warns that the combination of a rapidly aging population and the increase in medical costs will cause the deficit to rise rapidly, driven by the higher costs of pension and health-care benefits for middle-income retirees.
According to the CBO, without legislative changes, the fiscal deficit in 2037 will be 17% of GDP, while the national debt will increase to more than 195% of GDP.
A large and rising national debt is a serious danger to an economy’s health.
Higher debt-service costs require higher tax rates, which in turn weaken incentives and reduce economic growth.
By the end of the decade, the US will have to pay an amount equivalent to more than one-third of the revenue from personal-income taxes just to pay the interest on the national debt.
Foreign investors now hold more than half of that debt.
Paying interest to them requires sending more goods and services to the rest of the world than the US receives from the rest of the world.
That requires a weaker dollar to make US goods more attractive to foreign buyers and to make foreign goods more expensive to American consumers.
The weaker dollar reduces the US standard of living.
A large national debt also limits the government’s ability to respond to emergencies, including both military threats and economic downturns.
And it makes the US vulnerable to changes in financial-market sentiment, as the European experience has shown.
Reducing future deficits and reversing the rise in the national debt require raising tax revenue and slowing the growth of government pension and health-care programs.
Tax revenue can be raised without increasing marginal tax rates by limiting the tax subsidies that are built into the current tax code.
Those subsidies are a hidden form of government spending on everything from home mortgages and health insurance to the purchase of hybrid cars and residential solar panels.
Slowing the growth of the pension and health-care programs for middle-class retirees cannot be done abruptly.
It must begin by giving notice to those who are now a decade away from retirement – which is why it is important to launch such reforms now.
Unfortunately, the new complacency about future deficits makes it difficult, if not impossible, to enact the legislation needed to begin the process of trimming America’s long-term fiscal deficit.
It is important for policymakers and the public alike to understand the real fiscal outlook and the damage that high deficits will cause if prompt action is not taken.
Merely moving the problem to the back burner will not prevent it from boiling over.
Meeting America’s Growth Challenge
BERKELEY – The United States continues to recover from its deepest economic slump since the Great Depression, but the pace of recovery remains frustratingly slow.
There are several reasons to anticipate modest improvement in 2013, although, as usual, there are downside risks.
Prolonged recession or a financial crisis in Europe and slower growth in emerging markets are the main external sources of potential danger.
At home, political infighting underlies the two greatest risks: failure to reach a deal to raise the debt ceiling and an additional round of fiscal contraction that stymies economic growth.
Since 2010, tepid average annual GDP growth of 2.1% has meant weak job creation.
In both this recovery and the previous two, the rebound in employment growth has been weaker and later than the rebound in GDP growth.
But the loss of jobs in the most recent recession was more than twice as large as in previous recessions, so a slow recovery has meant a much higher unemployment rate for a much longer period.
Weak aggregate demand is the primary culprit for subdued GDP and employment growth.
The 2008 recession was triggered by a financial crisis that erupted after the collapse of a credit-fueled asset bubble decimated the housing market.
Private-sector demand contracts sharply and recovers only slowly after such crises.
The private-sector financial balance swung from a deficit of 3.7% of GDP in 2006, at the height of the boom, to a surplus of about 6.8% of GDP in 2010 and about 5% today.
This represents the sharpest contraction and weakest recovery in private-sector demand since the end of World War II.
Growth in two components of private demand, residential investment and consumption, which account for more than 75% of total spending in the US economy, has been especially slow.
Both sources of demand are likely to strengthen in 2013.
Residential investment is still at an historic low as a share of GDP as a result of overbuilding during the 2003-2008 housing boom and the tsunami of foreclosures that followed.
But the headwinds in the housing market are dissipating.
Home sales, prices, and construction all rose last year, while foreclosures declined.
Residential investment should be a source of output and job growth this year.
Large losses in household wealth, deleveraging from unsustainable debt, weak wage growth, and a decline in labor’s share of national income to a historic low have combined to constrain consumption growth.
Real median household income is still nearly 7% below its 2007 peak, real median household net worth dropped by 35% between 2005 and 2010 (and remains significantly below its pre-recession peak), and about 90% of the income gains during the recovery have gone to the top 1%.
To be sure, the balance-sheet headwinds holding back consumption have eased.
Households have slashed their debt – often through painful foreclosures and bankruptcies – and their debt relative to income has sunk to its 2005 level, significantly below its 2008 peak. &#160;Helped by low interest rates, debt service relative to household income has fallen back to levels not seen since the early 1980’s.
But consumption will be hit by the expiration of the payroll tax cut, which will reduce household income by about $125 billion this year.
Another factor holding back recovery has been weak growth in spending on goods and services by both state and local governments, and more recently by the federal government.
Indeed, since the recession’s onset, state and local governments have cut nearly 600,000 jobs and reduced spending for infrastructure projects by 20%.
The fiscal trends for 2013 are mixed, but negative overall.
While state and local government cutbacks in spending and employment are ending as the recovery boosts their tax revenues, the fiscal drag at the federal level is strengthening.
The American Taxpayer Relief Act – the tax deal reached in early January to avoid the “fiscal cliff” – shaves about $750 billion from the deficit over the next ten years and could take a percentage point off the 2013 growth rate.
In addition, although less widely appreciated, significant reductions in federal spending are already under way, with more likely to come.
Spending cuts and revenue increases that have been legislated since 2011 will reduce the projected deficit by $2.4 trillion over the next decade, with three-quarters coming from spending cuts, almost exclusively in non-defense discretionary programs.
Based on current economic assumptions, the US needs about $4 trillion in savings to stabilize the debt/GDP ratio over the next decade.
It is already three-fifths of the way there.
The so-called sequester (the across-the-board spending cuts scheduled to begin in March), would slash another $100 billion this year and $1.2 trillion over the next decade.
Although it could stabilize the debt/GDP ratio, the sequester would be a mistake: it fails to distinguish among spending priorities, would undermine essential programs, and would mean another significant dent in growth this year.
Moreover, despite the warnings of deficit alarmists, the US does not face an imminent debt crisis.
Currently, the federal debt held by the public is just over 70% of GDP, a level not seen since the early 1950’s.
However, government debt soars by an average of 86% after severe financial crises, so the increase in the federal debt by 70% between 2008 and 2012 is not surprising.
